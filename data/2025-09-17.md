<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.SE](#cs.SE) [Total: 17]
- [cs.LO](#cs.LO) [Total: 8]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Converting IEC 61131-3 LD into SFC Using Large Language Model: Dataset and Testing](https://arxiv.org/abs/2509.12593)
*Yimin Zhang,Mario de Sousa*

Main category: cs.PL

TL;DR: 本研究构建了SFC与LD程序对数据集，使用大语言模型进行LD到SFC自动转换，实验表明LLM可行且准确率较高，展示了该方法的未来潜力。


<details>
  <summary>Details</summary>
Motivation: 当前PLC编程领域的LD到SFC转换面临缺乏领域知识和算法状态爆炸问题，且缺乏合适的数据集，限制了数据驱动方法的发展。

Method: 构建了一批符合IEC 61131-3标准的SFC与LD程序文本对数据集，并基于这些数据集使用LLM进行自动转换实验。

Result: 微调后的LLM模型在部分数据集上准确率最高达到91%，最低79%。

Conclusion: 初步实验证明，经过微调的LLM模型能有效支持LD到SFC的自动转换，准确率高达91%。

Abstract: In the domain of Programmable Logic Controller (PLC) programming, converting
a Ladder Diagram (LD) into a Sequential Function Chart (SFC) is an inherently
challenging problem, primarily due to the lack of domain-specific knowledge and
the issue of state explosion in existing algorithms. However, the rapid
development of Artificial Intelligence (AI) - especially Large Language Model
(LLM) - offers a promising new approach.
  Despite this potential, data-driven approaches in this field have been
hindered by a lack of suitable datasets. To address this gap, we constructed
several datasets consisting of paired textual representations of SFC and LD
programs that conform to the IEC 61131-3 standard.
  Based on these datasets, we explored the feasibility of automating the LD-SFC
conversion using LLM. Our preliminary experiments show that a fine-tuned LLM
model achieves up to 91% accuracy on certain dataset, with the lowest observed
accuracy being 79%, suggesting that with proper training and representation,
LLMs can effectively support LD-SFC conversion. These early results highlight
the viability and future potential of this approach.

</details>


### [2] [Efficient Compilation of Algorithms into Compact Linear Programs](https://arxiv.org/abs/2509.13006)
*Shermin Khosravi,David Bremner*

Main category: cs.PL

TL;DR: 该论文提出一种将算法自动编译为超紧凑LP模型的新方法，极大减小LP规模并提升求解效率，实验结果证实方法有效。


<details>
  <summary>Details</summary>
Motivation: 现有LP编译器虽可自动生成多项式规模LP，但模型依然过大，难以实际求解。论文致力于开发更紧凑的自动LP编码方法，以促进大规模组合优化问题的实际应用。

Method: 论文引入了分层线性流水线技术，将嵌套的程序结构分解为同步区域，并据此对LP约束和变量进行局部化，减少冗余与规模，同时保证编译所得模型的普适性。

Result: 在典型的指数扩展复杂度问题（如makespan和加权最小生成树）上，用所提方法生成的LP规模缩减高达25倍，并带来了商业及非商业求解器性能的大幅提升。

Conclusion: 论文提出了一种能够极大缩减由算法自动生成的线性规划（LP）模型规模的新方法，并在保持通用性和有效性的前提下，使约束和变量局部化。该方法在多个基准问题上显著减少了LP规模，提高了求解器性能。

Abstract: Linear Programming (LP) is widely applied in industry and is a key component
of various other mathematical problem-solving techniques. Recent work
introduced an LP compiler translating polynomial-time, polynomial-space
algorithms into polynomial-size LPs using intuitive high-level programming
languages, offering a promising alternative to manually specifying each set of
constraints through Algebraic Modeling Languages (AMLs). However, the resulting
LPs, while polynomial in size, are often extremely large, posing challenges for
existing LP solvers. In this paper, we propose a novel approach for generating
substantially smaller LPs from algorithms. Our goal is to establish
minimum-size compact LP formulations for problems in P having natural
formulations with exponential extension complexities. Our broader vision is to
enable the systematic generation of Compact Integer Programming (CIP)
formulations for problems with exponential-size IPs having polynomial-time
separation oracles. To this end, we introduce a hierarchical linear pipelining
technique that decomposes nested program structures into synchronized regions
with well-defined execution transitions -- functions of compile-time
parameters. This decomposition allows us to localize LP constraints and
variables within each region, significantly reducing LP size without the loss
of generality, ensuring the resulting LP remains valid for all inputs of size
$n$. We demonstrate the effectiveness of our method on two benchmark problems
-- the makespan problem, which has exponential extension complexity, and the
weighted minimum spanning tree problem -- both of which have exponential-size
natural LPs. Our results show up to a $25$-fold reduction in LP size and
substantial improvements in solver performance across both commercial and
non-commercial LP solvers.

</details>


### [3] [Pleasant Imperative Program Proofs with GallinaC](https://arxiv.org/abs/2509.13019)
*Frédéric Fort,David Nowak,Vlad Rusu*

Main category: cs.PL

TL;DR: 本文提出GallinaC，把图灵完备命令式语言嵌入在Gallina证明助手中，实现了易于证明且语义良好的命令式编程。原型已通过链表反转程序正确性验证，展现出可行性，并正在对GallinaC与CompCert入口语言Cminor进行对接研究。


<details>
  <summary>Details</summary>
Motivation: 尽管函数式编程越来越流行，但命令式编程仍是底层软件（如操作系统内核）的重要范式。由于这些程序常作为信任计算基（TCB）关键组件，对其进行数学上的正确性证明变得非常重要。然而，现有命令式语言的语义过于宽泛，导致证明过程繁琐且易出错。因此，迫切需要一种能兼顾语义良好与命令式编程习惯、且易于证明正确性的语言。

Method: 作者提出并在Rocq证明助手中的Gallina语言内实现了一种名为GallinaC的命令式语言的浅嵌入。GallinaC具备完全图灵完备的命令式特性（如通用、无界的while循环），并且依托于Gallina的函数式核心，使得对GallinaC程序的证明可以采用与纯函数式程序相同的工具和策略。所有工具开发都在证明助手内完成，实现机器校验的程序证明。

Result: GallinaC的原型已完成，并用来对链表反转程序进行了正确性证明，表明了其可行性。当前工作侧重在GallinaC中间表示（IR）与CompCert后端入口语言Cminor之间的前向模拟。

Conclusion: GallinaC实现了命令式语言在证明助手内的嵌入，兼具图灵完备性和易于证明的优势，为底层安全关键软件的正确性实现了有力支撑。原型结果显示其方案可行，并为与工业级证明工具如CompCert整合奠定了基础。

Abstract: Even with the increase of popularity of functional programming, imperative
programming remains a key programming paradigm, especially for programs
operating at lower levels of abstraction. When such software offers key
components of a Trusted Computing Base (TCB), e.g. an operating system kernel,
it becomes desirable to provide mathematical correctness proofs.
  However, current real-world imperative programming languages possess
"expressive", i.e. overly permissive, semantics. Thus, producing correctness
proofs of such programs becomes tedious and error-prone, requiring to take care
of numerous "administrative" details. Ideally, a proof-oriented imperative
language should feature well-behaved semantics while allowing imperative
idioms.
  To obtain a high-degree of confidence in the correctness of such a language,
its tools should be developed inside a proof-assistant such that program proofs
are machine checked.
  We present GallinaC, a shallow embedding of a Turing-complete imperative
language directly inside the functional programming language of the Rocq proof
assistant, Gallina. In particular, it features a truly generic and unbounded
while loop. Having a functional core means proofs about GallinaC programs may
use the same tactics as proofs about pure functional ones.
  Work on GallinaC is still under progress, but we present first promising
results. A prototype implementation has shown the viability of GallinaC with
the correctness proof of a list reversal procedure for linked-lists of unknown
size. We currently focus on the forward simulation between the GallinaC
intermediate representation (IR) and Cminor, the entry language of the CompCert
back-end.

</details>


### [4] [Navigating the Python Type Jungle](https://arxiv.org/abs/2509.13022)
*Andrei Nacu,Dorel Lucanu*

Main category: cs.PL

TL;DR: 本文通过借助类型理论，建立了Python类型系统的正式理论基础，有助于完善规范并推动类型推断工具的发展。


<details>
  <summary>Details</summary>
Motivation: Python类型系统功能强大，但其规范分散且理论基础不统一，需要一个正式化描述以支持今后类型推断工具发展。

Method: 结合类型理论的相关概念，构建并给出了Python类型系统的形式化表达。

Result: 给出了Python类型系统的优雅形式化描述，并奠定了未来开发类型推断工具的关键基础。

Conclusion: 本文提出了一个正式的理论基础，用于统一和描述Python目前分散的类型系统规范。

Abstract: Python's typing system has evolved pragmatically into a powerful but
theoretically fragmented system, with scattered specifications. This paper
proposes a formalization to address this fragmentation. The central
contribution is a formal foundation that uses concepts from type theory to
demonstrate that Python's type system can be elegantly described. This work
aims to serve as a crucial first step toward the future development of type
inference tools.

</details>


### [5] [Try-Mopsa: Relational Static Analysis in Your Pocket](https://arxiv.org/abs/2509.13128)
*Raphaël Monat*

Main category: cs.PL

TL;DR: 本文提出了Try-Mopsa—一个能在网页端运行的精简版静态分析器，不仅易于安装和使用，且保留了Mopsa的大部分核心分析能力，特别适合教学与新手体验。


<details>
  <summary>Details</summary>
Motivation: 静态分析器依赖复杂，安装困难，妨碍了用户和学生的学习与使用。

Method: 将完整的Mopsa静态分析平台编译成JavaScript，实现可直接在浏览器（包括桌面和移动设备）端运行的Try-Mopsa；并对界面和核心组件做出适配和修改。

Result: Try-Mopsa保留了Mopsa的核心功能，支持关系型数值域，拥有响应式界面，可跨平台运行，并适用于教学和新用户入门。

Conclusion: Try-Mopsa极大简化了静态分析器的使用和教学门槛，为用户和教育场景带来了便利。

Abstract: Static analyzers are complex pieces of software with large dependencies. They
can be difficult to install, which hinders adoption and creates barriers for
students learning static analysis. This work introduces Try-Mopsa: a
scaled-down version of the Mopsa static analysis platform, compiled into
JavaScript to run purely as a client-side application in web browsers.
Try-Mopsa provides a responsive interface that works on both desktop and mobile
devices. Try-Mopsa features all the core components of Mopsa. In particular, it
supports relational numerical domains. We present the interface, changes and
adaptations required to have a pure JavaScript version of Mopsa. We envision
Try-Mopsa as a convenient platform for onboarding or teaching purposes.

</details>


### [6] [Rebound: Efficient, Expressive, and Well-Scoped Binding](https://arxiv.org/abs/2509.13261)
*Noé De Santo,Stephanie Weirich*

Main category: cs.PL

TL;DR: Rebound库通过一等环境和静态作用域管理，简化了Haskell中的绑定结构操作，提高了安全性和性能，且在多种语言特性实现及性能测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在Haskell中，处理绑定结构（如变量替换、α等价性等）通常复杂且容易出错，尤其是涉及de Bruijn索引时。本文旨在简化这些操作并提升安全性。

Method: 提出Rebound库，利用一等环境来映射变量和表达式，并通过静态方式跟踪作用域，同时允许显式访问环境。通过这一设计自动实现替换和α等价等绑定相关操作。

Result: Rebound库不仅能够实现多种复杂语言特性和抽象语法操作，还在性能基准测试中优于竞争对手库，产生更快的代码。

Conclusion: Rebound为Haskell绑定结构的处理带来了更高的表达性、安全性和性能，是处理抽象语法和语言特性构建的有效工具。

Abstract: We introduce the Rebound library that supports well-scoped term
representations in Haskell and automates the definition of substitution,
alpha-equivalence, and other operations that work with binding structures. The
key idea of our design is the use of first-class environments that map
variables to expressions in some new scope. By statically tracking scopes,
users of this library gain confidence that they have correctly maintained the
subtle invariants that stem from using de Bruijn indices. Behind the scenes,
Rebound uses environments to optimize the application of substitutions, while
providing explicit access to these data structures when desired. We demonstrate
that this library is expressive by using it to implement a wide range of
language features with sophisticated uses of binding and several different
operations that use this abstract syntax. Our examples include pi-forall, a
tutorial implementation of a type checker for a dependently-typed programming
language. Finally, we benchmark Rebound to understand its performance
characteristics and find that it produces faster code than competing libraries.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML](https://arxiv.org/abs/2509.12395)
*Yash Mundhra,Max Valk,Maliheh Izadi*

Main category: cs.SE

TL;DR: 本文在ASML闭源工业代码环境中，系统评估了大语言模型代码生成能力，并提出了新指标build@k。发现提示工程和模型大小对效果影响显著，但通用与专用LLM性能差距不大。提出的评测体系可为今后工业LLM应用提供参考。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在开源领域的代码生成表现优异，但其在专有工业环境中的适用性和实际表现尚未被充分探索，尤其是在存在领域特定约束和代码相互依赖的复杂环境下。作者希望填补这一研究空白。

Method: 作者与ASML的leveling部门合作，针对ASML专有代码库开发了一个评估框架，并新增了一个基准测试。此外，提出了新的评估指标build@k，用于判定LLM生成代码在实际工业仓库中的编译与集成表现。实验中考察了不同提示工程技术，比较了通用LLM与代码专用LLM的表现，并考察了模型规模的影响。

Result: 结果表明：提示工程和模型规模对代码生成质量有显著影响，few-shot和chain-of-thought 提示获取了最高的build成功率。通用LLM与代码专用LLM之间的性能差异并不明显，且在不同模型家族间变化较大。

Conclusion: 在高度专业化的封闭工业环境下，大语言模型经过适当的提示和规模调整后，能够生成功能性强且可维护的代码。新提出的build@k指标和评测框架为工业场景下LLM应用提供了有效参考。今后在工业实践中采纳LLM需根据场景灵活选择模型及提示策略。

Abstract: Large language models have shown impressive performance in various domains,
including code generation across diverse open-source domains. However, their
applicability in proprietary industrial settings, where domain-specific
constraints and code interdependencies are prevalent, remains largely
unexplored. We present a case study conducted in collaboration with the
leveling department at ASML to investigate the performance of LLMs in
generating functional, maintainable code within a closed, highly specialized
software environment.
  We developed an evaluation framework tailored to ASML's proprietary codebase
and introduced a new benchmark. Additionally, we proposed a new evaluation
metric, build@k, to assess whether LLM-generated code successfully compiles and
integrates within real industrial repositories. We investigate various
prompting techniques, compare the performance of generic and code-specific
LLMs, and examine the impact of model size on code generation capabilities,
using both match-based and execution-based metrics. The findings reveal that
prompting techniques and model size have a significant impact on output
quality, with few-shot and chain-of-thought prompting yielding the highest
build success rates. The difference in performance between the code-specific
LLMs and generic LLMs was less pronounced and varied substantially across
different model families.

</details>


### [8] [Understanding Prompt Management in GitHub Repositories: A Call for Best Practices](https://arxiv.org/abs/2509.12421)
*Hao Li,Hicham Masri,Filipe R. Cogo,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 对大量开源自然语言提示进行实证分析，揭示了管理中的主要问题，并为开发者提出改善建议，提高开源promptware的质量。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型（如大语言模型）的广泛应用催生了基于自然语言提示的软件（promptware），有效管理这些提示变得越来越重要，但也面临诸多挑战。

Method: 对92个GitHub仓库中的24,800个开源提示进行实证分析。

Result: 发现了许多关键问题，包括提示格式不一致、内部和外部提示重复显著，常见的可读性和拼写问题。

Conclusion: 开源提示（prompt）的管理存在诸多挑战，比如格式不一致、提示重复、可读性和拼写错误；针对这些问题，本文给出针对性建议以提升开源提示软件的易用性和可维护性。

Abstract: The rapid adoption of foundation models (e.g., large language models) has
given rise to promptware, i.e., software built using natural language prompts.
Effective management of prompts, such as organization and quality assurance, is
essential yet challenging. In this study, we perform an empirical analysis of
24,800 open-source prompts from 92 GitHub repositories to investigate prompt
management practices and quality attributes. Our findings reveal critical
challenges such as considerable inconsistencies in prompt formatting,
substantial internal and external prompt duplication, and frequent readability
and spelling issues. Based on these findings, we provide actionable
recommendations for developers to enhance the usability and maintainability of
open-source prompts within the rapidly evolving promptware ecosystem.

</details>


### [9] [From Legacy Fortran to Portable Kokkos:An Autonomous Agentic AI Workflow](https://arxiv.org/abs/2509.12443)
*Sparsh Gupta,Kamalavasan Kamalakkannan,Maxim Moraru,Galen Shipman,Patrick Diehl*

Main category: cs.SE

TL;DR: 本论文提出利用AI代理协作，对旧Fortran代码自动转换为高性能且跨平台可移植的Kokkos C++代码，实验证明该方法高效且生成代码优于原始版本，展现了LLM在科学计算领域自动化现代化的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 随着高性能计算（HPC）领域从传统的CPU架构转向异构的GPU加速架构，大量遗留的Fortran代码面临移植和现代化的需求。然而，许多加速器缺乏Fortran的原生支持，且手动迁移至如Kokkos这类性能可移植框架既耗时又需高专门技术。与此同时，大语言模型（LLM）在代码生成领域展现潜力，但自动化、性能可移植的代码翻译仍未被充分探索。

Method: 论文提出了一种基于AI代理（agentic AI）的工作流，由多个专门的LLM“代理”协作完成从Fortran到Kokkos C++的自动化翻译、验证、编译、运行、测试、调试及优化过程。

Result: 该流程成功实现了一系列基准Fortran内核的现代化转换，生成了在不同硬件平台上性能可移植的Kokkos代码。付费的OpenAI模型如GPT-5和o4-mini-high仅需几美元便能执行该流程并生成优于原始Fortran代码的优化结果，而开源模型如Llama4-Maverick则常常无法生成可运行代码。

Conclusion: 本文展示了利用agentic AI系统实现Fortran到Kokkos自动化转换的可行性，为遗留科学应用程序的现代化和性能可移植性提供了一条新路径，同时突显了LLM驱动的agentic系统在结构化、领域专用任务中的潜力。

Abstract: Scientific applications continue to rely on legacy Fortran codebases
originally developed for homogeneous, CPU-based systems. As High-Performance
Computing (HPC) shifts toward heterogeneous GPU-accelerated architectures, many
accelerators lack native Fortran bindings, creating an urgent need to modernize
legacy codes for portability. Frameworks like Kokkos provide performance
portability and a single-source C++ abstraction, but manual Fortran-to-Kokkos
porting demands significant expertise and time. Large language models (LLMs)
have shown promise in source-to-source code generation, yet their use in fully
autonomous workflows for translating and optimizing parallel code remains
largely unexplored, especially for performance portability across diverse
hardware.
  This paper presents an agentic AI workflow where specialized LLM "agents"
collaborate to translate, validate, compile, run, test, debug, and optimize
Fortran kernels into portable Kokkos C++ programs. Results show the pipeline
modernizes a range of benchmark kernels, producing performance-portable Kokkos
codes across hardware partitions. Paid OpenAI models such as GPT-5 and
o4-mini-high executed the workflow for only a few U.S. dollars, generating
optimized codes that surpassed Fortran baselines, whereas open-source models
like Llama4-Maverick often failed to yield functional codes.
  This work demonstrates the feasibility of agentic AI for Fortran-to-Kokkos
transformation and offers a pathway for autonomously modernizing legacy
scientific applications to run portably and efficiently on diverse
supercomputers. It further highlights the potential of LLM-driven agentic
systems to perform structured, domain-specific reasoning tasks in scientific
and systems-oriented applications.

</details>


### [10] [Perspectives, Needs and Challenges for Sustainable Software Engineering Teams: A FinServ Case Study](https://arxiv.org/abs/2509.12466)
*Satwik Ghanta,Peggy Gregory,Gul Calikli*

Main category: cs.SE

TL;DR: 本文通过对金融服务公司进行定性案例研究，揭示了管理层与开发者对SSE理解的分歧，并提出需根据实际场景、以协同设计方式推动可持续性实践。


<details>
  <summary>Details</summary>
Motivation: 可持续软件工程（SSE）在提升企业声誉、利润和效率等方面日益成为行业需求，但其定义多样，导致企业难以形成统一共识。尤其在金融服务等特定组织背景下，关于SSE的实际需求和理解尚有空白。

Method: 本文以一家金融服务公司FinServCo为案例对象，采用探索性定性研究方法，通过访谈和焦点小组讨论（对象包括六名高管和十六名不同层级的软件工程师），深入调查了IT部门成员对SSE的认知、实践方式、责任归属及面临的挑战。

Result: 研究发现不同组织层级对可持续性的理解存在明显分歧。高管更重视技术与经济层面的可持续性，主要关注云迁移和数据可用性以保障业务连续性；开发人员则关注以人为本的问题，如工作负载管理和压力缓解。部分开发者对组织的可持续性举措持怀疑态度，认为只是公关策略。多数受访者倾向于设立专门的可持续性团队，借鉴内部安全治理模式。

Conclusion: 组织目标与一线开发者需求之间的脱节表明，引入敏感于具体情境、共设计的干预举措至关重要。针对不同岗位和实际需求制定SSE策略，有助于提升金融服务行业的可持续性实践效果。

Abstract: Sustainable Software Engineering (SSE) is slowly becoming an industry need
for reasons including reputation enhancement, improved profits and more
efficient practices. However, SSE has many definitions, and this is a challenge
for organisations trying to build a common and broadly agreed understanding of
the term. Although much research effort has gone into identifying general SSE
practices, there is a gap in understanding the sustainability needs of specific
organisational contexts, such as financial services, which are highly
data-driven, operate under strict regulatory requirements, and handle millions
of transactions day to day. To address this gap, our research focuses on a
financial services company (FinServCo) that invited us to investigate
perceptions of sustainability in their IT function: how it could be put into
practice, who is responsible for it, and what the challenges are. We conducted
an exploratory qualitative case study using interviews and a focus group with
six higher management employees and 16 software engineers comprising various
experience levels from junior developers to team leaders. Our study found a
clear divergence in how sustainability is perceived between organisational
levels. Higher management emphasised technical and economic sustainability,
focusing on cloud migration and business continuity through data availability.
In contrast, developers highlighted human-centric concerns such as workload
management and stress reduction. Scepticism toward organisational initiatives
was also evident, with some developers viewing them as a PR strategy. Many
participants expressed a preference for a dedicated sustainability team,
drawing analogies to internal structures for security governance. The
disconnect between organisational goals and individual developer needs
highlights the importance of context-sensitive, co-designed interventions.

</details>


### [11] [Good Vibrations? A Qualitative Study of Co-Creation, Communication, Flow, and Trust in Vibe Coding](https://arxiv.org/abs/2509.12491)
*Veronica Pimenova,Sarah Fakhoury,Christian Bird,Margaret-Anne Storey,Madeline Endres*

Main category: cs.SE

TL;DR: 本文首次定性系统分析了AI辅助vibe coding编程范式，提出以会话互动、共创与开发流畅为核心理论，总结痛点和最佳实践，并为AI开发工具及后续研究提供启示。


<details>
  <summary>Details</summary>
Motivation: Vibe coding作为一种新兴的AI辅助自然语言编程范式，快速流行但存在争议。以往研究大多关注代码分析或理论探讨，缺乏开发者实际感知和体验的系统性理解。该文旨在填补该空白。

Method: 本研究系统性地进行定性分析，收集并分析19万字半结构化访谈、Reddit讨论和LinkedIn帖子，通过质性方法探究开发者对vibe coding的看法与实践。

Result: 研究提出了以与AI会话互动、共同创作、开发者流畅与乐趣为核心的vibe coding理论。发现AI信任影响从委托到共创的互动模式，并通过支持开发者的流程体验带来积极效果。同时揭示在规范、可靠性、调试、延迟、代码审查和协作等方面存在痛点及风险，并总结出一系列社区形成的最佳实践以缓解这些问题。

Conclusion: Vibe coding作为AI新时代的编程方式，其实施面临挑战，但也带来了提升开发体验的新机会。未来AI开发工具设计和相关研究应重点关注AI与开发者的互动、信任构建及支持开发流程的机制。

Abstract: Vibe coding, a term coined by Andrej Karpathy in February 2025, has quickly
become a compelling and controversial natural language programming paradigm in
AI-assisted software development. Centered on iterative co-design with an AI
assistant, vibe coding emphasizes flow and experimentation over strict upfront
specification. While initial studies have begun to explore this paradigm, most
focus on analyzing code artifacts or proposing theories with limited empirical
backing. There remains a need for a grounded understanding of vibe coding as it
is perceived and experienced by developers. We present the first systematic
qualitative investigation of vibe coding perceptions and practice. Drawing on
over 190,000 words from semi-structured interviews, Reddit threads, and
LinkedIn posts, we characterize what vibe coding is, why and how developers use
it, where it breaks down, and which emerging practices aim to support it. We
propose a qualitatively grounded theory of vibe coding centered on
conversational interaction with AI, co-creation, and developer flow and joy. We
find that AI trust regulates movement along a continuum from delegation to
co-creation and supports the developer experience by sustaining flow. We
surface recurring pain points and risks in areas including specification,
reliability, debugging, latency, code review burden, and collaboration. We also
present best practices that have been discovered and shared to mitigate these
challenges. We conclude with implications for the future of AI dev tools and
directions for researchers investigating vibe coding.

</details>


### [12] [Ensembling Large Language Models for Code Vulnerability Detection: An Empirical Evaluation](https://arxiv.org/abs/2509.12629)
*Zhihong Sun,Jia Li,Yao Wan,Chuanyi Li,Hongyu Zhang,Zhi jin,Ge Li,Hong Liu,Chen Lyu,Songlin Hu*

Main category: cs.SE

TL;DR: 本文提出利用集成学习（包括Bagging、Boosting、Stacking及新颖DGS方法）提升LLM代码漏洞检测效果，在多个模型和数据集上的实验证实集成方法能显著提高检测性能，特别在数据不平衡、复杂分类场景下表现优越，为构建高效LLM漏洞检测系统提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在代码漏洞检测方面表现出潜力，但在不同模型或同一模型的不同训练阶段中，检测结果常常不一致。这种不一致性影响了检测的稳定性，但也表明模型之间存在互补性，可以通过集成学习提升检测效果。

Method: 本文综合使用了五种LLM（DeepSeek-Coder-6.7B、CodeLlama-7B、CodeLlama-13B、CodeQwen1.5-7B和StarCoder2-15B），并采用三种集成策略（Bagging、Boosting和Stacking）在Devign、ReVeal和BigVul三个数据集上进行实验。此外，提出了一种受专家混合（MoE）技术启发的动态门控堆叠（DGS）方法，用以改善漏洞检测。

Result: 实验结果显示，各种集成方法均显著提升了模型的漏洞检测能力。其中，Boosting在处理数据不平衡时表现尤为突出，DGS方法在应对类别不均衡和多分类任务时优于传统Stacking方法。

Conclusion: 集成学习能够有效提升LLM在源代码漏洞检测任务上的性能和稳定性，特别是新提出的DGS方法，对构建更可靠和高效的漏洞检测系统具有重要意义。

Abstract: Code vulnerability detection is crucial for ensuring the security and
reliability of modern software systems. Recently, Large Language Models (LLMs)
have shown promising capabilities in this domain. However, notable
discrepancies in detection results often arise when analyzing identical code
segments across different training stages of the same model or among
architecturally distinct LLMs. While such inconsistencies may compromise
detection stability, they also highlight a key opportunity: the latent
complementarity among models can be harnessed through ensemble learning to
create more robust vulnerability detection systems. In this study, we explore
the potential of ensemble learning to enhance the performance of LLMs in source
code vulnerability detection. We conduct comprehensive experiments involving
five LLMs (i.e., DeepSeek-Coder-6.7B, CodeLlama-7B, CodeLlama-13B,
CodeQwen1.5-7B, and StarCoder2-15B), using three ensemble strategies (i.e.,
Bagging, Boosting, and Stacking). These experiments are carried out across
three widely adopted datasets (i.e., Devign, ReVeal, and BigVul). Inspired by
Mixture of Experts (MoE) techniques, we further propose Dynamic Gated Stacking
(DGS), a Stacking variant tailored for vulnerability detection. Our results
demonstrate that ensemble approaches can significantly improve detection
performance, with Boosting excelling in scenarios involving imbalanced
datasets. Moreover, DGS consistently outperforms traditional Stacking,
particularly in handling class imbalance and multi-class classification tasks.
These findings offer valuable insights into building more reliable and
effective LLM-based vulnerability detection systems through ensemble learning.

</details>


### [13] [When Large Language Models Meet UAVs: How Far Are We?](https://arxiv.org/abs/2509.12795)
*Yihua Chen,Xingle Que,Jiashuo Zhang,Ting Chen,Guangshun Li,Jiachi Chen*

Main category: cs.SE

TL;DR: 系统分析无人机（UAV）与大规模语言模型（LLM）结合研究与落地现状：学界偏理论，业界重实用，落地受多种因素制约。提出发展挑战与建议。


<details>
  <summary>Details</summary>
Motivation: 当前学术界和工业界对无人机（UAV）与大型语言模型（LLM）结合兴趣上升，但现实应用与学术研究之间存在差距，部分原因是理论研究对实际需求关注有限。这种脱节可能阻碍技术落地，提升对结合现状的系统性分析的需求。

Method: 本文系统性地分析了74篇学术论文和56个开源GitHub项目，归纳了UAV系统中LLM的九类任务并统计分布。同时，作者通过在线问卷调查收集了52份行业从业者的反馈，进一步识别实际应用的阻碍因素。

Result: 研究发现，学术界更关注理论与任务优化，关注点分散；而工业界更重视飞行控制、任务规划和人机交互等实用性强的领域。40.4%的行业从业者已尝试将LLM应用到无人机任务，实际落地受技术成熟度、性能、安全性与成本等因素限制。

Conclusion: 论文总结了学术研究与实际应用之间的关键差异，突出需要提升技术成熟度、应用安全性等，提出未来发展挑战和建议以促进LLM在UAV系统中的实际应用。

Abstract: The integration of unmanned aerial vehicles (UAVs) and large language models
(LLMs) has emerged as a research direction of growing interest, with the
potential to address challenges in autonomous decision-making, human-UAV
interaction, and real-time adaptability. However, existing studies have
remained largely in preliminary exploration with a limited understanding of
real-world practice, risking a misalignment between academic research and
practical needs and hindering the translation of results. To examine and
address these potential challenges, we conducted an empirical study of 74
selected papers and 56 public GitHub projects, identified nine task types for
LLMs in UAV systems, and quantified their distribution. Our findings show that
academic research emphasizes theoretical modeling and task optimization with
dispersed attention across tasks. In contrast, industrial projects focus on
flight control, task planning, and human-machine interaction, prioritizing
operability and efficiency. To further capture industry perspectives, we
distributed an online questionnaire. We obtained 52 valid responses: 40.4% of
practitioners have attempted to apply LLMs to UAV tasks. We further identify
factors that impede real-world integration, including technological maturity,
performance, safety, cost, and other considerations. Finally, we highlight
challenges for future development and provide recommendations.

</details>


### [14] [LLM-Based Approach for Enhancing Maintainability of Automotive Architectures](https://arxiv.org/abs/2509.12798)
*Nenad Petrovic,Lukasz Mazur,Alois Knoll*

Main category: cs.SE

TL;DR: 本文探讨GPT-4o等大语言模型用于提升汽车系统灵活性的自动化流程，通过三个案例初步验证了模型在升级、兼容性检测和架构建议等方面的作用，为汽车系统长期维护和扩展带来新可能。


<details>
  <summary>Details</summary>
Motivation: 汽车系统在维护、更新和扩展过程中受到多种瓶颈制约，这主要包括重新工程、标准化、合规流程繁琐，以及设备和软件异构性强，数量众多，导致长期管理难度大。该论文旨在解决这些灵活性不足的问题。

Method: 论文通过探索大语言模型（LLM）在提升汽车系统灵活性方面的自动化任务和流程的应用潜力，设计并实现了三个初步案例研究：（1）系统更新、硬件抽象与合规， （2）接口兼容性检测，和（3）体系结构修改建议。采用OpenAI的GPT-4o模型进行了概念验证。

Result: 初步研究结果表明，基于GPT-4o的大语言模型可以在自动化升级、硬件抽象、接口兼容性检测和架构建议等方面发挥作用，为提升汽车系统的灵活性提供了新思路和技术路径。

Conclusion: 应用大语言模型有望减少汽车系统在维护与升级过程中的繁琐流程和人工干预，提升整体系统灵活性和可持续性。未来有望进一步拓展模型能力并优化实际应用场景。

Abstract: There are many bottlenecks that decrease the flexibility of automotive
systems, making their long-term maintenance, as well as updates and extensions
in later lifecycle phases increasingly difficult, mainly due to long
re-engineering, standardization, and compliance procedures, as well as
heterogeneity and numerosity of devices and underlying software components
involved. In this paper, we explore the potential of Large Language Models
(LLMs) when it comes to the automation of tasks and processes that aim to
increase the flexibility of automotive systems. Three case studies towards
achieving this goal are considered as outcomes of early-stage research: 1)
updates, hardware abstraction, and compliance, 2) interface compatibility
checking, and 3) architecture modification suggestions. For proof-of-concept
implementation, we rely on OpenAI's GPT-4o model.

</details>


### [15] [SateLight: A Satellite Application Update Framework for Satellite Computing](https://arxiv.org/abs/2509.12809)
*Jinfeng Wen,Jianshu Zhao,Zixi Zhu,Xiaomin Zhang,Qi Liang,Ao Zhou,Shangguang Wang*

Main category: cs.SE

TL;DR: 针对卫星应用在线更新难题，SateLight框架通过容器化、差分更新及容错设计，实现了高效、可靠的软件更新，性能明显优于现有方案，并通过仿真和实际在轨测试验证其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 卫星计算作为新兴范式，提升了卫星对地面依赖性并增强了响应能力。但由于应用的异构性、带宽有限和恶劣空间环境，现有地面系统的软件更新方法不再适用，亟需有针对性的解决方案。

Method: 提出了SateLight框架，利用容器技术封装并管理异构卫星应用，结合内容感知差分策略降低数据量、细粒度的车载更新机制优化目标应用重构，以及分层容错机制提升更新可靠性。

Result: 在卫星仿真环境和10个代表性卫星应用上测试，SateLight在数据传输延迟上最多下降91.18%（平均56.54%），并在所有应用中均实现100%更新正确率，还进行了真实在轨卫星案例验证其实用性。

Conclusion: SateLight能高效、安全地实现卫星应用的软件更新，显著减少数据传输量、提升鲁棒性，适合在空间环境下广泛部署。

Abstract: Satellite computing is an emerging paradigm that empowers satellites to
perform onboard processing tasks (i.e., \textit{satellite applications}),
thereby reducing reliance on ground-based systems and improving responsiveness.
However, enabling application software updates in this context remains a
fundamental challenge due to application heterogeneity, limited
ground-to-satellite bandwidth, and harsh space conditions. Existing software
update approaches, designed primarily for terrestrial systems, fail to address
these constraints, as they assume abundant computational capacity and stable
connectivity.
  To address this gap, we propose SateLight, a practical and effective
satellite application update framework tailored for satellite computing.
SateLight leverages containerization to encapsulate heterogeneous applications,
enabling efficient deployment and maintenance. SateLight further integrates
three capabilities: (1) a content-aware differential strategy that minimizes
communication data volume, (2) a fine-grained onboard update design that
reconstructs target applications, and (3) a layer-based fault-tolerant recovery
mechanism to ensure reliability under failure-prone space conditions.
Experimental results on a satellite simulation environment with 10
representative satellite applications demonstrate that SateLight reduces
transmission latency by up to 91.18% (average 56.54%) compared to the best
currently available baseline. It also consistently ensures 100% update
correctness across all evaluated applications. Furthermore, a case study on a
real-world in-orbit satellite demonstrates the practicality of our approach.

</details>


### [16] [Evaluating Large Language Models for Code Translation: Effects of Prompt Language and Prompt Design](https://arxiv.org/abs/2509.12973)
*Aamer Aljagthami,Mohammed Banabila,Musab Alshehri,Mohammed Kabini,Mohammad D. Alahmadi*

Main category: cs.SE

TL;DR: 本文系统比较了最先进LLM和传统TransCoder在多种编程语言间代码翻译的表现，发现详细提示词和英文提示能显著提升质量。所有LLM均优于传统基线，为软件现代化和多语言互操作性提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 自动源代码翻译对于软件迁移、维护和跨语言互操作性至关重要，但缺乏关于模型选择、提示设计和提示语言对多编程语言翻译质量影响的系统性证据。

Method: 系统性评估了多种最先进的LLM和TransCoder在C++、Java、Python、C#之间的自动代码翻译表现，考察了不同的提示词风格（简洁与详细）和提示语言（英语与阿拉伯语），并采用BLEU和CodeBLEU进行定量分析。

Result: 详细的提示词能带来一致的性能提升，英文提示比阿拉伯语高出13-15%。顶级模型在如Java到C#和Python到C++的复杂翻译任务上取得最高CodeBLEU分数。所有LLM均超过TransCoder基线。

Conclusion: 每种大型语言模型（LLM）在代码翻译质量上都超过了传统基线TransCoder。优化提示词设计和选择提示语言有助于提升代码迁移和互操作性。

Abstract: Large language models (LLMs) have shown promise for automated source-code
translation, a capability critical to software migration, maintenance, and
interoperability. Yet comparative evidence on how model choice, prompt design,
and prompt language shape translation quality across multiple programming
languages remains limited. This study conducts a systematic empirical
assessment of state-of-the-art LLMs for code translation among C++, Java,
Python, and C#, alongside a traditional baseline (TransCoder). Using BLEU and
CodeBLEU, we quantify syntactic fidelity and structural correctness under two
prompt styles (concise instruction and detailed specification) and two prompt
languages (English and Arabic), with direction-aware evaluation across language
pairs. Experiments show that detailed prompts deliver consistent gains across
models and translation directions, and English prompts outperform Arabic by
13-15%. The top-performing model attains the highest CodeBLEU on challenging
pairs such as Java to C# and Python to C++. Our evaluation shows that each LLM
outperforms TransCoder across the benchmark. These results demonstrate the
value of careful prompt engineering and prompt language choice, and provide
practical guidance for software modernization and cross-language
interoperability.

</details>


### [17] [Validating Solidity Code Defects using Symbolic and Concrete Execution powered by Large Language Models](https://arxiv.org/abs/2509.13023)
*Ştefan-Claudiu Susan,Andrei Arusoaie,Dorel Lucanu*

Main category: cs.SE

TL;DR: 本文提出融合多种分析工具与LLM的Solidity漏洞自动检测与验证流程, 可有效减少误报并提升自动审计能力，对于难检测核心缺陷表现优异，为智能合约审计提供更高可靠性的方案。


<details>
  <summary>Details</summary>
Motivation: Solidity智能合约的静态分析工具和大语言模型（LLM）误报率高，导致漏洞检测变得复杂，现有方法难以有效且有依据地证明缺陷的存在，亟需更可靠的检测与验证方法。

Method: 提出了一个集成定制Slither检测器、LLM、Kontrol与Forge的新检测流程，通过组合符号执行或具体执行，对合约进行分层、串联式检测，实现缺陷的可靠检测与自动生成证明。

Result: 在七类关键缺陷检测实验中取得了效果，针对现有验证方案常常误报或漏报的三类漏洞（可重入、复杂回退、错误访问控制），能够有效分类和验证代码缺陷，大幅减少人工验证工作量。

Conclusion: 该方法将启发式分析与形式化验证结合，显著提高了Solidity合约自动化审计的可靠性，也明确指出LLM的不稳定性与成本等局限性，为更稳健和自动化的合约审计提供了路线框架。

Abstract: The high rate of false alarms from static analysis tools and Large Language
Models (LLMs) complicates vulnerability detection in Solidity Smart Contracts,
demanding methods that can formally or empirically prove the presence of
defects. This paper introduces a novel detection pipeline that integrates
custom Slither-based detectors, LLMs, Kontrol, and Forge. Our approach is
designed to reliably detect defects and generate proofs. We currently perform
experiments with promising results for seven types of critical defects. We
demonstrate the pipeline's efficacy by presenting our findings for three
vulnerabilities -- Reentrancy, Complex Fallback, and Faulty Access Control
Policies -- that are challenging for current verification solutions, which
often generate false alarms or fail to detect them entirely. We highlight the
potential of either symbolic or concrete execution in correctly classifying
such code faults. By chaining these instruments, our method effectively
validates true positives, significantly reducing the manual verification
burden. Although we identify potential limitations, such as the inconsistency
and the cost of LLMs, our findings establish a robust framework for combining
heuristic analysis with formal verification to achieve more reliable and
automated smart contract auditing.

</details>


### [18] [GView: A Survey of Binary Forensics via Visual, Semantic, and AI-Enhanced Analysis](https://arxiv.org/abs/2509.13025)
*Raul Zaharia,Dragoş Gavriluţ,Gheorghiţă Mutu*

Main category: cs.SE

TL;DR: GView是一款结合视觉化和AI推理的开源网络安全取证分析工具，通过引入大语言模型与逻辑推理，实现对复杂威胁的高效智能分析，兼具学术和产业价值。


<details>
  <summary>Details</summary>
Motivation: 网络安全威胁日益复杂和多样，导致安全分析的难度和工作量剧增，亟需更智能和自动化的取证工具。

Method: GView框架融合了视觉化分析和AI增强推理，采用逻辑谓词与推理规则，对已分析的文档以及用户操作进行智能化建议，还动态利用大语言模型优化推理流程。

Result: GView具备可扩展架构，支持开放源码，结合逻辑推理与AI，优化了取证流程，提高了分析建议的质量和效率，被验证具有学术与实际应用的高度潜力。

Conclusion: GView通过结合大语言模型和可视化推理，显著提升了网络安全取证工作的效率和智能化水平，同时搭建了学术与实际应用之间的桥梁。

Abstract: Cybersecurity threats continue to become more sophisticated and diverse in
their artifacts, boosting both their volume and complexity. To overcome those
challenges, we present GView, an open-source forensic analysis framework with
visual and AI-enhanced reasoning. It started with focus on the practical
cybersecurity industry. It has evolved significantly, incorporating large
language models (LLMs) to dynamically enhance reasoning and ease the forensic
workflows. This paper surveys both the current state of GView with its
published papers alongside those that are in the publishing process. It also
includes its innovative use of logical inference through predicates and
inference rules for both the analyzed documents and the user's actions for
better suggestions. We highlight the extensible architecture, showcasing its
potential as a bridge between the practical forensics worlds with the academic
research.

</details>


### [19] [Automating Code Generation for Semiconductor Equipment Control from Developer Utterances with LLMs](https://arxiv.org/abs/2509.13055)
*Youngkyoung Kim,Sanghyeok Park,Misoo Kim,Gangho Yoon,Eunseok Lee,Simon S. Woo*

Main category: cs.SE

TL;DR: 本文提出了多阶段渐进式知识增强方法，显著提升大语言模型在低级设备语言（如ALPG）代码生成的表现，精准率提高超11%，有助于半导体行业代码开发提效。


<details>
  <summary>Details</summary>
Motivation: 半导体行业依赖低级设备语言进行硬件控制，但这类语言难以编程且学习曲线陡峭。同时，现有的大语言模型在生成高级代码方面表现良好，但在低级设备语言上的能力有限，因此需要提升LLM在该领域的适用性和准确性。

Method: 提出了一种新的多阶段提示框架——渐进式知识增强（PKE），通过逐步激活和抽取LLM中的潜在知识，结合由简单到复杂的例子指导模型，无需大量微调即可提升其对低级设备语言的代码生成能力。

Result: 在工业ALPG数据集上的实证评估显示，PKE在生成正确ALPG代码方面显著优于标准提示和现有最新方法，精确匹配分数分别高出第二优方法11.1%和15.2%。对各组件的进一步分析表明，基于难度的知识渐进抽取能提升准确性。

Conclusion: PKE为提升LLM在专用低级编程领域的能力提供了实用方法，有助于提高半导体软件开发的生产力。

Abstract: Semiconductors form the backbone of modern electronics, with their
manufacturing and testing relying on highly specialized equipment and
domain-specific programming languages. Equipment languages such as the
Algorithmic Pattern Generator (ALPG) are critical for precise hardware control
but are challenging to program due to their low-level syntax and steep learning
curve. While large language models (LLMs) have shown promise in generating
high-level code from natural language, their effectiveness on low-level
equipment languages remains limited. To address this, we propose Progressive
Knowledge Enhancement (PKE), a novel multi-stage prompting framework that
progressively extracts and activates the latent knowledge within LLMs, guiding
them from simple to complex examples without extensive fine-tuning. Empirical
evaluation on an industrial ALPG dataset shows that PKE significantly
outperforms standard prompting and surpasses state-of-the-art methods in
generating correct ALPG code, achieving 11.1\% and 15.2\% higher exact match
scores compared to the second-best technique. Further analysis of individual
components confirms that progressive knowledge extraction based on difficulty
enhances accuracy. Our study offer a practical approach to boosting LLM
capabilities for specialized low-level programming, supporting greater
productivity in semiconductor software development.

</details>


### [20] [Accelerating Discovery: Rapid Literature Screening with LLMs](https://arxiv.org/abs/2509.13103)
*Santiago Matalonga,Domenico Amalfitano,Jean Carlo Rossa Hauck,Martín Solari,Guilherme H. Travassos*

Main category: cs.SE

TL;DR: 本研究开发了一种基于大语言模型和RAG技术的自动化工具，以提升多声道文献综述的检索和筛选效率，实验结果表明其与人工筛选结果高度一致，有望大幅减轻研究者负担，但人工参与和核查仍不可或缺。


<details>
  <summary>Details</summary>
Motivation: 进行多声道文献综述（MVLR）具有高时间和精力成本，尤其在面对大量零散、信息稀疏且异构的文献时，人工筛选效率极低。因此，研究者希望借助自动化工具提升这一过程的效率和准确性。

Method: 应用严谨的工程实践，开发了基于大语言模型（LLM）的本地工具，并结合检索增强生成（RAG）技术，以支持MVLR中文献的检索与筛选。采用Positive Percent Agreement（PPA）作为核心指标，结合人工判断和统计抽样进行工具的验证。

Result: 该工具在判别与研究无关文献时，与人工结果的PPA达到了90%。工具的开发细节也已公开，便于不同行业领域的调整和应用。

Conclusion: 基于LLM的工具可以有效辅助学者高效且严谨地进行MVLR，大幅节省时间，便于学者关注高层次研究任务，但仍需研究者参与以确保研究质量。

Abstract: Background: Conducting Multi Vocal Literature Reviews (MVLRs) is often time
and effort-intensive. Researchers must review and filter a large number of
unstructured sources, which frequently contain sparse information and are
unlikely to be included in the final study. Our experience conducting an MVLR
on Context-Aware Software Systems (CASS) Testing in the avionics domain
exemplified this challenge, with over 8,000 highly heterogeneous documents
requiring review. Therefore, we developed a Large Language Model (LLM)
assistant to support the search and filtering of documents. Aims: To develop
and validate an LLM based tool that can support researchers in performing the
search and filtering of documents for an MVLR without compromising the rigor of
the research protocol. Method: We applied sound engineering practices to
develop an on-premises LLM-based tool incorporating Retrieval Augmented
Generation (RAG) to process candidate sources. Progress towards the aim was
quantified using the Positive Percent Agreement (PPA) as the primary metric to
ensure the performance of the LLM based tool. Convenience sampling, supported
by human judgment and statistical sampling, were used to verify and validate
the tool's quality-in-use. Results: The tool currently demonstrates a PPA
agreement with human researchers of 90% for sources that are not relevant to
the study. Development details are shared to support domain-specific adaptation
of the tool. Conclusions: Using LLM-based tools to support academic researchers
in rigorous MVLR is feasible. These tools can free valuable time for
higher-level, abstract tasks. However, researcher participation remains
essential to ensure that the tool supports thorough research.

</details>


### [21] [Vulnerability Patching Across Software Products and Software Components: A Case Study of Red Hat's Product Portfolio](https://arxiv.org/abs/2509.13117)
*Jukka Ruohonen,Sani Abdullahi,Abhishek Tiwari*

Main category: cs.SE

TL;DR: 通过分段回归分析Red Hat产品和组件过去25年脆弱性修补的数据，发现其数量变化不稳且呈现断点，表明安全债务的进一步恶化可能正在减缓。


<details>
  <summary>Details</summary>
Motivation: 受软件维护和安全债务概念影响，分析Red Hat产品和组件脆弱性修补情况，探索脆弱性数量的趋势变化。

Method: 利用分段回归分析，对1999年至2024年间Red Hat产品和组件的脆弱性补丁时间序列进行研究。

Result: 发现脆弱产品和组件的数量并不稳定，许多序列可用线性趋势很好地描述，但也存在明显断点，表明线性趋势并非普遍适用，并暗示安全债务的增长可能在趋于稳定。

Conclusion: 产品和组件脆弱性的数量变化存在波动，无法以统一的趋势描述，说明安全债务的增长可能已进入稳定阶段。

Abstract: Motivated by software maintenance and the more recent concept of security
debt, the paper presents a time series analysis of vulnerability patching of
Red Hat's products and components between 1999 and 2024. According to the
results based on segmented regression analysis, the amounts of vulnerable
products and components have not been stable; a linear trend describes many of
the series well. Nor do the amounts align well with trends characterizing
vulnerabilities in general. There are also visible breakpoints indicating that
the linear trend is not universally applicable and that the growing security
debt may be stabilizing.

</details>


### [22] [Optimizing Code Embeddings and ML Classifiers for Python Source Code Vulnerability Detection](https://arxiv.org/abs/2509.13134)
*Talaya Farasat,Joachim Posegga*

Main category: cs.SE

TL;DR: 在自动检测Python源码漏洞中，BiLSTM与Word2Vec组合比新型模型略胜一筹，说明选择合适的嵌入技术与分类器至关重要。


<details>
  <summary>Details</summary>
Motivation: 随着源代码复杂性和规模不断增加，人工检测软件漏洞变得越来越不现实，因此亟需自动化方法来提高漏洞检测效率。

Method: 本文评估了三种代码嵌入技术（Word2Vec、CodeBERT、GraphCodeBERT）与两种深度学习分类器（BiLSTM和CNN）组合，用于自动检测Python源代码中的漏洞。

Result: 虽然CNN与GraphCodeBERT结合表现强劲，但BiLSTM结合Word2Vec始终展现出更优的整体结果。与最新架构如CodeBERT、GraphCodeBERT相比，经典的Word2Vec与BiLSTM的组合在性能上具备一定优势。

Conclusion: 选择合适的嵌入与分类器组合对于提升自动化漏洞检测效果至关重要，尤其是在Python源代码中。Word2Vec结合BiLSTM是一个性能优异的选择。

Abstract: In recent years, the growing complexity and scale of source code have
rendered manual software vulnerability detection increasingly impractical. To
address this challenge, automated approaches leveraging machine learning and
code embeddings have gained substantial attention. This study investigates the
optimal combination of code embedding techniques and machine learning
classifiers for vulnerability detection in Python source code. We evaluate
three embedding techniques, i.e., Word2Vec, CodeBERT, and GraphCodeBERT
alongside two deep learning classifiers, i.e., Bidirectional Long Short-Term
Memory (BiLSTM) networks and Convolutional Neural Networks (CNN). While CNN
paired with GraphCodeBERT exhibits strong performance, the BiLSTM model using
Word2Vec consistently achieves superior overall results. These findings suggest
that, despite the advanced architectures of recent models like CodeBERT and
GraphCodeBERT, classical embeddings such as Word2Vec, when used with
sequence-based models like BiLSTM, can offer a slight yet consistent
performance advantage. The study underscores the critical importance of
selecting appropriate combinations of embeddings and classifiers to enhance the
effectiveness of automated vulnerability detection systems, particularly for
Python source code.

</details>


### [23] [Towards the Next Generation of Software: Insights from Grey Literature on AI-Native Applications](https://arxiv.org/abs/2509.13144)
*Lingli Cao,Shanshan Li,Ying Fan,Danyang Li,Chenxing Zhong*

Main category: cs.SE

TL;DR: 本文系统梳理了AI原生应用的定义、质量属性和技术栈，通过文献与实践案例分析，总结出其工程特征，首次提出双层工程蓝图为行业提供参考。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的迅速发展推动了人工智能原生应用的兴起，这一新范式正在重塑软件的设计、开发和演化方式，但相关工程定义和架构体系尚未统一，行业缺乏系统化指导。

Method: 采用灰色文献综述方法，结合Google和Bing的定向检索的概念观点与GitHub主流开源项目的实践经验，通过结构化协议（包括文献筛选、质量评估和主题分析）综合多源信息。

Result: 最终筛选出106项研究，发现AI原生应用以AI为核心智能范式，并具有概率性和非确定性特征。关键质量属性包括可靠性、可用性、性能效率以及AI特有的可观测性。典型技术栈已逐渐成型，包括LLM编排框架、向量数据库与AI原生可观测平台。与传统软件相比，更强调响应质量、成本效益和结果可预测性。

Conclusion: 首次提出了具备双层结构的AI原生应用工程蓝图，为系统设计、质量保障和技术选择提供基础参考，填补理论与应用实践的空白。

Abstract: Background: The rapid advancement of large language models (LLMs) has given
rise to AI-native applications, a new paradigm in software engineering that
fundamentally redefines how software is designed, developed, and evolved.
Despite their growing prominence, AI-native applications still lack a unified
engineering definition and architectural blueprint, leaving practitioners
without systematic guidance for system design, quality assurance, and
technology selection.
  Objective: This study seeks to establish a comprehensive understanding of
AI-native applications by identifying their defining characteristics, key
quality attributes, and typical technology stacks, as well as by clarifying the
opportunities and challenges they present.
  Method: We conducted a grey literature review, integrating conceptual
perspectives retrieved from targeted Google and Bing searches with practical
insights derived from leading open-source projects on GitHub. A structured
protocol encompassing source selection, quality assessment, and thematic
analysis was applied to synthesize findings across heterogeneous sources.
  Results: We finally identified 106 studies based on the selection criteria.
The analysis reveals that AI-native applications are distinguished by two core
pillars: the central role of AI as the system's intelligence paradigm and their
inherently probabilistic, non-deterministic nature. Critical quality attributes
include reliability, usability, performance efficiency, and AI-specific
observability. In addition, a typical technology stack has begun to emerge,
comprising LLM orchestration frameworks, vector databases, and AI-native
observability platforms. These systems emphasize response quality,
cost-effectiveness, and outcome predictability, setting them apart from
conventional software systems.
  Conclusion: This study is the first to propose a dual-layered engineering
blueprint...

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [24] [Determination of the fifth Busy Beaver value](https://arxiv.org/abs/2509.12337)
*The bbchallenge Collaboration,Justin Blanchard,Daniel Briggs,Konrad Deka,Nathan Fenner,Yannick Forster,Georgi Georgiev,Matthew L. House,Rachel Hunter,Iijil,Maja Kądziołka,Pavel Kropitz,Shawn Ligocki,mxdys,Mateusz Naściszewski,savask,Tristan Stérin,Chris Xu,Jason Yuen,Théo Zimmermann*

Main category: cs.LO

TL;DR: 本文利用Coq证明助手，枚举并验证了5状态忙海狸值S(5)，得到S(5)=47,176,870，标志着40年来首次得到新值，也是首次通过形式化证明验证忙海狸值，有力展示了大规模协作在线研究的成效。


<details>
  <summary>Details</summary>
Motivation: 忙海狸数S(n)是计算理论中的一个著名问题，代表一个不可计算函数。自1962年Tibor Radó提出以来，S(5)一直未被确定。本论文旨在解决这一长期悬而未决的数学挑战，并验证大型协作在线研究的有效性。

Method: 研究通过枚举181,385,789个具有5状态的2符号图灵机，并判断每台图灵机是否会停机，从而计算S(5)的具体数值。所有证明均在Coq形式化验证系统下进行。

Result: 确定了S(5)=47,176,870，并首次实现了忙海狸数值的正式验证。

Conclusion: 我们使用Coq证明助手正式确定了S(5)=47,176,870，这是忙海狸数的一个新值，也是40多年来首次被确定的新值，并且实现了历史上第一次对忙海狸值进行形式化验证。

Abstract: We prove that $S(5) = 47,176,870$ using the Coq proof assistant. The Busy
Beaver value $S(n)$ is the maximum number of steps that an $n$-state 2-symbol
Turing machine can perform from the all-zero tape before halting, and $S$ was
historically introduced by Tibor Rad\'o in 1962 as one of the simplest examples
of an uncomputable function. The proof enumerates $181,385,789$ Turing machines
with 5 states and, for each machine, decides whether it halts or not. Our
result marks the first determination of a new Busy Beaver value in over 40
years and the first Busy Beaver value ever to be formally verified, attesting
to the effectiveness of massively collaborative online research
(bbchallenge$.$org).

</details>


### [25] [Probabilistic Model Checking: Applications and Trends](https://arxiv.org/abs/2509.12968)
*Marta Kwiatkowska,Gethin Norman,David Parker*

Main category: cs.LO

TL;DR: 本文综述了概率模型检测在多个领域的应用、技术演进及实际价值，并为推动其未来发展提出了建议。


<details>
  <summary>Details</summary>
Motivation: 概率模型检测作为对随机系统进行形式化建模与分析的方法，在过去25年中应用场景与相关技术都有显著的发展。本文旨在评估其在不同行业中的应用价值与技术演进。

Method: 本文通过梳理与总结概率模型检测的主要应用领域、底层理论与关键技术，并结合典型案例分析其实际效益。

Result: 明确了概率模型检测的应用优势，总结出其理论技术进步及对实际问题的积极影响。

Conclusion: 本文为潜在用户与研究者提供了对该领域技术使用的参考，并为未来相关研究与应用发展指明了方向。

Abstract: Probabilistic model checking is an approach to the formal modelling and
analysis of stochastic systems. Over the past twenty five years, the number of
different formalisms and techniques developed in this field has grown
considerably, as has the range of problems to which it has been applied. In
this paper, we identify the main application domains in which probabilistic
model checking has proved valuable and discuss how these have evolved over
time. We summarise the key strands of the underlying theory and technologies
that have contributed to these advances, and highlight examples which
illustrate the benefits that probabilistic model checking can bring. The aim is
to inform potential users of these techniques and to guide future developments
in the field.

</details>


### [26] [On a Dependently Typed Encoding of Matching Logic](https://arxiv.org/abs/2509.13018)
*Ádám Kurucz,Péter Bereczky,Dániel Horpácsi*

Main category: cs.LO

TL;DR: 本文提出首个基于依赖类型的匹配μ-逻辑定义，通过类型索引确保语法元素良好排序，提升了元理论推理的形式化、可靠性和工具化潜力。


<details>
  <summary>Details</summary>
Motivation: 匹配逻辑作为推理各种理论的通用框架，在编程语言语义方面具有重要作用。为了进行元理论推理，需要在基础理论中表达该逻辑，选择依赖类型理论则可将对象理论的良好排序性与主理论的良好类型性直接对应。

Method: 提出首个依赖类型定义的匹配μ-逻辑，通过类型索引编码有序的上下文来保证良好排序性。

Result: 不良排序的语法元素无法被表示，且良好排序元素的语义被保证落在其相应排序的定义域中。

Conclusion: 依赖类型化的匹配μ-逻辑不仅能确保良好排序性，还能通过类型系统保证语义的正确归属，为形式化编程语言语义的推理和验证提供新工具。

Abstract: Matching logic is a general formal framework for reasoning about a wide range
of theories, with particular emphasis on programming language semantics.
Notably, the intermediate language of the K semantics framework is an extension
of matching $\mu$-logic, a sorted, polyadic variant of the logic. Metatheoretic
reasoning requires the logic to be expressed within a foundational theory;
opting for a dependently typed one enables well-sortedness in the object theory
to correspond directly to well-typedness in the host theory. In this paper, we
present the first dependently typed definition of matching $\mu$-logic,
ensuring well-sortedness via sorted contexts encoded in type indices. As a
result, ill-sorted syntax elements are unrepresentable, and the semantics of
well-sorted elements are guaranteed to lie within the domain of their
associated sort.

</details>


### [27] [Łukasiewicz Logic with Actions for Neural Networks training](https://arxiv.org/abs/2509.13020)
*Ioana Leuştean,Bogdan Macovei*

Main category: cs.LO

TL;DR: 该论文将MLP训练过程转换为形式化逻辑推理，对其算法实现进行了自动化证明，为理论理解与正确性验证提供了坚实基础。


<details>
  <summary>Details</summary>
Motivation: 已知多层感知机（MLP）与有理系数Lukasiewicz逻辑之间存在联系，但其训练过程缺乏形式化解释。论文希望以逻辑方式对MLP训练过程进行深入分析和证明。

Method: 采用三序混合模态逻辑把MLP建模为逻辑公式，将训练过程的操作表示为模态算子，并将整个训练序列视为逻辑演绎过程。利用Lean 4定理证明助手和编程语言对训练过程实现进行算法及证明层面的认证。

Result: 将MLP训练过程在形式逻辑系统下进行了严密建模，并通过Lean 4对这一过程进行了形式化算法实现和证明，确保了训练步骤的理论可证性。

Conclusion: 论文将MLP的训练抽象为逻辑演绎，在理论上严格刻画了训练机制，并通过自动化工具实现与证明其正确性。

Abstract: Based on the already known connection between multilayer perceptrons and
Lukasiewicz logic with rational coefficients, we take a step forward in
analyzing its training process using a three-sorted hybrid modal logic: a
multilayer perceptron is a logical formula; the actions of the training process
are modal operators; the training process is a sequence of logical deductions.
Using the proof assistant and the programming language Lean 4, the algorithmic
implementation of the training process is certified by logical proofs.

</details>


### [28] [The Hidden Strength of Costrong Functors](https://arxiv.org/abs/2509.13026)
*Adriana Balan,Silviu-George Pantelimon*

Main category: cs.LO

TL;DR: 本文首次提出并探讨了costrong functors，揭示其在幺半结构与函子交互中独特的理论意义，拓展了计算语义相关的范畴理论视角。


<details>
  <summary>Details</summary>
Motivation: 虽然strong functors和monads已广泛应用，且comonads也被用于描述依赖上下文的计算结构，但“costrong”的性质尚未被系统研究，存在理论空缺。作者试图填补这一空白，进一步拓展函子的理论。

Method: 通过理论分析，对比strong functors和costrong functors的性质，探讨它们在计算语义中的应用潜力。

Result: 作为一项进行中的工作，文章主要阐述了研究costrong functors的必要性，并为后续性质研究和应用方向打下基础。

Conclusion: 文章提出了costrong functors这一概念，并认为其能为我们理解函子与幺半结构的交互提供不同视角。

Abstract: Strong functors and monads are ubiquitous in Computer Science. More recently,
comonads have demonstrated their use in structuring context-dependent notions
of computation. However, the dualisation of ``being strong'' property passed
somehow unobserved so far. We argue that ``being costrong'' gives a different
understanding of how functors can interact with monoidal structures. This work
in progress aims to explore costrong functors and their natural properties,
with an eye towards the semantics of computations.

</details>


### [29] [Intuitionistic modal logics: epistemic reasoning with distributed knowledge](https://arxiv.org/abs/2509.13038)
*Philippe Balbiani*

Main category: cs.LO

TL;DR: 作者在已有的直觉主义认知与认识逻辑框架中新增菱形算子，扩展了逻辑系统，并证明了新系统的语义完备性。


<details>
  <summary>Details</summary>
Motivation: 扩展直觉主义认知逻辑和认识逻辑，使其能够表达更多相关性质，特别是分布式知识；为理论提供更加丰富的工具。

Method: 在已有的基于参数盒子的直觉主义认知逻辑与认识逻辑语言基础上，加入菱形算子，并构造相应的逻辑系统，证明系统的完备性。

Result: 得到带分布式知识的直觉主义认知逻辑与认识逻辑，并证明了其在相应关系模型下的完备性。

Conclusion: 本文证明了引入菱形算子的系统在其关联关系语义下的完备性。

Abstract: In this article, we add a diamond to the parametrized box-based propositional
language of intuitionistic doxastic logic and intuitionistic epistemic logic
introduced by Artemov and Protopopescu. The main results of this article are
the proofs of completeness with respect to their appropriate relational
semantics of the resulting intuitionistic doxastic logic and intuitionistic
epistemic logic with distributed knowledge.

</details>


### [30] [Reducts of fuzzy contexts: Formal concept analysis vs. rough set theory](https://arxiv.org/abs/2509.13059)
*Yuxu Chen,Jing Liu,Lili Shen,Xiaoye Tang*

Main category: cs.LO

TL;DR: 该论文探讨了形式概念分析与粗糙集理论中的模糊语境约简，提出了它们之间通过否定操作互可定义的条件，并证明只有在底层结构满足双重否定律时这一等价关系才成立。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在将形式概念分析（Formal Concept Analysis）与粗糙集理论（Rough Set Theory）中的模糊语境约简进行统一和比较，解决二者之间在处理模糊信息时的定义和关系问题。

Method: 基于完备可加幂积格（complete residuated lattice, 简称L）理论，数学证明了在形式概念分析与粗糙集理论中关于L-语境的约简情况，并考察它们通过“否定”操作是否具有互可定义性。

Result: 当且仅当L满足双重否定律时，形式概念分析中的L-语境约简与粗糙集理论中的L-语境约简可通过“否定”互相定义。

Conclusion: 论文揭示了形式概念分析与粗糙集理论在处理模糊语境约简上的关系条件，即完备可加幂积格系统在满足双重否定律时，两者约简定义等价。

Abstract: We postulate the intuitive idea of reducts of fuzzy contexts based on formal
concept analysis and rough set theory. For a complete residuated lattice $L$,
it is shown that reducts of $L$-contexts in formal concept analysis are
interdefinable with reducts of $L$-contexts in rough set theory via negation
if, and only if, $L$ satisfies the law of double negation.

</details>


### [31] [Proceedings of the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification](https://arxiv.org/abs/2509.13258)
*Giorgio Bacci,Adrian Francalanza*

Main category: cs.LO

TL;DR: GandALF 2025国际会议汇集学术界与业界专家，促进了博弈、自动机、逻辑与形式验证领域的交流与合作。


<details>
  <summary>Details</summary>
Motivation: 旨在促进博弈、自动机、逻辑及形式化验证等领域内理论与应用的深入研究，并推动学术界与工业界之间的协作。

Method: 通过举办国际学术研讨会，邀请领域内专家和参与者进行主题交流和论文报告。

Result: 会议涵盖了广泛的主题，达成了理论与应用的交流与跨领域合作的目标。促进了该领域的学术氛围和研究进展。

Conclusion: 会议成功汇集了在博弈、自动机、逻辑和形式化验证领域内的学者与业界人士，推动了相关领域的学术交流与交叉合作。

Abstract: This volume contains the proceedings of GandALF 2025, the Sixteenth
International Symposium on Games, Automata, Logics, and Formal Verification.
GandALF 2025 took place on 16-17th September 2025, in Valletta, Malta. The aim
of GandALF 2025 is to bring together researchers from academia and industry who
are actively working in the fields of Games, Automata, Logics, and Formal
Verification. The idea is to cover an ample spectrum of themes, ranging from
theory to applications, and stimulate cross-fertilisation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [32] [MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch](https://arxiv.org/abs/2509.12340)
*Nikolay Banar,Ehsan Lotfi,Jens Van Nooten,Cristina Arhiliuc,Marija Kliocaite,Walter Daelemans*

Main category: cs.CL

TL;DR: 本文针对荷兰语在多语言嵌入资源中的缺失，构建了荷兰语专属评测基准和训练数据，训练并发布了高效的荷兰语嵌入模型，资源已开源以推动荷兰语嵌入技术的发展。


<details>
  <summary>Details</summary>
Motivation: 目前主流多语言嵌入资源中荷兰语被严重低估和忽略，缺乏专门支持荷兰语的模型和数据。作者希望通过提供全面的荷兰语资源，推动该语种嵌入体系的发展。

Method: 作者构建了MTEB-NL评测基准，汇集现有和新建的荷兰语任务数据集；收集并扩充荷兰语检索训练数据，包括大模型生成的合成数据；最后训练并发布了E5-NL系列嵌入模型。

Result: 发布了荷兰语专属的评测基准MTEB-NL、扩展后的训练数据集，以及高性能E5-NL嵌入模型。这些资源全部开源，便于社区使用和持续提升。

Conclusion: 论文通过提供荷兰语专属的评测基准和训练数据集，显著提升了荷兰语嵌入资源的发展，并发布了高效且性能优异的荷兰语嵌入模型。

Abstract: Recently, embedding resources, including models, benchmarks, and datasets,
have been widely released to support a variety of languages. However, the Dutch
language remains underrepresented, typically comprising only a small fraction
of the published multilingual resources. To address this gap and encourage the
further development of Dutch embeddings, we introduce new resources for their
evaluation and generation. First, we introduce the Massive Text Embedding
Benchmark for Dutch (MTEB-NL), which includes both existing Dutch datasets and
newly created ones, covering a wide range of tasks. Second, we provide a
training dataset compiled from available Dutch retrieval datasets, complemented
with synthetic data generated by large language models to expand task coverage
beyond retrieval. Finally, we release a series of E5-NL models compact yet
efficient embedding models that demonstrate strong performance across multiple
tasks. We make our resources publicly available through the Hugging Face Hub
and the MTEB package.

</details>


### [33] [MORABLES: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables](https://arxiv.org/abs/2509.12371)
*Matteo Marcuzzo,Alessandro Zangari,Andrea Albarelli,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 本文提出了基于文学故事的道德推理基准MORABLES，用于评估LLM深层次理解和推理能力。实验证明，尽管大型模型表现更好，但仍易被对抗样本操纵，依赖表面特征，且存在明显自我矛盾，推理增强并未实质改进结果，表明LLM在道德推理任务上的能力仍有限。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在标准阅读理解测试上表现优异，因此研究重点转向它们在复杂抽象推理和推断能力上的评价。文学类基准测试因其故事性和道德深度，成为评估深层理解能力的有力工具。

Method: 作者提出了MORABLES，这是一个经过人工验证的基准，内容来自历史文学中的寓言和短篇故事。主要任务以多项选择题的结构，针对道德推理进行考查，设计了能逼迫模型超越浅层抽取式问答的干扰项。同时，还引入了对抗性变体，以暴露LLM因数据污染等问题产生的脆弱性和捷径。

Result: 研究结果显示，大型模型的表现优于小型模型，但仍容易受到对抗操控，且常依赖表面模式而非真正的道德推理。这导致相当程度的自我矛盾，当道德选择的表达方式变化时，最好的模型会有约20%的情况下推翻自己之前的答案。

Conclusion: 即使是强化推理能力的模型也未能弥补这一缺陷，显示模型规模而非推理能力是当前表现的主要动力。

Abstract: As LLMs excel on standard reading comprehension benchmarks, attention is
shifting toward evaluating their capacity for complex abstract reasoning and
inference. Literature-based benchmarks, with their rich narrative and moral
depth, provide a compelling framework for evaluating such deeper comprehension
skills. Here, we present MORABLES, a human-verified benchmark built from fables
and short stories drawn from historical literature. The main task is structured
as multiple-choice questions targeting moral inference, with carefully crafted
distractors that challenge models to go beyond shallow, extractive question
answering. To further stress-test model robustness, we introduce adversarial
variants designed to surface LLM vulnerabilities and shortcuts due to issues
such as data contamination. Our findings show that, while larger models
outperform smaller ones, they remain susceptible to adversarial manipulation
and often rely on superficial patterns rather than true moral reasoning. This
brittleness results in significant self-contradiction, with the best models
refuting their own answers in roughly 20% of cases depending on the framing of
the moral choice. Interestingly, reasoning-enhanced models fail to bridge this
gap, suggesting that scale - not reasoning ability - is the primary driver of
performance.

</details>


### [34] [LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.12382)
*Anu Pradhan,Alexandra Ortan,Apurv Verma,Madhavan Seshadri*

Main category: cs.CL

TL;DR: 本文提出以大语言模型充当评估者，结合更稳健的一致性指标和统计方法，实现了面向法律检索的推荐系统自动化、高精度评估，为消除人工评估瓶颈提供了一条成本低、可靠性高的新路径。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在推荐系统中的广泛应用，传统评估指标难以捕捉如法律检索等专业领域中的细致质量维度，造成评估瓶颈。如何更有效、可信地评估这类系统，尤其是大语言模型（LLM）是否能作为自身系统的评判者，成为亟需解决的问题。

Method: 本文尝试以LLM作为‘评判者’，系统性地评估法律领域中的检索增强生成（Retrieval-Augmented Generation，RAG）系统。作者分析了适用于LLM与人工评估一致性的互评可靠性指标，并探讨了竞争系统之间的统计显著性检验方法。通过实验，对比了Krippendorff's alpha、Gwet's AC2、秩相关系数，并结合Wilcoxon符号秩检验与Benjamini-Hochberg校正方法。

Result: 实验结果显示，在AI系统评估中的偏态分布下，传统的Krippendorff's alpha指标可能存在误导性。Gwet's AC2和秩相关系数作为评判LMM与人工评估对齐度的指标更加稳健。而用于系统比对的Wilcoxon符号秩检验结合FDR校正，能保证统计严谨性。整体方法实现了自动、高效且精度满足法律要求的评价流程。

Conclusion: 利用大语言模型作为评判者，可以在法律等高要求领域实现兼具规模化、低成本和高精度的自动化评估框架，有效缓解因人工介入造成的评估瓶颈。

Abstract: The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.

</details>


### [35] [SENTRA: Selected-Next-Token Transformer for LLM Text Detection](https://arxiv.org/abs/2509.12385)
*Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian*

Main category: cs.CL

TL;DR: 本文提出了用于检测隐藏LLM生成文本的新方法SENTRA，通过创新模型结构和预训练方案，在多个数据集和领域上表现出越界的通用性和检测准确率，显著优于现有主流检测方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）应用越来越广泛，其被滥用的风险也随之增加。检测那些未声明来源的LLM生成文本成为了亟需解决的问题。

Method: 提出了一种新的Transformer结构编码器SENTRA，利用“选定的下一个token概率序列”，并对大量无标签数据进行对比式预训练，随后进行监督学习优化。

Result: 在三类主流公共数据集、24个文本领域上的实验结果显示，SENTRA是一款通用的文本分类器，并且在跨领域检测中显著优于其它主流方法。

Conclusion: SENTRA在各类文本领域的检测任务中表现优异，能够有效检测未声明的LLM生成文本，且在跨领域任务中优于现有方法。

Abstract: LLMs are becoming increasingly capable and widespread. Consequently, the
potential and reality of their misuse is also growing. In this work, we address
the problem of detecting LLM-generated text that is not explicitly declared as
such. We present a novel, general-purpose, and supervised LLM text detector,
SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder
leveraging selected-next-token-probability sequences and utilizing contrastive
pre-training on large amounts of unlabeled data. Our experiments on three
popular public datasets across 24 domains of text demonstrate SENTRA is a
general-purpose classifier that significantly outperforms popular baselines in
the out-of-domain setting.

</details>


### [36] [MORQA: Benchmarking Evaluation Metrics for Medical Open-Ended Question Answering](https://arxiv.org/abs/2509.12405)
*Wen-wai Yim,Asma Ben Abacha,Zixuan Yu,Robert Doerning,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 医学领域的NLG任务评估复杂，传统自动评分指标不足。作者提出了MORQA数据集，通过专家答案与评审进行多语言对比，发现基于大语言模型的自动评估远胜传统指标，更贴合专家判断，为未来医学NLG评估设立新基准。


<details>
  <summary>Details</summary>
Motivation: 传统的自动评估指标在医学领域的自然语言生成（NLG）任务中无法有效区分高质量输出，且医学问答任务常存在多个合理答案，使评估变得更加困难。

Method: 提出MORQA（医学开放式问答）多语言基准，包括英语和中文视觉及文本问答数据集，每个问题由医学专家提供2-4个以上标准答案及专家打分。比较传统评估指标与基于大语言模型（LLM）如GPT-4、Gemini的评估方法在与专家判断一致性上的表现。

Result: 基于LLM的评估方法显著优于传统自动指标，能更好地捕捉语义细微差别，并能应对参考答案的多样性。因而更好地与医学专家的评分一致。

Conclusion: 医学NLG评估需依赖更贴近人类判断的评估方法。MORQA提供了首个综合性的多语言医学NLG评估基准，未来将公开支持社区研究。

Abstract: Evaluating natural language generation (NLG) systems in the medical domain
presents unique challenges due to the critical demands for accuracy, relevance,
and domain-specific expertise. Traditional automatic evaluation metrics, such
as BLEU, ROUGE, and BERTScore, often fall short in distinguishing between
high-quality outputs, especially given the open-ended nature of medical
question answering (QA) tasks where multiple valid responses may exist. In this
work, we introduce MORQA (Medical Open-Response QA), a new multilingual
benchmark designed to assess the effectiveness of NLG evaluation metrics across
three medical visual and text-based QA datasets in English and Chinese. Unlike
prior resources, our datasets feature 2-4+ gold-standard answers authored by
medical professionals, along with expert human ratings for three English and
Chinese subsets. We benchmark both traditional metrics and large language model
(LLM)-based evaluators, such as GPT-4 and Gemini, finding that LLM-based
approaches significantly outperform traditional metrics in correlating with
expert judgments. We further analyze factors driving this improvement,
including LLMs' sensitivity to semantic nuances and robustness to variability
among reference answers. Our results provide the first comprehensive,
multilingual qualitative study of NLG evaluation in the medical domain,
highlighting the need for human-aligned evaluation methods. All datasets and
annotations will be publicly released to support future research.

</details>


### [37] [MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts](https://arxiv.org/abs/2509.12440)
*Jiayi He,Yangmin Huang,Qianyun Du,Xiangying Zhou,Zhiyang He,Jiaxue Hu,Xiaodong Tao,Lixian Lai*

Main category: cs.CL

TL;DR: 提出了中文医学事实核查新基准MedFact，评测LLMs在事实判断和错误定位上的能力，发现模型定位错误仍较弱且易过度批评，MedFact有助于推动更可靠的医学应用模型发展。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在医疗领域的应用越来越广泛，但其事实可靠性评估却受限于现有基准数据的范围狭窄，无法充分反映真实世界医疗信息的复杂性，因此亟需更全面、更具挑战性的医疗事实核查基准。

Method: 构建了MedFact中文医学事实核查新基准，涵盖13个医学专科、8种细分错误类型、4种写作风格和不同难度，由AI与专家协同标注，共收录2116条真实世界实例，并采用多维审查与专家迭代反馈提升数据质量和难度。同时，对20个主流LLM在事实分类与错误定位任务上与专家基线进行全面评测。

Result: 结果显示，模型通常能够判断文本是否存在错误，但在精准定位错误方面与人类专家仍有明显差距。此外，模型常出现“过度批评”现象，尤其在多代理协作和推理时扩大规模后，会错误地将正确信息也判为错误。

Conclusion: MedFact显著揭示了当前LLMs在医疗事实核查应用中的关键挑战，尤其是在错误定位和信息辨别方面，并为提升模型的医学知识可靠性与表现提供了坚实基础。

Abstract: The increasing deployment of Large Language Models (LLMs) in healthcare
necessitates a rigorous evaluation of their factual reliability. However,
existing benchmarks are often limited by narrow domains of data, failing to
capture the complexity of real-world medical information. To address this
critical gap, we introduce MedFact, a new and challenging benchmark for Chinese
medical fact-checking. MedFact comprises 2,116 expert-annotated instances
curated from diverse real-world texts, spanning 13 medical specialties, 8
fine-grained error types, 4 writing styles, and multiple difficulty levels. Its
construction employs a hybrid AI-human framework where iterative expert
feedback refines an AI-driven, multi-criteria filtering process, ensuring both
high data quality and difficulty. We conduct a comprehensive evaluation of 20
leading LLMs, benchmarking their performance on veracity classification and
error localization against a human expert baseline. Our results reveal that
while models can often determine if a text contains an error, precisely
localizing it remains a substantial challenge, with even top-performing models
falling short of human performance. Furthermore, our analysis uncovers a
frequent ``over-criticism'' phenomenon, a tendency for models to misidentify
correct information as erroneous, which is exacerbated by advanced reasoning
techniques such as multi-agent collaboration and inference-time scaling. By
highlighting these critical challenges for deploying LLMs in medical
applications, MedFact provides a robust resource to drive the development of
more factually reliable and medically aware models.

</details>


### [38] [Topic Coverage-based Demonstration Retrieval for In-Context Learning](https://arxiv.org/abs/2509.12451)
*Wonbin Kweon,SeongKu Kang,Runchu Tian,Pengcheng Jiang,Jiawei Han,Hwanjo Yu*

Main category: cs.CL

TL;DR: 提出了TopicK话题覆盖示例检索框架，通过覆盖输入所需话题并迭代补足模型知识短板，显著提升了上下文学习效果。


<details>
  <summary>Details</summary>
Motivation: 以往上下文学习示例选择方法多依赖于嵌入相似性或生成概率，容易造成选择的示例与测试输入不相关或信息冗余，难以覆盖测试输入所需的细粒度知识。

Method: 提出TopicK，一种基于话题覆盖的检索框架。首先估算输入所需的话题，评估模型在这些话题上的知识水平，随后迭代性地选择能引入尚未覆盖且模型知识较弱话题的示例，实现高效、充分的话题知识覆盖。

Result: 在多个数据集和开放、闭源大模型上的实验表明，TopicK能够有效提升上下文学习示例选择的相关性和全面性。

Conclusion: TopicK通过话题覆盖的方法提升了上下文学习的示例选取效率和有效性，解决了以往方法容易选取冗余或无关示例的问题。

Abstract: The effectiveness of in-context learning relies heavily on selecting
demonstrations that provide all the necessary information for a given test
input. To achieve this, it is crucial to identify and cover fine-grained
knowledge requirements. However, prior methods often retrieve demonstrations
based solely on embedding similarity or generation probability, resulting in
irrelevant or redundant examples. In this paper, we propose TopicK, a topic
coverage-based retrieval framework that selects demonstrations to
comprehensively cover topic-level knowledge relevant to both the test input and
the model. Specifically, TopicK estimates the topics required by the input and
assesses the model's knowledge on those topics. TopicK then iteratively selects
demonstrations that introduce previously uncovered required topics, in which
the model exhibits low topical knowledge. We validate the effectiveness of
TopicK through extensive experiments across various datasets and both open- and
closed-source LLMs. Our source code is available at
https://github.com/WonbinKweon/TopicK_EMNLP2025.

</details>


### [39] [Does Language Model Understand Language?](https://arxiv.org/abs/2509.12459)
*Suvojit Acharjee,Utathya Aich,Asfak Ali*

Main category: cs.CL

TL;DR: 本文比较了多种SOTA语言模型在英语和孟加拉语中处理否定、时态、语态等细粒度现象的能力，提出新数据集和评测方式，结果表明Compound-Beta模型最能贴近人类理解，适合应用于需语言精度的领域。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言生成与理解领域取得了进展，但当前的大型语言模型（LM）仍然难以处理时态、否定、语态和情态等细粒度语言现象。这些现象是有效人类沟通的核心元素，尤其在联合国可持续发展目标4（SDG 4）的语境下，语言清晰度至关重要。因此，教育技术中部署LM需格外谨慎。

Method: 本研究评估了多种主流SOTA语言模型在英语和孟加拉语的细粒度语言理解场景中的表现。研究引入了LUCID数据集，包含精心设计的英语和孟加拉语句对，特别针对否定、时态、语态变换等语言理解关键点；并提出系统性环境下认知推理的评估新规范（Route for Evaluation of Cognitive Inference in Systematic Environments guidelines）。使用Pearson相关、Spearman相关、平均绝对误差（MAE）及新颖的HCE准确率进行评测，HCE衡量模型预测与人类评分的相似度。

Result: 实验结果显示，Compound-Beta模型表现最为均衡，在英语和多语言数据上均获得最高或次高的相关性与最低MAE，HCE指标也突出，较好地模拟了人类对语言理解可变性的容忍度。其在混合语言场景下同样展现了对人类判断的高度一致性。

Conclusion: 技术进展下，主流大模型虽然存在对部分语言现象理解不足的问题，但经过系统、细致的评估与数据集设计，部分模型（如Compound-Beta）已能较好地对齐人类的细粒度语言理解，尤其有望应用于教育等对语义准确有高要求的场景。

Abstract: Despite advances in natural language generation and understanding, LM still
struggle with fine grained linguistic phenomena such as tense, negation, voice,
and modality which are the elements central to effective human communication.
In the context of the United Nations SDG 4, where linguistic clarity is
critical, the deployment of LMs in educational technologies demands careful
scrutiny. As LMs are increasingly powering applications like tutoring systems,
automated grading, and translation, their alignment with human linguistic
interpretation becomes essential for effective learning. In this study, we
conduct a evaluation of SOTA language models across these challenging contexts
in both English and Bengali. To ensure a structured assessment, we introduce a
new Route for Evaluation of Cognitive Inference in Systematic Environments
guidelines. Our proposed LUCID dataset, composed of carefully crafted sentence
pairs in English and Bengali, specifically challenges these models on critical
aspects of language comprehension, including negation, tense, voice variations.
We assess the performance of SOTA models including MISTRAL-SABA-24B,
LLaMA-4-Scout-17B, LLaMA-3.3-70B, Gemma2-9B, and Compound-Beta using standard
metrics like Pearson correlation, Spearman correlation, and Mean Absolute
Error, as well as novel, linguistically inspired metric the HCE accuracy. The
HCE accuracy measures how often model predictions fall within one standard
deviation of the mean human rating, thus capturing human like tolerance for
variability in language interpretation. Our findings highlight Compound-Beta as
the most balanced model, consistently achieving high correlations and low MAEs
across diverse language conditions. It records the highest Pearson correlation
in English and demonstrates robust performance on mixed-language data,
indicating a strong alignment with human judgments in cross lingual scenarios.

</details>


### [40] [Audited Reasoning Refinement: Fine-Tuning Language Models via LLM-Guided Step-Wise Evaluation and Correction](https://arxiv.org/abs/2509.12476)
*Sumanta Bhattacharyya,Sara Riaz,Pedram Rooshenas*

Main category: cs.CL

TL;DR: 本论文提出R2tA方法，通过精细化LLM输出的推理痕迹，生成高质量数据并对小模型进行两阶段对齐训练。在数据库设计复杂任务上，方法显著提升模型表现，为数据匮乏领域低成本、可拓展地适应LLM提供新方案。


<details>
  <summary>Details</summary>
Motivation: 在缺乏高质量标签或人类监督时，训练任务特定的小型推理模型非常具有挑战性。此时，具有推理能力的大模型（LLM）能够生成丰富的中间推理过程，这些过程经过系统化优化后，可以作为有效的监督信号。动机在于利用现有LLM的能力，通过精细化推理痕迹，解决数据稀缺领域模型训练困难的问题。

Method: 提出了Reason-Refine-then-Align（R2tA）方法。首先，使用开源基础模型在任务特定输入上生成初步推理过程和响应。随后，对这些推理痕迹进行人工或自动化精细化，纠正幻觉和不一致之处，形成高质量的数据集。接下来，采用两阶段的对齐流程：一是有监督微调（SFT），二是直接偏好优化（DPO），使模型的中间推理过程更符合人类偏好，最终输出基于已对齐的推理。

Result: 在数据库系统设计中，将R2tA用于评估扩展实体关系图（EERD）。搭建了包含600个带有11类人为错误的EERD变体数据集（450训练、150测试），实证表明R2tA能够在数据稀缺领域有效且低成本地提升模型适应能力，其性能在结构复杂任务上优于仅用prompt的方法，能减少漏报和幻觉。

Conclusion: R2tA为数据匮乏领域的任务特定推理模型提供了一条实用且可扩展的训练路径，能够将经过打磨的模型推理转化为高保真监督信号，从而支撑可复现的AI工具，具备教育等多领域应用潜力。

Abstract: Training a task-specific small reasoning model is challenging when direct
human supervision or high-quality labels are scarce. However, LLMs with
reasoning capabilities produce abundant intermediate reasoning traces that can
be systematically refined to create effective supervision signals. We propose
Reason-Refine-then-Align (R2tA), which turns refined model rationales into
supervision for training task-specific reasoning models. Our method generates
initial reasoning and responses from an open-source base model on task-specific
inputs, then refines these traces, fixing hallucinations and inconsistencies,
to form a high-fidelity dataset. We perform a two-stage alignment, supervised
fine-tuning (SFT), followed by direct preference optimization (DPO) to
calibrate the model's intermediate reasoning with human-validated conceptual
preferences and then condition the final output on that aligned reasoning. As a
case study, we apply R2tA to evaluate extended entity relationship diagrams
(EERDs) in database system design, a structurally complex task where
prompt-only methods miss or hallucinate errors. We curated a dataset of 600
EERD variants (train/test split of 450/150, respectively) with induced mistakes
spanning 11 categories. Empirical evaluation suggests R2tA provides a
practical, cost-effective path to scalable LLM adaptation in data-scarce
domains, enabling reproducible AI tools for education and beyond.

</details>


### [41] [FunAudio-ASR Technical Report](https://arxiv.org/abs/2509.12508)
*Keyu An,Yanni Chen,Chong Deng,Changfeng Gao,Zhifu Gao,Bo Gong,Xiangang Li,Yabin Li,Xiang Lv,Yunjie Ji,Yiheng Jiang,Bin Ma,Haoneng Luo,Chongjia Ni,Zexu Pan,Yiping Peng,Zhendong Peng,Peiyao Wang,Hao Wang,Wen Wang,Wupeng Wang,Biao Tian,Zhentao Tan,Nan Yang,Bin Yuan,Jieping Ye,Jixing Yu,Qinglin Zhang,Kun Zou,Han Zhao,Shengkui Zhao,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文提出的FunAudio-ASR系统综合大数据、强模型、与LLM深度融合，并通过多项实际优化，打破了LLM-ASR “只会测论文分不能上生产”的局限。实验表明，FunAudio-ASR在真实产业评测集上取得了SOTA表现，具备强实际部署价值。


<details>
  <summary>Details</summary>
Motivation: 近年来语音识别技术（ASR）取得了巨大进步，主要得益于数据扩展、模型扩展以及与大语言模型（LLM）的深度结合。但LLM有“幻想”（hallucination）问题，这会严重影响实际应用的用户体验。

Method: 提出了FunAudio-ASR系统，融合大规模数据、强大模型容量、LLM集成和强化学习，同时针对实际部署进行了优化（如：流式能力、抗噪、代码切换、热词定制等），以满足各种实际场景需求。

Result: 在实验中，FunAudio-ASR在真实应用数据集上取得了业界领先性能。相比多数LLM-ASR系统仅在公开测试集表现良好，FunAudio-ASR在实际工业评测集上也表现优异。

Conclusion: FunAudio-ASR系统通过多方面优化，提升了现实场景下的识别效果和系统鲁棒性，能够更好地满足实际应用需求。

Abstract: In recent years, automatic speech recognition (ASR) has witnessed
transformative advancements driven by three complementary paradigms: data
scaling, model size scaling, and deep integration with large language models
(LLMs). However, LLMs are prone to hallucination, which can significantly
degrade user experience in real-world ASR applications. In this paper, we
present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically
combines massive data, large model capacity, LLM integration, and reinforcement
learning to achieve state-of-the-art performance across diverse and complex
speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized
for practical deployment, with enhancements in streaming capability, noise
robustness, code-switching, hotword customization, and satisfying other
real-world application requirements. Experimental results show that while most
LLM-based ASR systems achieve strong performance on open-source benchmarks,
they often underperform on real industry evaluation sets. Thanks to
production-oriented optimizations, FunAudio-ASR achieves SOTA performance on
real application datasets, demonstrating its effectiveness and robustness in
practical settings.

</details>


### [42] [A comparison of pipelines for the translation of a low resource language based on transformers](https://arxiv.org/abs/2509.12514)
*Chiara Bonfanti,Michele Colombino,Giulia Coucourde,Faeze Memari,Stefano Pinardi,Rosa Meo*

Main category: cs.CL

TL;DR: 本文比较了三种神经网络机器翻译管道在法语到班巴拉语上的表现，结果显示简单transformer模型效果最佳，尤其适合低资源场景，复杂模型对特定数据集则更敏感。


<details>
  <summary>Details</summary>
Motivation: 班巴拉语是一种在非洲使用但资源稀缺的语言，缺乏有效的机器翻译系统。因此本文旨在探索和比较不同神经网络管道在将法语翻译为班巴拉语上的效果。

Method: 本文对比了三类基于transformer的机器翻译训练流程：一是直接训练简单transformer进行法语到班巴拉语翻译；二是使用只有解码器的LLaMA3（3B-8B）模型进行微调；三是采用语言蒸馏方法，用师生网络将班巴拉语整合进预训练LaBSE模型，并用BERT扩展实现翻译。所有流程在医疗和多领域测试集进行评估，并在新的Yiri数据集上验证性能。

Result: 实验结果显示，简单transformer管道在Bayelemagaba数据集上表现最好（BLEU 10%、chrF 21%），在Yiri自制数据集上也取得了较高分数（BLEU 33.81%、chrF 41%）；Instructor模型在单一数据集上效果较好，但集成数据集表现不佳，说明其更易学习数据集特有模式。

Conclusion: 对于低资源语言班巴拉语的法译班翻译任务，简单transformer架构反而实现了最佳翻译质量，高于更复杂或预训练的蒸馏模型。微调Instructor模型适合针对特定数据集优化，但难以泛化于多领域。

Abstract: This work compares three pipelines for training transformer-based neural
networks to produce machine translators for Bambara, a Mand\`e language spoken
in Africa by about 14,188,850 people. The first pipeline trains a simple
transformer to translate sentences from French into Bambara. The second
fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures
for French-to-Bambara translation. Models from the first two pipelines were
trained with different hyperparameter combinations to improve BLEU and chrF
scores, evaluated on both test sentences and official Bambara benchmarks. The
third pipeline uses language distillation with a student-teacher dual neural
network to integrate Bambara into a pre-trained LaBSE model, which provides
language-agnostic embeddings. A BERT extension is then applied to LaBSE to
generate translations. All pipelines were tested on Dokotoro (medical) and
Bayelemagaba (mixed domains). Results show that the first pipeline, although
simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on
Bayelemagaba), consistent with low-resource translation results. On the Yiri
dataset, created for this work, it achieves 33.81% BLEU and 41% chrF.
Instructor-based models perform better on single datasets than on aggregated
collections, suggesting they capture dataset-specific patterns more
effectively.

</details>


### [43] [MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](https://arxiv.org/abs/2509.12591)
*Vijay Govindarajan,Pratik Patel,Sahil Tripathi,Md Azizul Hoque,Gautam Siddharth Kashyap*

Main category: cs.CL

TL;DR: 该论文提出一种基于预训练模型和大语言模型的零样本自动音频描述方法，无需大量训练，能有效提升音频描述质量，关键词提示和音频-文本匹配模型对结果影响显著。


<details>
  <summary>Details</summary>
Motivation: 尽管自动音频描述（AAC）在为音频片段生成描述方面有应用潜力，但由于可用数据集有限，相较于图像描述任务面临更大挑战。为了减少对大规模训练所需数据和资源的依赖，亟需探索无需大量监督数据的音频描述方法。

Method: 本研究提出了零样本自动音频描述（AAC）系统。该方法利用了预训练的音频CLIP模型提取音频特征，并生成结构化提示词，指导大型语言模型（LLM）进行描述生成。和传统的贪婪解码方法不同，本文方法结合了音频CLIP模型对Token选择进行校正，使生成的描述与音频内容更加一致。

Result: 实验证明，基于WavCaps模型并采用MAGIC搜索的情况下，NLG平均分数提升了35%（由4.7提升到7.3）。该系统性能对音频-文本匹配模型和关键词的选择高度敏感，使用单关键词提示词时性能最优；若不使用关键词列表，性能下降约50%。

Conclusion: 通过利用预训练音频-文本模型和结构化提示结合LLM，可在缺乏大量数据集的情况下，大幅提升自动音频描述的效果。此外，关键词提示和音频-文本对齐模型对性能有显著影响。

Abstract: Automated Audio Captioning (AAC) generates captions for audio clips but faces
challenges due to limited datasets compared to image captioning. To overcome
this, we propose the zero-shot AAC system that leverages pre-trained models,
eliminating the need for extensive training. Our approach uses a pre-trained
audio CLIP model to extract auditory features and generate a structured prompt,
which guides a Large Language Model (LLM) in caption generation. Unlike
traditional greedy decoding, our method refines token selection through the
audio CLIP model, ensuring alignment with the audio content. Experimental
results demonstrate a 35% improvement in NLG mean score (from 4.7 to 7.3) using
MAGIC search with the WavCaps model. The performance is heavily influenced by
the audio-text matching model and keyword selection, with optimal results
achieved using a single keyword prompt, and a 50% performance drop when no
keyword list is used.

</details>


### [44] [EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving](https://arxiv.org/abs/2509.12603)
*Mukai Li,Linfeng Song,Zhenwen Liang,Jiahao Xu,Shansan Gong,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: 本文针对自动定理证明模型推理效率低下的问题，提出动态CoT切换和多样化强化学习相结合的方法，在减少计算资源消耗的同时保持了性能，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有大模型的自动定理证明方法，虽然提升了性能，但推理时计算消耗大，且成本分析不精确，亟需高效节能的解决方案。

Method: 系统对比不同ATP测试时扩展策略的效率，提出动态CoT切换和多样化并行RL相结合的统一管道EconRL，通过实验验证其性能和效率。

Result: EconProver在miniF2F和ProofNet数据集上，仅用12%的计算成本即可达到与主流方法相当的表现。

Conclusion: 提出的EconProver方法能够在保持性能的同时，大幅降低自动定理证明的计算成本，适合实际部署。

Abstract: Large Language Models (LLMs) have recently advanced the field of Automated
Theorem Proving (ATP), attaining substantial performance gains through widely
adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT)
reasoning and increased sampling passes. However, they both introduce
significant computational overhead for inference. Moreover, existing cost
analyses typically regulate only the number of sampling passes, while
neglecting the substantial disparities in sampling costs introduced by
different scaling strategies. In this paper, we systematically compare the
efficiency of different test-time scaling strategies for ATP models and
demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source
approaches. We then investigate approaches to significantly reduce token usage
and sample passes while maintaining the original performance. Specifically, we
propose two complementary methods that can be integrated into a unified EconRL
pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching
mechanism designed to mitigate unnecessary token consumption, and (2) Diverse
parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance
pass rates under constrained sampling passes. Experiments on miniF2F and
ProofNet demonstrate that our EconProver achieves comparable performance to
baseline methods with only 12% of the computational cost. This work provides
actionable insights for deploying lightweight ATP models without sacrificing
performance.

</details>


### [45] [Positional Encoding via Token-Aware Phase Attention](https://arxiv.org/abs/2509.12635)
*Yu,Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian*

Main category: cs.CL

TL;DR: RoPE在长上下文有固有限制，TAPA通过引入可学习相位更好处理长序列，微调简单且表现优于RoPE，尤其是在长文本场景下。


<details>
  <summary>Details</summary>
Motivation: RoPE存在距离相关偏置，限制了长上下文建模能力，目前的改进方法需要训练后再调整，较为繁琐。

Method: 提出了Token-Aware Phase Attention (TAPA)方法，将可学习的相位函数引入注意力机制中。

Result: TAPA能够保留长距离token的交互，支持更长上下文的直接微调和插值，并且在长上下文任务上表现优异。

Conclusion: TAPA明确优于RoPE家族，可以更好处理长上下文，且在长文本上表现出更低的困惑度。

Abstract: We prove under practical assumptions that Rotary Positional Embedding (RoPE)
introduces an intrinsic distance-dependent bias in attention scores that limits
RoPE's ability to model long-context. RoPE extension methods may alleviate this
issue, but they typically require post-hoc adjustments after pretraining, such
as rescaling or hyperparameters retuning. This paper introduces Token-Aware
Phase Attention (TAPA), a new positional encoding method that incorporates a
learnable phase function into the attention mechanism. TAPA preserves token
interactions over long range, extends to longer contexts with direct and light
fine-tuning, extrapolates to unseen lengths, and attains significantly lower
perplexity on long-context than RoPE families.

</details>


### [46] [PAC: Pronunciation-Aware Contextualized Large Language Model-based Automatic Speech Recognition](https://arxiv.org/abs/2509.12647)
*Li Fu,Yu Xin,Sunlu Zeng,Lu Fan,Youzheng Wu,Xiaodong He*

Main category: cs.CL

TL;DR: 论文提出PAC框架，通过发音引导的上下文学习和发音判别强化学习，有效解决LLM-ASR系统的发音建模和同音词区分难题，在英语和普通话数据集上均显著降低了WER，提升了生词及长尾词的识别性能。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的自动语音识别（ASR）系统在发音建模和同音词区分方面存在挑战，特别是对于生词或长尾词的识别效果不佳，因此亟需解决这两个关键问题以提升整体识别性能。

Method: 提出了一个Pronunciation-Aware Contextualized（PAC）框架，采用两阶段学习方法：第一阶段引入发音引导的上下文学习，结合字母-音素交错建模及字母干扰项，引导模型更好地利用语音信息；第二阶段通过带扰动标签采样的发音判别强化学习算法，增强模型区分上下文同音词的能力。

Result: 在公开数据集Librispeech（英语）和AISHELL-1（普通话）上的实验显示，PAC框架相较于预训练LLM-ASR模型分别使单词错误率（WER）降低30.2%和53.8%；对长尾词的有偏WER较强基线分别降低31.8%和60.5%。

Conclusion: PAC框架有效提升了LLM-ASR系统在发音建模和同音词区分上的能力，显著提高了生词和长尾词的识别准确率。

Abstract: This paper presents a Pronunciation-Aware Contextualized (PAC) framework to
address two key challenges in Large Language Model (LLM)-based Automatic Speech
Recognition (ASR) systems: effective pronunciation modeling and robust
homophone discrimination. Both are essential for raw or long-tail word
recognition. The proposed approach adopts a two-stage learning paradigm. First,
we introduce a pronunciation-guided context learning method. It employs an
interleaved grapheme-phoneme context modeling strategy that incorporates
grapheme-only distractors, encouraging the model to leverage phonemic cues for
accurate recognition. Then, we propose a pronunciation-discriminative
reinforcement learning method with perturbed label sampling to further enhance
the model\'s ability to distinguish contextualized homophones. Experimental
results on the public English Librispeech and Mandarin AISHELL-1 datasets
indicate that PAC: (1) reduces relative Word Error Rate (WER) by 30.2% and
53.8% compared to pre-trained LLM-based ASR models, and (2) achieves 31.8% and
60.5% relative reductions in biased WER for long-tail words compared to strong
baselines, respectively.

</details>


### [47] [Don't Change My View: Ideological Bias Auditing in Large Language Models](https://arxiv.org/abs/2509.12652)
*Paul Kröger,Emilio Barkett*

Main category: cs.CL

TL;DR: 论文提出无需访问模型内部的统计检测方法，通过分析输出分布，识别LLM在特定主题下的意识形态引导，为审计黑箱模型提供有效工具，并经实验证明方法可行。


<details>
  <summary>Details</summary>
Motivation: 随着LLM广泛应用于公众产品，模型被人为引导至特定意识形态可能影响舆论，需开发检测引导行为的方法，从而促进公正与透明。

Method: 采用无需访问模型内部的统计方法，通过分析语料输出在特定主题相关提示下的分布变化，检测意识形态偏向。该方法具备模型无关性，尤其适用于黑箱系统。

Result: 通过一系列实验验证了所提出方法的实际可行性及在独立事后审计LLM行为中的潜力。

Conclusion: 所提出的方法可以有效检测LLM输出中的意识形态引导现象，为独立审计提供支持。

Abstract: As large language models (LLMs) become increasingly embedded in products used
by millions, their outputs may influence individual beliefs and, cumulatively,
shape public opinion. If the behavior of LLMs can be intentionally steered
toward specific ideological positions, such as political or religious views,
then those who control these systems could gain disproportionate influence over
public discourse. Although it remains an open question whether LLMs can
reliably be guided toward coherent ideological stances and whether such
steering can be effectively prevented, a crucial first step is to develop
methods for detecting when such steering attempts occur. In this work, we adapt
a previously proposed statistical method to the new context of ideological bias
auditing. Our approach carries over the model-agnostic design of the original
framework, which does not require access to the internals of the language
model. Instead, it identifies potential ideological steering by analyzing
distributional shifts in model outputs across prompts that are thematically
related to a chosen topic. This design makes the method particularly suitable
for auditing proprietary black-box systems. We validate our approach through a
series of experiments, demonstrating its practical applicability and its
potential to support independent post hoc audits of LLM behavior.

</details>


### [48] [Mitigating Strategy Preference Bias in Emotional Support Conversation via Uncertainty Estimations](https://arxiv.org/abs/2509.12661)
*Yougen Zhou,Qin Chen,Ningning Zhou,Jie Zhou,Xingjiao Wu,Liang He*

Main category: cs.CL

TL;DR: 本文针对情感支持对话中LLM的策略规划偏好问题，分析了根本成因，并提出强化学习结合双重奖励策略。实验结果显示新方法明显优于现有方案，提升了对话效果。


<details>
  <summary>Details</summary>
Motivation: 情感支持对话（ESC）旨在通过富有同理心的交流来缓解情绪困扰。然而，大型语言模型（LLMs）在策略规划的准确率较低，且存在偏好某些策略的倾向性（偏置）。以往方法虽然尝试使用微调的策略规划器降低此偏好，但对其根本原因缺乏深入研究。

Method: 首先揭示了LLMs在策略规划中的知识边界，从根本上分析优偏好产生原因。随后，提出了一种结合双重奖励函数的强化学习方法：该方法通过基于准确性和熵信心度，对应知识边界内不同区域进行优化，从而提升策略规划效果并缓解偏好偏置。

Result: 在ESCov和ExTES数据集上，结合多种LLM骨干模型进行实验，所提方法在策略规划方面优于基线模型。

Conclusion: 本文方法有效提升了情感支持对话中策略规划的准确度，并显著缓解了模型的策略偏好问题。

Abstract: Emotional support conversation (ESC) aims to alleviate distress through
empathetic dialogue, yet large language models (LLMs) face persistent
challenges in delivering effective ESC due to low accuracy in strategy
planning. Moreover, there is a considerable preference bias towards specific
strategies. Prior methods using fine-tuned strategy planners have shown
potential in reducing such bias, while the underlying causes of the preference
bias in LLMs have not well been studied. To address these issues, we first
reveal the fundamental causes of the bias by identifying the knowledge
boundaries of LLMs in strategy planning. Then, we propose an approach to
mitigate the bias by reinforcement learning with a dual reward function, which
optimizes strategy planning via both accuracy and entropy-based confidence for
each region according to the knowledge boundaries. Experiments on the ESCov and
ExTES datasets with multiple LLM backbones show that our approach outperforms
the baselines, confirming the effectiveness of our approach.

</details>


### [49] [Chat-Driven Text Generation and Interaction for Person Retrieval](https://arxiv.org/abs/2509.12662)
*Zequn Xie,Chuxin Wang,Sihang Cai,Yeqiang Wang,Shulei Wang,Tao Jin*

Main category: cs.CL

TL;DR: 本文针对文本描述人员检索的人工标注难题，提出了多轮文本生成和交互模块，实现了高质量无监督检索，提升各项表现且具有实际部署潜力。


<details>
  <summary>Details</summary>
Motivation: 自然语言文本描述的人员检索（TBPS）在安防领域具有重要价值，但高质量文本标注获取过程繁琐，导致该技术难以大规模实际应用。

Method: 提出两个互补模块：多轮文本生成（MTG）通过与多模态大模型（MLLMs）虚拟对话，生成高质量无监督的伪标签文本；多轮文本交互（MTI）在推理阶段通过动态对话推理机制，使系统能更好理解和完善用户模糊、不完整或歧义的描述。

Result: 该方法无需人工标注文本，显著提升了检索准确性、鲁棒性和易用性。实验证明，该方法取得了有竞争力或更优的性能，并为TBPS系统的大规模、实用部署提供了可行性。

Conclusion: 通过创新的MTG和MTI模块，本文实现了无需人工标注的高效TBPS方法，推动了该领域系统的实际应用发展。

Abstract: Text-based person search (TBPS) enables the retrieval of person images from
large-scale databases using natural language descriptions, offering critical
value in surveillance applications. However, a major challenge lies in the
labor-intensive process of obtaining high-quality textual annotations, which
limits scalability and practical deployment. To address this, we introduce two
complementary modules: Multi-Turn Text Generation (MTG) and Multi-Turn Text
Interaction (MTI). MTG generates rich pseudo-labels through simulated dialogues
with MLLMs, producing fine-grained and diverse visual descriptions without
manual supervision. MTI refines user queries at inference time through dynamic,
dialogue-based reasoning, enabling the system to interpret and resolve vague,
incomplete, or ambiguous descriptions - characteristics often seen in
real-world search scenarios. Together, MTG and MTI form a unified and
annotation-free framework that significantly improves retrieval accuracy,
robustness, and usability. Extensive evaluations demonstrate that our method
achieves competitive or superior results while eliminating the need for manual
captions, paving the way for scalable and practical deployment of TBPS systems.

</details>


### [50] [Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](https://arxiv.org/abs/2509.12672)
*Shaz Furniturewala,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 提出利用机制可解释性识别并主动抑制毒性检测模型中的脆弱神经网络组件，提升其对抗攻击的鲁棒性，并分析了不同群体的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 网络上的机器生成内容因LLMs的广泛使用迅速增长，对内容审核系统提出了新的挑战。传统的内容审核分类器主要训练于人类文本，无法很好应对LLM生成文本和躲避检测的对抗性攻击。现有防御方法多为被动应对，缺乏主动机制，亟需更有效的解决策略。

Method: 作者提出基于机械可解释性技术，分析并识别毒性分类器中易受攻击的组件（神经网络电路），以细调后的BERT和RoBERTa为例，通过对抗性攻击技术定位这些脆弱电路，并抑制其功能，从而提升对抗鲁棒性。还结合不同少数群体数据，探讨了公平性和鲁棒性问题。

Result: 识别出模型中有些注意力头对性能至关重要，但也有部分头容易受到攻击。抑制脆弱头能改善模型对抗输入时的表现。不同群体受影响的头不同，可为更具包容性的毒性检测模型开发提供参考。

Conclusion: 通过机制可解释性和主动抑制易攻击电路，能显著提升毒性分类器在对抗样本上的鲁棒性，并揭示不同数据群体下的公平性问题，为内容审核系统的安全与包容发展提供新思路。

Abstract: The volume of machine-generated content online has grown dramatically due to
the widespread use of Large Language Models (LLMs), leading to new challenges
for content moderation systems. Conventional content moderation classifiers,
which are usually trained on text produced by humans, suffer from
misclassifications due to LLM-generated text deviating from their training data
and adversarial attacks that aim to avoid detection. Present-day defence
tactics are reactive rather than proactive, since they rely on adversarial
training or external detection models to identify attacks. In this work, we aim
to identify the vulnerable components of toxicity classifiers that contribute
to misclassification, proposing a novel strategy based on mechanistic
interpretability techniques. Our study focuses on fine-tuned BERT and RoBERTa
classifiers, testing on diverse datasets spanning a variety of minority groups.
We use adversarial attacking techniques to identify vulnerable circuits.
Finally, we suppress these vulnerable circuits, improving performance against
adversarial attacks. We also provide demographic-level insights into these
vulnerable circuits, exposing fairness and robustness gaps in model training.
We find that models have distinct heads that are either crucial for performance
or vulnerable to attack and suppressing the vulnerable heads improves
performance on adversarial input. We also find that different heads are
responsible for vulnerability across different demographic groups, which can
inform more inclusive development of toxicity detection models.

</details>


### [51] [Case-Based Decision-Theoretic Decoding with Quality Memories](https://arxiv.org/abs/2509.12677)
*Hiroyuki Deguchi,Masaaki Nagata*

Main category: cs.CL

TL;DR: 本文提出CBDT解码方法，通过领域案例提升文本生成质量，与MBR联合使用效果最佳，在多个翻译和图像任务中优于传统解码方法。


<details>
  <summary>Details</summary>
Motivation: 传统MBR解码依赖生成模型的采样文本，在处理领域外知识时效果有限，需改进期望效用的估算方式以更好地捕捉领域内信息。

Method: 提出了一种基于案例的决策理论解码方法（CBDT），用于文本生成任务，通过领域实例估算解码期望效用，并在多领域的机器翻译与图像描述任务中进行评估。

Result: CBDT生成文本质量优于MAP解码，且MBR与CBDT结合在七个翻译任务和图像描述任务（MSCOCO和nocaps数据集）中均超越单独MBR。

Conclusion: CBDT解码方法通过利用领域数据案例，更准确估算期望效用，提升了生成文本的质量，结合MBR和CBDT比单独MBR解码表现更佳。

Abstract: Minimum Bayes risk (MBR) decoding is a decision rule of text generation,
which selects the hypothesis that maximizes the expected utility and robustly
generates higher-quality texts than maximum a posteriori (MAP) decoding.
However, it depends on sample texts drawn from the text generation model; thus,
it is difficult to find a hypothesis that correctly captures the knowledge or
information of out-of-domain. To tackle this issue, we propose case-based
decision-theoretic (CBDT) decoding, another method to estimate the expected
utility using examples of domain data. CBDT decoding not only generates
higher-quality texts than MAP decoding, but also the combination of MBR and
CBDT decoding outperformed MBR decoding in seven domain De--En and
Ja$\leftrightarrow$En translation tasks and image captioning tasks on MSCOCO
and nocaps datasets.

</details>


### [52] [HistoryBankQA: Multilingual Temporal Question Answering on Historical Events](https://arxiv.org/abs/2509.12720)
*Biswadip Mandal,Anant Khandelwal,Manish Gupta*

Main category: cs.CL

TL;DR: 本文提出了HistoryBank，一个包含1000万+历史事件的多语言数据库，并构建了多语言时序推理问答基准，评测多种LLM的时序理解能力，并公开代码数据。GPT4o在所有语言和任务上表现优异，Gemma-2领先其他小模型。


<details>
  <summary>Details</summary>
Motivation: 现有时序推理数据集规模有限、缺乏多语覆盖且偏重当代事件，无法系统评估LLM在历史事件时序推理上的能力。作者希望建立大规模、多语种覆盖、兼具历史深度的新资源，全面推进该方向基准测试与模型研究。

Method: 从英文及多语种维基百科中提取了超过1000万条历史事件形成HistoryBank数据库，涵盖10种语言。构建了涵盖6类时序推理任务的多语言时间问答基准，并在多个主流LLMs（如LLaMA-3-8B、Mistral-7B、Gemma-2-9b、Qwen3-8B、GPT4o）上进行了评测。

Result: 构建了大规模、多语言的历史事件数据库HistoryBank，并建立了多语言、覆盖多种时序推理题型的基准测试。GPT4o在所有任务和语言上表现最佳，Gemma-2在小型模型中表现突出。数据集和代码将在论文接收后公开。

Conclusion: GPT4o在所有任务和语言中表现最好，Gemma-2优于其他小型语言模型。作者开发的HistoryBank数据库和基准测试有效促进了多语言和时序相关的自然语言理解领域的发展。

Abstract: Temporal reasoning about historical events is a critical skill for NLP tasks
like event extraction, historical entity linking, temporal question answering,
timeline summarization, temporal event clustering and temporal natural language
inference. Yet efforts on benchmarking temporal reasoning capabilities of large
language models (LLMs) are rather limited. Existing temporal reasoning datasets
are limited in scale, lack multilingual coverage and focus more on contemporary
events. To address these limitations, we present HistoryBank, a multilingual
database of 10M+ historical events extracted from Wikipedia timeline pages and
article infoboxes. Our database provides unprecedented coverage in both
historical depth and linguistic breadth with 10 languages. Additionally, we
construct a comprehensive question answering benchmark for temporal reasoning
across all languages. This benchmark covers a diverse set of 6 temporal QA
reasoning tasks, and we evaluate a suite of popular language models
(LLaMA-3-8B, Mistral-7B, Gemma-2-9b, Qwen3-8B, GPT4o) to assess their
performance on these tasks. As expected GPT4o performs best across all answer
types and languages; Gemma-2 outperforms the other small language models. Our
work aims to provide a comprehensive resource for advancing multilingual and
temporally-aware natural language understanding of historical events. To
facilitate further research, we will make our code and datasets publicly
available upon acceptance of this paper.

</details>


### [53] [Contrastive Learning with Enhanced Abstract Representations using Grouped Loss of Abstract Semantic Supervision](https://arxiv.org/abs/2509.12771)
*Omri Suissa,Muhiim Ali,Shengmai Chen,Yinuo Cai,Shekhar Pradhan*

Main category: cs.CL

TL;DR: 作者提出MAGIC数据集和分组对比损失训练CLEAR GLASS模型，提升了视觉语言模型对图像抽象概念的识别能力，实验效果优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 人类可以超越对物体及其关系的基本识别，理解图像所表达的抽象概念，但当前视觉语言模型（VLMs）是否具备这一能力尚未充分研究。作者希望提升VLM在抽象概念层面的理解能力。

Method: 提出了MAGIC数据集，包含分组的图像-描述及其高阶概念标签。利用创新的分组对比损失（grouped contrastive loss），其中包含组间的对比损失（outer）和组内的对比损失（inner），使模型编码每组中图像-描述间的共性信息。此外，训练过程并未直接暴露高阶概念，而是让模型在隐空间生成靠近这些概念的表示。基于此方法训练出CLEAR GLASS模型。

Result: 实验表明，CLEAR GLASS模型在抽象概念识别任务上相比SOTA（当前最优）模型有更好的表现。

Conclusion: 通过引入分组对比损失和特殊的数据集构建方法，使得VLM模型在无需直接接触高阶概念的前提下，具备了更强的抽象概念识别能力。该方法推动了视觉语言模型在语义抽象层面的进步。

Abstract: Humans can recognize an image as an instance of a general concept, beyond
simply identifying its objects and their relationships. In this paper, we
investigate 1. The extent to which VLMs have this concept abstraction capacity,
and 2. Strategies for encoding the sort of higher-concept information in images
that would enable the resulting VLM model (CLEAR GLASS model) to have this
capability to a greater degree. To this end, we introduce a grouped
image-caption dataset (MAGIC), which consists of several groups of image
captions and for each group a set of associated images and higher-level
conceptual labels. We use a novel contrastive loss technique to induce the
model to encode in the representation of each image (caption) in a group the
information that is common to all members of the image-caption group. Our main
contribution is a grouped contrastive loss function based on text-image
contrastive groups (outer contrastive loss) as well as an inner loss which
measures the distances between image-caption instances in the group. Our
training methodology results in the CLEAR GLASS model having the concept
abstraction capacity as an emergent capacity because the model is not exposed
to the higher-level concepts associated with each group. Instead, the training
forces the model to create for each image-caption group a semantic
representation that brings it closer to the semantic representation of the
higher-level concepts in the latent semantic space. Our experiments show that
this training methodology results in a model which shows improvement in
abstract concept recognition compared to SOTA models.

</details>


### [54] [ConvergeWriter: Data-Driven Bottom-Up Article Construction](https://arxiv.org/abs/2509.12811)
*Binquan Ji,Jiaqi Wang,Ruiting Li,Xingchen Han,Yiyang Qi,Shichao Wang,Yifei Lu,Yuantao Han,Feiliang Ren*

Main category: cs.CL

TL;DR: 作者提出了一种基于“先检索知识后聚类结构”的自下而上的长文生成方法，显著提升了内容的准确性和条理性，在多个参数规模下都达到甚至超过了现有技术水平，对于需要高度可靠性的知识文档生成特别有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在文本生成方面表现优异，但在生成基于大规模外部知识库的长文本、事实性文档时仍面临挑战。现有自上而下的方法由于先规划结构后查找证据，常导致内容割裂和事实错误。

Method: 提出一种新颖的“自下而上”、数据驱动的生成框架，先从知识库进行全面检索，再用无监督聚类将检索结果组织成知识簇，以数据驱动的方式搭建文档结构，指导后续大纲生成及正文写作。

Result: 实验显示，在14B和32B参数规模的模型上，该方法与当前最先进的基线持平或表现更优，且在知识受限、高要求场景下具有独特优势。

Conclusion: 该工作为生成可靠、结构化的长文档提供了一种高效范式，有望推动LLM在高风险、知识密集型领域的实际应用。

Abstract: Large Language Models (LLMs) have shown remarkable prowess in text
generation, yet producing long-form, factual documents grounded in extensive
external knowledge bases remains a significant challenge. Existing "top-down"
methods, which first generate a hypothesis or outline and then retrieve
evidence, often suffer from a disconnect between the model's plan and the
available knowledge, leading to content fragmentation and factual inaccuracies.
To address these limitations, we propose a novel "bottom-up," data-driven
framework that inverts the conventional generation pipeline. Our approach is
predicated on a "Retrieval-First for Knowledge, Clustering for Structure"
strategy, which first establishes the "knowledge boundaries" of the source
corpus before any generative planning occurs. Specifically, we perform
exhaustive iterative retrieval from the knowledge base and then employ an
unsupervised clustering algorithm to organize the retrieved documents into
distinct "knowledge clusters." These clusters form an objective, data-driven
foundation that directly guides the subsequent generation of a hierarchical
outline and the final document content. This bottom-up process ensures that the
generated text is strictly constrained by and fully traceable to the source
material, proactively adapting to the finite scope of the knowledge base and
fundamentally mitigating the risk of hallucination. Experimental results on
both 14B and 32B parameter models demonstrate that our method achieves
performance comparable to or exceeding state-of-the-art baselines, and is
expected to demonstrate unique advantages in knowledge-constrained scenarios
that demand high fidelity and structural coherence. Our work presents an
effective paradigm for generating reliable, structured, long-form documents,
paving the way for more robust LLM applications in high-stakes,
knowledge-intensive domains.

</details>


### [55] [Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data](https://arxiv.org/abs/2509.12853)
*Kurt Micallef,Nizar Habash,Claudia Borg*

Main category: cs.CL

TL;DR: 本论文考察了如何利用阿拉伯语资源通过跨语言数据增强（如音译和机器翻译）提升马耳他语NLP能力，实验结果显示多种增强策略显著提升了马耳他语NLP任务表现。


<details>
  <summary>Details</summary>
Motivation: 马耳他语虽具有闪米特语的根源，但由于受意大利语和英语等罗曼语及日耳曼语的影响，其书写系统采用拉丁字母，与闪米特语家族中的阿拉伯语存在一定距离。受限于资源稀缺，研究者希望利用阿拉伯语资源通过跨语言增强，提升马耳他语自然语言处理的能力。

Method: 研究采用多种方法，将阿拉伯语文本与马耳他语对齐，包括不同的音译方案和机器翻译方法。同时，提出了新的音译系统以更准确地表现马耳他语的正字法。之后在单语及多语模型上评估这些增强手段的效果。

Result: 实验显示，基于阿拉伯语的跨语言增强对于马耳他语的NLP任务有显著正面作用。

Conclusion: 阿拉伯语资源通过跨语言增强确实能提升马耳他语的NLP表现，尤其在资源稀缺场景下效果明显。

Abstract: Maltese is a unique Semitic language that has evolved under extensive
influence from Romance and Germanic languages, particularly Italian and
English. Despite its Semitic roots, its orthography is based on the Latin
script, creating a gap between it and its closest linguistic relatives in
Arabic. In this paper, we explore whether Arabic-language resources can support
Maltese natural language processing (NLP) through cross-lingual augmentation
techniques. We investigate multiple strategies for aligning Arabic textual data
with Maltese, including various transliteration schemes and machine translation
(MT) approaches. As part of this, we also introduce novel transliteration
systems that better represent Maltese orthography. We evaluate the impact of
these augmentations on monolingual and mutlilingual models and demonstrate that
Arabic-based augmentation can significantly benefit Maltese NLP tasks.

</details>


### [56] [Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents](https://arxiv.org/abs/2509.12876)
*Fuyu Xing,Zimu Wang,Wei Wang,Haiyang Zhang*

Main category: cs.CL

TL;DR: 首次系统性评估LVLMs在多媒体事件抽取任务上的表现，发现其跨模态协同有明显优势，但在文本任务及细致对齐方面仍有挑战，微调可大幅提升性能。


<details>
  <summary>Details</summary>
Motivation: 多媒体内容的激增迫切需要高效的多媒体事件抽取（M2E2）系统。然而，大型视觉-语言模型（LVLMs）在这一任务中的作用尚未被深入探讨。

Method: 首次系统性评估了代表性LVLMs（如DeepSeek-VL2和Qwen-VL系列）在M2E2数据集上的表现。评估涵盖文本、图像以及跨媒体子任务，并在少样本提示与微调两种条件下进行。还进行了详细的错误分析。

Result: 主要发现：1）LVLMs在少样本场景下视觉任务表现优异，但文本任务表现不佳；2）通过LoRA微调显著提升了模型性能；3）多模态信息融合带来的模型性能增益明显，跨模态环境下取得最佳表现。同时，模型在语义精度、定位与跨模态对齐等方面仍存难点。

Conclusion: 当前LVLMs在多媒体事件抽取任务中展现出跨模态协同优势，但在文本理解和细粒度对齐等方面仍需进一步提升，未来需针对语义精度和跨模态能力持续优化。

Abstract: The proliferation of multimedia content necessitates the development of
effective Multimedia Event Extraction (M2E2) systems. Though Large
Vision-Language Models (LVLMs) have shown strong cross-modal capabilities,
their utility in the M2E2 task remains underexplored. In this paper, we present
the first systematic evaluation of representative LVLMs, including DeepSeek-VL2
and the Qwen-VL series, on the M2E2 dataset. Our evaluations cover text-only,
image-only, and cross-media subtasks, assessed under both few-shot prompting
and fine-tuning settings. Our key findings highlight the following valuable
insights: (1) Few-shot LVLMs perform notably better on visual tasks but
struggle significantly with textual tasks; (2) Fine-tuning LVLMs with LoRA
substantially enhances model performance; and (3) LVLMs exhibit strong synergy
when combining modalities, achieving superior performance in cross-modal
settings. We further provide a detailed error analysis to reveal persistent
challenges in areas such as semantic precision, localization, and cross-modal
grounding, which remain critical obstacles for advancing M2E2 capabilities.

</details>


### [57] [The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations](https://arxiv.org/abs/2509.12886)
*Yubo Zhu,Dongrui Liu,Zecheng Lin,Wei Tong,Sheng Zhong,Jing Shao*

Main category: cs.CL

TL;DR: 作者提出了一种只用隐藏状态就能高效准确估计LLM输入难度的新方法，在多种任务上优于现有方法，并助力推理效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）对输入问题难度的感知估计方法，往往依赖于多次采样、辅助模型或对目标模型的微调，这会带来大量计算开销或影响模型的通用性，因此急需更高效、泛用的新方法。

Method: 本论文提出以隐藏表示为基础的难度估计方法：将token生成过程建模为马尔可夫链，并借助价值函数在任何隐藏状态下估计预期输出质量，只需依赖初始隐藏状态即可高效、准确地评估难度，无需生成输出。

Result: 在文本和多模态任务中的广泛实验表明，该方法在困难估计上稳定优于各种现有方法。同时，该难度估计可以用以指导自适应推理策略（如Self-Consistency、Best-of-N和Self-Refine），有效提升推理效率，减少生成token数量。

Conclusion: 以隐藏状态为基础的难度估计方法在准确性、效率和泛用性方面优于传统方法，并显著提升模型的推理表现。

Abstract: Estimating the difficulty of input questions as perceived by large language
models (LLMs) is essential for accurate performance evaluation and adaptive
inference. Existing methods typically rely on repeated response sampling,
auxiliary models, or fine-tuning the target model itself, which may incur
substantial computational costs or compromise generality. In this paper, we
propose a novel approach for difficulty estimation that leverages only the
hidden representations produced by the target LLM. We model the token-level
generation process as a Markov chain and define a value function to estimate
the expected output quality given any hidden state. This allows for efficient
and accurate difficulty estimation based solely on the initial hidden state,
without generating any output tokens. Extensive experiments across both textual
and multimodal tasks demonstrate that our method consistently outperforms
existing baselines in difficulty estimation. Moreover, we apply our difficulty
estimates to guide adaptive reasoning strategies, including Self-Consistency,
Best-of-N, and Self-Refine, achieving higher inference efficiency with fewer
generated tokens.

</details>


### [58] [Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings](https://arxiv.org/abs/2509.12892)
*Shiyu Li,Yang Tang,Ruijie Liu,Shi-Zhe Chen,Xi Chen*

Main category: cs.CL

TL;DR: 本文提出Conan-embedding-v2，一款从头训练并专门优化的文本嵌入LLM，通过创新的数据和训练方法，参数量小但在多语言嵌入任务上取得最先进表现。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLM）在文本嵌入任务上表现优异，但现有方法如LoRA微调受限于LLM与嵌入模型之间的数据和训练方式的差异。需要弥合这一差距以提升嵌入性能。

Method: 1. 从头训练一个1.4B参数的LLM，并微调为文本嵌入模型。2. 预训练时加入新闻与多语对数据，缩小数据差距。3. 构建跨语言检索数据集，实现不同语言嵌入整合。4. 提出软掩码机制，实现从因果掩码到双向掩码的平滑过渡。5. 动态硬负样本挖掘，训练过程中不断引入更难负样本。

Result: Conan-embedding-v2模型参数仅1.4亿，在英语与中文的MTEB基准上达到最新最强（SOTA）性能。

Conclusion: 通过软掩码与数据设计，成功缩小LLM与嵌入模型训练与数据差距，开发出高效且表现优异的Conan-embedding-v2嵌入模型。

Abstract: Large language models (LLMs) have recently demonstrated excellent performance
in text embedding tasks. Previous work usually use LoRA to fine-tune existing
LLMs, which are limited by the data and training gap between LLMs and embedding
models. In this work, we introduce Conan-embedding-v2, a new 1.4B-parameter LLM
trained from scratch and fine-tuned as a text embedder. First, we add news data
and multilingual pairs for LLM pretraining to bridge the data gap. Based on
this, we propose a cross-lingual retrieval dataset that enables the LLM to
better integrate embeddings across different languages. Second, whereas LLMs
use a causal mask with token-level loss, embedding models use a bidirectional
mask with sentence-level loss. This training gap makes full fine-tuning less
effective than LoRA. We introduce a soft-masking mechanism to gradually
transition between these two types of masks, enabling the model to learn more
comprehensive representations. Based on this, we propose a dynamic hard
negative mining method that exposes the model to more difficult negative
examples throughout the training process. Being intuitive and effective, with
only approximately 1.4B parameters, Conan-embedding-v2 achieves SOTA
performance on both the Massive Text Embedding Benchmark (MTEB) and Chinese
MTEB (May 19, 2025).

</details>


### [59] [All Roads Lead to Rome: Graph-Based Confidence Estimation for Large Language Model Reasoning](https://arxiv.org/abs/2509.12908)
*Caiqi Zhang,Chang Shu,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 该论文针对推理任务提出了无需训练、基于推理路径图结构的置信度估计方法，并通过多项实验验证了其能有效提升置信度估计和下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法主要针对事实问答任务，难以泛化到推理任务，造成模型在推理任务中可靠性不足。

Method: 采用训练无关、基于图结构的方法，通过建模推理路径为有向图，利用中心性、路径收敛、路径加权等图属性估算置信度。

Result: 在两种大语言模型和三个推理数据集上的实验表明，提出的方法提升了置信度估计准确性，并在两个下游任务上取得了更好的性能。

Conclusion: 提出的方法提升了大语言模型在推理任务中的置信度估计效果，对下游任务的性能有所增强。

Abstract: Confidence estimation is essential for the reliable deployment of large
language models (LLMs). Existing methods are primarily designed for factual QA
tasks and often fail to generalize to reasoning tasks. To address this gap, we
propose a set of training-free, graph-based confidence estimation methods
tailored to reasoning tasks. Our approach models reasoning paths as directed
graphs and estimates confidence by exploiting graph properties such as
centrality, path convergence, and path weighting. Experiments with two LLMs on
three reasoning datasets demonstrate improved confidence estimation and
enhanced performance on two downstream tasks.

</details>


### [60] [Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework](https://arxiv.org/abs/2509.12955)
*Heng Zhang,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 该论文针对现有流程提取方法碎片化、难以还原完整科研流程的问题，提出了基于深度学习和大模型的自动化流程挖掘框架，并在NLP领域进行了实证，能高效生成结构化流程图。结果显示方法性能优异，同时揭示了科研范式的演变趋势，对AI助力科学研究具有重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 现有的研究方法通常只能提取零散的流程组成部分，难以获取完整的研究工作流程，这限制了科研的可复现性和"AI促进科学"的发展。为了解决这个问题，作者希望提出能够自动生成结构化、完整研究流程的技术框架。

Method: 提出了一种端到端的流程挖掘框架，针对NLP领域的论文。主要方法包括：1）用PU学习和SciBERT模型识别描述研究流程的段落；2）利用Flan-T5和提示学习生成工作流程短语；3）结合ChatGPT和少样本学习将短语分为数据准备、数据处理和数据分析三阶段，最后通过定位短语在原文中的位置生成流程图。

Result: 该框架在段落识别环节F1值达0.9772，流程短语生成环节ROUGE-1达0.4543，ROUGE-2达0.2877，ROUGE-L达0.4427，分类精度为0.958。生成的流程图反映了领域发展趋势，如对数据分析重视度增强、从特征工程转向消融研究等。相关源代码与数据已公开。

Conclusion: 作者提出的自动化研究流程生成框架能够从学术论文中挖掘并可视化完整工作流程，为理解科学方法的发展变化提供新角度，对提升研究可复现性和促进AI在科学领域应用具有重要意义。

Abstract: The automated generation of research workflows is essential for improving the
reproducibility of research and accelerating the paradigm of "AI for Science".
However, existing methods typically extract merely fragmented procedural
components and thus fail to capture complete research workflows. To address
this gap, we propose an end-to-end framework that generates comprehensive,
structured research workflows by mining full-text academic papers. As a case
study in the Natural Language Processing (NLP) domain, our paragraph-centric
approach first employs Positive-Unlabeled (PU) Learning with SciBERT to
identify workflow-descriptive paragraphs, achieving an F1-score of 0.9772.
Subsequently, we utilize Flan-T5 with prompt learning to generate workflow
phrases from these paragraphs, yielding ROUGE-1, ROUGE-2, and ROUGE-L scores of
0.4543, 0.2877, and 0.4427, respectively. These phrases are then systematically
categorized into data preparation, data processing, and data analysis stages
using ChatGPT with few-shot learning, achieving a classification precision of
0.958. By mapping categorized phrases to their document locations in the
documents, we finally generate readable visual flowcharts of the entire
research workflows. This approach facilitates the analysis of workflows derived
from an NLP corpus and reveals key methodological shifts over the past two
decades, including the increasing emphasis on data analysis and the transition
from feature engineering to ablation studies. Our work offers a validated
technical framework for automated workflow generation, along with a novel,
process-oriented perspective for the empirical investigation of evolving
scientific paradigms. Source code and data are available at:
https://github.com/ZH-heng/research_workflow.

</details>


### [61] [Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models](https://arxiv.org/abs/2509.12960)
*Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 本文发现，ReLoRA等低秩方法在小语言模型的预训练上效果较差，且随着模型变大差距扩大，主要原因是加剧了小模型的秩缺陷问题，提示未来需针对低算力环境的创新。


<details>
  <summary>Details</summary>
Motivation: LoRA等参数高效微调方法已在大模型微调中取得较大成功，但其在预训练场景、特别是小语言模型（SLMs）上的扩展（ReLoRA）尚不清楚。然而小模型因计算和环境成本低，具有广泛应用前景。本文旨在系统性探究ReLoRA在小模型上的表现及其机制。

Method: 系统性实验研究了ReLoRA在11M-66M参数规模的小语言模型预训练中的表现，涵盖性能评估（如loss、Paloma perplexity、BLiMP），并通过消融实验深入分析ReLoRA影响学习动态的机制。

Result: 实验显示，ReLoRA在小模型预训练下表现普遍不如传统训练方法，且随着模型参数增加，ReLoRA与标准训练间的性能差距进一步扩大。进一步分析显示ReLoRA加剧了小模型中已存在的秩缺陷问题。

Conclusion: 低秩更新方法（如ReLoRA）在小模型预训练中的效果不理想，不能直接移植大模型的成功经验，表明低算力场景下需进一步创新参数高效预训练方法。

Abstract: Parameter-efficient methods such as LoRA have revolutionised the fine-tuning
of LLMs. Still, their extension to pretraining via ReLoRA is less well
understood, especially for small language models (SLMs), which offer lower
computational and environmental costs. This work is the first systematic study
of ReLoRA in SLMs (11M-66M parameters), evaluating both performance and
learning dynamics. Through ablation experiments, we find that ReLoRA generally
performs worse than standard training on loss, Paloma perplexity and BLiMP,
with the gap widening for the larger models. Further analysis of the learning
dynamics of the models indicates that ReLoRA reinforces the rank deficiencies
found in smaller models. These results indicate that low-rank update strategies
may not transfer easily to SLM pretraining, highlighting the need for more
research in the low-compute regime.

</details>


### [62] [Do LLMs Understand Wine Descriptors Across Cultures? A Benchmark for Cultural Adaptations of Wine Reviews](https://arxiv.org/abs/2509.12961)
*Chenye Zou,Xingyue Wen,Tianyi Hu,Qian Janice Wang,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 本文首次探讨中英葡萄酒评论的跨文化自适应翻译，构建对齐语料库并评测主流及前沿模型，在提出新的人文评价指标后发现现有模型难以处理文化细节，提示提升跨文化翻译能力仍需努力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在文化相关语言任务中展现出很大潜力，但在实际跨文化文本翻译中，如葡萄酒评论，往往仅停留在字面翻译，忽略了地区性口味偏好和文化特有风味描述。本文旨在推动跨文化自适应翻译研究，特别是在中英两种文化下的葡萄酒评论领域。

Method: 作者构建了首个跨文化专业葡萄酒评论平行语料库，包含8000条中文和16000条英语评论。在此基础上，利用神经机器翻译模型和最先进的LLM对翻译效果进行基准测试。评估方式包括自动指标和人工评测。人工评测提出了三项文化相关评价标准：文化贴近性、文化中立性和文化真实感，用于衡量翻译内容在目标文化受众中的自然度和认可度。

Result: 实验表明，现有的机翻模型和大语言模型在跨文化细节处理上存在不足，尤其是在葡萄酒描述等高度文化敏感的文本翻译时，无法准确捕捉和映射文化差异。这反映出现有技术在文化信息处理上的挑战和局限。

Conclusion: 翻译模型在处理包含显著文化差异的文本（如葡萄酒评论）时，尚未能良好适应不同文化的表达和理解需求。应进一步加强文化意识相关的模型设计和训练数据构建。

Abstract: Recent advances in large language models (LLMs) have opened the door to
culture-aware language tasks. We introduce the novel problem of adapting wine
reviews across Chinese and English, which goes beyond literal translation by
incorporating regional taste preferences and culture-specific flavor
descriptors. In a case study on cross-cultural wine review adaptation, we
compile the first parallel corpus of professional reviews, containing 8k
Chinese and 16k Anglophone reviews. We benchmark both
neural-machine-translation baselines and state-of-the-art LLMs with automatic
metrics and human evaluation. For the latter, we propose three culture-oriented
criteria -- Cultural Proximity, Cultural Neutrality, and Cultural Genuineness
-- to assess how naturally a translated review resonates with target-culture
readers. Our analysis shows that current models struggle to capture cultural
nuances, especially in translating wine descriptions across different cultures.
This highlights the challenges and limitations of translation models in
handling cultural content.

</details>


### [63] [SitLLM: Large Language Models for Sitting Posture Health Understanding via Pressure Sensor Data](https://arxiv.org/abs/2509.12994)
*Jian Gao,Fufangchen Zhao,Yiyang Zhang,Danfeng Yan*

Main category: cs.CL

TL;DR: SitLLM结合压力传感与大语言模型，实现更细致、个性化的坐姿监测与健康反馈，比传统方法更智能和实用。


<details>
  <summary>Details</summary>
Motivation: 现有的坐姿监测系统往往只能进行粗粒度识别，且缺乏足够的语义表达能力，不能为用户提供个性化的健康反馈。随着长期不良坐姿导致肌肉骨骼及生理系统的损伤和异常，如何实现更细腻、可解释、个性化的坐姿监测变得十分重要。

Method: 提出了SitLLM，这是一个轻量级多模态框架，结合了灵活的压力传感与大语言模型。具体包括三个模块：（1）高斯鲁棒传感器嵌入模块，对压力图进行空间分块，并注入局部噪声来增强特征鲁棒性；（2）基于提示的跨模态对齐模块，通过多头交叉注意力将传感器嵌入重新编入大语言模型的语义空间，利用预训练词嵌入；（3）多上下文提示模块，将特征、结构、统计和语义多种上下文信息融合，用于指导指令理解。

Result: SitLLM框架能够实现细粒度、高鲁棒性的坐姿理解，同时为用户生成个性化、健康导向的响应。有效解决了传统方法识别粗糙、反馈有限的瓶颈，提升了坐姿监测系统的实用性和智能化水平。

Conclusion: 将压力传感与大语言模型结合，可实现更细致与个性化坐姿监测，有助于预防长期不良坐姿引发的健康问题。SitLLM展现了多模态智能健康监护的广阔应用前景。

Abstract: Poor sitting posture is a critical yet often overlooked factor contributing
to long-term musculoskeletal disorders and physiological dysfunctions. Existing
sitting posture monitoring systems, although leveraging visual, IMU, or
pressure-based modalities, often suffer from coarse-grained recognition and
lack the semantic expressiveness necessary for personalized feedback. In this
paper, we propose \textbf{SitLLM}, a lightweight multimodal framework that
integrates flexible pressure sensing with large language models (LLMs) to
enable fine-grained posture understanding and personalized health-oriented
response generation. SitLLM comprises three key components: (1) a
\textit{Gaussian-Robust Sensor Embedding Module} that partitions pressure maps
into spatial patches and injects local noise perturbations for robust feature
extraction; (2) a \textit{Prompt-Driven Cross-Modal Alignment Module} that
reprograms sensor embeddings into the LLM's semantic space via multi-head
cross-attention using the pre-trained vocabulary embeddings; and (3) a
\textit{Multi-Context Prompt Module} that fuses feature-level, structure-level,
statistical-level, and semantic-level contextual information to guide
instruction comprehension.

</details>


### [64] [Multi-Model Synthetic Training for Mission-Critical Small Language Models](https://arxiv.org/abs/2509.13047)
*Nolan Platt,Pragyansmita Nayak*

Main category: cs.CL

TL;DR: 用大型语言模型合成问答数据，训练小模型并用于海事智能，显著降低成本且准确率接近大模型，为专业AI数据构建提供新方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多领域表现优异，但在专业领域的应用受限于缺乏高质量、特定领域的训练数据，手工标注高昂且难以获得。

Method: 提出利用LLM作为一次性教师，通过多模型协同生成（GPT-4o和o3-mini），将32亿条AIS船只追踪记录转化为21,543组合成问答数据，随后微调较小的Qwen2.5-7B模型，实现高效知识迁移。

Result: 微调后的Qwen2.5-7B模型在海事任务上达到75%准确率，并且推理成本比直接用大模型低261倍。经充分微调的小模型能以远低于大型模型的成本，取得相近准确率。

Conclusion: 方法极大降低了特定领域AI高质量训练数据的构建成本，验证了小模型在合成数据训练下的可行性与经济性，并为人工难以注释的专业领域提供了高复用性的方案与框架。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
many domains, yet their application to specialized fields remains constrained
by the scarcity and complexity of domain-specific training data. We present a
novel approach that achieves a 261x cost reduction for maritime intelligence by
using LLMs as one-time teachers rather than using them directly for inference.
Our method transforms 3.2 billion Automatic Identification System (AIS) vessel
tracking records into 21,543 synthetic question and answer pairs through
multi-model generation (GPT-4o and o3-mini), preventing overfitting and
ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves
75% accuracy on maritime tasks, while being substantially cheaper than using a
larger model for inference. We show that smaller, cheaper models -- when fine
tuned properly -- can provide similar accuracy compared to larger models that
are prohibitively expensive. Our work contributes to the growing field of
synthetic dataset generation for specialized AI applications and presents a
highly reproducible framework for domains where manual annotation is
infeasible. Beyond expanding research in the growing field of specialized small
language models, our approach has immediate applications in maritime safety,
security operations, and vessel traffic management systems in various
industries.

</details>


### [65] [Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO](https://arxiv.org/abs/2509.13081)
*Francesco Pappone,Ruggero Marino Lazzaroni,Federico Califano,Niccolò Gentile,Roberto Marras*

Main category: cs.CL

TL;DR: 本文提出一种结合小型encoder语义奖励模型的强化学习方法，在意大利医学院入学考试生成解释任务中，显著提升了解释质量，优于传统有监督微调。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在生成类似人类文本方面表现优秀，但要使其输出符合诸如教学合理性等复杂的定性目标仍存在挑战。现有强化学习方法要么依赖缓慢且成本高的“LLM判官”评估，要么依赖脆弱、仅基于关键词的指标（如ROUGE），难以捕捉高质量解释的语义本质。

Method: 作者提出在Group Relative Policy Optimisation（GRPO）框架下，采用小型高效的encoder-only transformer作为语义奖励模型。该模型基于生成解释与参考答案之间的余弦相似度产生密集、语义丰富的奖励信号，引导模型输出不仅事实正确，还在结构和概念上与专家推理一致。方法应用于意大利医学院入学考试模型的训练，经过领域自适应持续预训练（CPT）和有监督微调（SFT）。

Result: 采用所提出的语义奖励下的GRPO极大提升了模型解释的忠实性与清晰度，相比于强基线SFT方法效果更好，验证了轻量encoder模型在复杂生成任务中实现细致奖励塑造的有效性。

Conclusion: 小型、高效的encoder-only transformer语义奖励模型在复杂文本生成强化学习中，可以有效提升输出质量，尤其是解释的合理性和清晰度。

Abstract: While Large Language Models (LLMs) excel at generating human-like text,
aligning their outputs with complex, qualitative goals like pedagogical
soundness remains a significant challenge. Standard reinforcement learning
techniques often rely on slow and expensive LLM-as-a-judge evaluations or on
brittle, keyword-based metrics like ROUGE, which fail to capture the semantic
essence of a high-quality explanation. In this work, we introduce a novel
approach to reward shaping within the Group Relative Policy Optimisation (GRPO)
framework. Our central contribution is the use of a small, efficient
encoder-only transformer as a semantic reward model. This model provides a
dense, semantically rich reward signal based on the cosine similarity between a
generated explanation and a ground-truth reference, guiding the policy towards
explanations that are not just factually correct but also structurally and
conceptually aligned with expert reasoning. We apply this method to the task of
training a model for the Italian medical-school entrance examinations,
following standard domain-adaptive continued pre-training (CPT) and supervised
fine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic
reward significantly improves explanation faithfulness and clarity over a
strong SFT baseline, showcasing the power of using lightweight encoder models
for nuanced reward shaping in complex generation tasks

</details>


### [66] [Empowering LLMs with Parameterized Skills for Adversarial Long-Horizon Planning](https://arxiv.org/abs/2509.13127)
*Sijia Cui,Shuai Xu,Aiyao He,Yanna Wang,Bo Xu*

Main category: cs.CL

TL;DR: PLAP框架通过将LLM能力与参数化技能结合，显著提高了AI长序列任务规划与执行能力，在MicroRTS等复杂环境下取得优异表现、超越多项传统和基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在复杂长期和对抗环境下，难以直接产出可靠低级动作，或者过度依赖专家经验；亟需新的架构提升LLM的实际操作能力和泛化能力。

Method: 提出了PLAP（以语言规划、以参数行动）整体框架，包括技能库、LLM驱动的技能规划器和技能执行器，实现并在MicroRTS环境中评测。

Result: GPT-4o驱动的PLAP在零样本设定下超过80%基线代理，Qwen2-72B驱动的PLAP利用精心设计的样例超过顶级脚本代理（CoacAI）。还测试8种LLM并公布了相关排行榜。

Conclusion: PLAP框架显著提升了LLM驱动AI代理在复杂长期环境下的任务执行表现，多个主流LLM在该框架下取得了较优性能，并公布了相关排行榜和代码。

Abstract: Recent advancements in Large Language Models(LLMs) have led to the
development of LLM-based AI agents. A key challenge is the creation of agents
that can effectively ground themselves in complex, adversarial long-horizon
environments. Existing methods mainly focus on (1) using LLMs as policies to
interact with the environment through generating low-level feasible actions,
and (2) utilizing LLMs to generate high-level tasks or language guides to
stimulate action generation. However, the former struggles to generate reliable
actions, while the latter relies heavily on expert experience to translate
high-level tasks into specific action sequences. To address these challenges,
we introduce the Plan with Language, Act with Parameter (PLAP) planning
framework that facilitates the grounding of LLM-based agents in long-horizon
environments. The PLAP method comprises three key components: (1) a skill
library containing environment-specific parameterized skills, (2) a skill
planner powered by LLMs, and (3) a skill executor converting the parameterized
skills into executable action sequences. We implement PLAP in MicroRTS, a
long-horizon real-time strategy game that provides an unfamiliar and
challenging environment for LLMs. The experimental results demonstrate the
effectiveness of PLAP. In particular, GPT-4o-driven PLAP in a zero-shot setting
outperforms 80% of baseline agents, and Qwen2-72B-driven PLAP, with carefully
crafted few-shot examples, surpasses the top-tier scripted agent, CoacAI.
Additionally, we design comprehensive evaluation metrics and test 6
closed-source and 2 open-source LLMs within the PLAP framework, ultimately
releasing an LLM leaderboard ranking long-horizon skill planning ability. Our
code is available at https://github.com/AI-Research-TeamX/PLAP.

</details>


### [67] [LLM Hallucination Detection: A Fast Fourier Transform Method Based on Hidden Layer Temporal Signals](https://arxiv.org/abs/2509.13154)
*Jinxin Li,Gang Tu,ShengYu Cheng,Junjie Hu,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的LLM幻觉检测方法HSAD，利用隐藏状态信号的频域特征进行识别，有效提升了检测效果和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在应用到高可靠性场景时，幻觉（hallucination）问题是一个关键障碍。现有检测方法受限于知识覆盖和无法动态分析推理过程，导致效果和鲁棒性有限。本文旨在提出更高效、鲁棒的幻觉检测方法。

Method: 提出了HSAD（基于隐藏信号分析的检测）框架，通过采集LLMs在生成过程中的隐藏激活信号，通过快速傅里叶变换（FFT）转为频域特征，提取最强非直流分量作为谱特征，并结合自回归特性选择最佳观测点进行检测。

Result: 在包括TruthfulQA等多项基准上，HSAD比之前最先进的方法提高了10个百分点以上。

Conclusion: 结合推理过程建模和频域分析，HSAD为鲁棒性强的大语言模型幻觉检测建立了新范式。

Abstract: Hallucination remains a critical barrier for deploying large language models
(LLMs) in reliability-sensitive applications. Existing detection methods
largely fall into two categories: factuality checking, which is fundamentally
constrained by external knowledge coverage, and static hidden-state analysis,
that fails to capture deviations in reasoning dynamics. As a result, their
effectiveness and robustness remain limited. We propose HSAD (Hidden Signal
Analysis-based Detection), a novel hallucination detection framework that
models the temporal dynamics of hidden representations during autoregressive
generation. HSAD constructs hidden-layer signals by sampling activations across
layers, applies Fast Fourier Transform (FFT) to obtain frequency-domain
representations, and extracts the strongest non-DC frequency component as
spectral features. Furthermore, by leveraging the autoregressive nature of
LLMs, HSAD identifies optimal observation points for effective and reliable
detection. Across multiple benchmarks, including TruthfulQA, HSAD achieves over
10 percentage points improvement compared to prior state-of-the-art methods. By
integrating reasoning-process modeling with frequency-domain analysis, HSAD
establishes a new paradigm for robust hallucination detection in LLMs.

</details>


### [68] [The Few-shot Dilemma: Over-prompting Large Language Models](https://arxiv.org/abs/2509.13196)
*Yongjian Tang,Doruk Tuncel,Christian Koerner,Thomas Runkler*

Main category: cs.CL

TL;DR: 论文发现大型语言模型在few-shot学习时，示例数量过多反而会损害性能，通过精细化选择和优化示例数量，可以避免过度提示并提升实际任务表现。


<details>
  <summary>Details</summary>
Motivation: 以往观点认为在prompt中加入更多相关的few-shot示例能提升大型语言模型（LLM）性能，但实际发现过多示例可能导致性能下降，即过度提示（over-prompting）的问题。论文旨在解释和解决这一few-shot困境。

Method: 提出一个prompt设计框架，利用三种标准few-shot选择方法：随机抽样、语义嵌入和TF-IDF向量，并在多个LLM上（包括GPT-4o、GPT-3.5-turbo、DeepSeek-V3、Gemma-3、LLaMA-3.1、LLaMA-3.2、Mistral）进行跨模型实验。进一步在两个真实的软件需求分类数据集上，通过逐步增加TF-IDF选择和分层few-shot示例，探索每个模型的最佳示例数量。

Result: 实验表明，过多领域相关示例会导致部分LLM性能下降，否定了“越多越好”的既有经验。通过优化示例数量，结合TF-IDF选择和分层策略，获得最佳性能，并在功能与非功能需求分类任务上超过现有最优方法1%。

Conclusion: 合理选择和控制few-shot示例的数量，比一味增加相关示例效果更佳，有效规避过度提示现象，在实际需求分类中能提升LLM表现。研究为prompt设计和应用提供了新见解。

Abstract: Over-prompting, a phenomenon where excessive examples in prompts lead to
diminished performance in Large Language Models (LLMs), challenges the
conventional wisdom about in-context few-shot learning. To investigate this
few-shot dilemma, we outline a prompting framework that leverages three
standard few-shot selection methods - random sampling, semantic embedding, and
TF-IDF vectors - and evaluate these methods across multiple LLMs, including
GPT-4o, GPT-3.5-turbo, DeepSeek-V3, Gemma-3, LLaMA-3.1, LLaMA-3.2, and Mistral.
Our experimental results reveal that incorporating excessive domain-specific
examples into prompts can paradoxically degrade performance in certain LLMs,
which contradicts the prior empirical conclusion that more relevant few-shot
examples universally benefit LLMs. Given the trend of LLM-assisted software
engineering and requirement analysis, we experiment with two real-world
software requirement classification datasets. By gradually increasing the
number of TF-IDF-selected and stratified few-shot examples, we identify their
optimal quantity for each LLM. This combined approach achieves superior
performance with fewer examples, avoiding the over-prompting problem, thus
surpassing the state-of-the-art by 1% in classifying functional and
non-functional requirements.

</details>


### [69] [Evaluating LLM Alignment on Personality Inference from Real-World Interview Data](https://arxiv.org/abs/2509.13244)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 现有LLM人格推断与真实人格结构吻合度较低，不同建模方式改善有限。该研究暴露了模型在人格理解方面的瓶颈，并指出了未来提升对齐性的方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）被广泛应用于需要理解心理细微差别的领域（如情感支持、咨询等），但其对人类个性特质的理解能力依然未被充分探索，尤其是在自然对话环境下。

Method: 本文构建了一个新基准数据集，包括半结构化访谈文本及连续型Big Five人格评价分数，系统评估了三种模型范式：（1）GPT-4.1 Mini的零样本和链式思维提示；（2）基于LoRA的RoBERTa和Meta-LLaMA微调；（3）利用预训练BERT和OpenAI text-embedding-3-small的静态嵌入做回归。

Result: 所有模型预测人格分数与真实分数之间的Pearson相关系数均低于0.26，说明当前LLM与验证过的人格结构的对齐性有限。链式思维提示对性能提升有限，表明人格推断更多依赖语义表征。

Conclusion: 现有大语言模型很难准确对齐并理解人类复杂人格特质。未来亟需开展面向特质的提示设计、上下文感知建模和以对齐为目的的模型微调。

Abstract: Large Language Models (LLMs) are increasingly deployed in roles requiring
nuanced psychological understanding, such as emotional support agents,
counselors, and decision-making assistants. However, their ability to interpret
human personality traits, a critical aspect of such applications, remains
unexplored, particularly in ecologically valid conversational settings. While
prior work has simulated LLM "personas" using discrete Big Five labels on
social media data, the alignment of LLMs with continuous, ground-truth
personality assessments derived from natural interactions is largely
unexamined. To address this gap, we introduce a novel benchmark comprising
semi-structured interview transcripts paired with validated continuous Big Five
trait scores. Using this dataset, we systematically evaluate LLM performance
across three paradigms: (1) zero-shot and chain-of-thought prompting with
GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA
architectures, and (3) regression using static embeddings from pretrained BERT
and OpenAI's text-embedding-3-small. Our results reveal that all Pearson
correlations between model predictions and ground-truth personality traits
remain below 0.26, highlighting the limited alignment of current LLMs with
validated psychological constructs. Chain-of-thought prompting offers minimal
gains over zero-shot, suggesting that personality inference relies more on
latent semantic representation than explicit reasoning. These findings
underscore the challenges of aligning LLMs with complex human attributes and
motivate future work on trait-specific prompting, context-aware modeling, and
alignment-oriented fine-tuning.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [70] [A Variety of Request-Response Specifications](https://arxiv.org/abs/2509.13078)
*Daichi Aiba,Masaki Waga,Hiroya Fujinami,Koko Muroya,Shutaro Ouchi,Naoki Ueda,Yosuke Yokoyama,Yuta Wada,Ichiro Hasuo*

Main category: cs.FL

TL;DR: 论文系统梳理了request-response规范的六种变体，给出决策树指引应用选择，并利用多种形式化方法予以精确定义，同时调研相应监控工具，推动理论与实践结合。


<details>
  <summary>Details</summary>
Motivation: 现实中request-response规范存在多种变体，这些变体在实际应用中影响很大，但缺乏统一系统的区分和形式化描述，容易导致规范选择和监控的混乱。作者因此希望通过系统分类和形式化推动理论和实践的结合。

Method: 首先，将request-response的变体分为六类，并设计决策树辅助用户选择；其次，利用时序逻辑、文法和自动机等多种形式方法对六类进行形式化建模，指出其中两类需扩展的非正规形式化工具；最后，调研并分析相关监控工具。

Result: 成功分类出六种request-response变体，并以形式逻辑、文法和自动机等形式方法予以表达，其中两种为非正规类型。论文还梳理了可用于监控的相关工具，有助于实际工程应用。

Conclusion: 论文提出了对request-response规范不同变体的系统分类，并在形式化建模和实用监控工具层面提供了详尽阐述。这种分类能更好匹配实际应用需求。

Abstract: We find, motivated by real-world applications, that the well-known
request-response specification comes with multiple variations, and that these
variations should be distinguished. As the first main contribution, we
introduce a classification of those variations into six types, and present it
as a decision tree, where a user is led to the type that is suited for their
application by answering a couple of questions. Our second main contribution is
the formalization of those six types in various formalisms such as temporal
logics, grammars, and automata; here, two types out of the six are non-regular
specifications and their formalization requires extended formalisms. We also
survey tools for monitoring these specifications to cater for practitioners'
needs.

</details>
