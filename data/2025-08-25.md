<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.SE](#cs.SE) [Total: 4]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Correctness-Guaranteed Code Generation via Constrained Decoding](https://arxiv.org/abs/2508.15866)
*Lingxiao Li,Salar Rahili,Yiwei Zhao*

Main category: cs.PL

TL;DR: 该论文针对代码生成正确性问题，提出结合上下文敏感解析器和约束性解码的新算法，并通过sLua和游戏实例验证了其可生成语义及运行时均正确的程序，适合对代码质量要求极高的场景。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在代码生成领域的广泛应用，提高生成代码的正确性已成为核心难题。一般软件开发过程中不完美代码尚可接受，但在视频游戏和机器人领域，对运行时关键组件则要求一次性生成正确代码。

Method: 提出了一种约束性解码算法，结合上下文敏感的解析器。该解析器在生成过程中每一步输出一个满足关键不可扩展属性的正则表达式，指导下一个可生成正确程序的符号序列。此外，提出了基于动态解析器树（ToP）的框架，每个解析器对应上下文相关的信息，如变量作用域和类型约束，树分支则表示代码未来段的不确定性。

Result: 通过对Lua的强类型变种sLua进行实验，证明所提出方法能生成满足指定脚本API的语义正确程序。进一步在roguelike游戏机制生成上，验证该方法可通过设计获得运行时正确性。

Conclusion: 提出的上下文敏感解析和约束解码算法能显著提升语言模型生成代码的语义和运行时正确性，特别适用于需要高正确性保证的领域，如游戏和机器人开发。

Abstract: Language Models (LMs) are increasingly being used for code generation, but
ensuring the correctness of generated programs remains a significant challenge.
Although imperfect code may be acceptable during software development with
human oversight, domains such as video games and robotics require one-shot
correctness for runtime-critical components. We present a constrained decoding
algorithm for generating semantically correct programs that incorporates a
context-sensitive parser, which, at each step, outputs a regular expression
that satisfies a critical non-extensible property to guide the generation of
the next token sequence that can continue to a correct program. To build such a
context-sensitive parser, we propose a framework of a dynamic tree of parsers
(ToP) during parsing, where each parser corresponds to a modular context-free
grammar enriched with contextual information such as variable scopes and type
constraints, with tree branches representing ambiguity in the future code
segment. We demonstrate our approach through sLua, a strongly typed variant of
Lua, showing that our method can generate semantically correct programs
conforming to any prescribed scripting API. We further show that, with careful
design, our semantic guarantees extend to runtime correctness, as validated in
the application of generating game mechanics for a roguelike video game.

</details>


### [2] [Automated Formal Verification of a Software Fault Isolation System](https://arxiv.org/abs/2508.15898)
*Matthew Sotoudeh,Zachary Yedidia*

Main category: cs.PL

TL;DR: 本文利用自动化形式化验证方法，证明LFI系统中的SFI验证器能够安全地限制代码仅访问沙箱内存区域，有效提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: SFI（软件故障隔离）作为一种流行的沙箱技术，其安全性依赖于验证器确保不可信代码无法访问指定沙箱区域之外的内存。验证器出现漏洞将危及整体安全性，允许恶意代码越界访问敏感内存。本文关注于SFI验证器潜在的正确性问题。

Method: 作者对一种名为LFI（轻量级故障隔离）的最新SFI系统进行了自动化形式化验证，具体检查验证器接受的程序是否严格限制在沙箱区域内读写内存。

Result: 作者实现了对LFI验证器的自动化形式化验证，证明其能保证被接收的程序仅在指定的沙箱区域内读写内存。

Conclusion: 本文证实LFI系统的验证器是正确且安全的，被接受的程序不会越界读写内存，从而有效消除相关的安全隐患。

Abstract: Software fault isolation (SFI) is a popular way to sandbox untrusted
software. A key component of SFI is the verifier that checks the untrusted code
is written in a subset of the machine language that guarantees it never reads
or writes outside of a region of memory dedicated to the sandbox. Soundness
bugs in the SFI verifier would break the SFI security model and allow the
supposedly sandboxed code to read protected memory. In this paper, we address
the concern of SFI verifier bugs by performing an automated formal verification
of a recent SFI system called Lightweight Fault Isolation (LFI). In particular,
we formally verify that programs accepted by the LFI verifier never read or
write to memory outside of a designated sandbox region.

</details>


### [3] [Synthesizing DSLs for Few-Shot Learning](https://arxiv.org/abs/2508.16063)
*Paul Krogmeier,P. Madhusudan*

Main category: cs.PL

TL;DR: 该论文研究了基于少样本学习自动合成领域特定语言的问题，提出了判定性分析方法，并给出在树自动机语义下的可判定性理论结果。


<details>
  <summary>Details</summary>
Motivation: 少样本学习在符号领域应用广泛，但实际往往缺乏有效的DSL来支持表达和推断。研究基于少量训练样本自动合成能推广到测试样本的DSL，以提升少样本学习的可扩展性和自动化程度。

Method: 通过形式化DSL的合成问题，并利用树自动机分析含有固定结构的语言语义，同时以解析树深度刻画表达式规模。进一步通过正规树集合描述满足训练样本及测试样本的语法。还对宏语法及仅对输入问题适用的DSL合成问题进行了判定性分析。

Result: 论文证明了，当固定结构语言可由树自动机评估且表达式大小对应于语法解析树深度时，DSL合成问题是可判定的；给出了相关语法的正规树集表示。也证明了宏语法和部分变体场景下问题的可判定性。

Conclusion: 论文证明了在特定条件下，合成领域特定语言（DSLs）以支持符号领域的少样本学习问题是可判定的，并且可得到满足要求的DSL语法。

Abstract: We study the problem of synthesizing domain-specific languages (DSLs) for
few-shot learning in symbolic domains. Given a base language and instances of
few-shot learning problems, where each instance is split into training and
testing samples, the DSL synthesis problem asks for a grammar over the base
language that guarantees that small expressions solving training samples also
solve corresponding testing samples. We prove that the problem is decidable for
a class of languages whose semantics over fixed structures can be evaluated by
tree automata and when expression size corresponds to parse tree depth in the
grammar, and, furthermore, the grammars solving the problem correspond to a
regular set of trees. We also prove decidability results for variants of the
problem where DSLs are only required to express solutions for input learning
problems and where DSLs are defined using macro grammars.

</details>


### [4] [Leveraging Large Language Models to Detect Missed Peephole Optimizations](https://arxiv.org/abs/2508.16125)
*Zhenyang Xu,Hongxu Xu,Yongqiang Tian,Xintong Zhou,Chengnian Sun*

Main category: cs.PL

TL;DR: Lampo自动化框架利用LLM与验证工具，显著提升LLVM编译器peephole优化的发现与修复能力，超越已有工具，表现出持续优化和发现新优化的潜力。


<details>
  <summary>Details</summary>
Motivation: peephole优化是一种关键的编译器优化，能直接提升代码性能和节省代码体积，但在复杂多样的指令集下，发现新的高效peephole优化非常困难。以往方法在规模化和优化能力方面存在局限。

Method: 提出了Lampo，一个结合LLM创造性但不太可靠的代码优化能力与翻译验证工具严谨验证的自动化框架，通过反馈驱动的迭代流程，实现对peephole优化的自动检测与评估。

Result: Lampo平均可以识别LLVM中25项已报道遗漏peephole优化中的17项，理论上换用不同LLM可达22项。对比之下，LLVM现有最先进的Souper工具只能识别15项。同时在7个月的发展与间歇试验中，Lampo新发现了26项遗漏peephole优化，其中15项已确认，6项已修复。

Conclusion: Lampo显示出持续发现遗漏peephole优化的强大潜力，有望显著提升编译器优化水平。

Abstract: By replacing small, suboptimal instruction sequences within programs with a
more efficient equivalent, peephole optimization can not only directly optimize
code size and performance, but also potentially enables further transformations
in the subsequent optimization pipeline. Although peephole optimization is a
critical class of compiler optimizations, discovering new and effective
peephole optimizations is challenging as the instruction sets can be extremely
complex and diverse. Previous methods either do not scale well or can only
capture a limited subset of peephole optimizations. In this work, we leverage
Large Language Models (LLMs) to detect missed peephole optimizations. We
propose Lampo, a novel automated framework that synergistically combines the
creative but unreliable code optimization ability of LLMs with rigorous
correctness verification performed by translation validation tools, integrated
in a feedback-driven iterative process. Through a comprehensive evaluation
within LLVM ecosystems, we show that Lampo can successfully detect up to 17 out
of 25 previously reported missed optimizations in LLVM on average, and that 22
out of 25 can potentially be found by Lampo with different LLMs. For
comparison, the state-of-the-art superoptimizer for LLVM, Souper, identified 15
of them. Moreover, within seven months of development and intermittent
experiments, Lampo found 26 missed peephole optimizations, 15 of which have
been confirmed and 6 already fixed. These results demonstrate Lampo's strong
potential in continuously detecting missed peephole optimizations.

</details>


### [5] [On the Duality of Task and Actor Programming Models](https://arxiv.org/abs/2508.16522)
*Rohan Yadav,Joseph Guman,Sean Treichler,Michael Garland,Alex Aiken,Fredrik Kjolstad,Michael Bauer*

Main category: cs.PL

TL;DR: 任务与actor模型本质上是对偶，通过技术互通，任务模型既能高效开发又能媲美actor模型性能。


<details>
  <summary>Details</summary>
Motivation: 分布式和异构计算机对于现代负载场景越来越重要，但现有的任务模型和actor模型在开发效率和性能之间存在权衡。因此，如何兼具高生产力与高性能成为关键问题。

Method: 论文系统性分析了任务模型和actor模型的本质关系，提出两者互为对偶，并进一步提出在任务模型中应用借鉴自actor模型的性能优化技术。所提技术分别在Realm（显式并行任务运行时）和Legion（隐式并行任务运行时）进行验证。

Result: 在Realm系统中，优化技术将运行时开销降低了1.7-5.3倍，性能接近比优化极致的actor系统（如Charm++和MPI）只高一倍以内；在Legion系统中，未修改应用的强扩展性提升了1.3-5.0倍。

Conclusion: 任务模型与actor模型具有理论和实际的对偶关系，通过跨模型的技术迁移，可以使任务模型实现接近actor模型的性能优势，同时仍保持高生产力。

Abstract: Programming models for distributed and heterogeneous machines are rapidly
growing in popularity to meet the demands of modern workloads. Task and actor
models are common choices that offer different trade-offs between development
productivity and achieved performance. Task-based models offer better
productivity and composition of software, whereas actor-based models routinely
deliver better peak performance due to lower overheads. While task-based and
actor-based models appear to be different superficially, we demonstrate these
programming models are duals of each other. Importantly, we show that this
duality extends beyond functionality to performance, and elucidate techniques
that let task-based systems deliver performance competitive with actor-based
systems without compromising productivity. We apply these techniques to both
Realm, an explicitly parallel task-based runtime, as well as Legion, an
implicitly parallel task-based runtime. We show these techniques reduce Realm's
overheads by between 1.7-5.3x, coming within a factor of two of the overheads
imposed by heavily optimized actor-based systems like Charm++ and MPI. We
further show that our techniques enable between 1.3-5.0x improved strong
scaling of unmodified Legion applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [A Systematic Literature Review of Machine Learning Approaches for Migrating Monolithic Systems to Microservices](https://arxiv.org/abs/2508.15941)
*Imen Trabelsi,Brahim Mahmoudi,Jean Baptiste Minani,Naouel Moha,Yann-Gaël Guéhéneuc*

Main category: cs.SE

TL;DR: 本文通过系统性文献回顾，梳理了2015-2024年间ML支持单体系统到微服务迁移的主要研究，总结了各阶段的研究现状与不足，提出未来发展方向应解决数据、工具和标准化等核心挑战。


<details>
  <summary>Details</summary>
Motivation: 单体系统的可扩展性和可维护性难题促使微服务架构广泛被采用。但现有单体系统迁移到微服务过程复杂、耗时，部分阶段可通过ML自动化，选择适合的ML方法和了解现有研究现状成为实践者面临的难点，有必要对相关研究进行系统梳理和归纳。

Method: 采取系统性文献回顾（SLR）的方法，遵循PRISMA准则，收集2015-2024年间发表的81项主要研究，系统性提取与分析ML在迁移过程中的应用、阶段、输入、技术及评估方式等。

Result: 系统归类了ML在迁移过程中的应用场景，发现监控和服务识别等阶段研究充分，而如微服务封装等环节研究空白。主要挑战包括数据获取不足、复杂性与可扩展性限制、工具支持不足、缺乏标准化评测等，呼吁后续研究关注更全面的解决方案。

Conclusion: 本综述系统性梳理了使用机器学习（ML）辅助单体系统迁移到微服务的相关研究与方法，并指出虽然部分迁移阶段有良好研究基础，但仍有多个关键环节和挑战需进一步研究与改进。

Abstract: Scalability and maintainability challenges in monolithic systems have led to
the adoption of microservices, which divide systems into smaller, independent
services. However, migrating existing monolithic systems to microservices is a
complex and resource-intensive task, which can benefit from machine learning
(ML) to automate some of its phases. Choosing the right ML approach for
migration remains challenging for practitioners. Previous works studied
separately the objectives, artifacts, techniques, tools, and benefits and
challenges of migrating monolithic systems to microservices. No work has yet
investigated systematically existing ML approaches for this migration to
understand the \revised{automated migration phases}, inputs used, ML techniques
applied, evaluation processes followed, and challenges encountered. We present
a systematic literature review (SLR) that aggregates, synthesises, and
discusses the approaches and results of 81 primary studies (PSs) published
between 2015 and 2024. We followed the Preferred Reporting Items for Systematic
Review and Meta-Analysis (PRISMA) statement to report our findings and answer
our research questions (RQs). We extract and analyse data from these PSs to
answer our RQs. We synthesise the findings in the form of a classification that
shows the usage of ML techniques in migrating monolithic systems to
microservices. The findings reveal that some phases of the migration process,
such as monitoring and service identification, are well-studied, while others,
like packaging microservices, remain unexplored. Additionally, the findings
highlight key challenges, including limited data availability, scalability and
complexity constraints, insufficient tool support, and the absence of
standardized benchmarking, emphasizing the need for more holistic solutions.

</details>


### [7] [Breaking Barriers in Software Testing: The Power of AI-Driven Automation](https://arxiv.org/abs/2508.16025)
*Saba Naqvi,Mohammad Baqar*

Main category: cs.SE

TL;DR: 该文提出AI+NLP+RL智能自动生成和优化软件测试用例框架，有效提升缺陷检测与测试效率，实证显示可大幅减少人工、促进快速高质量交付。


<details>
  <summary>Details</summary>
Motivation: 传统软件测试效率低、成本高且覆盖面有限，急需智能化、自动化解决方案提升缺陷检测能力、减少人工和提高软件质量。

Method: 提出了基于NLP、强化学习和预测模型的AI自动化测试框架，包括需求的自然语言转化、测试用例自动生成与持续优化，并利用实时分析验证结果，融合可信与公平政策。通过案例研究验证效果。

Result: 该AI驱动测试框架提升了缺陷检测率，降低了测试工作量，加快了发布周期，展现了在复杂软件环境下扩展和集成的优势。

Conclusion: AI和自动化技术能够有效提升软件测试的效率和质量，能从传统人工流程转向更主动和自适应的智能测试体系。框架经实证展现了可扩展性、实用性和提升可靠性的潜力。

Abstract: Software testing remains critical for ensuring reliability, yet traditional
approaches are slow, costly, and prone to gaps in coverage. This paper presents
an AI-driven framework that automates test case generation and validation using
natural language processing (NLP), reinforcement learning (RL), and predictive
models, embedded within a policy-driven trust and fairness model. The approach
translates natural language requirements into executable tests, continuously
optimizes them through learning, and validates outcomes with real-time analysis
while mitigating bias. Case studies demonstrate measurable gains in defect
detection, reduced testing effort, and faster release cycles, showing that
AI-enhanced testing improves both efficiency and reliability. By addressing
integration and scalability challenges, the framework illustrates how AI can
shift testing from a reactive, manual process to a proactive, adaptive system
that strengthens software quality in increasingly complex environments.

</details>


### [8] [ARSP: Automated Repair of Verilog Designs via Semantic Partitioning](https://arxiv.org/abs/2508.16517)
*Bingkun Yao,Ning Wang,Xiangfeng Liu,Yuxin Du,Yuchen Hu,Hong Gao,Zhe Jiang,Nan Guan*

Main category: cs.SE

TL;DR: 文章提出了ARSP，一种通过语义分割和专用修复模型提升Verilog自动化调试性能的新系统。与主流工具和模型相比，在工业级模块上准确率有明显提升，有效解决了长上下文信号稀释问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大模型的自动化调试方法，在工业级Verilog模块上表现不佳，主要原因是由于长上下文导致的bug信号稀释，即与bug相关的语句被大量无关代码淹没，从而影响模型的聚焦与修复能力。

Method: 提出了ARSP系统，采用两阶段策略。首先通过Partition LLM将模块分割为语义紧密的碎片，随后通过Repair LLM对每个碎片独立进行修复，最终将修改合并，从而避免影响无关逻辑。系统还构建了合成数据框架，生成包括不同bug类型、设计风格和规模的碎片级训练对，以监督模型训练。

Result: 实验结果表明，ARSP在pass@1上达到77.92%，pass@5为83.88%，优于主流商用大模型（如Claude-3.7）及顶级自动Verilog调试工具（Strider和MEIC）。语义分割策略相比整体模块调试，分别提升了pass@1和pass@5 11.6%和10.2%。

Conclusion: 基于片段级语义分割的调试系统，可以有效缓解长上下文中的bug信号稀释问题，大幅提升了工业级Verilog模块调试的自动化准确率。ARSP在工业场景下优于主流工具与模型。

Abstract: Debugging functional Verilog bugs consumes a significant portion of front-end
design time. While Large Language Models (LLMs) have demonstrated great
potential in mitigating this effort, existing LLM-based automated debugging
methods underperform on industrial-scale modules. A major reason for this is
bug signal dilution in long contexts, where a few bug-relevant tokens are
overwhelmed by hundreds of unrelated lines, diffusing the model's attention. To
address this issue, we introduce ARSP, a two-stage system that mitigates
dilution via semantics-guided fragmentation. A Partition LLM splits a module
into semantically tight fragments; a Repair LLM patches each fragment; edits
are merged without altering unrelated logic. A synthetic data framework
generates fragment-level training pairs spanning bug types, design styles, and
scales to supervise both models. Experiments show that ARSP achieves 77.92%
pass@1 and 83.88% pass@5, outperforming mainstream commercial LLMs including
Claude-3.7 and SOTA automated Verilog debugging tools Strider and MEIC. Also,
semantic partitioning improves pass@1 by 11.6% and pass@5 by 10.2% over
whole-module debugging, validating the effectiveness of fragment-level scope
reduction in LLM-based Verilog debugging.

</details>


### [9] [Measuring the effectiveness of code review comments in GitHub repositories: A machine learning approach](https://arxiv.org/abs/2508.16053)
*Shadikur Rahman,Umme Ayman Koana,Hasibul Karim Shanto,Mahmuda Akter,Chitra Roy,Aras M. Ismael*

Main category: cs.SE

TL;DR: 本文分析了七种机器学习方法在代码审查文本语义分类中的效果，发现线性SVC表现最好，能有效帮助程序员理解评论、减少错误。


<details>
  <summary>Details</summary>
Motivation: 随着代码审查在软件开发过程中的普及，如何高效、准确地理解和分类代码审查评论中的语义与情感倾向成为一个重要问题。这不仅可以提升代码质量，还能帮助程序员识别和避免错误。

Method: 本研究从GitHub的三个开源项目中提取了当年开发活动的代码审查评论，并且对13557条评论进行了人工标注。接着，应用了七种机器学习算法对评论的情感倾向进行分类，并对这些算法的表现进行了比较。

Result: 在七种机器学习算法中，线性支持向量分类器(SVC)在情感倾向分类任务中取得了最高的准确率。

Conclusion: 通过对不同机器学习方法的比较，线性SVC最适合用于代码审查评论的情感分类，这有助于程序员根据评论做出更合理的判断，避免误解和错误。

Abstract: This paper illustrates an empirical study of the working efficiency of
machine learning techniques in classifying code review text by semantic
meaning. The code review comments from the source control repository in GitHub
were extracted for development activity from the existing year for three
open-source projects. Apart from that, programmers need to be aware of their
code and point out their errors. In that case, it is a must to classify the
sentiment polarity of the code review comments to avoid an error. We manually
labelled 13557 code review comments generated by three open source projects in
GitHub during the existing year. In order to recognize the sentiment polarity
(or sentiment orientation) of code reviews, we use seven machine learning
algorithms and compare those results to find the better ones. Among those
Linear Support Vector Classifier(SVC) classifier technique achieves higher
accuracy than others. This study will help programmers to make any solution
based on code reviews by avoiding misconceptions.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [10] [Experimental Results for Vampire on the Equational Theories Project](https://arxiv.org/abs/2508.15856)
*Mikoláš Janota*

Main category: cs.LO

TL;DR: 本文探讨了自动定理证明器Vampire在一类特定一阶逻辑蕴含式上的证明与反驳能力，发现其几乎能全部判别正确与错误的情形，显示自动推理工具在逻辑分析领域的价值。


<details>
  <summary>Details</summary>
Motivation: 本文承接Equational Theories Project的后续研究，旨在探讨如何借助自动定理证明器自动验证、反驳某类一阶逻辑蕴含式。该项目已完成，但启发了进一步的自动化研究。

Method: 作者使用了自动定理证明器Vampire，对若干特定类型的一阶逻辑蕴含式进行自动证明或反驳。通过实验性研究比较了Vampire对成立与不成立蕴含式的处理能力。

Result: Vampire能够自动证明所有成立的蕴含式，并能反驳大多数不成立的蕴含式，表现出强大的自动验证与反证能力。

Conclusion: 自动定理证明器（如Vampire）在分析这类一阶逻辑蕴含式时既高效又准确，是推进相关自动推理研究的有力工具。

Abstract: Equational Theories Project is a collaborative effort, which explores the
validity of certain first-order logic implications of certain kind. The project
has been completed but triggered further research. This report investigates how
much can be automatically proven and disproven by the automated theorem prover
Vampire. An interesting conclusion is that Vampire can prove all the considered
implications that hold and also is able to refute a vast majority of those that
do not hold.

</details>


### [11] [Lean Meets Theoretical Computer Science: Scalable Synthesis of Theorem Proving Challenges in Formal-Informal Pairs](https://arxiv.org/abs/2508.15878)
*Terry Jingchen Zhang,Wenyuan Jiang,Rongchuan Liu,Yisong Wang,Junran Yang,Ning Wang,Nicole Ni,Yinya Huang,Mrinmaya Sachan*

Main category: cs.LO

TL;DR: 提出用理论计算机科学自动生成高难度定理证明数据，有效揭示并推动大模型在自动推理领域的挑战和进步。


<details>
  <summary>Details</summary>
Motivation: 当前大模型的自动证明能力受到数据集有限的制约，主要因为人工整理成本高、难以获取大量带有严格验证的难题。作者希望突破这一瓶颈，为自动化推理研究提供更多高质量数据。

Method: 作者提出利用理论计算机科学（TCS）算法定义明确、可自动生成大量困难定理-证明对的特点，自动规模化生成具有正式和非正式描述的证明数据（分别用Lean4和Markdown格式）。研究涵盖了两个领域：忙海狸（Busy Beaver）问题和混合布尔算术问题。整个流程自动生成题目、双重规范描述，并用于评估大模型的定理证明能力。

Result: 在最新大模型上评估发现：在忙海狸任务中，DeepSeekProver-V2-67B取得了57.5%的成功率，但在混合布尔算术下成功率仅为12%。

Conclusion: TCS可作为生成高难度、验证准确的定理证明数据集的可扩展方案。即使对于易于验证的问题，复杂的长证明生成仍存在很大难度，这凸显TCS领域对推进自动化推理研究的重要价值。

Abstract: Formal theorem proving (FTP) has emerged as a critical foundation for
evaluating the reasoning capabilities of large language models, enabling
automated verification of mathematical proofs at scale. However, progress has
been constrained by limited datasets due to the high cost of manual curation
and the scarcity of challenging problems with verified formal-informal
correspondences. We propose leveraging theoretical computer science (TCS) as a
scalable source of rigorous proof problems, where algorithmic definitions
enable automated generation of arbitrarily many challenging theorem-proof
pairs. We demonstrate this approach on two TCS domains: Busy Beaver problems,
which involve proving bounds on Turing machine halting behavior, and Mixed
Boolean Arithmetic problems, which combine logical and arithmetic reasoning.
Our framework automatically synthesizes problems with parallel formal (Lean4)
and informal (Markdown) specifications, creating a scalable pipeline for
generating verified proof challenges. Evaluation on frontier models reveals
substantial gaps in automated theorem proving: while DeepSeekProver-V2-671B
achieves 57.5\% success on Busy Beaver problems, it manages only 12\% on Mixed
Boolean Arithmetic problems. These results highlight the difficulty of
long-form proof generation even for problems that are computationally easy to
verify, demonstrating the value of TCS domains for advancing automated
reasoning research.

</details>


### [12] [Disjunctions of Two Dependence Atoms](https://arxiv.org/abs/2508.16146)
*Nicolas Fröhlich,Phokion G. Kolaitis,Arne Meier*

Main category: cs.LO

TL;DR: 本文系统分析了两个依赖原子析取的模型检测复杂度，提出三分法（NL、LOGSPACE或AC[0]），并刻画了更一般情况的复杂度，拓展了依赖逻辑在数据库理论中的理论基础。


<details>
  <summary>Details</summary>
Motivation: 依赖逻辑可以表达关系数据库中的函数依赖。虽然三个依赖原子的析取已知模型检测是NP-完全的，但尚未系统研究两个一元依赖原子的情况，这与数据库理论中的实际问题密切相关。作者希望揭示这类公式模型检测问题的复杂度边界。

Method: 作者对包含两个一元依赖原子的公式的模型检测问题进行了系统复杂度分类，建立三分法定理，并进一步分析任意两个依赖原子公式的情形。同时，作者还研究了这些析取式的相干性（满足小模型性质的条件），并在过程中识别出一个LOGSPACE-完全的新型2CNF公式类。

Result: 对两个一元依赖原子的析取模型检测问题，作者证明：其复杂度严格落在三类之一——NL-完全、LOGSPACE-完全或一阶可定义（AC[0]内）。同时给出了两个任意依赖原子的复杂度确定和相干性刻画，以及LOGSPACE-完全的2CNF-公式类。

Conclusion: 该工作揭示了依赖逻辑中特定析取公式模型检测问题的细致复杂度分层，为理解依赖原子表达式的计算属性和其在数据库理论中的应用打下基础。也为判断复杂公式哪些情形易于计算给出了明确标准。

Abstract: Dependence logic is a formalism that augments the syntax of first-order logic
with dependence atoms asserting that the value of a variable is determined by
the values of some other variables, i.e., dependence atoms express functional
dependencies in relational databases. On finite structures, dependence logic
captures NP, hence there are sentences of dependence logic whose model-checking
problem is NP-complete. In fact, it is known that there are disjunctions of
three dependence atoms whose model-checking problem is NP-complete. Motivated
from considerations in database theory, we study the model-checking problem for
disjunctions of two unary dependence atoms and establish a trichotomy theorem,
namely, for every such formula, one of the following is true for the
model-checking problem: (i) it is NL-complete; (ii) it is LOGSPACE-complete;
(iii) it is first-order definable (hence, in AC[0]). Furthermore, we classify
the complexity of the model-checking problem for disjunctions of two arbitrary
dependence atoms, and also characterize when such a disjunction is coherent,
i.e., when it satisfies a certain small-model property. Along the way, we
identify a new class of 2CNF-formulas whose satisfiability problem is
LOGSPACE-complete.

</details>


### [13] [A Reduction of Input/Output Logics to SAT](https://arxiv.org/abs/2508.16242)
*Alexander Steen*

Main category: cs.LO

TL;DR: 本文提出将I/O规范逻辑自动化的方法，通过命题可满足性归约并开发了原型推理系统rio，经实证示例展示了可行性。


<details>
  <summary>Details</summary>
Motivation: 研究规范、义务、许可和禁止等范畴的逻辑形式化问题，尤其关注条件规范的处理方式。I/O逻辑作为一种特殊的规范型逻辑，将条件规范独立于对象逻辑语言，同时探讨其自动化推理的可行性。

Method: 提出了一种将I/O逻辑自动化的方案，即通过合适的简化方法将其归约为（多步）命题可满足性问题，并据此开发了原型工具rio进行实现。

Result: 提出的自动化方法能够有效实现I/O逻辑的推理，并且通过实用示例验证了方法和工具的可行性。

Conclusion: I/O逻辑的自动化处理可以通过归约命题可满足性问题实现，并通过原型系统rio展示了其实用性。该方法为规范推理领域提供了新的技术路线和工具支持。

Abstract: Deontic logics are formalisms for reasoning over norms, obligations,
permissions and prohibitions. Input/Output (I/O) Logics are a particular family
of so-called norm-based deontic logics that formalize conditional norms outside
of the underlying object logic language, where conditional norms do not carry a
truth-value themselves. In this paper, an automation approach for I/O logics is
presented that makes use of suitable reductions to (sequences of) propositional
satisfiability problems. A prototypical implementation, named rio (reasoner for
input/output logics), of the proposed procedures is presented and applied to
illustrative examples.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration](https://arxiv.org/abs/2508.15790)
*Nan Wang,Yongqi Fan,yansha zhu,ZongYu Wang,Xuezhi Cao,Xinyan He,Haiyun Jiang,Tong Ruan,Jingping Liu*

Main category: cs.CL

TL;DR: 本文针对LLM在多跳复杂推理中易偏离正确推理路径的问题，提出融合知识图谱的四阶段推理增强方法KG-o1，显著提升了模型推理性能，在多个数据集上超越现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在知识密集型、多跳推理任务（如复杂问答）中表现不佳，主要因为其链式推理容易偏离真实或先验的推理路径。而知识图谱（KGs）可以明确表示实体和事实间的逻辑连接，且有大型推理模型（LRMs）的相关研究表明长步推理能提升LLMs性能。作者希望结合KG与LLM提升多跳推理能力。

Method: 提出KG-o1方法，采用四阶段流程：1）筛选初始实体并生成复杂子图；2）为子图构建逻辑路径；3）利用知识图谱构建包含复杂、扩展脑力激荡过程的数据集，用于训练LLM仿效长期推理；4）通过拒绝采样生成自我提升语料，用于DPO优化进一步增强模型推理能力。

Result: 在两个简单和两个复杂数据集上的实验证明，KG-o1方法在所有任务上都优于现有的大型推理模型（LRMs）。

Conclusion: KG与LLM结合的新方法KG-o1能显著提升多跳推理任务中的表现，相比现有方法具有更强的推理能力和泛化效果。

Abstract: Large Language Models (LLMs) face challenges in knowledge-intensive reasoning
tasks like classic multi-hop question and answering, which involves reasoning
across multiple facts. This difficulty arises because the chain of thoughts
(CoTs) generated by LLMs in such tasks often deviate from real or a priori
reasoning paths. In contrast, knowledge graphs (KGs) explicitly represent the
logical connections between facts through entities and relationships. This
reflects a significant gap. Meanwhile, large reasoning models (LRMs), such as
o1, have demonstrated that long-step reasoning significantly enhances the
performance of LLMs. Building on these insights, we propose KG-o1, a four-stage
approach that integrates KGs to enhance the multi-hop reasoning abilities of
LLMs. We first filter out initial entities and generate complex subgraphs.
Secondly, we construct logical paths for subgraphs and then use knowledge
graphs to build a dataset with a complex and extended brainstorming process,
which trains LLMs to imitate long-term reasoning. Finally, we employ rejection
sampling to generate a self-improving corpus for direct preference optimization
(DPO), further refining the LLMs reasoning abilities. We conducted experiments
on two simple and two complex datasets. The results show that KG-o1 models
exhibit superior performance across all tasks compared to existing LRMs.

</details>


### [15] [InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling](https://arxiv.org/abs/2508.15791)
*Xiaolei Diao,Zhihan Zhou,Lida Shi,Ting Wang,Ruihua Qi,Hao Xu,Daqian Shi*

Main category: cs.CL

TL;DR: 本研究提出了InteChar统一汉字编码方案，并构建了甲骨文语料库OracleCS。实验表明，基于该方案训练的模型在古汉语理解任务上有明显提升，为古汉语NLP研究开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 现有构建历史语言模型面临两大挑战：一是历史文本样本稀缺导致大规模无监督预训练效果差；二是古文字编码不足，影响数字化处理，尤其以早期汉字为甚。

Method: 提出InteChar，一个统一且可扩展的汉字列表，将未编码的甲骨文字符与传统、现代汉字融合，实现历史文本的统一数字化与表示。并构建Oracle Corpus Set（OracleCS），结合专家标注与大模型辅助扩增，生成古汉语语料库用于实验。

Result: 使用InteChar和OracleCS训练的模型在多项历史语言理解任务上表现显著提升。

Conclusion: InteChar和OracleCS为古汉语自然语言处理奠定了坚实基础，有效提升了历史文本建模能力。

Abstract: Constructing historical language models (LMs) plays a crucial role in aiding
archaeological provenance studies and understanding ancient cultures. However,
existing resources present major challenges for training effective LMs on
historical texts. First, the scarcity of historical language samples renders
unsupervised learning approaches based on large text corpora highly
inefficient, hindering effective pre-training. Moreover, due to the
considerable temporal gap and complex evolution of ancient scripts, the absence
of comprehensive character encoding schemes limits the digitization and
computational processing of ancient texts, particularly in early Chinese
writing. To address these challenges, we introduce InteChar, a unified and
extensible character list that integrates unencoded oracle bone characters with
traditional and modern Chinese. InteChar enables consistent digitization and
representation of historical texts, providing a foundation for robust modeling
of ancient scripts. To evaluate the effectiveness of InteChar, we construct the
Oracle Corpus Set (OracleCS), an ancient Chinese corpus that combines
expert-annotated samples with LLM-assisted data augmentation, centered on
Chinese oracle bone inscriptions. Extensive experiments show that models
trained with InteChar on OracleCS achieve substantial improvements across
various historical language understanding tasks, confirming the effectiveness
of our approach and establishing a solid foundation for future research in
ancient Chinese NLP.

</details>


### [16] [Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers](https://arxiv.org/abs/2508.15792)
*Samyak S. Sanghvi*

Main category: cs.CL

TL;DR: 提出了一种新颖的双空间架构Bhav-Net，结合BERT与图神经网络，实现了多语言下反义词与同义词的高效区分，并具备强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 跨语言的反义词与同义词区分具有复杂的计算挑战，原因在于反义词通常处于相似语义域但意义相反。本研究旨在解决这一建模难题，实现多语言条件下反义词与同义词的有效区分。

Method: 提出了一种名为Bhav-Net的双空间架构：结合语言特定的BERT编码器与图神经网络，将语义关系映射到两个不同的空间，使同义词聚类在一个空间，反义词在另外一个空间表现出高相似性，并实现知识从多语言复杂模型到单一语言模型的迁移。

Result: 在包含英语、德语、法语、西班牙语、意大利语、葡萄牙语、荷兰语和俄语的八种语言上进行了评测，Bhav-Net展现了跨语言的有效语义关系建模能力。该方法在表现、解释性与跨语言泛化能力上均与当前最先进的基线方法竞争。

Conclusion: Bhav-Net能够高效地对多语言环境下的反义词和同义词进行区分，同时提供了可解释性的语义表达和良好的跨语言迁移能力。

Abstract: Antonym vs synonym distinction across multiple languages presents unique
computational challenges due to the paradoxical nature of antonymous
relationships words that share semantic domains while expressing opposite
meanings. This work introduces Bhav-Net, a novel dual-space architecture that
enables effective knowledge transfer from complex multilingual models to
simpler, language-specific architectures while maintaining robust cross-lingual
antonym--synonym distinction capabilities. Our approach combines
language-specific BERT encoders with graph transformer networks, creating
distinct semantic projections where synonymous pairs cluster in one space while
antonymous pairs exhibit high similarity in a complementary space. Through
comprehensive evaluation across eight languages (English, German, French,
Spanish, Italian, Portuguese, Dutch, and Russian), we demonstrate that semantic
relationship modeling transfers effectively across languages. The dual-encoder
design achieves competitive performance against state-of-the-art baselines
while providing interpretable semantic representations and effective
cross-lingual generalization.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [17] [Passive Model Learning of Visibly Deterministic Context-free Grammars](https://arxiv.org/abs/2508.16305)
*Edi Muškardin,Tamim Burgstaller*

Main category: cs.FL

TL;DR: 本文提出了PAPNI算法，通过扩展RPNI，将其学习能力提升至确定性上下文无关文法，并在实际文法学习任务中验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 原有的被动自动机学习方法RPNI只能学习正则语言，难以应对包含栈结构的复杂语言如确定性上下文无关文法。该论文动机是通过扩展RPNI，能够学习更复杂的语言模型。

Method: 提出了PAPNI算法，它以RPNI为基础，通过对输入字母表进行结构化预处理（知道哪些符号推入、弹出或不影响栈），实现对确定性下推自动机的学习。并在多个已知文法上测试了算法有效性。

Result: PAPNI在多个确定性上下文无关文法的测试集上表现良好，所学习到的模型在预测准确性上优于仅使用RPNI算法。

Conclusion: PAPNI可以通过被动学习算法，有效学习可见确定性下推自动机，从而能学习确定性上下文无关文法，对比RPNI具有更强表达能力。

Abstract: We present PAPNI, a passive automata learning algorithm capable of learning
deterministic context-free grammars, which are modeled with visibly
deterministic pushdown automata. PAPNI is a generalization of RPNI, a passive
automata learning algorithm capable of learning regular languages from positive
and negative samples. PAPNI uses RPNI as its underlying learning algorithm
while assuming a priori knowledge of the visibly deterministic input alphabet,
that is, the alphabet decomposition into symbols that push to the stack, pop
from the stack, or do not affect the stack.
  In this paper, we show how passive learning of deterministic pushdown
automata can be viewed as a preprocessing step of standard RPNI
implementations. We evaluate the proposed approach on various deterministic
context-free grammars found in the literature and compare the predictive
accuracy of learned models with RPNI.

</details>


### [18] [Automata Learning -- Expect Delays!](https://arxiv.org/abs/2508.16384)
*Gabriel Dengler,Sven Apel,Holger Hermanns*

Main category: cs.FL

TL;DR: 该文提出了一种有效区分自动机行为与延迟采样的新方法，在处理带随机延迟的Mealy机学习任务时，能大幅减少无效采样并提升学习质量，优于传统AAL算法。


<details>
  <summary>Details</summary>
Motivation: 主动自动机学习（AAL）通常侧重于确定系统的行为描述，但在存在随机延迟的情况下，推断模型变得更加困难。现有算法如$L^*$在集成延迟采样时会导致在状态空间根部的过度抽样，效率低下。因此，作者希望提升AAL在随机延迟场景下的效率与精准性。

Method: 该论文针对带有随机延迟的Mealy机，提出了将行为学习与延迟学习概念性分离的方法。在学习逻辑行为的过程中，收集有效的信息，引导延迟采样，从而设计高效的输入序列进行采样，避免无意义的过度抽样。该方法强调即使输入/输出行为一致，延迟特征可能不同的特殊情形。

Result: 实验表明，该分离行为与延迟的采样方法在多种基准测试下均优于直接集成延迟采样的朴素基线，并在实际场景下（如关系数据库连接顺序）具备良好适用性。

Conclusion: 将主动自动机学习中的行为与延迟采样相分离，可以显著提升在有随机延迟情形下的模型学习效率和精度，解决了传统AAL中因朴素采样带来的效率瓶颈和误差放大问题。

Abstract: This paper studies active automata learning (AAL) in the presence of
stochastic delays. We consider Mealy machines that have stochastic delays
associated with each transition and explore how the learner can efficiently
arrive at faithful estimates of those machines, the precision of which
crucially relies on repetitive sampling of transition delays. While it is
possible to na\"ively integrate the delay sampling into AAL algorithms such as
$L^*$, this leads to considerable oversampling near the root of the state
space. We address this problem by separating conceptually the learning of
behavior and delays such that the learner uses the information gained while
learning the logical behavior to arrive at efficient input sequences for
collecting the needed delay samples. We put emphasis on treating cases in which
identical input/output behaviors might stem from distinct delay
characteristics. Finally, we provide empirical evidence that our method
outperforms the na\"ive baseline across a wide range of benchmarks and
investigate its applicability in a realistic setting by studying the join order
in a relational database.

</details>
