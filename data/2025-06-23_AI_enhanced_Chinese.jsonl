{"id": "2506.15884", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15884", "abs": "https://arxiv.org/abs/2506.15884", "authors": ["Shamse Tasnim Cynthia", "Nuri Almarimi", "Banani Roy"], "title": "How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?", "comment": null, "summary": "Community smells reflect poor organizational practices that often lead to\nsocio-technical issues and the accumulation of Self-Admitted Technical Debt\n(SATD). While prior studies have explored these problems in general software\nsystems, their interplay in machine learning (ML)-based projects remains\nlargely underexamined. In this study, we investigated the prevalence of\ncommunity smells and their relationship with SATD in open-source ML projects,\nanalyzing data at the release level. First, we examined the prevalence of ten\ncommunity smell types across the releases of 155 ML-based systems and found\nthat community smells are widespread, exhibiting distinct distribution patterns\nacross small, medium, and large projects. Second, we detected SATD at the\nrelease level and applied statistical analysis to examine its correlation with\ncommunity smells. Our results showed that certain smells, such as Radio Silence\nand Organizational Silos, are strongly correlated with higher SATD occurrences.\nThird, we considered the six identified types of SATD to determine which\ncommunity smells are most associated with each debt category. Our analysis\nrevealed authority- and communication-related smells often co-occur with\npersistent code and design debt. Finally, we analyzed how the community smells\nand SATD evolve over the releases, uncovering project size-dependent trends and\nshared trajectories. Our findings emphasize the importance of early detection\nand mitigation of socio-technical issues to maintain the long-term quality and\nsustainability of ML-based systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u5f00\u6e90ML\u9879\u76ee\u4e2d\u793e\u533a\u5f02\u5473\u4e0e\u81ea\u627f\u8ba4\u6280\u672f\u503a\u52a1\u7684\u6570\u91cf\u3001\u5206\u5e03\u4e0e\u6f14\u5316\u89c4\u5f8b\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u7279\u5b9a\u6a21\u5f0f\u4e0b\u9ad8\u5ea6\u76f8\u5173\uff0c\u5e76\u968f\u9879\u76ee\u89c4\u6a21\u548c\u7248\u672c\u6f14\u53d8\uff0c\u5f3a\u8c03\u4e86\u65e9\u671f\u7ba1\u7406\u793e\u533a\u95ee\u9898\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u867d\u7136\u793e\u533a\u5f02\u5473\uff08community smells\uff09\u548c\u81ea\u627f\u8ba4\u6280\u672f\u503a\u52a1\uff08SATD\uff09\u5df2\u5728\u4e00\u822c\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u88ab\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u5728\u673a\u5668\u5b66\u4e60\u9879\u76ee\u4e2d\u7684\u76f8\u4e92\u5173\u7cfb\u5c1a\u672a\u6df1\u5165\u63a2\u8ba8\u3002\u4f5c\u8005\u5e0c\u671b\u63ed\u793a\u5728\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u9879\u76ee\u4e2d\u793e\u533a\u5f02\u5473\u7684\u666e\u904d\u6027\u53ca\u5176\u4e0eSATD\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u4f5c\u8005\u5728155\u4e2a\u5f00\u6e90ML\u9879\u76ee\u7684\u4e0d\u540c\u7248\u672c\u4e0a\uff0c\u5206\u6790\u5e76\u91cf\u5316\u4e8610\u79cd\u793e\u533a\u5f02\u5473\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u68c0\u6d4bSATD\u7684\u51fa\u73b0\uff0c\u5bf9\u793e\u533a\u5f02\u5473\u4e0eSATD\u7684\u76f8\u5173\u6027\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u5e76\u8fdb\u4e00\u6b65\u5206\u6790\u4e24\u8005\u968f\u9879\u76ee\u53d1\u5e03\u7248\u672c\u7684\u6f14\u5316\u8d8b\u52bf\u3002", "result": "\uff081\uff09\u793e\u533a\u5f02\u5473\u5728ML\u9879\u76ee\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5e76\u5728\u4e0d\u540c\u89c4\u6a21\u9879\u76ee\u4e2d\u5448\u73b0\u4e0d\u540c\u5206\u5e03\u6a21\u5f0f\u3002\uff082\uff09\u67d0\u4e9b\u793e\u533a\u5f02\u5473\uff08\u5982\u6c89\u9ed8\u548c\u7ec4\u7ec7\u5b64\u5c9b\uff09\u4e0e\u9ad8SATD\u51fa\u73b0\u7387\u5f3a\u76f8\u5173\u3002\uff083\uff09\u6743\u5a01\u4e0e\u6c9f\u901a\u76f8\u5173\u7684\u5f02\u5473\u5e38\u4e0e\u6301\u4e45\u6027\u4ee3\u7801\u4e0e\u8bbe\u8ba1\u503a\u52a1\u5171\u73b0\u3002\uff084\uff09\u793e\u533a\u5f02\u5473\u4e0eSATD\u968f\u9879\u76ee\u53d1\u5e03\u6f14\u5316\uff0c\u5b58\u5728\u4e0e\u9879\u76ee\u89c4\u6a21\u76f8\u5173\u7684\u8d8b\u52bf\u3002", "conclusion": "\u5e94\u53ca\u65e9\u53d1\u73b0\u548c\u6d88\u9664\u793e\u533a\u5f02\u5473\u7b49\u793e\u4f1a\u6280\u672f\u95ee\u9898\uff0c\u4ee5\u7ef4\u62a4ML\u9879\u76ee\u7684\u8d28\u91cf\u548c\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2506.16101", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16101", "abs": "https://arxiv.org/abs/2506.16101", "authors": ["Yupeng Jiang", "Shuaiyi Sun", "Xi Zheng"], "title": "Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques", "comment": null, "summary": "Regression testing plays a critical role in maintaining software reliability,\nparticularly for ROS-based autonomous systems (ROSAS), which frequently undergo\ncontinuous integration and iterative development. However, conventional\nregression testing techniques face significant challenges when applied to\nautonomous systems due to their dynamic and non-deterministic behaviors,\ncomplex multi-modal sensor data, asynchronous distributed architectures, and\nstringent safety and real-time constraints. Although numerous studies have\nexplored test optimization in traditional software contexts, regression testing\noptimization specifically for ROSAS remains largely unexplored. To address this\ngap, we present the first comprehensive survey systematically reviewing\nregression testing optimization techniques tailored for ROSAS. We analyze and\ncategorize 122 representative studies into regression test case prioritization,\nminimization, and selection methods. A structured taxonomy is introduced to\nclearly illustrate their applicability and limitations within ROSAS contexts.\nFurthermore, we highlight major challenges specific to regression testing for\nROSAS, including effectively prioritizing tests in response to frequent system\nmodifications, efficiently minimizing redundant tests, and difficulty in\naccurately selecting impacted test cases. Finally, we propose research insights\nand identify promising future directions, such as leveraging frame-to-vector\ncoverage metrics, multi-source foundation models, and neurosymbolic reasoning\nto enhance regression testing efficiency and effectiveness. This survey\nprovides a foundational reference and practical roadmap for advancing the\nstate-of-the-art in regression testing optimization for ROSAS.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u81ea\u4e3b\u7cfb\u7edf\uff08ROSAS\uff09\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u65b9\u6cd5\uff0c\u5f52\u7eb3\u4e3b\u8981\u96be\u9898\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u5168\u9762\u53c2\u8003\u3002", "motivation": "\u76ee\u524d\u56de\u5f52\u6d4b\u8bd5\u5728ROS\u4e3a\u57fa\u7840\u7684\u81ea\u4e3b\u7cfb\u7edf\uff08ROSAS\uff09\u4e2d\u7684\u4f18\u5316\u7814\u7a76\u8f83\u5c11\uff0c\u800c\u8fd9\u4e9b\u7cfb\u7edf\u7531\u4e8e\u5177\u6709\u52a8\u6001\u6027\u3001\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u548c\u9ad8\u5b89\u5168\u8981\u6c42\uff0c\u7ed9\u4f20\u7edf\u56de\u5f52\u6d4b\u8bd5\u65b9\u6cd5\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u672c\u6587\u9996\u6b21\u5bf9\u9488\u5bf9ROSAS\u7684\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u6280\u672f\u8fdb\u884c\u4e86\u7cfb\u7edf\u7efc\u8ff0\uff0c\u5bf9122\u7bc7\u7814\u7a76\u8fdb\u884c\u4e86\u5206\u6790\u548c\u5f52\u7c7b\uff0c\u6db5\u76d6\u6d4b\u8bd5\u7528\u4f8b\u4f18\u5148\u7ea7\u6392\u5e8f\u3001\u6700\u5c0f\u5316\u548c\u9009\u62e9\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\u4ee5\u8bf4\u660e\u5404\u79cd\u65b9\u6cd5\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "\u5efa\u7acb\u4e86ROSAS\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u6280\u672f\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u4f53\u7cfb\uff0c\u5f52\u7eb3\u603b\u7ed3\u4e86\u4f18\u5148\u7ea7\u6392\u5e8f\u3001\u5197\u4f59\u6700\u5c0f\u5316\u548c\u5f71\u54cd\u7528\u4f8b\u9009\u62e9\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u5e27\u5411\u91cf\u8986\u76d6\u5ea6\u3001\u8de8\u6e90\u57fa\u7840\u6a21\u578b\u548c\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3aROSAS\u7684\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u63d0\u4f9b\u4e86\u7cfb\u7edf\u53c2\u8003\u548c\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u5bf9\u8be5\u9886\u57df\u7684\u53d1\u5c55\u5177\u6709\u5960\u57fa\u610f\u4e49\u3002"}}
{"id": "2506.16136", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16136", "abs": "https://arxiv.org/abs/2506.16136", "authors": ["Kai Huang", "Jian Zhang", "Xiaofei Xie", "Chunyang Chen"], "title": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing", "comment": null, "summary": "Large language model-(LLM) based automated program repair (APR) techniques\nhave shown promising results in resolving real-world GitHub issue tasks.\nExisting APR systems are primarily evaluated in unimodal settings (e.g.,\nSWE-bench). However, these autonomous systems struggle to resolve multimodal\nproblem scenarios (e.g., SWE-bench M) due to limitations in interpreting and\nleveraging visual information. In multimodal scenarios, LLMs need to rely on\nvisual information in the graphical user interface (GUI) to understand bugs and\ngenerate fixes. To bridge this gap, we propose GUIRepair, a cross-modal\nreasoning approach for resolving multimodal issue scenarios by understanding\nand capturing visual information. Specifically, GUIRepair integrates two key\ncomponents, Image2Code and Code2Image, to enhance fault comprehension and patch\nvalidation. Image2Code extracts relevant project documents based on the issue\nreport, then applies this domain knowledge to generate the reproduced code\nresponsible for the visual symptoms, effectively translating GUI images into\nexecutable context for better fault comprehension. Code2Image replays the\nvisual issue scenario using the reproduced code and captures GUI renderings of\nthe patched program to assess whether the fix visually resolves the issue,\nproviding feedback for patch validation. We evaluate GUIRepair on SWE-bench M,\nand the approach demonstrates significant effectiveness. When utilizing GPT-4o\nas the base model, GUIRepair solves 157 instances, outperforming the best\nopen-source baseline by 26 instances. Furthermore, when using o4-mini as the\nbase model, GUIRepair can achieve even better results and solve 175 instances,\noutperforming the top commercial system by 22 instances. This emphasizes the\nsuccess of our new perspective on incorporating cross-modal reasoning by\nunderstanding and capturing visual information to resolve multimodal issues.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u96be\u4ee5\u5904\u7406GUI\u76f8\u5173\u591a\u6a21\u6001\u95ee\u9898\uff0c\u63d0\u51faGUIRepair\u8de8\u6a21\u6001\u63a8\u7406\u65b9\u6cd5\uff0c\u6709\u6548\u96c6\u6210\u89c6\u89c9\u4e0e\u6587\u672c\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u95ee\u9898\u4fee\u590d\u80fd\u529b\uff0c\u5728SWE-bench M\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u6280\u672f\u5728\u5355\u4e00\u6a21\u6001\uff08\u5982\u6587\u672c\uff09\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7406\u89e3\u548c\u5229\u7528\u53ef\u89c6\u5316\u4fe1\u606f\u7684\u591a\u6a21\u6001\u573a\u666f\uff08\u4f8b\u5982\u9700\u8981\u5206\u6790GUI\u754c\u9762\u7684bug\uff09\u5219\u6548\u679c\u6b20\u4f73\u3002\u5982\u4f55\u8ba9APR\u7cfb\u7edf\u9ad8\u6548\u89e3\u51b3\u6d89\u53ca\u89c6\u89c9\u4fe1\u606f\u7684\u591a\u6a21\u6001\u95ee\u9898\uff0c\u662f\u63d0\u5347\u5176\u5b9e\u7528\u6027\u7684\u91cd\u8981\u65b9\u5411\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86GUIRepair\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u8de8\u6a21\u6001\u63a8\u7406\uff0c\u9488\u5bf9\u591a\u6a21\u6001issue\uff0c\u6574\u5408\u4e86Image2Code\u548cCode2Image\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1aImage2Code\u57fa\u4e8eissue\u62a5\u544a\u68c0\u7d22\u3001\u7406\u89e3\u76f8\u5173\u9879\u76ee\u6587\u6863\uff0c\u5c06GUI\u56fe\u50cf\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u5e2e\u52a9\u66f4\u597d\u5730\u5b9a\u4f4d\u548c\u7406\u89e3\u6545\u969c\uff1bCode2Image\u91cd\u73b0\u4fee\u590d\u540e\u7684GUI\u754c\u9762\uff0c\u8f85\u52a9\u8bc4\u4f30\u8865\u4e01\u662f\u5426\u4fee\u590d\u4e86\u53ef\u89c6\u5316\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u8865\u4e01\u9a8c\u8bc1\u3002", "result": "\u5728SWE-bench M\u57fa\u51c6\u96c6\u4e0a\uff0cGUIRepair\u91c7\u7528GPT-4o\u4f5c\u4e3a\u5e95\u6a21\u65f6\u89e3\u51b3\u4e86157\u4e2a\u5b9e\u4f8b\uff0c\u6bd4\u6700\u4f73\u5f00\u6e90\u57fa\u7ebf\u591a26\u4e2a\uff1b\u91c7\u7528o4-mini\u5e95\u6a21\u65f6\u89e3\u51b3\u4e86175\u4e2a\u5b9e\u4f8b\uff0c\u8d85\u8d8a\u4e86\u6700\u4f18\u5546\u4e1a\u7cfb\u7edf22\u4e2a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9488\u5bf9\u591a\u6a21\u6001\u95ee\u9898\u7684\u4fee\u590d\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u8de8\u6a21\u6001\u63a8\u7406\u4e0e\u53ef\u89c6\u5316\u4fe1\u606f\u7406\u89e3\u673a\u5236\uff0cGUIRepair\u6781\u5927\u63d0\u5347\u4e86\u591a\u6a21\u6001\u8f6f\u4ef6\u95ee\u9898\u7684\u81ea\u52a8\u4fee\u590d\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u5149\u9760\u6587\u672c\u4fe1\u606f\u96be\u4ee5\u5904\u7406\u89c6\u89c9\u76f8\u5173bug\u7684\u5c40\u9650\uff0c\u4e5f\u4e3aAPR\u7cfb\u7edf\u53d1\u5c55\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.16214", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16214", "abs": "https://arxiv.org/abs/2506.16214", "authors": ["Klara Borowa", "Andrzej Ratkowski", "Roberto Verdecchia"], "title": "The Technical Debt Gamble: A Case Study on Technical Debt in a Large-Scale Industrial Microservice Architecture", "comment": "Preprint accepted to Journal of Systems and Software", "summary": "Microservice architectures provide an intuitive promise of high\nmaintainability and evolvability due to loose coupling. However, these quality\nattributes are notably vulnerable to technical debt (TD). Few studies address\nTD in microservice systems, particularly on a large scale. This research\nexplores how TD manifests in a large-scale microservice-based industrial\nsystem. The research is based on a mixed-method case study of a project\nincluding over 100 microservices and serving over 15k locations. Results are\ncollected via a quantitative method based static code analyzers combined with\nqualitative insights derived from a focus group discussion with the development\nteam and a follow-up interview with the lead architect of the case study\nsystem. Results show that (1) simple static source code analysis can be an\nefficient and effective entry point for holistic TD discovery, (2) inadequate\ncommunication significantly contributes to TD, (3) misalignment between\narchitectural and organizational structures can exacerbate TD accumulation, (4)\nmicroservices can rapidly cycle through TD accumulation and resolution, a\nphenomenon referred to as \"microservice architecture technical debt gamble\".\nFinally, we identify a set of fitting strategies for TD management in\nmicroservice architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5927\u89c4\u6a21\u5de5\u4e1a\u6848\u4f8b\uff0c\u63ed\u793a\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u5728\u6280\u672f\u503a\u52a1\u7ba1\u7406\u4e0a\u7684\u4e3b\u8981\u6311\u6218\u548c\u5bf9\u7b56\uff0c\u5f3a\u8c03\u4e86\u9759\u6001\u4ee3\u7801\u5206\u6790\u3001\u6c9f\u901a\u4e0e\u7ec4\u7ec7\u7ed3\u6784\u5339\u914d\u7b49\u63aa\u65bd\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u56e0\u5176\u677e\u8026\u5408\u7279\u6027\uff0c\u88ab\u8ba4\u4e3a\u9ad8\u5ea6\u53ef\u7ef4\u62a4\u4e14\u6613\u4e8e\u6f14\u5316\uff0c\u4f46\u8fd9\u7c7b\u7cfb\u7edf\u7684\u6280\u672f\u503a\u52a1\uff08TD\uff09\u95ee\u9898\u5c1a\u672a\u88ab\u5927\u89c4\u6a21\u6df1\u5165\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u7ed3\u5408\u9759\u6001\u4ee3\u7801\u5206\u6790\u7684\u5b9a\u91cf\u624b\u6bb5\u548c\u5f00\u53d1\u56e2\u961f\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\u53ca\u9996\u5e2d\u67b6\u6784\u5e08\u8bbf\u8c08\u83b7\u53d6\u7684\u5b9a\u6027\u89c1\u89e3\uff0c\u5206\u6790\u5305\u542b100\u591a\u4e2a\u5fae\u670d\u52a1\u3001\u670d\u52a1\u4e8e1.5\u4e07\u4e2a\u7ad9\u70b9\u7684\u5927\u578b\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\uff081\uff09\u7b80\u5355\u7684\u9759\u6001\u6e90\u4ee3\u7801\u5206\u6790\u80fd\u9ad8\u6548\u3001\u6709\u6548\u5730\u4f5c\u4e3a\u5168\u65b9\u4f4d\u53d1\u73b0\u6280\u672f\u503a\u52a1\u7684\u5207\u5165\u70b9\uff1b\uff082\uff09\u6c9f\u901a\u4e0d\u7545\u662fTD\u79ef\u7d2f\u7684\u91cd\u8981\u56e0\u7d20\uff1b\uff083\uff09\u67b6\u6784\u4e0e\u7ec4\u7ec7\u7ed3\u6784\u7684\u4e0d\u4e00\u81f4\u4f1a\u52a0\u5267TD\u79ef\u7d2f\uff1b\uff084\uff09\u5fae\u670d\u52a1\u7cfb\u7edf\u5728TD\u79ef\u7d2f\u4e0e\u89e3\u51b3\u4e4b\u95f4\u201c\u5feb\u901f\u5faa\u73af\u201d\uff0c\u5373\u201c\u5fae\u670d\u52a1\u67b6\u6784\u6280\u672f\u503a\u52a1\u8d4c\u535a\u201d\u3002\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u9488\u5bf9\u5fae\u670d\u52a1TD\u7ba1\u7406\u7684\u7b56\u7565\u3002", "conclusion": "\u6280\u672f\u503a\u52a1\u662f\u5f71\u54cd\u5fae\u670d\u52a1\u67b6\u6784\u7cfb\u7edf\u8d28\u91cf\u548c\u53ef\u7ef4\u62a4\u6027\u7684\u5173\u952e\u95ee\u9898\uff0c\u9700\u901a\u8fc7\u9002\u5f53\u7684\u68c0\u6d4b\u4e0e\u7ba1\u7406\u7b56\u7565\u4e88\u4ee5\u91cd\u89c6\u3002\u7b80\u5355\u7684\u9759\u6001\u4ee3\u7801\u5206\u6790\u7ed3\u5408\u7ec4\u7ec7\u4e0e\u67b6\u6784\u534f\u540c\u3001\u6709\u6548\u6c9f\u901a\u7b49\u7efc\u5408\u5e72\u9884\uff0c\u6709\u52a9\u4e8e\u7cfb\u7edf\u6027\u5730\u89e3\u51b3TD\u95ee\u9898\u3002"}}
{"id": "2506.15875", "categories": ["cs.PL", "cs.AR", "cs.DC", "cs.ET", "D.3; D.1; I.6; J.2"], "pdf": "https://arxiv.org/pdf/2506.15875", "abs": "https://arxiv.org/abs/2506.15875", "authors": ["Dirk Van Essendelft", "Patrick Wingo", "Terry Jordan", "Ryan Smith", "Wissam Saidi"], "title": "A System Level Compiler for Massively-Parallel, Spatial, Dataflow Architectures", "comment": "26 pages, 5 figures, 14 listings", "summary": "We have developed a novel compiler called the Multiple-Architecture Compiler\nfor Advanced Computing Hardware (MACH) designed specifically for\nmassively-parallel, spatial, dataflow architectures like the Wafer Scale\nEngine. Additionally, MACH can execute code on traditional unified-memory\ndevices. MACH addresses the complexities in compiling for spatial architectures\nthrough a conceptual Virtual Machine, a flexible domain-specific language, and\na compiler that can lower high-level languages to machine-specific code in\ncompliance with the Virtual Machine concept. While MACH is designed to be\noperable on several architectures and provide the flexibility for several\nstandard and user-defined data mappings, we introduce the concept with dense\ntensor examples from NumPy and show lowering to the Wafer Scale Engine by\ntargeting Cerebras' hardware specific languages.", "AI": {"tldr": "MACH \u7f16\u8bd1\u5668\u4e3a\u9ad8\u5c42\u4ee3\u7801\u5230\u7a7a\u95f4\u6570\u636e\u6d41\u786c\u4ef6\u7684\u9ad8\u6548\u6620\u5c04\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u7b80\u5316\u4e86\u590d\u6742\u7a7a\u95f4\u67b6\u6784\u7684\u7f16\u8bd1\u6d41\u7a0b\uff0c\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c AI \u5de5\u4f5c\u8d1f\u8f7d\u6709\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\uff08\u5982 Wafer Scale Engine\uff09\u56e0\u5176\u7f16\u7a0b\u548c\u7f16\u8bd1\u590d\u6742\u5ea6\u9ad8\uff0c\u4f7f\u5f97\u9ad8\u6548\u5229\u7528\u8fd9\u7c7b\u786c\u4ef6\u53d8\u5f97\u56f0\u96be\u3002\u7f3a\u4e4f\u7edf\u4e00\u3001\u7075\u6d3b\u7684\u7f16\u8bd1\u5de5\u5177\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u9762\u5411\u5927\u89c4\u6a21\u5e76\u884c\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684 MACH \u7f16\u8bd1\u5668\uff0c\u5b9e\u73b0\u4e86\u865a\u62df\u673a\u62bd\u8c61\u3001\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u53ca\u652f\u6301\u591a\u5e73\u53f0\u4ee3\u7801\u964d\u4f4e\u7684\u529f\u80fd\u3002\u5c55\u793a\u4e86\u9488\u5bf9 NumPy \u5f20\u91cf\u64cd\u4f5c\u5230 Wafer Scale Engine \u7684\u964d\u4f4e\u8fc7\u7a0b\u3002", "result": "MACH \u652f\u6301\u9762\u5411\u7a7a\u95f4\u67b6\u6784\u548c\u4f20\u7edf\u7edf\u4e00\u5185\u5b58\u8bbe\u5907\u7684\u4ee3\u7801\u7f16\u8bd1\uff0c\u80fd\u6709\u6548\u5c06\u9ad8\u5c42\u6570\u503c\u8fd0\u7b97\uff08\u5982 NumPy \u5f20\u91cf\u64cd\u4f5c\uff09\u901a\u8fc7\u786c\u4ef6\u7279\u5b9a\u8bed\u8a00\u5bf9\u63a5\u786c\u4ef6\u5e73\u53f0\uff08\u4f8b\u5982 Cerebras\uff09\u3002", "conclusion": "MACH \u7f16\u8bd1\u5668\u901a\u8fc7\u865a\u62df\u673a\u62bd\u8c61\u548c\u7075\u6d3b\u7684 DSL\uff0c\u4fc3\u8fdb\u4e86\u9ad8\u5c42\u4ee3\u7801\u5230\u7279\u5b9a\u7a7a\u95f4\u67b6\u6784\u7684\u8f6c\u6362\uff0c\u5e76\u6210\u529f\u652f\u6301\u4ee5 NumPy \u5f20\u91cf\u64cd\u4f5c\u4e3a\u4f8b\u7684\u964d\u4f4e\u8fc7\u7a0b\u3002"}}
{"id": "2506.16206", "categories": ["cs.LO", "math.LO", "F.4.1; I.2.4"], "pdf": "https://arxiv.org/pdf/2506.16206", "abs": "https://arxiv.org/abs/2506.16206", "authors": ["James Carr"], "title": "Locality in Many-Valued Structures", "comment": null, "summary": "Many-valued models generalise the structures from classical model theory by\ndefining truth values for a model with an arbitrary algebra. Just as algebraic\nvarieties provide semantics for many non-classical propositional logics, models\ndefined over algebras in a variety provide the semantics for the corresponding\nnon-classical predicate logics. In particular models defined over varieties of\nresiduated lattices represent the model theory for first-order substructrual\nlogics.\n  In this paper we study the extent to which the classical locality theorems\nfrom Hanf and Gaifman hold true in the residuated lattice setting. We\ndemonstrate that the answer is sensitive both to how locality is understood in\nthe generalised context and the behaviour of the truth-defining algebra. In the\ncase of Hanf's theorem, we will show that the theorem fails for the natural\nunderstanding of local neighbourhoods, but is recoverable in one special case\nfor well-connected residuated lattices. For Gaifman's theorem, rather than\nconsider Gaifman normal forms directly we focus on the main lemma of the\ntheorem from textbook proofs. We prove that for a number of different\nunderstandings of locality, provided the algebra is well-behaved enough to\nexpress locality in its syntax, this main lemma can be recovered. In each case\nwe will see that importance of an order-interpreting connective which creates a\nlink between the modelling relation between models and formulas and the\nvaluation function from formulas into the algebra.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u591a\u503c\u6a21\u578b\u4e0b\u7ecf\u5178\u5c40\u90e8\u6027\u5b9a\u7406\uff08Hanf\u4e0eGaifman\uff09\u662f\u5426\u9002\u7528\u3002\u7ed3\u679c\u53d1\u73b0Hanf\u5b9a\u7406\u901a\u5e38\u4e0d\u6210\u7acb\uff0c\u4f46\u5bf9\u7279\u6b8awell-connected\u6b8b\u4f59\u683c\u53ef\u6062\u590d\uff1bGaifman\u5b9a\u7406\u7684\u4e3b\u5f15\u7406\u5728\u826f\u597d\u4ee3\u6570\u7ed3\u6784\u4e0b\u591a\u79cd\u60c5\u5f62\u53ef\u8bc1\u660e\u3002\u5c40\u90e8\u6027\u5b9a\u7406\u80fd\u5426\u6210\u7acb\u4e0e\u4ee3\u6570\u6027\u8d28\u53ca\u8fde\u63a5\u8bcd\u5bc6\u5207\u76f8\u5173\uff0c\u4e3a\u591a\u503c\u6a21\u578b\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "motivation": "\u5728\u7ecf\u5178\u6a21\u578b\u7406\u8bba\u4e2d\uff0c\u5c40\u90e8\u6027\uff08locality\uff09\u5b9a\u7406\u5982Hanf\u5b9a\u7406\u548cGaifman\u5b9a\u7406\u5bf9\u4e8e\u5206\u6790\u6a21\u578b\u4e0e\u516c\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u5728\u591a\u503c\u6a21\u578b\uff08\u5982\u5269\u4f59\u683cresiduated lattices\u6a21\u578b\uff09\u4e0b\uff0c\u8fd9\u4e9b\u5b9a\u7406\u662f\u5426\u4f9d\u7136\u6210\u7acb\u5c1a\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u63a2\u7a76\u591a\u503c\u6a21\u578b\u4e2d\u8fd9\u4e9b\u5b9a\u7406\u7684\u9002\u7528\u6027\u3002", "method": "\u672c\u6587\u8003\u5bdf\u4e86\u6b8b\u4f59\u683c\u4e0a\u7684\u4e00\u9636\u5b50\u7ed3\u6784\u903b\u8f91\u7684\u591a\u503c\u6a21\u578b\uff0c\u5206\u522b\u7814\u7a76\u4e86\u5728\u4e0d\u540c\u5c40\u90e8\u6027\u7406\u89e3\u4e0b\uff0cHanf\u5b9a\u7406\u4e0eGaifman\u5b9a\u7406\u5728\u8fd9\u79cd\u6a21\u578b\u4e0a\u7684\u6210\u7acb\u60c5\u51b5\u3002\u5bf9\u4e8eHanf\u5b9a\u7406\uff0c\u8003\u5bdf\u5176\u5bf9\u81ea\u7136\u5b9a\u4e49\u7684\u90bb\u57df\u5931\u8d25\u4e0e\u7279\u6b8a\u60c5\u5f62\u4e0b\u7684\u53ef\u6062\u590d\u6027\uff1b\u5bf9\u4e8eGaifman\u5b9a\u7406\uff0c\u4e0d\u76f4\u63a5\u5904\u7406Normal Form\uff0c\u800c\u662f\u805a\u7126\u6559\u6750\u4e2d\u5b9a\u7406\u7684\u4e3b\u5f15\u7406\uff0c\u5e76\u5728\u4e0d\u540c\u5c40\u90e8\u6027\u7406\u89e3\u4e0e\u826f\u597d\u4ee3\u6570\u7ed3\u6784\uff08well-behaved algebra\uff09\u6761\u4ef6\u4e0b\u5bf9\u8be5\u5f15\u7406\u7684\u53ef\u6062\u590d\u6027\u8fdb\u884c\u8bc1\u660e\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1\uff09Hanf\u5b9a\u7406\u5728\u6b8b\u4f59\u683c\u81ea\u7136\u90bb\u57df\u4e0b\u4e00\u822c\u4e0d\u6210\u7acb\uff0c\u4f46\u5728well-connected\u5269\u4f59\u683c\u7684\u7279\u6b8a\u573a\u666f\u4e0b\u53ef\u4ee5\u6062\u590d\uff1b2\uff09\u5bf9\u4e8eGaifman\u5b9a\u7406\uff0c\u4e3b\u5f15\u7406\u5728\u8bed\u6cd5\u4e0a\u53ef\u4ee5\u8868\u8fbe\u5c40\u90e8\u6027\u65f6\uff08\u5373\u4ee3\u6570\u7ed3\u6784\u8db3\u591f\u826f\u597d\uff09\uff0c\u5728\u591a\u79cd\u5bf9\u5c40\u90e8\u6027\u7684\u7406\u89e3\u4e0b\u90fd\u53ef\u4ee5\u8bc1\u660e\u6210\u7acb\uff1b3\uff09\u5224\u5b9a\u8fd9\u4e9b\u5c40\u90e8\u6027\u5b9a\u7406\u80fd\u5426\u6210\u7acb\u7684\u6838\u5fc3\uff0c\u5728\u4e8e\u662f\u5426\u5b58\u5728\u4e00\u79cdorder-interpreting\u7684\u8fde\u63a5\u8bcd\uff0c\u5c06\u6a21\u578b\u2014\u516c\u5f0f\u7684\u5173\u7cfb\u4e0e\u516c\u5f0f\u5728\u4ee3\u6570\u4e2d\u7684\u8d4b\u503c\u51fd\u6570\u76f8\u8054\u7cfb\u3002", "conclusion": "\u591a\u503c\u6a21\u578b\uff08\u7279\u522b\u662f\u57fa\u4e8e\u6b8b\u4f59\u683c\u7684\u6a21\u578b\uff09\u4e0b\uff0c\u7ecf\u5178\u5c40\u90e8\u6027\u5b9a\u7406\uff08Hanf\u3001Gaifman\uff09\u7684\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u5bf9\u5c40\u90e8\u6027\u7684\u5b9a\u4e49\u53ca\u6240\u7528\u4ee3\u6570\u7ed3\u6784\u7684\u6027\u8d28\u3002\u9002\u5f53\u7684\u4ee3\u6570\u7ed3\u6784\u548c\u8fde\u63a5\u8bcd\u662f\u5b9a\u7406\u6210\u7acb\u7684\u5173\u952e\u3002\u90e8\u5206\u7ecf\u5178\u7ed3\u8bba\u53ef\u63a8\u5e7f\u81f3\u591a\u503c\u60c5\u5f62\uff0c\u4f46\u9700\u5bf9\u90bb\u57df\u3001\u65ad\u8a00\u8868\u8fbe\u53ca\u4ee3\u6570\u8981\u6c42\u52a0\u4ee5\u9650\u5b9a\u3002\u672c\u6587\u4e3a\u591a\u503c\u6a21\u578b\u7406\u8bba\u7684\u5c40\u90e8\u6027\u6027\u8d28\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\u4e0e\u82e5\u5e72\u6b63\u53cd\u5b9e\u4f8b\u3002"}}
{"id": "2506.15794", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15794", "abs": "https://arxiv.org/abs/2506.15794", "authors": ["Taylor Lynn Curtis", "Maximilian Puelma Touzel", "William Garneau", "Manon Gruaz", "Mike Pinder", "Li Wei Wang", "Sukanya Krishna", "Luda Cohen", "Jean-Fran\u00e7ois Godbout", "Reihaneh Rabbany", "Kellin Pelrine"], "title": "Veracity: An Open-Source AI Fact-Checking System", "comment": null, "summary": "The proliferation of misinformation poses a significant threat to society,\nexacerbated by the capabilities of generative AI. This demo paper introduces\nVeracity, an open-source AI system designed to empower individuals to combat\nmisinformation through transparent and accessible fact-checking. Veracity\nleverages the synergy between Large Language Models (LLMs) and web retrieval\nagents to analyze user-submitted claims and provide grounded veracity\nassessments with intuitive explanations. Key features include multilingual\nsupport, numerical scoring of claim veracity, and an interactive interface\ninspired by familiar messaging applications. This paper will showcase\nVeracity's ability to not only detect misinformation but also explain its\nreasoning, fostering media literacy and promoting a more informed society.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5f00\u6e90\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edfVeracity\uff0c\u7ed3\u5408\u5927\u6a21\u578b\u4e0e\u68c0\u7d22\uff0c\u652f\u6301\u591a\u8bed\u8a00\u3001\u6570\u503c\u5316\u8bc4\u5206\u3001\u89e3\u91ca\u6027\u5f3a\uff0c\u80fd\u6709\u6548\u5e2e\u52a9\u7528\u6237\u5224\u522b\u548c\u7406\u89e3\u4fe1\u606f\u771f\u4f2a\u3002", "motivation": "\u865a\u5047\u4fe1\u606f\u7684\u6cdb\u6ee5\u5bf9\u793e\u4f1a\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u5c24\u5176\u7531\u4e8e\u751f\u6210\u5f0fAI\u80fd\u529b\u63d0\u5347\u800c\u52a0\u5267\u3002", "method": "\u63d0\u51fa\u4e86Veracity\u7cfb\u7edf\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u7f51\u9875\u68c0\u7d22\u4ee3\u7406\uff0c\u5206\u6790\u7528\u6237\u63d0\u4ea4\u7684\u58f0\u660e\uff0c\u5e76\u63d0\u4f9b\u6709\u636e\u53ef\u4f9d\u7684\u771f\u4f2a\u8bc4\u4f30\u548c\u76f4\u89c2\u89e3\u91ca\u3002", "result": "Veracity\u7cfb\u7edf\u5177\u5907\u591a\u8bed\u8a00\u652f\u6301\u3001\u58f0\u660e\u771f\u4f2a\u7684\u91cf\u5316\u8bc4\u5206\u548c\u7c7b\u5373\u65f6\u901a\u8baf\u5e94\u7528\u7684\u4ea4\u4e92\u754c\u9762\uff0c\u80fd\u591f\u68c0\u6d4b\u865a\u5047\u4fe1\u606f\u5e76\u89e3\u91ca\u5176\u5224\u65ad\u7406\u7531\u3002", "conclusion": "Veracity\u7cfb\u7edf\u80fd\u591f\u63d0\u5347\u7528\u6237\u5bf9\u865a\u5047\u4fe1\u606f\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u652f\u6301\u5a92\u4f53\u7d20\u517b\u6559\u80b2\uff0c\u63a8\u52a8\u793e\u4f1a\u4fe1\u606f\u900f\u660e\u4e0e\u5065\u5eb7\u53d1\u5c55\u3002"}}
{"id": "2506.16440", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16440", "abs": "https://arxiv.org/abs/2506.16440", "authors": ["Ebube Alor", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Evaluating the Use of LLMs for Documentation to Code Traceability", "comment": null, "summary": "Large Language Models (LLMs) offer new potential for automating\ndocumentation-to-code traceability, yet their capabilities remain\nunderexplored. We present a comprehensive evaluation of LLMs (Claude 3.5\nSonnet, GPT-4o, and o3-mini) in establishing trace links between various\nsoftware documentation (including API references and user guides) and source\ncode. We create two novel datasets from two open-source projects (Unity Catalog\nand Crawl4AI). Through systematic experiments, we assess three key\ncapabilities: (1) trace link identification accuracy, (2) relationship\nexplanation quality, and (3) multi-step chain reconstruction. Results show that\nthe best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two\ndatasets, substantially outperforming our baselines (TF-IDF, BM25, and\nCodeBERT). While fully correct relationship explanations range from 42.9% to\n71.1%, partial accuracy exceeds 97%, indicating that fundamental connections\nare rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy\nbut vary in capturing precise intermediate links. Error analysis reveals that\nmany false positives stem from naming-based assumptions, phantom links, or\novergeneralization of architectural patterns. We demonstrate that task-framing,\nsuch as a one-to-many matching strategy, is critical for performance. These\nfindings position LLMs as powerful assistants for trace discovery, but their\nlimitations could necessitate human-in-the-loop tool design and highlight\nspecific error patterns for future research.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86LLM\u5728\u6587\u6863\u5230\u4ee3\u7801\u8ffd\u6eaf\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u8fdc\u8d85\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u4ecd\u6709\u4e00\u5b9a\u8bef\u5dee\u7c7b\u578b\uff0c\u5efa\u8bae\u7ed3\u5408\u4eba\u5de5\u53c2\u4e0e\u4ee5\u63d0\u9ad8\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u6863\u5230\u4ee3\u7801\u53ef\u8ffd\u6eaf\u6027\u81ea\u52a8\u5316\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u6316\u6398\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5bf9\u5176\u6027\u80fd\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u63a2\u7d22\u5176\u5e94\u7528\u524d\u666f\u4e0e\u5c40\u9650\u3002", "method": "\u4f5c\u8005\u9009\u53d6Claude 3.5 Sonnet\u3001GPT-4o\u548co3-mini\u4e09\u79cdLLM\uff0c\u6784\u5efa\u4e86\u4e24\u4e2a\u5305\u542bAPI\u53c2\u8003\u548c\u7528\u6237\u6307\u5357\u7b49\u6587\u6863\u7684\u5f00\u6e90\u9879\u76ee\uff08Unity Catalog\u4e0eCrawl4AI\uff09\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86LLM\u5728\u8ffd\u8e2a\u94fe\u63a5\u51c6\u786e\u6027\u3001\u5173\u7cfb\u89e3\u91ca\u8d28\u91cf\u548c\u591a\u6b65\u94fe\u91cd\u5efa\u4e09\u4e2a\u65b9\u9762\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4e0eTF-IDF\u3001BM25\u3001CodeBERT\u7b49\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u8fdb\u884c\u4e86\u8bef\u5dee\u5206\u6790\u3002", "result": "\u6700\u4f73LLM\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684F1\u5206\u6570\u5206\u522b\u8fbe\u523079.4%\u548c80.4%\uff0c\u5927\u5e45\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff1b\u5b8c\u5168\u6b63\u786e\u7684\u5173\u7cfb\u89e3\u91ca\u5360\u6bd4\u4e3a42.9%-71.1%\uff0c\u90e8\u5206\u51c6\u786e\u7387\u8d8597%\uff1b\u591a\u6b65\u94fe\u7684\u7ec8\u70b9\u8bc6\u522b\u51c6\u786e\u4f46\u4e2d\u95f4\u94fe\u6761\u91cd\u5efa\u6709\u5dee\u5f02\u3002\u9519\u8bef\u591a\u7531\u547d\u540d\u5047\u8bbe\u3001\u865a\u5047\u94fe\u63a5\u6216\u8fc7\u5ea6\u6cdb\u5316\u9020\u6210\u3002\u4efb\u52a1\u8868\u8ff0\uff08\u5982\u4e00\u5bf9\u591a\u5339\u914d\u7b56\u7565\uff09\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "LLM\u5728\u6587\u6863\u5230\u4ee3\u7801\u53ef\u8ffd\u6eaf\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u5f3a\u6709\u529b\u7684\u8f85\u52a9\u5de5\u5177\uff0c\u4f46\u7531\u4e8e\u5b58\u5728\u7279\u5b9a\u8bef\u5dee\u7c7b\u578b\uff0c\u4ecd\u9700\u4eba\u673a\u534f\u4f5c\u548c\u540e\u7eed\u9488\u5bf9\u6027\u6539\u8fdb\u3002"}}
{"id": "2506.16048", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.16048", "abs": "https://arxiv.org/abs/2506.16048", "authors": ["Byeongjee Kang", "Harsh Desai", "Limin Jia", "Brandon Lucia"], "title": "WAMI: Compilation to WebAssembly through MLIR without Losing Abstraction", "comment": null, "summary": "WebAssembly (Wasm) is a portable bytecode format that serves as a compilation\ntarget for high-level languages, enabling their secure and efficient execution\nacross diverse platforms, including web browsers and embedded systems. To\nimprove support for high-level languages without incurring significant code\nsize or performance overheads, Wasm continuously evolves by integrating\nhigh-level features such as Garbage Collection and Stack Switching. However,\nexisting compilation approaches either lack reusable design -- requiring\nredundant implementation efforts for each language -- or lose abstraction by\nlowering high-level constructs into low-level shared representations like LLVM\nIR, which hinder the adoption of high-level features. MLIR compiler\ninfrastructure provides the compilation pipeline with multiple levels of\nabstraction, preserving high-level abstractions throughout the compilation\npipeline, yet the current MLIR pipeline relies on the LLVM backend for Wasm\ncode generation, thereby inheriting LLVM's limitations.\n  This paper presents a novel compilation pipeline for Wasm, featuring Wasm\ndialects explicitly designed to represent high-level Wasm constructs within\nMLIR. Our approach enables direct generation of high-level Wasm code from\ncorresponding high-level MLIR dialects without losing abstraction, providing a\nmodular and extensible way to incorporate high-level Wasm features. We\nillustrate this extensibility through a case study that leverages Stack\nSwitching, a recently introduced high-level feature of Wasm. Performance\nevaluations on PolyBench benchmarks show that our pipeline, benefiting from\noptimizations within the MLIR and Wasm ecosystems, produces code with at most\n7.7\\% slower, and faster in some execution environments, compared to LLVM-based\ncompilers.", "AI": {"tldr": "\u8bba\u6587\u521b\u65b0\u6027\u63d0\u51fa\u4e86\u5728MLIR\u4e2d\u7528\u4e13\u7528Wasm\u65b9\u8a00\u652f\u6301\u9ad8\u5c42Wasm\u7279\u6027\u7684\u7f16\u8bd1\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4e86\u62bd\u8c61\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u7684\u5e73\u8861\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u6570\u573a\u666f\u4e0b\u4e0eLLVM\u65b9\u6cd5\u6548\u679c\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7684Wasm\u7f16\u8bd1\u65b9\u5f0f\uff0c\u8981\u4e48\u6bcf\u4e2a\u9ad8\u5c42\u8bed\u8a00\u90fd\u9700\u5355\u72ec\u5b9e\u73b0\u652f\u6301\uff0c\u5bfc\u81f4\u91cd\u590d\u5de5\u4f5c\uff1b\u8981\u4e48\u76f4\u63a5\u964d\u7ea7\u4e3a\u4f4e\u5c42\u8868\u793a\uff08\u5982LLVM IR\uff09\uff0c\u635f\u5931\u4e86\u9ad8\u5c42\u62bd\u8c61\u6027\uff0c\u9650\u5236\u4e86\u5bf9\u9ad8\u5c42Wasm\u7279\u6027\u7684\u652f\u6301\u3002MLIR\u53ef\u652f\u6301\u591a\u5c42\u62bd\u8c61\uff0c\u4f46\u5176Wasm\u4ee3\u7801\u751f\u6210\u4f9d\u8d56LLVM\u540e\u7aef\uff0c\u5e26\u6765\u4e86LLVM\u7684\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684Wasm\u7f16\u8bd1\u6d41\u6c34\u7ebf\uff1a\u5728MLIR\u4e2d\u8bbe\u8ba1\u4e13\u95e8\u7684Wasm\u65b9\u8a00\uff0c\u9ad8\u5c42MLIR\u65b9\u8a00\u53ef\u76f4\u63a5\u751f\u6210\u9ad8\u5c42Wasm\u4ee3\u7801\uff0c\u65e0\u9700\u4e22\u5931\u62bd\u8c61\u6027\u3002\u901a\u8fc7\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u8bbe\u8ba1\u66f4\u597d\u5730\u652f\u6301\u9ad8\u5c42Wasm\u7279\u6027\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u5173\u4e8eStack Switching\uff08Wasm\u65b0\u9ad8\u5c42\u7279\u6027\uff09\u7684\u6848\u4f8b\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u3002PolyBench\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u672c\u6d41\u6c34\u7ebf\u751f\u6210\u7684\u4ee3\u7801\uff0c\u6700\u6162\u4ec5\u6bd4LLVM\u7f16\u8bd1\u5668\u61627.7%\uff0c\u90e8\u5206\u73af\u5883\u4e0b\u66f4\u5feb\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eMLIR\u7684\u9ad8\u5c42Wasm\u7f16\u8bd1\u6d41\u6c34\u7ebf\u517c\u987e\u62bd\u8c61\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u9ad8\u5c42\u8bed\u8a00\u5f15\u5165Wasm\u65b0\u7279\u6027\u63d0\u4f9b\u4e86\u66f4\u4f18\u89e3\u51b3\u65b9\u6848\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6a21\u5757\u5316\u3001\u6613\u6269\u5c55\u4e14\u6027\u80fd\u826f\u597d\u3002"}}
{"id": "2506.16244", "categories": ["cs.LO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2506.16244", "abs": "https://arxiv.org/abs/2506.16244", "authors": ["Alejandro D\u00edaz-Caro", "Nicolas A. Monzon"], "title": "A Quantum-Control Lambda-Calculus with Multiple Measurement Bases", "comment": "18 pages + appendix", "summary": "We introduce Lambda-SX, a typed quantum lambda-calculus that supports\nmultiple measurement bases. By tracking duplicability relative to arbitrary\nbases within the type system, Lambda-SX enables more flexible control and\ncompositional reasoning about measurements. We formalise its syntax, typing\nrules, subtyping, and operational semantics, and establish its key\nmeta-theoretical properties. This proof-of-concept shows that support for\nmultiple bases can be coherently integrated into the type discipline of quantum\nprogramming languages.", "AI": {"tldr": "Lambda-SX\u662f\u4e00\u79cd\u65b0\u578b\u5e26\u7c7b\u578b\u7cfb\u7edf\u7684\u91cf\u5b50lambda\u6f14\u7b97\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u8bed\u6cd5\u548c\u7c7b\u578b\u89c4\u5219\uff0c\u5b9e\u73b0\u4e86\u591a\u6d4b\u91cf\u57fa\u7684\u7075\u6d3b\u652f\u6301\uff0c\u63d0\u9ad8\u4e86\u91cf\u5b50\u6d4b\u91cf\u7684\u53ef\u7ec4\u5408\u53ca\u7c7b\u578b\u53ef\u63a7\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u7406\u8bba\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u7a0b\u5e8f\u8bbe\u8ba1\u8bed\u8a00\u5728\u7c7b\u578b\u7cfb\u7edf\u4e2d\u901a\u5e38\u4ec5\u652f\u6301\u5355\u4e00\u6d4b\u91cf\u57fa\uff0c\u7f3a\u4e4f\u5bf9\u591a\u57fa\u6d4b\u91cf\u7684\u7075\u6d3b\u63a7\u5236\u4e0e\u7ec4\u5408\u6027\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u8ddf\u8e2a\u4efb\u610f\u57fa\u4e0b\u53ef\u590d\u5236\u6027\u7684\u7c7b\u578b\u7cfb\u7edf\u3002", "method": "\u5f62\u5f0f\u5316\u4e86Lambda-SX\u7684\u8bed\u6cd5\u3001\u7c7b\u578b\u89c4\u5219\u3001\u5b50\u7c7b\u578b\u4ee5\u53ca\u64cd\u4f5c\u8bed\u4e49\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5173\u952e\u7684\u5143\u7406\u8bba\u6027\u8d28\u3002", "result": "\u5b9e\u9a8c\u6027\u5730\u8bc1\u660e\u4e86\u652f\u6301\u591a\u57fa\u6d4b\u91cf\u53ef\u4ee5\u88ab\u4e00\u81f4\u5730\u96c6\u6210\u8fdb\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u7684\u7c7b\u578b\u7cfb\u7edf\u4e2d\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Lambda-SX\u91cf\u5b50lambda\u6f14\u7b97\u5728\u7c7b\u578b\u7cfb\u7edf\u4e2d\u80fd\u591f\u4e00\u81f4\u5730\u96c6\u6210\u591a\u6d4b\u91cf\u57fa\u7684\u652f\u6301\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e00\u6a21\u578b\u7684\u5408\u7406\u8bba\u57fa\u7840\u548c\u53ef\u884c\u6027\u3002"}}
{"id": "2506.15830", "categories": ["cs.CL", "quant-ph", "I.2; I.7"], "pdf": "https://arxiv.org/pdf/2506.15830", "abs": "https://arxiv.org/abs/2506.15830", "authors": ["Riccardo Di Sipio"], "title": "Rethinking LLM Training through Information Geometry and Quantum Metrics", "comment": "9 pages, 1 figure(s)", "summary": "Optimization in large language models (LLMs) unfolds over high-dimensional\nparameter spaces with non-Euclidean structure. Information geometry frames this\nlandscape using the Fisher information metric, enabling more principled\nlearning via natural gradient descent. Though often impractical, this geometric\nlens clarifies phenomena such as sharp minima, generalization, and observed\nscaling laws. We argue that curvature-aware approaches deepen our understanding\nof LLM training. Finally, we speculate on quantum analogies based on the\nFubini-Study metric and Quantum Fisher Information, hinting at efficient\noptimization in quantum-enhanced systems.", "AI": {"tldr": "\u7528\u4fe1\u606f\u51e0\u4f55\u89c6\u89d2\u548c\u81ea\u7136\u68af\u5ea6\u65b9\u6cd5\u89e3\u91caLLM\u4f18\u5316\u673a\u5236\uff0c\u63ed\u793a\u66f2\u7387\u5bf9\u6cdb\u5316\u4e0e\u6781\u5c0f\u503c\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u671b\u4e86\u91cf\u5b50\u4f18\u5316\u6f5c\u529b\u3002", "motivation": "\u968f\u7740LLM\u53c2\u6570\u7a7a\u95f4\u590d\u6742\u5ea6\u548c\u7ef4\u5ea6\u7684\u589e\u957f\uff0c\u4f20\u7edf\u6b27\u6c0f\u7a7a\u95f4\u4e0b\u7684\u4f18\u5316\u5206\u6790\u96be\u4ee5\u5145\u5206\u63ed\u793a\u5176\u8bad\u7ec3\u52a8\u6001\u53ca\u6cdb\u5316\u884c\u4e3a\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u4fe1\u606f\u51e0\u4f55\u89c6\u89d2\uff0c\u5229\u7528\u81ea\u7136\u68af\u5ea6\u65b9\u6cd5\u548cFisher\u4fe1\u606f\u5ea6\u91cf\uff0c\u66f4\u52a0\u7cfb\u7edf\u5730\u7406\u89e3\u548c\u89e3\u91caLLM\u4f18\u5316\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u51e0\u4f55\u7684\u89c6\u89d2\uff0c\u5c06Fisher\u4fe1\u606f\u5ea6\u91cf\u7528\u4f5c\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u7684\u5ea6\u91cf\u5de5\u5177\uff0c\u4ece\u800c\u9610\u91ca\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u5728LLM\u4f18\u5316\u4e2d\u7684\u4f5c\u7528\u548c\u539f\u7406\u3002\u8fdb\u4e00\u6b65\u57fa\u4e8eFubini-Study\u5ea6\u91cf\u548c\u91cf\u5b50Fisher\u4fe1\u606f\uff0c\u63a2\u7d22\u91cf\u5b50\u4f18\u5316\u8303\u5f0f\u5bf9\u672a\u6765\u6a21\u578b\u8bad\u7ec3\u7684\u542f\u793a\u548c\u6f5c\u529b\u3002", "result": "\u901a\u8fc7\u51e0\u4f55\u89c6\u89d2\u89e3\u91ca\u4e86LLM\u8bad\u7ec3\u4e2d\u7684\u9510\u6781\u5c0f\u503c\u3001\u6cdb\u5316\u3001\u4ee5\u53ca\u5927\u6a21\u578b\u6027\u80fd\u968f\u89c4\u6a21\u63d0\u5347\u7684\u89c4\u5f8b\uff0c\u5e76\u6307\u51fa\u66f2\u7387\u611f\u77e5\u4f18\u5316\u65b9\u6cd5\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u7406\u89e3\u548c\u6539\u8fdbLLM\u8bad\u7ec3\u3002\u6700\u540e\u5bf9\u91cf\u5b50\u589e\u5f3a\u4f18\u5316\u8fdb\u884c\u4e86\u7406\u8bba\u4e0a\u7684\u7c7b\u6bd4\u4e0e\u524d\u666f\u5c55\u671b\u3002", "conclusion": "\u5bf9LLM\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5f53\u4f7f\u7528\u5305\u542bFisher\u4fe1\u606f\u5ea6\u91cf\u7684\u51e0\u4f55\u65b9\u6cd5\u5206\u6790\u65f6\uff0c\u53ef\u4ee5\u66f4\u672c\u8d28\u5730\u7406\u89e3\u8bf8\u5982\u6cdb\u5316\u4e0e\u6781\u5c0f\u503c\u7b49\u5173\u952e\u73b0\u8c61\uff0c\u4e5f\u4e3a\u672a\u6765\u66f2\u7387\u76f8\u5173\u6216\u91cf\u5b50\u589e\u5f3a\u4f18\u5316\u65b9\u6cd5\u7684\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.16453", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16453", "abs": "https://arxiv.org/abs/2506.16453", "authors": ["Buthayna AlMulla", "Maram Assi", "Safwat Hassan"], "title": "Understanding the Challenges and Promises of Developing Generative AI Apps: An Empirical Study", "comment": "45 pages, 24 figures, 7 tables", "summary": "The release of ChatGPT in 2022 triggered a rapid surge in generative\nartificial intelligence mobile apps (i.e., Gen-AI apps). Despite widespread\nadoption, little is known about how end users perceive and evaluate these\nGen-AI functionalities in practice. In this work, we conduct a user-centered\nanalysis of 676,066 reviews from 173 Gen-AI apps on the Google Play Store. We\nintroduce a four-phase methodology, SARA (Selection, Acquisition, Refinement,\nand Analysis), that enables the systematic extraction of user insights using\nprompt-based LLM techniques. First, we demonstrate the reliability of LLMs in\ntopic extraction, achieving 91% accuracy through five-shot prompting and\nnon-informative review filtering. Then, we apply this method to the informative\nreviews, identify the top 10 user-discussed topics (e.g., AI Performance,\nContent Quality, and Content Policy & Censorship) and analyze the key\nchallenges and emerging opportunities. Finally, we examine how these topics\nevolve over time, offering insight into shifting user expectations and\nengagement patterns with Gen-AI apps. Based on our findings and observations,\nwe present actionable implications for developers and researchers.", "AI": {"tldr": "\u672c\u7814\u7a76\u57fa\u4e8e67\u4e07\u7528\u6237\u8bc4\u8bba\uff0c\u5229\u7528LLM\u63d0\u51fa\u9ad8\u6548\u8bdd\u9898\u6316\u6398\u65b9\u6cd5\uff0c\u6df1\u5165\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u5e94\u7528\u7684\u7528\u6237\u5173\u6ce8\u70b9\uff0c\u5e76\u4e3a\u5f00\u53d1\u548c\u7814\u7a76\u63d0\u4f9b\u5efa\u8bae\u3002", "motivation": "\u867d\u7136Gen-AI\u5e94\u7528\u5e7f\u53d7\u6b22\u8fce\uff0c\u4f46\u7528\u6237\u5b9e\u9645\u8ba4\u77e5\u548c\u8bc4\u4ef7\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5206\u6790\u7528\u6237\u771f\u5b9e\u53cd\u9988\uff0c\u4e3a\u4ea7\u54c1\u4f18\u5316\u548c\u5b66\u672f\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u5e76\u5e94\u7528\u4e86SARA\uff08\u9009\u62e9\u3001\u83b7\u53d6\u3001\u7cbe\u70bc\u4e0e\u5206\u6790\uff09\u56db\u9636\u6bb5\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u4e94\u6b21\u63d0\u793a\u5b66\u4e60\uff0c\u5bf9173\u6b3eGen-AI\u5e94\u7528\u3001\u517167\u4e07\u4f59\u6761\u8c37\u6b4c\u5546\u5e97\u7528\u6237\u8bc4\u8bba\u8fdb\u884c\u8bdd\u9898\u63d0\u53d6\u3001\u5206\u7ec4\u4e0e\u65f6\u5e8f\u5206\u6790\u3002", "result": "LLM\u5728\u8bdd\u9898\u62bd\u53d6\u4e2d\u7684\u51c6\u786e\u7387\u9ad8\u8fbe91%\uff0c\u7528\u6237\u8ba8\u8bba\u6700\u591a\u7684\u8bdd\u9898\u5305\u62ecAI\u6027\u80fd\u3001\u5185\u5bb9\u8d28\u91cf\u3001\u653f\u7b56\u4e0e\u5ba1\u67e5\u7b49\uff0c\u5206\u6790\u8bc6\u522b\u4e86\u4e3b\u8981\u6311\u6218\u548c\u65b0\u673a\u9047\uff0c\u5e76\u8ffd\u8e2a\u4e86\u7528\u6237\u5173\u6ce8\u70b9\u7684\u52a8\u6001\u53d8\u5316\u3002\u672c\u6587\u6700\u540e\u63d0\u51fa\u4e86\u4fc3\u8fdb\u5e94\u7528\u4f18\u5316\u548c\u672a\u6765\u7814\u7a76\u7684\u5efa\u8bae\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u7528\u6237\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08Gen-AI\uff09\u79fb\u52a8\u5e94\u7528\u7684\u8bc4\u4ef7\uff0c\u6587\u7ae0\u63ed\u793a\u4e86\u7528\u6237\u5173\u6ce8\u7684\u6838\u5fc3\u8bdd\u9898\u53ca\u5176\u968f\u65f6\u95f4\u53d8\u5316\u7684\u8d8b\u52bf\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u6027\u7684\u5efa\u8bae\u3002"}}
{"id": "2506.16883", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.16883", "abs": "https://arxiv.org/abs/2506.16883", "authors": ["Christoph Jung", "C. F. Bolz-Tereick"], "title": "Low Overhead Allocation Sampling in a Garbage Collected Virtual Machine", "comment": null, "summary": "Compared to the more commonly used time-based profiling, allocation profiling\nprovides an alternate view of the execution of allocation heavy dynamically\ntyped languages. However, profiling every single allocation in a program is\nvery inefficient. We present a sampling allocation profiler that is deeply\nintegrated into the garbage collector of PyPy, a Python virtual machine. This\nintegration ensures tunable low overhead for the allocation profiler, which we\nmeasure and quantify. Enabling allocation sampling profiling with a sampling\nperiod of 4 MB leads to a maximum time overhead of 25% in our benchmarks, over\nun-profiled regular execution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u4e0ePyPy\u5783\u573e\u56de\u6536\u5668\u6df1\u5ea6\u96c6\u6210\u7684\u5206\u914d\u91c7\u6837\u5206\u6790\u5de5\u5177\uff0c\u4ee5\u8f83\u4f4e\u7684\u6027\u80fd\u5f00\u9500\uff08\u6700\u592725%\uff09\u4e3a\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u7a0b\u5e8f\u7684\u6027\u80fd\u8c03\u4f18\u63d0\u4f9b\u6709\u6548\u652f\u6301\u3002", "motivation": "\u5728\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u7279\u522b\u662f\u5206\u914d\u5bc6\u96c6\u578b\u7a0b\u5e8f\u4e2d\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u65f6\u95f4\u7684\u6027\u80fd\u5206\u6790\u65b9\u6cd5\u5e76\u4e0d\u603b\u662f\u80fd\u5f88\u597d\u53cd\u6620\u7a0b\u5e8f\u8d44\u6e90\u6d88\u8017\u3002\u672c\u6587\u5173\u6ce8\u901a\u8fc7\u5206\u914d\u5206\u6790\u6765\u8865\u5145\u65f6\u95f4\u5206\u6790\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u6027\u80fd\u89c2\u6d4b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u5206\u914d\u5206\u6790\u5668\uff0c\u5e76\u5c06\u5176\u6df1\u5ea6\u96c6\u6210\u5230PyPy\uff08\u4e00\u4e2aPython\u865a\u62df\u673a\uff09\u7684\u5783\u573e\u56de\u6536\u5668\u4e2d\u3002\u901a\u8fc7\u8c03\u6574\u91c7\u6837\u5468\u671f\uff0c\u63a7\u5236\u5206\u6790\u5f00\u9500\u3002", "result": "\u5728\u91c7\u6837\u5468\u671f\u4e3a4MB\u65f6\uff0c\u5206\u914d\u91c7\u6837\u5206\u6790\u5668\u7684\u6700\u5927\u65f6\u95f4\u5f00\u9500\u4e3a25%\uff0c\u53ef\u8c03\u4e14\u4e0e\u672a\u5206\u6790\u65f6\u7684\u5e38\u89c4\u6267\u884c\u76f8\u6bd4\u6548\u7387\u8f83\u9ad8\u3002", "conclusion": "\u5c06\u5206\u914d\u91c7\u6837\u5206\u6790\u5668\u96c6\u6210\u8fdb\u5783\u573e\u56de\u6536\u5668\u662f\u4e00\u79cd\u53ef\u884c\u7684\u4f4e\u5f00\u9500\u5206\u914d\u5206\u6790\u65b9\u5f0f\uff0c\u4e3a\u5206\u914d\u5bc6\u96c6\u578b\u3001\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u7684\u6027\u80fd\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6848\u3002"}}
{"id": "2506.16775", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.16775", "abs": "https://arxiv.org/abs/2506.16775", "authors": ["Lina Gerlach", "Christof L\u00f6ding", "Erika \u00c1brah\u00e1m"], "title": "A Hyperlogic for Strategies in Stochastic Games (Extended Version)", "comment": "Accepted for publication at QEST+FORMATS 2025", "summary": "We propose a probabilistic hyperlogic called HyperSt$^2$ that can express\nhyperproperties of strategies in turn-based stochastic games. To the best of\nour knowledge, HyperSt$^2$ is the first hyperlogic for stochastic games.\nHyperSt$^2$ can relate probabilities of several independent executions of\nstrategies in a stochastic game. For example, in HyperSt$^2$ it is natural to\nformalize optimality, i.e., to express that some strategy is better than all\nother strategies, or to express the existence of Nash equilibria. We\ninvestigate the expressivity of HyperSt$^2$ by comparing it to existing logics\nfor stochastic games, as well as existing hyperlogics. Though the\nmodel-checking problem for HyperSt$^2$ is in general undecidable, we show that\nit becomes decidable for bounded memory and is in EXPTIME and PSPACE-hard over\nmemoryless deterministic strategies, and we identify a fragment for which the\nmodel-checking problem is PSPACE-complete.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u7814\u7a76\u4e86\u4e00\u79cd\u65b0\u578b\u6982\u7387\u8d85\u903b\u8f91HyperSt$^2$\uff0c\u9996\u6b21\u4f7f\u5f97\u56de\u5408\u5236\u968f\u673a\u535a\u5f08\u4e2d\u591a\u7b56\u7565\u3001\u591a\u8f68\u8ff9\u6982\u7387\u5173\u7cfb\u7684\u8868\u8fbe\u4e0e\u5224\u5b9a\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5224\u5b9a\u6027\u4e0e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u903b\u8f91\u4f53\u7cfb\u96be\u4ee5\u8868\u8fbe\u5173\u4e8e\u7b56\u7565\u7684\u8d85\u6027\u8d28\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u56de\u5408\u5236\u968f\u673a\u535a\u5f08\u4e2d\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u7b56\u7565\u95f4\u591a\u6267\u884c\u8f68\u8ff9\u6982\u7387\u5173\u7cfb\u7684\u903b\u8f91\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u8d85\u903b\u8f91HyperSt$^2$\uff0c\u80fd\u591f\u5728\u56de\u5408\u5236\u968f\u673a\u535a\u5f08\u4e2d\u8868\u8fbe\u548c\u5bf9\u6bd4\u591a\u79cd\u7b56\u7565\u591a\u4e2a\u72ec\u7acb\u6267\u884c\u7684\u6982\u7387\u5173\u7cfb\uff0c\u5e76\u5f62\u5f0f\u5316\u6700\u4f18\u6027\u53ca\u7eb3\u4ec0\u5747\u8861\u7b49\u6982\u5ff5\u3002\u6b64\u5916\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u8be5\u903b\u8f91\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u4e0e\u73b0\u6709\u7684\u903b\u8f91\u4f53\u7cfb\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86HyperSt$^2$\u903b\u8f91\u7684\u53ef\u5224\u5b9a\u6027\u53d7\u9650\u6761\u4ef6\uff0c\u5305\u62ec\u5bf9\u6709\u754c\u8bb0\u5fc6\u7684\u60c5\u51b5\u4e0b\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5728\u65e0\u8bb0\u5fc6\u786e\u5b9a\u6027\u7b56\u7565\u4e0b\u590d\u6742\u5ea6\u4e3aEXPTIME\u548cPSPACE-hard\uff0c\u5e76\u6307\u51fa\u5b58\u5728\u4e00\u4e2a\u7247\u65ad\uff0c\u5176\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\u4e3aPSPACE-complete\u3002", "conclusion": "HyperSt$^2$\u662f\u9996\u4e2a\u9762\u5411\u968f\u673a\u535a\u5f08\u7684\u8d85\u903b\u8f91\uff0c\u4e3a\u8868\u8fbe\u548c\u9a8c\u8bc1\u535a\u5f08\u4e2d\u7b56\u7565\u7684\u8d85\u6027\u8d28\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u5e76\u5bf9\u5176\u5224\u5b9a\u8fb9\u754c\u548c\u590d\u6742\u5ea6\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u7406\u8bba\u523b\u753b\u3002"}}
{"id": "2506.15841", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.15841", "abs": "https://arxiv.org/abs/2506.15841", "authors": ["Zijian Zhou", "Ao Qu", "Zhaoxuan Wu", "Sunghwan Kim", "Alok Prakash", "Daniela Rus", "Jinhua Zhao", "Bryan Kian Hsiang Low", "Paul Pu Liang"], "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents", "comment": null, "summary": "Modern language agents must operate over long-horizon, multi-turn\ninteractions, where they retrieve external information, adapt to observations,\nand answer interdependent queries. Yet, most LLM systems rely on full-context\nprompting, appending all past turns regardless of their relevance. This leads\nto unbounded memory growth, increased computational costs, and degraded\nreasoning performance on out-of-distribution input lengths. We introduce MEM1,\nan end-to-end reinforcement learning framework that enables agents to operate\nwith constant memory across long multi-turn tasks. At each turn, MEM1 updates a\ncompact shared internal state that jointly supports memory consolidation and\nreasoning. This state integrates prior memory with new observations from the\nenvironment while strategically discarding irrelevant or redundant information.\nTo support training in more realistic and compositional settings, we propose a\nsimple yet effective and scalable approach to constructing multi-turn\nenvironments by composing existing datasets into arbitrarily complex task\nsequences. Experiments across three domains, including internal retrieval QA,\nopen-domain web QA, and multi-turn web shopping, show that MEM1-7B improves\nperformance by 3.5x while reducing memory usage by 3.7x compared to\nQwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes\nbeyond the training horizon. Our results demonstrate the promise of\nreasoning-driven memory consolidation as a scalable alternative to existing\nsolutions for training long-horizon interactive agents, where both efficiency\nand performance are optimized.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684MEM1\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e86\u5e38\u91cf\u5185\u5b58\u3001\u591a\u8f6e\u63a8\u7406\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u8457\u63d0\u5347\u6548\u7387\u4e0e\u6027\u80fd\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80LLM\u5728\u957f\u5e8f\u5217\u548c\u591a\u4efb\u52a1\u573a\u666f\u4e0a\u7684\u74f6\u9888\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u4ee3\u7406\u9700\u8981\u5728\u957f\u65f6\u3001\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u73b0\u6709\u4e3b\u6d41LLM\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u5168\u4e0a\u4e0b\u6587\u63d0\u793a\uff0c\u65e0\u9009\u62e9\u5730\u6dfb\u52a0\u6240\u6709\u5386\u53f2\u5185\u5bb9\uff0c\u5bfc\u81f4\u5185\u5b58\u65e0\u754c\u589e\u957f\u3001\u8ba1\u7b97\u6210\u672c\u4e0a\u5347\u4ee5\u53ca\u63a8\u7406\u6027\u80fd\u4e0b\u964d\u3002\u8bba\u6587\u52a8\u673a\u662f\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u8f6e\u957f\u4efb\u52a1\u4e0b\u7684\u4f4e\u6548\u548c\u63a8\u7406\u80fd\u529b\u53d7\u9650\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6MEM1\uff0c\u53ef\u4f7f\u4ee3\u7406\u5728\u591a\u8f6e\u957f\u4efb\u52a1\u4e2d\u4ee5\u5e38\u91cf\u5185\u5b58\u8fd0\u884c\u3002\u6bcf\u4e00\u6b65\uff0cMEM1\u901a\u8fc7\u7d27\u51d1\u7684\u5185\u90e8\u72b6\u6001\u6574\u5408\u4e4b\u524d\u8bb0\u5fc6\u548c\u65b0\u89c2\u6d4b\uff0c\u540c\u65f6\u6709\u9009\u62e9\u5730\u4e22\u5f03\u65e0\u5173\u6216\u5197\u4f59\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u7684\u591a\u8f6e\u73af\u5883\uff0c\u5229\u7528\u73b0\u6709\u6570\u636e\u96c6\u7ec4\u5408\u751f\u6210\u590d\u6742\u4efb\u52a1\u5e8f\u5217\uff0c\u4ee5\u652f\u6301\u5728\u66f4\u771f\u5b9e\u548c\u53ef\u7ec4\u5408\u7684\u73af\u5883\u4e2d\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\uff08\u5185\u90e8\u68c0\u7d22\u95ee\u7b54\u3001\u5f00\u653e\u57df\u7f51\u9875\u95ee\u7b54\u548c\u591a\u8f6e\u7f51\u9875\u8d2d\u7269\uff09\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMEM1-7B\u572816\u76ee\u6807\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e0a\u6bd4Qwen2.5-14B-Instruct\u6027\u80fd\u63d0\u53473.5\u500d\uff0c\u540c\u65f6\u5185\u5b58\u4f7f\u7528\u51cf\u5c113.7\u500d\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u8bad\u7ec3\u4e4b\u5916\u7684\u4efb\u52a1\u957f\u5ea6\u3002", "conclusion": "\u4ee5\u63a8\u7406\u4e3a\u9a71\u52a8\u7684\u8bb0\u5fc6\u6574\u5408\u4e3a\u9ad8\u6548\u8bad\u7ec3\u548c\u90e8\u7f72\u957f\u65f6\u3001\u591a\u8f6e\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5728\u6548\u7387\u548c\u6027\u80fd\u95f4\u5b9e\u73b0\u4e86\u4f18\u5316\u3002"}}
{"id": "2506.16557", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16557", "abs": "https://arxiv.org/abs/2506.16557", "authors": ["Hern\u00e1n Gagliardi", "Victor Braberman", "Sebastian Uchitel"], "title": "Scaling GR(1) Synthesis via a Compositional Framework for LTL Discrete Event Control", "comment": "To be published in CAV25", "summary": "We present a compositional approach to controller synthesis of discrete event\nsystem controllers with linear temporal logic (LTL) goals. We exploit the\nmodular structure of the plant to be controlled, given as a set of labelled\ntransition systems (LTS), to mitigate state explosion that monolithic\napproaches to synthesis are prone to. Maximally permissive safe controllers are\niteratively built for subsets of the plant LTSs by solving weaker control\nproblems. Observational synthesis equivalence is used to reduce the size of the\ncontrolled subset of the plant by abstracting away local events. The result of\nsynthesis is also compositional, a set of controllers that when run in parallel\nensure the LTL goal. We implement synthesis in the MTSA tool for an expressive\nsubset of LTL, GR(1), and show it computes solutions to that can be up to 1000\ntimes larger than those that the monolithic approach can solve.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6a21\u5757\u5316\u7ec4\u5408\u5f0fLTL\u63a7\u5236\u5668\u5408\u6210\u6cd5\uff0c\u5927\u5927\u6269\u5c55\u4e86\u53ef\u63a7\u7cfb\u7edf\u89c4\u6a21\uff0c\u5e76\u5df2\u901a\u8fc7\u8f6f\u4ef6\u5de5\u5177\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5355\u4f53LTL\u63a7\u5236\u5668\u5408\u6210\u6613\u5f15\u53d1\u72b6\u6001\u7206\u70b8\u7684\u95ee\u9898\uff0c\u63d0\u5347\u53ef\u63a7\u7cfb\u7edf\u7684\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u5904\u7406\u80fd\u529b\u3002", "method": "\u5229\u7528\u88ab\u63a7\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u7ed3\u6784\uff0c\u5c06\u88ab\u63a7\u5bf9\u8c61\u5206\u89e3\u4e3aLTS\u7684\u5b50\u96c6\uff0c\u901a\u8fc7\u8fed\u4ee3\u5730\u4e3a\u5176\u5b50\u96c6\u751f\u6210\u6700\u5927\u5141\u8bb8\u7684\u5b89\u5168\u63a7\u5236\u5668\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u89c2\u6d4b\u7b49\u4ef7\u7c7b\u5c06\u5c40\u90e8\u4e8b\u4ef6\u62bd\u8c61\uff0c\u7b80\u5316\u5f85\u63a7\u5b50\u7cfb\u7edf\u89c4\u6a21\uff0c\u6700\u7ec8\u5408\u6210\u591a\u4e2a\u63a7\u5236\u5668\u5e76\u5e76\u884c\u8fd0\u884c\u3002\u65b9\u6cd5\u5728MTSA\u5de5\u5177\u4e0a\u5b9e\u73b0\uff0c\u9488\u5bf9LTL\u7684GR(1)\u5b50\u96c6\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u7ec4\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u53ef\u5904\u7406\u7cfb\u7edf\u89c4\u6a21\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u5408\u6210\u7684\u7cfb\u7edf\u89c4\u6a21\u662f\u5355\u4f53\u65b9\u6cd5\u76841000\u500d\u3002\u5176\u63a7\u5236\u5668\u80fd\u4fdd\u8bc1\u5e76\u884c\u534f\u4f5c\u4e0b\u6ee1\u8db3\u5168\u5c40LTL\u76ee\u6807\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7ec4\u5408\u5f0f\u5408\u6210\u65b9\u6cd5\u53ef\u4ee5\u63a7\u5236\u6bd4\u5355\u4e00\u65b9\u6cd5\u5927\u5f97\u591a\u7684\u7cfb\u7edf\u89c4\u6a21\uff0c\u5b9e\u73b0\u5b89\u5168\u4e14\u6ee1\u8db3LTL\u89c4\u683c\u7684\u63a7\u5236\u5668\u5408\u6210\u3002\u6240\u5f97\u63a7\u5236\u5668\u5177\u6709\u7ec4\u5408\u6027\uff0c\u5e76\u80fd\u4fdd\u8bc1\u5168\u5c40LTL\u76ee\u6807\u7684\u8fbe\u6210\u3002"}}
{"id": "2506.17142", "categories": ["cs.LO", "math.LO", "03B42", "F.4.1"], "pdf": "https://arxiv.org/pdf/2506.17142", "abs": "https://arxiv.org/abs/2506.17142", "authors": ["Adam Bjorndahl", "Philip Sink"], "title": "A Note on Proper Relational Structures", "comment": null, "summary": "In this note we provide an algorithm for translating relational structures\ninto \"proper\" relational structures, i.e., those such that there is no pair of\nworlds w and u such that w is accessible from u for every agent. In particular,\nour method of translation preserves many classical properties of relational\nstructures, such as transitivity and the Euclidean property. As a result, this\nmethod of translation has many applications in the literature on Simplicial\nSemantics for modal logic, where the creation of proper canonical relational\nstructures is a common step in proofs of completeness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4e00\u822c\u5173\u7cfb\u7ed3\u6784\u8f6c\u6362\u4e3a\u201c\u9002\u5f53\u201d\u5173\u7cfb\u7ed3\u6784\u7684\u7b97\u6cd5\uff0c\u4fdd\u7559\u4e86\u7ed3\u6784\u7684\u4f20\u9012\u6027\u7b49\u7ecf\u5178\u5c5e\u6027\uff0c\u5e76\u53ef\u7528\u4e8e\u6a21\u6001\u903b\u8f91\u76f8\u5173\u8bc1\u660e\u3002", "motivation": "\u672c\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u5c06\u5173\u7cfb\u7ed3\u6784\u8f6c\u5316\u4e3a\u201c\u9002\u5f53\u201d\u5173\u7cfb\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u5373\u4e0d\u5b58\u5728\u4e00\u5bf9\u4e16\u754cw\u548cu\uff0c\u4f7f\u5f97w\u5bf9\u4e8e\u6bcf\u4e2a\u4e3b\u4f53\u6765\u8bf4\u90fd\u53ef\u4ee5\u4eceu\u5230\u8fbe\u3002\u6b64\u95ee\u9898\u5728\u6a21\u6001\u903b\u8f91\u7684Simplicial\u8bed\u4e49\u4e2d\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5c06\u4efb\u610f\u5173\u7cfb\u7ed3\u6784\u8f6c\u6362\u4e3a\u201c\u9002\u5f53\u201d\u5173\u7cfb\u7ed3\u6784\u3002\u8be5\u7b97\u6cd5\u53ef\u4fdd\u7559\u5173\u7cfb\u7ed3\u6784\u7684\u8bb8\u591a\u7ecf\u5178\u6027\u8d28\uff0c\u5982\u4f20\u9012\u6027\u548cEuclidean\u5c5e\u6027\u3002", "result": "\u63d0\u51fa\u7684\u8f6c\u6362\u65b9\u6cd5\u80fd\u591f\u786e\u4fdd\u751f\u6210\u7684\u5173\u7cfb\u7ed3\u6784\u540c\u65f6\u5177\u6709\u201c\u9002\u5f53\u6027\u201d\u548c\u4fdd\u7559\u91cd\u8981\u6027\u8d28\uff0c\u8fd9\u4e3a\u8fdb\u4e00\u6b65\u7684\u903b\u8f91\u8bc1\u660e\u548c\u7406\u8bba\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u4e3a\u5173\u7cfb\u7ed3\u6784\u5411\u201c\u9002\u5f53\u201d\u5173\u7cfb\u7ed3\u6784\u7684\u8f6c\u6362\u63d0\u4f9b\u4e86\u6709\u6548\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u8be5\u7b97\u6cd5\u4e0d\u7834\u574f\u8bf8\u5982\u4f20\u9012\u6027\u4e0eEuclidean\u6027\u7b49\u5173\u952e\u7ed3\u6784\u5c5e\u6027\u3002\u5176\u6210\u679c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u6a21\u6001\u903b\u8f91Simplicial\u8bed\u4e49\u4e2d\u7684\u5b8c\u5907\u6027\u8bc1\u660e\u7b49\u573a\u666f\u3002"}}
{"id": "2506.15846", "categories": ["cs.CL", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2506.15846", "abs": "https://arxiv.org/abs/2506.15846", "authors": ["Glenn Matlin", "Mika Okamoto", "Huzaifa Pardawala", "Yang Yang", "Sudheer Chava"], "title": "Finance Language Model Evaluation (FLaME)", "comment": null, "summary": "Language Models (LMs) have demonstrated impressive capabilities with core\nNatural Language Processing (NLP) tasks. The effectiveness of LMs for highly\nspecialized knowledge-intensive tasks in finance remains difficult to assess\ndue to major gaps in the methodologies of existing evaluation frameworks, which\nhave caused an erroneous belief in a far lower bound of LMs' performance on\ncommon Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for\nthese FinNLP tasks, we present the first holistic benchmarking suite for\nFinancial Language Model Evaluation (FLaME). We are the first research paper to\ncomprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical\nstudy of 23 foundation LMs over 20 core NLP tasks in finance. We open-source\nour framework software along with all data and results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5f00\u6e90\u4e86\u9996\u4e2a\u91d1\u878dNLP\u5168\u9762\u8bc4\u6d4b\u5957\u4ef6FLaME\uff0c\u5bf9\u6bd4\u5206\u6790\u4e8623\u79cd\u8bed\u8a00\u6a21\u578b\u572820\u9879\u91d1\u878d\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u663e\u793a\u51fa\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u663e\u8457\u6f5c\u529b\uff0c\u7ea0\u6b63\u4e86\u4ee5\u5f80\u7684\u4f4e\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u91d1\u878d\u9886\u57dfNLP\u8bc4\u6d4b\u65b9\u6cd5\u5b58\u5728\u91cd\u5927\u4e0d\u8db3\uff0c\u5bfc\u81f4\u5bf9\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u4efb\u52a1\u8868\u73b0\u7684\u4f4e\u4f30\u3002\u9700\u8981\u4e00\u4e2a\u5168\u9762\u7684\u8bc4\u6d4b\u57fa\u51c6\u6765\u79d1\u5b66\u8861\u91cf\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u95e8\u91d1\u878dNLP\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5168\u9762\u7684\u91d1\u878d\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u57fa\u51c6\u5957\u4ef6FLaME\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u5bf9\u6bd4\u4e8623\u79cd\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u572820\u9879\u6838\u5fc3\u91d1\u878dNLP\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u4e86\u666e\u901a\u548c\u201c\u63a8\u7406\u5f3a\u5316\u201d\u7c7b\u578b\u7684\u8bed\u8a00\u6a21\u578b\u3002\u6240\u6709\u8f6f\u4ef6\u6846\u67b6\u3001\u6570\u636e\u4e0e\u7ed3\u679c\u5747\u5f00\u6e90\u3002", "result": "23\u79cd\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u572820\u9879\u91d1\u878dNLP\u4efb\u52a1\u4e0a\u7684\u7cfb\u7edf\u6027\u5b9e\u8bc1\u5206\u6790\uff0c\u5c55\u793a\u4e86\u5176\u5728\u91d1\u878d\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u7ea0\u6b63\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878dNLP\u4efb\u52a1\u4e2d\u7684\u4f4e\u4f30\u8868\u73b0\u3002", "conclusion": "\u5efa\u7acb\u4e86\u66f4\u79d1\u5b66\u7684\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u9996\u6b21\u5168\u9762\u5c55\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878dNLP\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u4e3a\u4eca\u540e\u91d1\u878dNLP\u7814\u7a76\u548c\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2506.16586", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16586", "abs": "https://arxiv.org/abs/2506.16586", "authors": ["Ihor Pysmennyi", "Roman Kyslyi", "Kyrylo Kleshch"], "title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions", "comment": "11 pages, 9 figures", "summary": "Traditional quality assurance (QA) methods face significant challenges in\naddressing the complexity, scale, and rapid iteration cycles of modern software\nsystems and are strained by limited resources available, leading to substantial\ncosts associated with poor quality. The object of this research is the Quality\nAssurance processes for modern distributed software applications. The subject\nof the research is the assessment of the benefits, challenges, and prospects of\nintegrating modern AI-oriented tools into quality assurance processes. We\nperformed comprehensive analysis of implications on both verification and\nvalidation processes covering exploratory test analyses, equivalence\npartitioning and boundary analyses, metamorphic testing, finding\ninconsistencies in acceptance criteria (AC), static analyses, test case\ngeneration, unit test generation, test suit optimization and assessment, end to\nend scenario execution. End to end regression of sample enterprise application\nutilizing AI-agents over generated test scenarios was implemented as a proof of\nconcept highlighting practical use of the study. The results, with only 8.3%\nflaky executions of generated test cases, indicate significant potential for\nthe proposed approaches. However, the study also identified substantial\nchallenges for practical adoption concerning generation of semantically\nidentical coverage, \"black box\" nature and lack of explainability from\nstate-of-the-art Large Language Models (LLMs), the tendency to correct mutated\ntest cases to match expected results, underscoring the necessity for thorough\nverification of both generated artifacts and test execution results. The\nresearch demonstrates AI's transformative potential for QA but highlights the\nimportance of a strategic approach to implementing these technologies,\nconsidering the identified limitations and the need for developing appropriate\nverification methodologies.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86AI\u5de5\u5177\u5e94\u7528\u4e8e\u73b0\u4ee3\u8f6f\u4ef6QA\u6d41\u7a0b\u7684\u673a\u9047\u4e0e\u6311\u6218\uff0c\u5b9e\u8bc1\u6f14\u793a\u4e86\u5176\u6f5c\u529b\uff0c\u4f46\u4e5f\u6307\u51fa\u201c\u9ed1\u76d2\u201d\u7b49\u96be\u9898\uff0c\u5f3a\u8c03\u5b9e\u65bd\u9700\u614e\u91cd\u5e76\u53d1\u5c55\u65b0\u9a8c\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u5206\u5e03\u5f0f\u8f6f\u4ef6\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\u3001\u89c4\u6a21\u5e9e\u5927\u4e14\u8fed\u4ee3\u8fc5\u901f\uff0c\u4f20\u7edf\u8d28\u91cf\u4fdd\u8bc1\uff08QA\uff09\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u800c\u8d44\u6e90\u6709\u9650\u53c8\u5bfc\u81f4\u8d28\u91cf\u95ee\u9898\u5e26\u6765\u9ad8\u6602\u6210\u672c\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684QA\u65b9\u6848\u3002", "method": "\u5bf9\u73b0\u4ee3AI\u5de5\u5177\u5728\u8d28\u91cf\u4fdd\u8bc1\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u6db5\u76d6\u4e86\u6d4b\u8bd5\u5206\u6790\u3001\u7b49\u4ef7\u5212\u5206\u548c\u8fb9\u754c\u5206\u6790\u3001\u53d8\u5f02\u6d4b\u8bd5\u3001\u9a8c\u6536\u6807\u51c6\u4e0d\u4e00\u81f4\u6027\u53d1\u73b0\u3001\u9759\u6001\u5206\u6790\u3001\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u3001\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u3001\u6d4b\u8bd5\u5957\u4ef6\u4f18\u5316\u4e0e\u8bc4\u4f30\u3001\u7aef\u5230\u7aef\u573a\u666f\u6267\u884c\u7b49\u65b9\u9762\u3002\u4ee5AI\u4ee3\u7406\u5728\u4f01\u4e1a\u5e94\u7528\u7aef\u5230\u7aef\u56de\u5f52\u6d4b\u8bd5\u4e3a\u5b9e\u4f8b\uff0c\u5b9e\u73b0\u4e86\u5b9e\u9645\u5e94\u7528\u6f14\u793a\u3002", "result": "AI\u751f\u6210\u6d4b\u8bd5\u6848\u4f8b\u4ec58.3%\u4e3aflaky\uff08\u4e0d\u7a33\u5b9a\u968f\u673a\u5931\u8d25\uff09\uff0c\u663e\u793a\u51fa\u65b9\u6cd5\u7684\u5de8\u5927\u6f5c\u529b\u3002\u4f46\u4e5f\u53d1\u73b0\u4e86\u5b9e\u9645\u91c7\u7528\u4e2d\u7684\u4e3b\u8981\u6311\u6218\uff0c\u4f8b\u5982\u751f\u6210\u8bed\u4e49\u7b49\u4ef7\u8986\u76d6\u7684\u96be\u5ea6\u3001LLM\u7684\u201c\u9ed1\u76d2\u201d\u5c5e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3001\u6a21\u578b\u503e\u5411\u5c06\u53d8\u5f02\u7528\u4f8b\u4fee\u6b63\u4e3a\u9884\u671f\u7ed3\u679c\u7b49\uff0c\u51f8\u663e\u4e86\u5bf9\u751f\u6210\u6210\u679c\u548c\u6d4b\u8bd5\u6267\u884c\u7ed3\u679c\u4e25\u683c\u9a8c\u8bc1\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "AI\u6709\u671b\u663e\u8457\u53d8\u9769\u73b0\u4ee3\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u6d41\u7a0b\uff0c\u4f46\u5e94\u5bf9AI\u5de5\u5177\u7684\u5c40\u9650\u91c7\u53d6\u6218\u7565\u6027\u5b9e\u65bd\uff0c\u5e76\u5f00\u53d1\u914d\u5957\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2506.15889", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15889", "abs": "https://arxiv.org/abs/2506.15889", "authors": ["Yifan Hu", "Frank Liang", "Dachuan Zhao", "Jonathan Geuter", "Varshini Reddy", "Craig W. Schmidt", "Chris Tanner"], "title": "Entropy-Driven Pre-Tokenization for Byte-Pair Encoding", "comment": null, "summary": "Byte-Pair Encoding (BPE) has become a widely adopted subword tokenization\nmethod in modern language models due to its simplicity and strong empirical\nperformance across downstream tasks. However, applying BPE to unsegmented\nlanguages such as Chinese presents significant challenges, as its\nfrequency-driven merge operation is agnostic to linguistic boundaries. To\naddress this, we propose two entropy-informed pre-tokenization strategies that\nguide BPE segmentation using unsupervised information-theoretic cues. The first\napproach uses pointwise mutual information and left/right entropy to identify\ncoherent character spans, while the second leverages predictive entropy derived\nfrom a pretrained GPT-2 model to detect boundary uncertainty. We evaluate both\nmethods on a subset of the PKU dataset and demonstrate substantial improvements\nin segmentation precision, recall, and F1 score compared to standard BPE. Our\nresults suggest that entropy-guided pre-tokenization not only enhances\nalignment with gold-standard linguistic units but also offers a promising\ndirection for improving tokenization quality in low-resource and multilingual\nsettings.", "AI": {"tldr": "\u4f5c\u8005\u6539\u8fdb\u4e86BPE\u5206\u8bcd\u65b9\u5f0f\uff0c\u5728BPE\u524d\u901a\u8fc7\u71b5\u4fe1\u606f\u9884\u5904\u7406\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e2d\u6587\u7b49\u65e0\u5207\u5206\u8bed\u8a00\u7684\u5206\u8bcd\u8d28\u91cf\u3002", "motivation": "\u5e38\u89c4BPE\u56e0\u53ea\u8003\u8651\u8bcd\u9891\u800c\u4e0d\u987e\u8bed\u8a00\u8fb9\u754c\uff0c\u5bfc\u81f4\u5728\u65e0\u5207\u5206\u8bed\u8a00\u5982\u4e2d\u6587\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u9700\u5f15\u5165\u65e0\u76d1\u7763\u4fe1\u606f\u5b66\u65b9\u6cd5\u8f85\u52a9\u5206\u5272\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u4fe1\u606f\u71b5\u9a71\u52a8\u7684\u9884\u5206\u8bcd\u65b9\u6cd5\uff1a\u4e00\u79cd\u7ed3\u5408\u70b9\u4e92\u4fe1\u606f\u4e0e\u5de6\u53f3\u71b5\u68c0\u6d4b\u5b57\u7b26\u7ec4\u5408\uff0c\u53e6\u4e00\u79cd\u501f\u52a9GPT-2\u6a21\u578b\u9884\u6d4b\u71b5\u8fa8\u8bc6\u5206\u754c\u70b9\uff0c\u7136\u540e\u518d\u7528BPE\u5206\u8bcd\u3002", "result": "\u5728PKU\u6570\u636e\u5b50\u96c6\u4e0a\u4e24\u79cd\u65b0\u65b9\u6cd5\u7684\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5f97\u5206\u5747\u4f18\u4e8e\u4f20\u7edfBPE\uff0c\u66f4\u8d34\u5408\u4eba\u5de5\u6807\u51c6\u5206\u8bcd\u5355\u5143\u3002", "conclusion": "\u5f15\u5165\u71b5\u4fe1\u606f\u7684\u9884\u5206\u8bcd\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86BPE\u5728\u4e2d\u6587\u5206\u8bcd\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5bf9\u4f4e\u8d44\u6e90\u548c\u591a\u8bed\u8a00\u573a\u666f\u7684\u5206\u8bcd\u8d28\u91cf\u6539\u8fdb\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.16639", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16639", "abs": "https://arxiv.org/abs/2506.16639", "authors": ["Boqi Chen", "Aren A. Babikian", "Shuzhao Feng", "D\u00e1niel Varr\u00f3", "Gunter Mussbacher"], "title": "LLM-based Satisfiability Checking of String Requirements by Consistent Data and Checker Generation", "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025\n  conference", "summary": "Requirements over strings, commonly represented using natural language (NL),\nare particularly relevant for software systems due to their heavy reliance on\nstring data manipulation. While individual requirements can usually be analyzed\nmanually, verifying properties (e.g., satisfiability) over sets of NL\nrequirements is particularly challenging. Formal approaches (e.g., SMT solvers)\nmay efficiently verify such properties, but are known to have theoretical\nlimitations. Additionally, the translation of NL requirements into formal\nconstraints typically requires significant manual effort. Recently, large\nlanguage models (LLMs) have emerged as an alternative approach for formal\nreasoning tasks, but their effectiveness in verifying requirements over strings\nis less studied. In this paper, we introduce a hybrid approach that verifies\nthe satisfiability of NL requirements over strings by using LLMs (1) to derive\na satisfiability outcome (and a consistent string, if possible), and (2) to\ngenerate declarative (i.e., SMT) and imperative (i.e., Python) checkers, used\nto validate the correctness of (1). In our experiments, we assess the\nperformance of four LLMs. Results show that LLMs effectively translate natural\nlanguage into checkers, even achieving perfect testing accuracy for\nPython-based checkers. These checkers substantially help LLMs in generating a\nconsistent string and accurately identifying unsatisfiable requirements,\nleading to more than doubled generation success rate and F1-score in certain\ncases compared to baselines without generated checkers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528LLM\u81ea\u52a8\u63a8\u65ad\u548c\u9a8c\u8bc1\u81ea\u7136\u8bed\u8a00\u5b57\u7b26\u4e32\u9700\u6c42\u53ef\u6ee1\u8db3\u6027\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u5f62\u5f0f/\u4ee3\u7801\u68c0\u67e5\u5668\u63d0\u5347\u9a8c\u8bc1\u6548\u679c\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u751f\u6210\u7684Python\u68c0\u67e5\u5668\u51c6\u786e\u7387\u9ad8\uff0c\u6574\u4f53\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9a8c\u8bc1\u6210\u529f\u7387\u4e0e\u51c6\u786e\u5ea6\u3002", "motivation": "\u5728\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u5b57\u7b26\u4e32\u76f8\u5173\u7684\u9700\u6c42\uff08\u901a\u5e38\u4ee5\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\uff09\u5206\u6790\u6bd4\u8f83\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5f53\u9700\u8981\u5bf9\u591a\u6761\u9700\u6c42\u96c6\u5408\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff08\u5982\u53ef\u6ee1\u8db3\u6027\uff09\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\uff08\u5982SMT\u6c42\u89e3\u5668\uff09\u867d\u7136\u6709\u6548\u4f46\u5b58\u5728\u7406\u8bba\u5c40\u9650\u6027\uff0c\u540c\u65f6\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u5f62\u5f0f\u7ea6\u675f\u901a\u5e38\u9700\u8981\u5927\u91cf\u4eba\u5de5\u64cd\u4f5c\u3002\u6700\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5f62\u5f0f\u5316\u63a8\u7406\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff1a\u9996\u5148\u5229\u7528LLM\u76f4\u63a5\u63a8\u65ad\u5b57\u7b26\u4e32\u9700\u6c42\u96c6\u5408\u7684\u53ef\u6ee1\u8db3\u6027\uff0c\u5e76\u5c1d\u8bd5\u7ed9\u51fa\u6ee1\u8db3\u6761\u4ef6\u7684\u5b9e\u4f8b\u5b57\u7b26\u4e32\uff1b\u7136\u540e\uff0c\u5229\u7528LLM\u81ea\u52a8\u751f\u6210\u58f0\u660e\u5f0f\uff08\u5982SMT\uff09\u548c\u547d\u4ee4\u5f0f\uff08\u5982Python\uff09\u7684\u68c0\u67e5\u5668\u4ee3\u7801\uff0c\u5bf9\u7b2c\u4e00\u6b65\u63a8\u65ad\u7684\u6b63\u786e\u6027\u8fdb\u884c\u9a8c\u8bc1\u3002\u5b9e\u9a8c\u4e2d\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u4e3b\u6d41LLM\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0cLLM\u53ef\u4ee5\u8f83\u9ad8\u8d28\u91cf\u5730\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u68c0\u67e5\u5668\u4ee3\u7801\uff0c\u5c24\u5176\u662fPython\u68c0\u67e5\u5668\u5728\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u51c6\u786e\u7387\u3002\u8fd9\u4e9b\u81ea\u52a8\u751f\u6210\u7684\u68c0\u67e5\u5668\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u7ed9\u51fa\u6ee1\u8db3\u6761\u4ef6\u5b57\u7b26\u4e32\u548c\u68c0\u6d4b\u4e0d\u53ef\u6ee1\u8db3\u9700\u6c42\u65b9\u9762\u7684\u51c6\u786e\u6027\uff0c\u76f8\u6bd4\u672a\u4f7f\u7528\u68c0\u67e5\u5668\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u751f\u6210\u6210\u529f\u7387\u548cF1\u5206\u6570\u63d0\u5347\u4e86\u4e00\u500d\u4ee5\u4e0a\u3002", "conclusion": "LLM\u5728\u81ea\u7136\u8bed\u8a00\u5b57\u7b26\u4e32\u9700\u6c42\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u9762\u5c55\u73b0\u51fa\u5f88\u5f3a\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u7ed3\u5408\u81ea\u52a8\u751f\u6210\u7684\u68c0\u67e5\u5668\u540e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9700\u6c42\u53ef\u6ee1\u8db3\u6027\u9a8c\u8bc1\u7684\u51c6\u786e\u5ea6\u548c\u81ea\u52a8\u5316\u6c34\u5e73\u3002\u8be5\u65b9\u6cd5\u4e3a\u51cf\u5c11\u4eba\u5de5\u7ffb\u8bd1\u548c\u63d0\u9ad8\u9700\u6c42\u9a8c\u8bc1\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.15894", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15894", "abs": "https://arxiv.org/abs/2506.15894", "authors": ["Sam Silver", "Jimin Sun", "Ivan Zhang", "Sara Hooker", "Eddie Kim"], "title": "Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive mathematical\nreasoning capabilities, yet their performance remains brittle to minor\nvariations in problem description and prompting strategy. Furthermore,\nreasoning is vulnerable to sampling-induced errors which autoregressive models\nmust primarily address using self-correction via additionally-generated tokens.\nTo better understand self-correction capabilities of recent models, we conduct\nexperiments measuring models' ability to self-correct synthetic perturbations\nintroduced into their Chain of Thought (CoT) reasoning. We observe robust\nsingle-utterance intrinsic self-correction behavior across a range of\nopen-weight models and datasets, ranging from subtle, implicit corrections to\nexplicit acknowledgments and corrections of errors. Our findings suggest that\nLLMs, including those not finetuned for long CoT, may possess stronger\nintrinsic self-correction capabilities than commonly shown in the literature.\nThe presence of this ability suggests that recent \"reasoning\" model work\ninvolves amplification of traits already meaningfully present in models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u94fe\u5f0f\u63a8\u7406\u4e2d\u81ea\u52a8\u7ea0\u9519\u80fd\u529b\u6bd4\u4e4b\u524d\u62a5\u9053\u7684\u66f4\u5f3a\uff0c\u65e0\u9700\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u5c55\u73b0\u51fa\u5bf9\u6270\u52a8\u63a8\u7406\u7684\u81ea\u6211\u4fee\u6b63\uff0c\u5927\u91cf\u57fa\u4e8e\u63a8\u7406\u7684\u5de5\u4f5c\u5176\u5b9e\u53ef\u80fd\u5efa\u7acb\u5728\u6a21\u578b\u672c\u6709\u7684\u80fd\u529b\u4e4b\u4e0a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u5f3a\u5927\uff0c\u4f46\u5bf9\u95ee\u9898\u63cf\u8ff0\u548c\u63d0\u793a\u7b56\u7565\u7684\u5fae\u5c0f\u53d8\u5316\u975e\u5e38\u654f\u611f\uff0c\u63a8\u7406\u8fc7\u7a0b\u4e5f\u5bb9\u6613\u53d7\u5230\u91c7\u6837\u6240\u5f15\u5165\u7684\u9519\u8bef\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u4e86\u89e3\u5f53\u524d\u6a21\u578b\u7684\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u53d8\u5f97\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5728\u6a21\u578b\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u5f15\u5165\u5408\u6210\u6270\u52a8\uff0c\u5b9e\u9a8c\u6d4b\u91cf\u591a\u4e2a\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u3002\u5206\u6790\u6a21\u578b\u80fd\u5426\u81ea\u52a8\u8bc6\u522b\u4e0e\u7ea0\u6b63\u8fd9\u4e9b\u6270\u52a8\u6240\u5e26\u6765\u7684\u63a8\u7406\u9519\u8bef\u3002", "result": "\u5b9e\u9a8c\u89c2\u5bdf\u5230\uff0c\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u5728\u5355\u6b21\u54cd\u5e94\u4e2d\u5c55\u73b0\u51fa\u7a33\u5065\u7684\u5185\u5728\u81ea\u6211\u7ea0\u9519\u884c\u4e3a\uff0c\u5305\u62ec\u9690\u5f0f\u4e0e\u663e\u5f0f\u7684\u9519\u8bef\u7ea0\u6b63\u3002\u8fd9\u4e00\u80fd\u529b\u8d85\u51fa\u901a\u5e38\u6587\u732e\u4e2d\u7684\u63cf\u8ff0\uff0c\u751a\u81f3\u5b58\u5728\u4e8e\u672a\u4e13\u95e8\u4e3a\u957f\u94fe\u5f0f\u63a8\u7406\u5fae\u8c03\u7684\u6a21\u578b\u4e2d\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u81ea\u6211\u7ea0\u9519\u65b9\u9762\u5177\u5907\u8f83\u5f3a\u7684\u5185\u5728\u80fd\u529b\uff0c\u8fd9\u610f\u5473\u7740\u8fd1\u671f\u7684\u5927\u91cf\u201c\u63a8\u7406\u201d\u6a21\u578b\u7814\u7a76\u53ef\u80fd\u53ea\u662f\u653e\u5927\u4e86\u6a21\u578b\u672c\u5c31\u5177\u5907\u7684\u80fd\u529b\u3002"}}
{"id": "2506.16650", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.16650", "abs": "https://arxiv.org/abs/2506.16650", "authors": ["Anvith Pabba", "Alex Mathai", "Anindya Chakraborty", "Baishakhi Ray"], "title": "SemAgent: A Semantics Aware Program Repair Agent", "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in downstream\nsoftware engineering tasks such as Automated Program Repair (APR). In\nparticular, there has been a lot of research on repository-level\nissue-resolution benchmarks such as SWE-Bench. Although there has been\nsignificant progress on this topic, we notice that in the process of solving\nsuch issues, existing agentic systems tend to hyper-localize on immediately\nsuspicious lines of code and fix them in isolation, without a deeper\nunderstanding of the issue semantics, code semantics, or execution semantics.\nConsequently, many existing systems generate patches that overfit to the user\nissue, even when a more general fix is preferable. To address this limitation,\nwe introduce SemAgent, a novel workflow-based procedure that leverages issue,\ncode, and execution semantics to generate patches that are complete -\nidentifying and fixing all lines relevant to the issue. We achieve this through\na novel pipeline that (a) leverages execution semantics to retrieve relevant\ncontext, (b) comprehends issue-semantics via generalized abstraction, (c)\nisolates code-semantics within the context of this abstraction, and (d)\nleverages this understanding in a two-stage architecture: a repair stage that\nproposes fine-grained fixes, followed by a reviewer stage that filters relevant\nfixes based on the inferred issue-semantics. Our evaluations show that our\nmethodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark\nbeating all other workflow-based approaches, and an absolute improvement of\n7.66% compared to our baseline, which lacks such deep semantic understanding.\nWe note that our approach performs particularly well on issues requiring\nmulti-line reasoning (and editing) and edge-case handling, suggesting that\nincorporating issue and code semantics into APR pipelines can lead to robust\nand semantically consistent repairs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSemAgent\uff0c\u4e00\u79cd\u5145\u5206\u5229\u7528\u591a\u91cd\u8bed\u4e49\u4fe1\u606f\u7684\u81ea\u52a8\u4ee3\u7801\u4fee\u590d\u6d41\u7a0b\uff0c\u5e76\u5728\u6743\u5a01\u57fa\u51c6\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u64c5\u957f\u591a\u884c\u4fee\u590d\u548c\u590d\u6742\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7b49\u4e0b\u6e38\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u76ee\u524d\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5e38\u5e38\u53ea\u5173\u6ce8\u5c40\u90e8\u7684\u53ef\u7591\u4ee3\u7801\u884c\uff0c\u5e76\u5b64\u7acb\u5730\u4fee\u590d\u5b83\u4eec\uff0c\u7f3a\u4e4f\u5bf9\u95ee\u9898\u8bed\u4e49\u3001\u4ee3\u7801\u8bed\u4e49\u548c\u6267\u884c\u8bed\u4e49\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8865\u4e01\u5bb9\u6613\u8fc7\u62df\u5408\u7528\u6237\u63cf\u8ff0\uff0c\u800c\u65e0\u6cd5\u63d0\u4f9b\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86SemAgent\uff0c\u4e00\u79cd\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u65b0\u9896\u81ea\u52a8\u4fee\u590d\u6d41\u7a0b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ba1\u9053\u5316\u6d41\u7a0b\uff1a\uff08a\uff09\u5229\u7528\u6267\u884c\u8bed\u4e49\u83b7\u53d6\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\uff08b\uff09\u901a\u8fc7\u6cdb\u5316\u62bd\u8c61\u7406\u89e3\u95ee\u9898\u8bed\u4e49\uff0c\uff08c\uff09\u5728\u62bd\u8c61\u4e0a\u4e0b\u6587\u4e2d\u8bc6\u522b\u4ee3\u7801\u8bed\u4e49\uff0c\uff08d\uff09\u5728\u4e24\u9636\u6bb5\u67b6\u6784\u4e0b\uff0c\u5148\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fee\u590d\uff0c\u518d\u901a\u8fc7\u5ba1\u67e5\u8005\u9636\u6bb5\u7ed3\u5408\u8bed\u4e49\u8fc7\u6ee4\u51fa\u76f8\u5173\u8865\u4e01\u3002", "result": "\u5728SWEBench-Lite\u57fa\u51c6\u4e0a\uff0cSemAgent\u7684\u89e3\u51b3\u7387\u8fbe\u523044.66%\uff0c\u4f18\u4e8e\u6240\u6709\u5176\u4ed6\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u65b9\u6cd5\uff0c\u6bd4\u7f3a\u4e4f\u6df1\u5ea6\u8bed\u4e49\u7406\u89e3\u7684\u57fa\u7ebf\u63d0\u53477.66%\u3002\u8be5\u65b9\u6cd5\u5728\u9700\u8981\u591a\u884c\u63a8\u7406\u548c\u8fb9\u754c\u60c5\u51b5\u5904\u7406\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u95ee\u9898\u4e0e\u4ee3\u7801\u8bed\u4e49\u7684\u6df1\u5c42\u5efa\u6a21\uff0c\u80fd\u663e\u8457\u63d0\u5347\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u6574\u4f53\u8868\u73b0\u548c\u8bed\u4e49\u4e00\u81f4\u6027\uff0cSemAgent\u5c55\u73b0\u4e86\u66f4\u5f3a\u7684\u901a\u7528\u6027\u548c\u5065\u58ee\u6027\u3002"}}
{"id": "2506.15911", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15911", "abs": "https://arxiv.org/abs/2506.15911", "authors": ["Mohammad Amaan Sayeed", "Mohammed Talha Alam", "Raza Imam", "Shahab Saquib Sohail", "Amir Hussain"], "title": "From RAG to Agentic: Validating Islamic-Medicine Responses with LLM Agents", "comment": "Under-review at the 4th Muslims in Machine Learning (MusIML) Workshop\n  (ICML-25)", "summary": "Centuries-old Islamic medical texts like Avicenna's Canon of Medicine and the\nProphetic Tibb-e-Nabawi encode a wealth of preventive care, nutrition, and\nholistic therapies, yet remain inaccessible to many and underutilized in modern\nAI systems. Existing language-model benchmarks focus narrowly on factual recall\nor user preference, leaving a gap in validating culturally grounded medical\nguidance at scale. We propose a unified evaluation pipeline, Tibbe-AG, that\naligns 30 carefully curated Prophetic-medicine questions with human-verified\nremedies and compares three LLMs (LLaMA-3, Mistral-7B, Qwen2-7B) under three\nconfigurations: direct generation, retrieval-augmented generation, and a\nscientific self-critique filter. Each answer is then assessed by a secondary\nLLM serving as an agentic judge, yielding a single 3C3H quality score.\nRetrieval improves factual accuracy by 13%, while the agentic prompt adds\nanother 10% improvement through deeper mechanistic insight and safety\nconsiderations. Our results demonstrate that blending classical Islamic texts\nwith retrieval and self-evaluation enables reliable, culturally sensitive\nmedical question-answering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u65b0\u7684\u5927\u6a21\u578b\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e86\u4f0a\u65af\u5170\u533b\u5b66\u7ecf\u5178\uff0c\u5229\u7528\u68c0\u7d22\u548c\u81ea\u6211\u6279\u5224\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u533b\u5b66\u76f8\u5173\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u6587\u5316\u9002\u5e94\u6027\u3002", "motivation": "\u4f0a\u65af\u5170\u7ecf\u5178\u533b\u5b66\u6587\u732e\u8574\u542b\u5927\u91cf\u9884\u9632\u533b\u7597\u3001\u8425\u517b\u548c\u6574\u4f53\u7597\u6cd5\u77e5\u8bc6\uff0c\u4f46\u56e0\u6587\u672c\u96be\u4ee5\u63a5\u8fd1\u548c\u73b0\u4ee3AI\u5e94\u7528\u4e0d\u8db3\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u6587\u5316\u533b\u7597\u77e5\u8bc6\u672a\u88ab\u5145\u5206\u5229\u7528\u3002\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u4fa7\u91cd\u4e8b\u5b9e\u56de\u5fc6\u6216\u7528\u6237\u504f\u597d\uff0c\u672a\u80fd\u6709\u6548\u5927\u89c4\u6a21\u9a8c\u8bc1\u5177\u6709\u6587\u5316\u57fa\u7840\u7684\u533b\u5b66\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u8bc4\u6d4b\u6d41\u7a0bTibbe-AG\uff0c\u5c0630\u4e2a\u7cbe\u5fc3\u6311\u9009\u7684\u5148\u77e5\u533b\u5b66\uff08Prophetic-medicine\uff09\u95ee\u9898\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u7597\u6cd5\u914d\u5bf9\uff0c\u5e76\u6bd4\u8f83\u4e09\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLaMA-3\u3001Mistral-7B\u3001Qwen2-7B\uff09\u5728\u76f4\u63a5\u751f\u6210\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u81ea\u6211\u79d1\u5b66\u6279\u5224\u8fc7\u6ee4\u4e09\u79cd\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\u3002\u6bcf\u4e2a\u7b54\u6848\u7531\u53e6\u4e00\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u4ee3\u7406\u8fdb\u884c\u8d28\u91cf\u8bc4\u5206\u3002", "result": "\u5f15\u5165\u68c0\u7d22\u63d0\u5347\u4e8613%\u7684\u4e8b\u5b9e\u51c6\u786e\u7387\uff0c\u4ee3\u7406\u5f0f\u63d0\u793a\u53c8\u901a\u8fc7\u52a0\u5f3a\u673a\u7406\u6d1e\u5bdf\u548c\u5b89\u5168\u6027\u8003\u8651\u63d0\u5347\u4e8610%\u7684\u5f97\u5206\u3002", "conclusion": "\u5c06\u7ecf\u5178\u4f0a\u65af\u5170\u533b\u5b66\u6587\u672c\u4e0e\u68c0\u7d22\u53ca\u81ea\u6211\u8bc4\u4f30\u673a\u5236\u7ed3\u5408\uff0c\u53ef\u5b9e\u73b0\u53ef\u9760\u4e14\u5177\u6587\u5316\u654f\u611f\u6027\u7684\u533b\u5b66\u95ee\u7b54\u3002"}}
{"id": "2506.16653", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16653", "abs": "https://arxiv.org/abs/2506.16653", "authors": ["Vladislav Belozerov", "Peter J Barclay", "Askhan Sami"], "title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape", "comment": null, "summary": "Large-language-model coding tools are now mainstream in software engineering.\nBut as these same tools move human effort up the development stack, they\npresent fresh dangers: 10% of real prompts leak private data, 42% of generated\nsnippets hide security flaws, and the models can even ``agree'' with wrong\nideas, a trait called sycophancy. We argue that firms must tag and review every\nAI-generated line of code, keep prompts and outputs inside private or\non-premises deployments, obey emerging safety regulations, and add tests that\ncatch sycophantic answers -- so they can gain speed without losing security and\naccuracy.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5de5\u5177\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4f46\u5e26\u6765\u9690\u79c1\u4e0e\u5b89\u5168\u98ce\u9669\uff0c\u4f01\u4e1a\u9700\u5b8c\u5584\u5ba1\u67e5\u6d41\u7a0b\u3001\u79c1\u6709\u5316\u90e8\u7f72\u5e76\u52a0\u5f3a\u68c0\u6d4b\u4ee5\u9632\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5de5\u5177\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u4f46\u5176\u5728\u63d0\u5347\u5f00\u53d1\u6548\u7387\u7684\u540c\u65f6\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u63d0\u793a\u548c\u6a21\u578b\u8f93\u51fa\u7684\u8c03\u67e5\uff0c\u63ed\u793a\u4e86\u6570\u636e\u6cc4\u9732\u3001\u5b89\u5168\u6f0f\u6d1e\u548c\u6a21\u578b\u8c04\u5a9a\u7b49\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5e94\u5bf9\u63aa\u65bd\u5efa\u8bae\u3002", "result": "\u53d1\u73b0\u7ea610%\u7684\u771f\u5b9e\u63d0\u793a\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c42%\u7684\u6a21\u578b\u751f\u6210\u4ee3\u7801\u5305\u542b\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e14\u6a21\u578b\u5bb9\u6613\u8fce\u5408\u7528\u6237\u9519\u8bef\u89c2\u70b9\uff08\u8c04\u5a9a\u6027\uff09\u3002", "conclusion": "\u5efa\u8bae\u4f01\u4e1a\u5bf9AI\u751f\u6210\u7684\u6bcf\u4e00\u884c\u4ee3\u7801\u8fdb\u884c\u6807\u8bb0\u548c\u5ba1\u67e5\uff0c\u5c06\u63d0\u793a\u4e0e\u8f93\u51fa\u63a7\u5236\u5728\u79c1\u6709\u6216\u672c\u5730\u73af\u5883\u4e2d\uff0c\u9075\u5b88\u65b0\u5174\u5b89\u5168\u6cd5\u89c4\uff0c\u52a0\u5165\u4e13\u95e8\u68c0\u6d4b\u8c04\u5a9a\u7b54\u6848\u7684\u6d4b\u8bd5\uff0c\u4ece\u800c\u5728\u63d0\u5347\u5f00\u53d1\u901f\u5ea6\u7684\u540c\u65f6\u4fdd\u969c\u5b89\u5168\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2506.15925", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15925", "abs": "https://arxiv.org/abs/2506.15925", "authors": ["Narutatsu Ri", "Nicholas Deas", "Kathleen McKeown"], "title": "Reranking-based Generation for Unbiased Perspective Summarization", "comment": "ACL 2025 Findings", "summary": "Generating unbiased summaries in real-world settings such as political\nperspective summarization remains a crucial application of Large Language\nModels (LLMs). Yet, existing evaluation frameworks rely on traditional metrics\nfor measuring key attributes such as coverage and faithfulness without\nverifying their applicability, and efforts to develop improved summarizers are\nstill nascent. We address these gaps by (1) identifying reliable metrics for\nmeasuring perspective summary quality, and (2) investigating the efficacy of\nLLM-based methods beyond zero-shot inference. Namely, we build a test set for\nbenchmarking metric reliability using human annotations and show that\ntraditional metrics underperform compared to language model-based metrics,\nwhich prove to be strong evaluators. Using these metrics, we show that\nreranking-based methods yield strong results, and preference tuning with\nsynthetically generated and reranking-labeled data further boosts performance.\nOur findings aim to contribute to the reliable evaluation and development of\nperspective summarization methods.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4f20\u7edf\u6458\u8981\u8bc4\u4ef7\u6307\u6807\u5728\u653f\u6cbb\u89c2\u70b9\u7b49\u65e0\u504f\u89c1\u6458\u8981\u4efb\u52a1\u4e2d\u4e0d\u53ef\u9760\uff0c\u63d0\u51fa\u7528\u8bed\u8a00\u6a21\u578b\u6307\u6807\u66ff\u4ee3\uff0c\u5e76\u901a\u8fc7\u91cd\u6392\u5e8f\u548c\u5408\u6210\u6570\u636e\u7684\u8c03\u4f18\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u6458\u8981\u6548\u679c\u3002", "motivation": "\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u5982\u653f\u6cbb\u89c2\u70b9\u6458\u8981\uff0c\u751f\u6210\u65e0\u504f\u89c1\u6458\u8981\u4f9d\u7136\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5173\u952e\u5e94\u7528\u3002\u4f46\u76ee\u524d\u7684\u8bc4\u4f30\u6846\u67b6\u4e3b\u8981\u4f9d\u8d56\u4f20\u7edf\u6307\u6807\uff0c\u800c\u8fd9\u4e9b\u6307\u6807\u5bf9\u4e8e\u6709\u6548\u6d4b\u91cf\u6458\u8981\u5c5e\u6027\u7684\u9002\u7528\u6027\u5c1a\u672a\u88ab\u9a8c\u8bc1\u3002\u6b64\u5916\uff0c\u6539\u8fdb\u7684\u6458\u8981\u751f\u6210\u65b9\u6cd5\u7814\u53d1\u4e5f\u5904\u4e8e\u521d\u7ea7\u9636\u6bb5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u4e24\u6b65\u586b\u8865\u4e0a\u8ff0\u7a7a\u767d\uff1a\uff081\uff09\u786e\u5b9a\u8bc4\u4ef7\u89c2\u70b9\u6458\u8981\u8d28\u91cf\u7684\u53ef\u9760\u6307\u6807\uff1b\uff082\uff09\u7814\u7a76LLM\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u63a8\u7406\u4e4b\u5916\u7684\u6709\u6548\u6027\u3002\u5177\u4f53\u505a\u6cd5\u5305\u62ec\uff1a\u6784\u5efa\u542b\u4eba\u5de5\u6807\u6ce8\u7684\u6d4b\u8bd5\u96c6\u8bc4\u4f30\u8bc4\u4ef7\u6307\u6807\u7684\u53ef\u9760\u6027\uff0c\u6bd4\u8f83\u4f20\u7edf\u6307\u6807\u4e0e\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6807\u6027\u80fd\uff0c\u5e76\u5728\u8bc4\u4ef7\u6307\u6807\u57fa\u7840\u4e0a\u5bf9\u91cd\u6392\u5e8f\u65b9\u6cd5\u3001\u5408\u6210\u6570\u636e\u7b49\u521b\u65b0\u7b56\u7565\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4ef7\u6307\u6807\u5728\u89c2\u70b9\u6458\u8981\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6307\u6807\uff1b\u91cd\u6392\u5e8f\u65b9\u6cd5\u3001\u5229\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u504f\u597d\u8c03\u4f18\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6458\u8981\u8d28\u91cf\u3002", "conclusion": "\u672c\u6587\u9a8c\u8bc1\u5e76\u63a8\u52a8\u4e86\u89c2\u70b9\u6458\u8981\u4efb\u52a1\u4e2d\u8bc4\u4ef7\u4e0e\u751f\u6210\u65b9\u6cd5\u7684\u8fdb\u6b65\uff0c\u786e\u7acb\u4e86\u66f4\u4e3a\u53ef\u9760\u7684\u6307\u6807\u57fa\u7840\uff0c\u5e76\u63a2\u7d22\u4e86\u9ad8\u6548\u7684\u751f\u6210\u7b56\u7565\u3002\u8be5\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u672a\u6765\u53ef\u9760\u3001\u516c\u6b63\u7684\u81ea\u52a8\u6458\u8981\u7cfb\u7edf\u5f00\u53d1\u3002"}}
{"id": "2506.16831", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16831", "abs": "https://arxiv.org/abs/2506.16831", "authors": ["Filippo Scaramuzza", "Damian A. Tamburri", "Willem-Jan van den Heuvel"], "title": "Accountability of Robust and Reliable AI-Enabled Systems: A Preliminary Study and Roadmap", "comment": "To be published in https://link.springer.com/book/9789819672370", "summary": "This vision paper presents initial research on assessing the robustness and\nreliability of AI-enabled systems, and key factors in ensuring their safety and\neffectiveness in practical applications, including a focus on accountability.\nBy exploring evolving definitions of these concepts and reviewing current\nliterature, the study highlights major challenges and approaches in the field.\nA case study is used to illustrate real-world applications, emphasizing the\nneed for innovative testing solutions. The incorporation of accountability is\ncrucial for building trust and ensuring responsible AI development. The paper\noutlines potential future research directions and identifies existing gaps,\npositioning robustness, reliability, and accountability as vital areas for the\ndevelopment of trustworthy AI systems of the future.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86AI\u7cfb\u7edf\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u548c\u8d23\u4efb\u6027\u7b49\u5173\u952e\u8bae\u9898\uff0c\u7ed3\u5408\u6848\u4f8b\u5206\u6790\u6307\u51fa\u73b0\u5b9e\u6311\u6218\uff0c\u5f3a\u8c03\u8d23\u4efb\u673a\u5236\u5bf9\u4e8e\u53ef\u4fe1AI\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u5176\u5b89\u5168\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u8bba\u6587\u5f3a\u8c03\u4e86\u5f53\u524d\u5173\u4e8e\u8fd9\u4e9b\u6982\u5ff5\u7684\u4e0d\u65ad\u6f14\u53d8\u4e0e\u73b0\u5b9e\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728\u8d23\u4efb\u8ffd\u6eaf\u65b9\u9762\uff0c\u65e8\u5728\u63a8\u52a8AI\u66f4\u52a0\u53ef\u4fe1\u548c\u53ef\u63a7\u3002", "method": "\u9996\u5148\u68b3\u7406\u4e86\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u3001\u8d23\u4efb\u6027\u7b49\u5173\u952e\u6982\u5ff5\u7684\u53d1\u5c55\uff0c\u5e76\u8fdb\u884c\u4e86\u6587\u732e\u7efc\u8ff0\uff0c\u7136\u540e\u901a\u8fc7\u6848\u4f8b\u5206\u6790\uff0c\u5c55\u793aAI\u7cfb\u7edf\u5728\u5b9e\u9645\u573a\u666f\u4e0b\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u8fdb\u4e00\u6b65\u63a2\u8ba8\u521b\u65b0\u6d4b\u8bd5\u65b9\u6848\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86\u76ee\u524d\u5b58\u5728\u7684\u4e3b\u8981\u6280\u672f\u6311\u6218\u548c\u5f53\u524d\u7684\u4e3b\u6d41\u7814\u7a76\u65b9\u6cd5\uff0c\u6848\u4f8b\u8bf4\u660e\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u9645\u4e2d\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\uff0c\u8bba\u6587\u6307\u51fa\u8d23\u4efb\u673a\u5236\u5bf9\u6784\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u52fe\u52d2\u4e86\u672a\u6765\u7814\u7a76\u7684\u91cd\u8981\u65b9\u5411\u548c\u5f53\u524d\u7684\u7814\u7a76\u7a7a\u767d\u3002", "conclusion": "\u8981\u5b9e\u73b0\u53ef\u4fe1\u7684AI\u7cfb\u7edf\uff0c\u5fc5\u987b\u628a\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u548c\u8d23\u4efb\u6027\u4f5c\u4e3a\u6838\u5fc3\u8bae\u9898\u3002\u8bba\u6587\u5f3a\u8c03\u5bf9\u521b\u65b0\u6d4b\u8bd5\u5de5\u5177\u548c\u8d23\u4efb\u6846\u67b6\u7684\u9700\u6c42\uff0c\u5e76\u547c\u5401\u4ece\u591a\u7ef4\u5ea6\u63a8\u52a8AI\u7684\u5b89\u5168\u548c\u53ef\u63a7\u53d1\u5c55\u3002"}}
{"id": "2506.15978", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15978", "abs": "https://arxiv.org/abs/2506.15978", "authors": ["Toan Nguyen Hai", "Ha Nguyen Viet", "Truong Quan Xuan", "Duc Do Minh"], "title": "A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension", "comment": null, "summary": "Vietnamese, the 20th most spoken language with over 102 million native\nspeakers, lacks robust resources for key natural language processing tasks such\nas text segmentation and machine reading comprehension (MRC). To address this\ngap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice\nReading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset\nincludes 15,942 documents for text segmentation and 16,347 synthetic\nmultiple-choice question-answer pairs generated with human quality assurance,\nensuring a reliable and diverse resource. Experiments show that mBERT\nconsistently outperforms monolingual models on both tasks, achieving an\naccuracy of 88.01% on MRC test set and an F1 score of 63.15\\% on text\nsegmentation test set. Our analysis reveals that multilingual models excel in\nNLP tasks for Vietnamese, suggesting potential applications to other\nunder-resourced languages. VSMRC is available at HuggingFace", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5927\u89c4\u6a21\u8d8a\u5357\u8bed\u6587\u672c\u5206\u5272\u548c\u9605\u8bfb\u7406\u89e3\u6570\u636e\u96c6VSMRC\uff0c\u5e76\u8bc1\u5b9e\u591a\u8bed\u79cd\u6a21\u578b\u5728\u8d8a\u5357\u8bedNLP\u4efb\u52a1\u4e2d\u4f18\u5f02\u8868\u73b0\uff0c\u4e3a\u6b20\u8d44\u6e90\u8bed\u8a00\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u8d44\u6e90\u548c\u65b0\u601d\u8def\u3002", "motivation": "\u8d8a\u5357\u8bed\u4f5c\u4e3a\u5168\u7403\u7b2c20\u5927\u6700\u5e38\u7528\u8bed\u8a00\uff0c\u5728\u6587\u672c\u5206\u5272\u548c\u673a\u5668\u9605\u8bfb\u7406\u89e3\uff08MRC\uff09\u7b49\u6838\u5fc3\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u8d44\u6e90\u532e\u4e4f\u3002\u8be5\u9886\u57df\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u5236\u7ea6\u8d8a\u5357\u8bedNLP\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u4e86VSMRC\u6570\u636e\u96c6\uff0c\u6570\u636e\u4ece\u8d8a\u5357\u8bed\u7ef4\u57fa\u767e\u79d1\u91c7\u96c6\uff0c\u5305\u62ec15942\u4e2a\u6587\u6863\u7528\u4e8e\u6587\u672c\u5206\u5272\u4efb\u52a1\uff0c16347\u4e2a\u4eba\u5de5\u5ba1\u6838\u751f\u6210\u7684\u591a\u9879\u9009\u62e9\u9605\u8bfb\u7406\u89e3\u95ee\u7b54\u5bf9\u3002\u5bf9\u73b0\u6709\u591a\u8bed\u79cd\uff08\u5982mBERT\uff09\u548c\u5355\u8bed\u79cd\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "mBERT\u591a\u8bed\u79cd\u6a21\u578b\u5728\u6587\u672c\u5206\u5272\u4e0eMRC\u4efb\u52a1\u4e2d\u90fd\u4f18\u4e8e\u5355\u8bed\u79cd\u6a21\u578b\uff0cMRC\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u8fbe88.01%\uff0c\u6587\u672c\u5206\u5272F1\u5206\u6570\u4e3a63.15%\u3002", "conclusion": "\u591a\u8bed\u79cd\u6a21\u578b\u5728\u8d8a\u5357\u8bed\u7b49\u6b20\u8d44\u6e90\u8bed\u8a00\u7684NLP\u4efb\u52a1\u8868\u73b0\u4f18\u8d8a\uff0cVSMRC\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u6570\u636e\u57fa\u7840\uff0c\u4e5f\u4e3a\u5176\u4ed6\u6b20\u8d44\u6e90\u8bed\u8a00NLP\u5e94\u7528\u5e26\u6765\u542f\u793a\u3002"}}
{"id": "2506.16876", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16876", "abs": "https://arxiv.org/abs/2506.16876", "authors": ["Halit Eris", "Stefan Wagner"], "title": "Revolutionizing Validation and Verification: Explainable Testing Methodologies for Intelligent Automotive Decision-Making Systems", "comment": "Preprint to be published at SE4ADS", "summary": "Autonomous Driving Systems (ADS) use complex decision-making (DM) models with\nmultimodal sensory inputs, making rigorous validation and verification (V&V)\nessential for safety and reliability. These models pose challenges in\ndiagnosing failures, tracing anomalies, and maintaining transparency, with\ncurrent manual testing methods being inefficient and labor-intensive. This\nvision paper presents a methodology that integrates explainability,\ntransparency, and interpretability into V&V processes. We propose refining V&V\nrequirements through literature reviews and stakeholder input, generating\nexplainable test scenarios via large language models (LLMs), and enabling\nreal-time validation in simulation environments. Our framework includes test\noracle, explanation generation, and a test chatbot, with empirical studies\nplanned to evaluate improvements in diagnostic efficiency and transparency. Our\ngoal is to streamline V&V, reduce resources, and build user trust in autonomous\ntechnologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7b49\u5148\u8fdb\u5de5\u5177\uff0c\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u9a8c\u8bc1\u4e0e\u786e\u8ba4\uff08V&V\uff09\u7684\u6548\u7387\u4e0e\u900f\u660e\u5ea6\uff0c\u76ee\u6807\u662f\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u5e76\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4f9d\u8d56\u590d\u6742\u7684\u51b3\u7b56\u6a21\u578b\u548c\u591a\u6a21\u6001\u4f20\u611f\u8f93\u5165\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u9a8c\u8bc1\u4e0e\u786e\u8ba4\uff08V&V\uff09\u4ee5\u4fdd\u969c\u5b89\u5168\u6027\u3002\u76ee\u524d\u7684\u624b\u52a8\u6d4b\u8bd5\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0c\u8017\u65f6\u8017\u529b\uff0c\u4e14\u96be\u4ee5\u8bca\u65ad\u5931\u8d25\u3001\u8ffd\u8e2a\u5f02\u5e38\u548c\u63d0\u5347\u7cfb\u7edf\u900f\u660e\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u53ef\u89e3\u91ca\u6027\u3001\u900f\u660e\u6027\u548c\u53ef\u7406\u89e3\u6027\u6574\u5408\u5230V&V\u6d41\u7a0b\u4e2d\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6587\u732e\u56de\u987e\u548c\u5229\u76ca\u76f8\u5173\u8005\u53cd\u9988\u7ec6\u5316V&V\u9700\u6c42\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u5177\u5907\u53ef\u89e3\u91ca\u6027\u7684\u6d4b\u8bd5\u573a\u666f\uff0c\u5e76\u5728\u4eff\u771f\u73af\u5883\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u9a8c\u8bc1\u3002\u6846\u67b6\u8fd8\u5305\u62ec\u6d4b\u8bd5\u5224\u5b9a\u673a\u5236\u3001\u89e3\u91ca\u751f\u6210\u4e0e\u6d4b\u8bd5\u804a\u5929\u673a\u5668\u4eba\u3002", "result": "\u8ba1\u5212\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u4ee5\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u8bca\u65ad\u6548\u7387\u548c\u900f\u660e\u5ea6\u7684\u63d0\u5347\u6548\u679c\u3002\u521d\u6b65\u76ee\u6807\u662f\u63d0\u9ad8V&V\u7684\u81ea\u52a8\u5316\u548c\u8d44\u6e90\u5229\u7528\u6548\u7387\uff0c\u589e\u5f3a\u7528\u6237\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u4fe1\u4efb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u671b\u7b80\u5316\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684V&V\u6d41\u7a0b\uff0c\u51cf\u5c11\u4eba\u529b\u7269\u529b\u6295\u5165\uff0c\u63d0\u9ad8\u5b89\u5168\u900f\u660e\u5ea6\uff0c\u4ece\u800c\u63a8\u52a8\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2506.15981", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15981", "abs": "https://arxiv.org/abs/2506.15981", "authors": ["Markus Frohmann", "Gabriel Meseguer-Brocal", "Markus Schedl", "Elena V. Epure"], "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion", "comment": "Accepted to ACL 2025 Findings", "summary": "The rapid advancement of AI-based music generation tools is revolutionizing\nthe music industry but also posing challenges to artists, copyright holders,\nand providers alike. This necessitates reliable methods for detecting such\nAI-generated content. However, existing detectors, relying on either audio or\nlyrics, face key practical limitations: audio-based detectors fail to\ngeneralize to new or unseen generators and are vulnerable to audio\nperturbations; lyrics-based methods require cleanly formatted and accurate\nlyrics, unavailable in practice. To overcome these limitations, we propose a\nnovel, practically grounded approach: a multimodal, modular late-fusion\npipeline that combines automatically transcribed sung lyrics and speech\nfeatures capturing lyrics-related information within the audio. By relying on\nlyrical aspects directly from audio, our method enhances robustness, mitigates\nsusceptibility to low-level artifacts, and enables practical applicability.\nExperiments show that our method, DE-detect, outperforms existing lyrics-based\ndetectors while also being more robust to audio perturbations. Thus, it offers\nan effective, robust solution for detecting AI-generated music in real-world\nscenarios. Our code is available at\nhttps://github.com/deezer/robust-AI-lyrics-detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001AI\u97f3\u4e50\u68c0\u6d4b\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u97f3\u9891\u548c\u81ea\u52a8\u8f6c\u5f55\u6b4c\u8bcd\u7684\u7279\u5f81\uff0c\u5b9e\u73b0\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u7684\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u6709\u671b\u5728\u5b9e\u9645\u4e2d\u5e7f\u6cdb\u5e94\u7528\u3002", "motivation": "AI\u4f5c\u66f2\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u63a8\u52a8\u97f3\u4e50\u4ea7\u4e1a\u53d8\u9769\uff0c\u4e5f\u5e26\u6765\u4e86\u4f2a\u9020\u4e0e\u7248\u6743\u98ce\u9669\uff0c\u4e9f\u9700\u53ef\u9760\u7684AI\u751f\u6210\u97f3\u4e50\u68c0\u6d4b\u65b9\u6cd5\u3002\u73b0\u6709\u57fa\u4e8e\u97f3\u9891\u6216\u6b4c\u8bcd\u7684\u68c0\u6d4b\u5668\u5b9e\u9645\u5e94\u7528\u6709\u9650\uff1a\u97f3\u9891\u6cd5\u6613\u53d7\u6270\u52a8\u4e14\u6cdb\u5316\u6027\u5dee\uff0c\u6b4c\u8bcd\u6cd5\u5219\u53d7\u51c6\u786e\u6b4c\u8bcd\u83b7\u53d6\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u521b\u65b0\u7684\u591a\u6a21\u6001\u3001\u6a21\u5757\u5316\u540e\u878d\u5408\u7ba1\u9053\uff0c\u5c06\u81ea\u52a8\u8f6c\u5f55\u7684\u5531\u8bcd\uff08\u6b4c\u8bcd\uff09\u4e0e\u5305\u542b\u8bed\u97f3\u7279\u5f81\u7684\u97f3\u9891\u4fe1\u606f\u878d\u5408\uff0c\u901a\u8fc7\u76f4\u63a5\u4ece\u97f3\u9891\u4e2d\u63d0\u53d6\u6b4c\u8bcd\u76f8\u5173\u7279\u5f81\u63d0\u5347\u9c81\u68d2\u6027\u5e76\u89c4\u907f\u4f4e\u7ea7\u97f3\u9891\u4f2a\u8ff9\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\uff08DE-detect\uff09\u4f18\u4e8e\u73b0\u6709\u6b4c\u8bcd\u68c0\u6d4b\u5668\uff0c\u540c\u65f6\u5bf9\u97f3\u9891\u6270\u52a8\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "DE-detect\u4e3a\u5b9e\u9645\u73af\u5883\u4e0b\u68c0\u6d4bAI\u751f\u6210\u97f3\u4e50\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.16878", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16878", "abs": "https://arxiv.org/abs/2506.16878", "authors": ["Man Zhang", "Yuechen Li", "Tao Yue", "Kai-Yuan Cai"], "title": "Quantum Optimization for Software Engineering: A Survey", "comment": null, "summary": "Quantum computing, particularly in the area of quantum optimization, is\nsteadily progressing toward practical applications, supported by an expanding\nrange of hardware platforms and simulators. While Software Engineering (SE)\noptimization has a strong foundation, which is exemplified by the active\nSearch-Based Software Engineering (SBSE) community and numerous classical\noptimization methods, the growing complexity of modern software systems and\ntheir engineering processes demands innovative solutions. This Systematic\nLiterature Review (SLR) focuses specifically on studying the literature that\napplies quantum or quantum-inspired algorithms to solve classical SE\noptimization problems. We examine 77 primary studies selected from an initial\npool of 2083 publications obtained through systematic searches of six digital\ndatabases using carefully crafted search strings. Our findings reveal\nconcentrated research efforts in areas such as SE operations and software\ntesting, while exposing significant gaps across other SE activities.\nAdditionally, the SLR uncovers relevant works published outside traditional SE\nvenues, underscoring the necessity of this comprehensive review. Overall, our\nstudy provides a broad overview of the research landscape, empowering the SBSE\ncommunity to leverage quantum advancements in addressing next-generation SE\nchallenges.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u7edf\u8ba1\u5e76\u5206\u6790\u4e86\u91cf\u5b50\u53ca\u7c7b\u91cf\u5b50\u4f18\u5316\u7b97\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u63ed\u793a\u4e86\u7814\u7a76\u70ed\u70b9\u4e0e\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u8de8\u9886\u57df\u521b\u65b0\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u548c\u5f00\u53d1\u6d41\u7a0b\u7684\u4e0d\u65ad\u590d\u6742\u5316\uff0c\u4f20\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u65b9\u6cd5\u9762\u4e34\u65b0\u7684\u6311\u6218\uff0c\u9700\u8981\u521b\u65b0\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002\u91cf\u5b50\u8ba1\u7b97\uff0c\u5c24\u5176\u662f\u91cf\u5b50\u4f18\u5316\u5728\u8bb8\u591a\u9886\u57df\u53d6\u5f97\u8fdb\u5c55\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u5176\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u56e2\u961f\u5728\u516d\u5927\u6570\u636e\u5e93\u4e2d\u7b5b\u9009\u51fa2083\u7bc7\u6587\u732e\uff0c\u5e76\u8fdb\u4e00\u6b65\u7cbe\u9009\u51fa77\u7bc7\u4e3b\u8981\u7814\u7a76\uff0c\u805a\u7126\u4e8e\u91cf\u5b50\u6216\u7c7b\u91cf\u5b50\u7b97\u6cd5\u5728\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u76f8\u5173\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u8fd0\u8425\u548c\u8f6f\u4ef6\u6d4b\u8bd5\u7b49\u9886\u57df\uff0c\u800c\u5728\u5176\u4ed6\u8f6f\u4ef6\u5de5\u7a0b\u6d3b\u52a8\u4e2d\u4ecd\u5b58\u5728\u660e\u663e\u7814\u7a76\u7a7a\u767d\u3002\u540c\u65f6\uff0c\u6709\u90e8\u5206\u6709\u4ef7\u503c\u7684\u5de5\u4f5c\u53d1\u8868\u5728\u975e\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u663e\u793a\u51fa\u91cf\u5b50\u4f18\u5316\u8de8\u5b66\u79d1\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u6587\u5168\u9762\u56de\u987e\u4e86\u91cf\u5b50\u8ba1\u7b97\u4e0e\u7c7b\u91cf\u5b50\u7b97\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4e2d\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u4e3a\u641c\u7d22\u5f0f\u8f6f\u4ef6\u5de5\u7a0b\uff08SBSE\uff09\u793e\u533a\u63d0\u4f9b\u4e86\u5229\u7528\u91cf\u5b50\u8fdb\u5c55\u5e94\u5bf9\u4e0b\u4e00\u4ee3\u8f6f\u4ef6\u5de5\u7a0b\u6311\u6218\u7684\u53c2\u8003\u3002"}}
{"id": "2506.16024", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16024", "abs": "https://arxiv.org/abs/2506.16024", "authors": ["Zhihan Guo", "Jiele Wu", "Wenqian Cui", "Yifei Zhang", "Minda Hu", "Yufei Wang", "Irwin King"], "title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation", "comment": null, "summary": "Current research on long-form context in Large Language Models (LLMs)\nprimarily focuses on the understanding of long-contexts, the Open-ended Long\nText Generation (Open-LTG) remains insufficiently explored. Training a\nlong-context generation model requires curation of gold standard reference\ndata, which is typically nonexistent for informative Open-LTG tasks. However,\nprevious methods only utilize general assessments as reward signals, which\nlimits accuracy. To bridge this gap, we introduce ProxyReward, an innovative\nreinforcement learning (RL) based framework, which includes a dataset and a\nreward signal computation method. Firstly, ProxyReward Dataset generation is\naccomplished through simple prompts that enables the model to create\nautomatically, obviating extensive labeled data or significant manual effort.\nSecondly, ProxyReward Signal offers a targeted evaluation of information\ncomprehensiveness and accuracy for specific questions. The experimental results\nindicate that our method ProxyReward surpasses even GPT-4-Turbo. It can\nsignificantly enhance performance by 20% on the Open-LTG task when training\nwidely used open-source models, while also surpassing the LLM-as-a-Judge\napproach. Our work presents effective methods to enhance the ability of LLMs to\naddress complex open-ended questions posed by human.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5f3a\u5316\u5b66\u4e60\u6846\u67b6ProxyReward\uff0c\u5305\u62ec\u81ea\u52a8\u751f\u6210\u7684\u6570\u636e\u96c6\u4e0e\u6709\u9488\u5bf9\u6027\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u4f7f\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u660e\u663e\u6027\u80fd\u63d0\u5347\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u4e3b\u6d41\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u5904\u7406\u957f\u6587\u672c\u7406\u89e3\u65b9\u9762\u6709\u8f83\u591a\u7814\u7a76\uff0c\u4f46\u5728\u5f00\u653e\u5f0f\u957f\u6587\u672c\u751f\u6210\uff08Open-LTG\uff09\u4efb\u52a1\u4e0a\u7814\u7a76\u8f83\u5c11\u3002\u800c\u60f3\u8981\u8bad\u7ec3\u8fd9\u7c7b\u6a21\u578b\u9700\u8981\u9ad8\u8d28\u91cf\u7684\u6807\u51c6\u53c2\u8003\u6570\u636e\uff0c\u73b0\u5b9e\u4e2d\u8fd9\u7c7b\u6570\u636e\u7f3a\u4e4f\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u662f\u5229\u7528\u901a\u7528\u8bc4\u4f30\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u5bfc\u81f4\u751f\u6210\u5185\u5bb9\u7684\u51c6\u786e\u6027\u6709\u9650\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86ProxyReward\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u96c6\u548c\u5956\u52b1\u8ba1\u7b97\u65b9\u6cd5\u3002\u6570\u636e\u96c6\u901a\u8fc7\u7b80\u5355\u63d0\u793a\u81ea\u52a8\u751f\u6210\uff0c\u51cf\u5c11\u4eba\u5de5\u548c\u6807\u6ce8\u6210\u672c\u3002\u5956\u52b1\u4fe1\u53f7\u5219\u80fd\u6709\u9488\u5bf9\u6027\u5730\u8bc4\u4ef7\u9488\u5bf9\u7279\u5b9a\u95ee\u9898\u7684\u4fe1\u606f\u5168\u9762\u6027\u548c\u51c6\u786e\u6027\u3002\u6846\u67b6\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cProxyReward\u6846\u67b6\u5728Open-LTG\u4efb\u52a1\u4e0a\u80fd\u8ba9\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90\u6a21\u578b\u6027\u80fd\u63d0\u534720%\uff0c\u6548\u679c\u751a\u81f3\u8d85\u8fc7GPT-4-Turbo\u548cLLM-as-a-Judge\u65b9\u6cd5\u3002\u6a21\u578b\u5bf9\u590d\u6742\u5f00\u653e\u5f0f\u95ee\u9898\u7684\u5904\u7406\u80fd\u529b\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "ProxyReward\u6846\u67b6\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u964d\u4f4e\u4e86\u6570\u636e\u51c6\u5907\u548c\u8bc4\u4f30\u7684\u96be\u5ea6\uff0c\u5e76\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2506.16997", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.16997", "abs": "https://arxiv.org/abs/2506.16997", "authors": ["Hannah Deters", "Laura Reinhardt", "Jakob Droste", "Martin Obaidi", "Kurt Schneider"], "title": "Identifying Explanation Needs: Towards a Catalog of User-based Indicators", "comment": "This paper has been accepted at the research track of the 33rd IEEE\n  International Requirements Engineering Conference (RE 2025)", "summary": "In today's digitalized world, where software systems are becoming\nincreasingly ubiquitous and complex, the quality aspect of explainability is\ngaining relevance. A major challenge in achieving adequate explanations is the\nelicitation of individual explanation needs, as it may be subject to severe\nhypothetical or confirmation biases. To address these challenges, we aim to\nestablish user-based indicators concerning user behavior or system events that\ncan be captured at runtime to determine when a need for explanations arises. In\nthis work, we conducted explorative research in form of an online study to\ncollect self-reported indicators that could indicate a need for explanation. We\ncompiled a catalog containing 17 relevant indicators concerning user behavior,\n8 indicators concerning system events and 14 indicators concerning emotional\nstates or physical reactions. We also analyze the relationships between these\nindicators and different types of need for explanation. The established\nindicators can be used in the elicitation process through prototypes, as well\nas after publication to gather requirements from already deployed applications\nusing telemetry and usage data. Moreover, these indicators can be used to\ntrigger explanations at appropriate moments during the runtime.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7528\u6237\u8c03\u7814\u53d1\u73b0\u591a\u7c7b\u80fd\u53cd\u6620\u89e3\u91ca\u9700\u6c42\u7684\u6307\u6807\uff0c\u4e3a\u5b9e\u73b0\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5b9e\u65f6\u548c\u9488\u5bf9\u6027\u7684\u89e3\u91ca\u8f93\u51fa\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "motivation": "\u5728\u73b0\u4eca\u6570\u5b57\u5316\u65f6\u4ee3\uff0c\u8f6f\u4ef6\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\u4e14\u65e0\u5904\u4e0d\u5728\uff0c\u201c\u53ef\u89e3\u91ca\u6027\u201d\u5df2\u6210\u4e3a\u5173\u952e\u8d28\u91cf\u5c5e\u6027\u3002\u73b0\u6709\u6311\u6218\u5728\u4e8e\uff0c\u5982\u4f55\u53d1\u73b0\u4e2a\u4f53\u771f\u5b9e\u7684\u89e3\u91ca\u9700\u6c42\uff0c\u56e0\u4e3a\u7528\u6237\u81ea\u6211\u62a5\u544a\u53ef\u80fd\u53d7\u5230\u5047\u8bbe\u6027\u6216\u786e\u8ba4\u504f\u5dee\u7684\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u5f00\u5c55\u4e86\u4e00\u9879\u63a2\u7d22\u6027\u7814\u7a76\uff0c\u901a\u8fc7\u7ebf\u4e0a\u8c03\u7814\u6536\u96c6\u7528\u6237\u81ea\u6211\u62a5\u544a\u7684\u884c\u4e3a\u3001\u7cfb\u7edf\u4e8b\u4ef6\u3001\u60c5\u7eea\u4e0e\u751f\u7406\u53cd\u5e94\u7b49\u6307\u6807\uff0c\u8fd9\u4e9b\u6307\u6807\u53ef\u80fd\u4f5c\u4e3a\u9700\u6c42\u89e3\u91ca\u7684\u4fe1\u53f7\u3002\u968f\u540e\uff0c\u6574\u7406\u51fa\u4e86\u76f8\u5173\u6307\u6807\u7684\u76ee\u5f55\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u6307\u6807\u4e0e\u4e0d\u540c\u7c7b\u578b\u89e3\u91ca\u9700\u6c42\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u7f16\u5236\u4e86\u5305\u542b17\u9879\u7528\u6237\u884c\u4e3a\u6307\u6807\u30018\u9879\u7cfb\u7edf\u4e8b\u4ef6\u6307\u6807\u548c14\u9879\u60c5\u7eea\u6216\u751f\u7406\u53cd\u5e94\u6307\u6807\u7684\u76ee\u5f55\uff0c\u5e76\u63ed\u793a\u4e86\u8fd9\u4e9b\u6307\u6807\u4e0e\u4e0d\u540c\u89e3\u91ca\u9700\u6c42\u7c7b\u578b\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u8fd9\u4e9b\u6307\u6807\u4e0d\u4ec5\u53ef\u7528\u4e8e\u8f6f\u4ef6\u539f\u578b\u7684\u9700\u6c42\u6316\u6398\u9636\u6bb5\uff0c\u8fd8\u80fd\u5728\u7cfb\u7edf\u53d1\u5e03\u540e\u901a\u8fc7\u9065\u6d4b\u53ca\u4f7f\u7528\u6570\u636e\u76d1\u6d4b\u89e3\u91ca\u9700\u6c42\uff0c\u8fdb\u800c\u80fd\u5728\u7cfb\u7edf\u8fd0\u884c\u65f6\u4e3b\u52a8\u89e6\u53d1\u89e3\u91ca\u8f93\u51fa\u3002"}}
{"id": "2506.16029", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16029", "abs": "https://arxiv.org/abs/2506.16029", "authors": ["Zhenting Qi", "Fan Nie", "Alexandre Alahi", "James Zou", "Himabindu Lakkaraju", "Yilun Du", "Eric Xing", "Sham Kakade", "Hanlin Zhang"], "title": "EvoLM: In Search of Lost Language Model Training Dynamics", "comment": null, "summary": "Modern language model (LM) training has been divided into multiple stages,\nmaking it difficult for downstream developers to evaluate the impact of design\nchoices made at each stage. We present EvoLM, a model suite that enables\nsystematic and transparent analysis of LMs' training dynamics across\npre-training, continued pre-training, supervised fine-tuning, and reinforcement\nlearning. By training over 100 LMs with 1B and 4B parameters from scratch, we\nrigorously evaluate both upstream (language modeling) and downstream\n(problem-solving) reasoning capabilities, including considerations of both\nin-domain and out-of-domain generalization. Key insights highlight the\ndiminishing returns from excessive pre-training and post-training, the\nimportance and practices of mitigating forgetting during domain-specific\ncontinued pre-training, the crucial role of continued pre-training in bridging\npre-training and post-training phases, and various intricate trade-offs when\nconfiguring supervised fine-tuning and reinforcement learning. To facilitate\nopen research and reproducibility, we release all pre-trained and post-trained\nmodels, training datasets for all stages, and our entire training and\nevaluation pipeline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEvoLM\u6a21\u578b\u5957\u4ef6\uff0c\u7cfb\u7edf\u5206\u6790\u5927\u6a21\u578b\u591a\u9636\u6bb5\u8bad\u7ec3\u4e2d\u7684\u5404\u79cd\u5f71\u54cd\u3001\u56de\u62a5\u548c\u6743\u8861\uff0c\u63d0\u5347\u6a21\u578b\u8bc4\u4f30\u900f\u660e\u6027\uff0c\u5e76\u5411\u793e\u533a\u516c\u5f00\u6240\u6709\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u5206\u4e3a\u591a\u4e2a\u9636\u6bb5\uff0c\u8fd9\u5bfc\u81f4\u6a21\u578b\u5728\u6bcf\u4e2a\u9636\u6bb5\u7684\u8bbe\u8ba1\u9009\u62e9\u5bf9\u4e0b\u6e38\u4efb\u52a1\u5f71\u54cd\u96be\u4ee5\u8bc4\u4f30\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8feb\u5207\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u5316\u4e0e\u900f\u660e\u5316\u7684\u65b9\u5f0f\u6765\u5206\u6790\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u52a8\u6001\u3002", "method": "\u63d0\u51faEvoLM\u6a21\u578b\u5957\u4ef6\uff0c\u901a\u8fc7\u4ece\u5934\u8bad\u7ec3100\u591a\u4e2a\uff081B\u548c4B\u53c2\u6570\u91cf\u7ea7\uff09\u8bed\u8a00\u6a21\u578b\uff0c\u5bf9\u9884\u8bad\u7ec3\u3001\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u7b49\u591a\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u8bed\u8a00\u5efa\u6a21\u548c\u63a8\u7406\u4efb\u52a1\uff08\u6db5\u76d6\u57df\u5185\u4e0e\u57df\u5916\u6cdb\u5316\uff09\u4e0a\u7684\u8868\u73b0\u3002", "result": "1. \u8fc7\u5ea6\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u5e26\u6765\u7684\u56de\u62a5\u9012\u51cf\uff1b2. \u6301\u7eed\u9884\u8bad\u7ec3\u9636\u6bb5\u6613\u9057\u5fd8\u539f\u9884\u8bad\u7ec3\u77e5\u8bc6\uff0c\u9700\u91c7\u53d6\u63aa\u65bd\u7f13\u89e3\uff1b3. \u6301\u7eed\u9884\u8bad\u7ec3\u5bf9\u4e8e\u8fde\u63a5\u9884\u8bad\u7ec3\u4e0e\u540e\u8bad\u7ec3\u9636\u6bb5\u81f3\u5173\u91cd\u8981\uff1b4. \u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u914d\u7f6e\u65f6\u5b58\u5728\u591a\u79cd\u6743\u8861\u3002", "conclusion": "EvoLM\u4e3a\u5206\u6790\u548c\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u591a\u9636\u6bb5\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u63ed\u793a\u8bad\u7ec3\u5404\u9636\u6bb5\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd\u3002\u53d1\u5e03\u4e86\u6240\u6709\u6a21\u578b\u3001\u6570\u636e\u96c6\u4e0e\u6d41\u7a0b\uff0c\u63a8\u52a8\u5f00\u653e\u7814\u7a76\u4e0e\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2506.17057", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17057", "abs": "https://arxiv.org/abs/2506.17057", "authors": ["Fernando Pastor Ric\u00f3s", "Beatriz Mar\u00edn", "I. S. W. B. Prasetya", "Tanja E. J. Vos", "Joseph Davidson", "Karel Hovorka"], "title": "Behavior Driven Development for 3D Games", "comment": null, "summary": "Computer 3D games are complex software environments that require novel\ntesting processes to ensure high-quality standards. The Intelligent\nVerification/Validation for Extended Reality Based Systems (iv4XR) framework\naddresses this need by enabling the implementation of autonomous agents to\nautomate game testing scenarios. This framework facilitates the automation of\nregression test cases for complex 3D games like Space Engineers. Nevertheless,\nthe technical expertise required to define test scripts using iv4XR can\nconstrain seamless collaboration between developers and testers. This paper\nreports how integrating a Behavior-driven Development (BDD) approach with the\niv4XR framework allows the industrial company behind Space Engineers to\nautomate regression testing. The success of this industrial collaboration has\ninspired the iv4XR team to integrate the BDD approach to improve the automation\nof play-testing for the experimental 3D game LabRecruits. Furthermore, the\niv4XR framework has been extended with tactical programming to enable the\nautomation of long-play test scenarios in Space Engineers. These results\nunderscore the versatility of the iv4XR framework in supporting diverse testing\napproaches while showcasing how BDD empowers users to create, manage, and\nexecute automated game tests using comprehensive and human-readable statements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06BDD\u65b9\u6cd5\u4e0eiv4XR\u6846\u67b6\u7ed3\u5408\uff0c\u6709\u6548\u7b80\u5316\u4e86\u590d\u67423D\u6e38\u620f\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u811a\u672c\u7f16\u5199\uff0c\u5e76\u63d0\u5347\u4e86\u5f00\u53d1\u4e0e\u6d4b\u8bd5\u56e2\u961f\u7684\u534f\u4f5c\u6548\u7387\uff0c\u540c\u65f6\u62d3\u5c55\u4e86\u6846\u67b6\u529f\u80fd\uff0c\u5b9e\u73b0\u4e86\u591a\u6837\u5316\u548c\u957f\u65f6\u6bb5\u81ea\u52a8\u6d4b\u8bd5\u3002", "motivation": "3D\u6e38\u620f\u7684\u590d\u6742\u6027\u4f7f\u5f97\u6d4b\u8bd5\u8fc7\u7a0b\u53d8\u5f97\u56f0\u96be\uff0c\u9700\u8981\u65b0\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u624b\u6bb5\u4ee5\u4fdd\u8bc1\u6e38\u620f\u8d28\u91cf\u3002iv4XR\u6846\u67b6\u867d\u53ef\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u4f46\u5176\u811a\u672c\u7f16\u5199\u5bf9\u6280\u672f\u95e8\u69db\u8f83\u9ad8\uff0c\u5f71\u54cd\u5f00\u53d1\u8005\u4e0e\u6d4b\u8bd5\u4eba\u5458\u7684\u534f\u4f5c\u3002", "method": "\u5c06\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\uff08BDD\uff09\u65b9\u6cd5\u4e0eiv4XR\u6846\u67b6\u7ed3\u5408\uff0c\u7b80\u5316\u81ea\u52a8\u5316\u6d4b\u8bd5\u811a\u672c\u7f16\u5199\uff0c\u5e76\u6269\u5c55\u6218\u672f\u7f16\u7a0b\u4ee5\u652f\u6301\u957f\u65f6\u95f4\u6e38\u620f\u6d4b\u8bd5\u3002", "result": "BDD\u65b9\u6cd5\u7684\u5f15\u5165\u8ba9\u5f00\u53d1\u8005\u548c\u6d4b\u8bd5\u4eba\u5458\u80fd\u591f\u4ee5\u4eba\u7c7b\u53ef\u8bfb\u7684\u8bed\u8a00\u7f16\u5199\u3001\u7ba1\u7406\u548c\u6267\u884c\u81ea\u52a8\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u5347\u4e86Space Engineers\u4e0eLabRecruits\u7b49\u6e38\u620f\u7684\u6d4b\u8bd5\u81ea\u52a8\u5316\u7a0b\u5ea6\u3002\u540c\u65f6\uff0c\u6846\u67b6\u6269\u5c55\u5b9e\u73b0\u4e86\u5bf9\u957f\u65f6\u6bb5\u6e38\u620f\u6d4b\u8bd5\u7684\u81ea\u52a8\u5316\u652f\u6301\u3002", "conclusion": "iv4XR\u6846\u67b6\u901a\u8fc7\u6574\u5408BDD\u548c\u6218\u672f\u7f16\u7a0b\uff0c\u62d3\u5c55\u4e86\u5176\u652f\u6301\u4e0d\u540c\u6d4b\u8bd5\u9700\u6c42\u7684\u80fd\u529b\uff0c\u800cBDD\u964d\u4f4e\u4e86\u534f\u4f5c\u95e8\u69db\uff0c\u4f7f\u81ea\u52a8\u6e38\u620f\u6d4b\u8bd5\u66f4\u52a0\u9ad8\u6548\u6613\u7528\u3002"}}
{"id": "2506.16037", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16037", "abs": "https://arxiv.org/abs/2506.16037", "authors": ["Xinyue Huang", "Ziqi Lin", "Fang Sun", "Wenchao Zhang", "Kejian Tong", "Yunbo Liu"], "title": "Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3", "comment": null, "summary": "This paper presents a novel Retrieval-Augmented Generation (RAG) framework\ntailored for complex question answering tasks, addressing challenges in\nmulti-hop reasoning and contextual understanding across lengthy documents.\nBuilt upon LLaMA 3, the framework integrates a dense retrieval module with\nadvanced context fusion and multi-hop reasoning mechanisms, enabling more\naccurate and coherent response generation. A joint optimization strategy\ncombining retrieval likelihood and generation cross-entropy improves the\nmodel's robustness and adaptability. Experimental results show that the\nproposed system outperforms existing retrieval-augmented and generative\nbaselines, confirming its effectiveness in delivering precise, contextually\ngrounded answers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684LLaMA 3\u57fa\u7840RAG\u65b0\u6846\u67b6\uff0c\u5728\u590d\u6742\u95ee\u7b54\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u9ad8\u6548\u5730\u4ea7\u751f\u4e0a\u4e0b\u6587\u76f8\u5173\u7b54\u6848\u3002", "motivation": "\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u9762\u4e34\u591a\u8df3\u63a8\u7406\u548c\u957f\u6587\u6863\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u6311\u6218\uff0c\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u5728\u8fd9\u4e9b\u65b9\u9762\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLaMA 3\u7684RAG\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u5bc6\u96c6\u68c0\u7d22\u6a21\u5757\u3001\u4e0a\u4e0b\u6587\u878d\u5408\u548c\u591a\u8df3\u63a8\u7406\u673a\u5236\uff0c\u5e76\u91c7\u7528\u8054\u5408\u4f18\u5316\u7b56\u7565\u63d0\u5347\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u4f18\u4e8e\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u548c\u751f\u6210\u57fa\u7ebf\uff0c\u5728\u7cbe\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u5173\u8054\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u751f\u6210\u51c6\u786e\u3001\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u7b54\u6848\uff0c\u63d0\u5347\u4e86\u590d\u6742\u95ee\u7b54\u7cfb\u7edf\u7684\u6548\u679c\u3002"}}
{"id": "2506.17095", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17095", "abs": "https://arxiv.org/abs/2506.17095", "authors": ["Ronnie de Souza Santos", "Matheus de Morais Leca", "Reydne Santos", "Cleyton Magalhaes"], "title": "Software Fairness Testing in Practice", "comment": null, "summary": "Software testing ensures that a system functions correctly, meets specified\nrequirements, and maintains high quality. As artificial intelligence and\nmachine learning (ML) technologies become integral to software systems, testing\nhas evolved to address their unique complexities. A critical advancement in\nthis space is fairness testing, which identifies and mitigates biases in AI\napplications to promote ethical and equitable outcomes. Despite extensive\nacademic research on fairness testing, including test input generation, test\noracle identification, and component testing, practical adoption remains\nlimited. Industry practitioners often lack clear guidelines and effective tools\nto integrate fairness testing into real-world AI development. This study\ninvestigates how software professionals test AI-powered systems for fairness\nthrough interviews with 22 practitioners working on AI and ML projects. Our\nfindings highlight a significant gap between theoretical fairness concepts and\nindustry practice. While fairness definitions continue to evolve, they remain\ndifficult for practitioners to interpret and apply. The absence of\nindustry-aligned fairness testing tools further complicates adoption,\nnecessitating research into practical, accessible solutions. Key challenges\ninclude data quality and diversity, time constraints, defining effective\nmetrics, and ensuring model interoperability. These insights emphasize the need\nto bridge academic advancements with actionable strategies and tools, enabling\npractitioners to systematically address fairness in AI systems.", "AI": {"tldr": "AI\u4e0eML\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u6d4b\u8bd5\u867d\u6709\u4e30\u5bcc\u5b66\u672f\u7814\u7a76\uff0c\u4f46\u884c\u4e1a\u5b9e\u8df5\u4e0d\u8db3\u3002\u901a\u8fc7\u8bbf\u8c08\u53d1\u73b0\uff0c\u4e3b\u8981\u96be\u9898\u5728\u4e8e\u7406\u8bba\u96be\u843d\u5730\u3001\u5de5\u5177\u7f3a\u4e4f\u3001\u6570\u636e\u4e0e\u6307\u6807\u7b49\u5b9e\u9645\u969c\u788d\u3002\u547c\u5401\u5f00\u53d1\u66f4\u63a5\u5730\u6c14\u7684\u6d4b\u8bd5\u5de5\u5177\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u5408\u5b66\u754c\u4e0e\u4e1a\u754c\u7684\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740AI\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u65e5\u76ca\u878d\u5165\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u4f20\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\u5df2\u65e0\u6cd5\u6ee1\u8db3AI\u7cfb\u7edf\u7684\u7279\u6b8a\u9700\u6c42\uff0c\u201c\u516c\u5e73\u6027\u6d4b\u8bd5\u201d\u4f5c\u4e3a\u89e3\u51b3AI\u7cfb\u7edf\u4f26\u7406\u548c\u504f\u89c1\u95ee\u9898\u7684\u5173\u952e\u624b\u6bb5\u9010\u6b65\u5174\u8d77\u3002\u5c3d\u7ba1\u5b66\u672f\u754c\u5728\u516c\u5e73\u6027\u6d4b\u8bd5\u65b9\u9762\u6295\u5165\u4e86\u5927\u91cf\u7814\u7a76\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u843d\u5730\u548c\u5b9e\u8df5\u5374\u8fdb\u5c55\u6709\u9650\u3002\u4f5c\u8005\u5e0c\u671b\u63ed\u793a\u7406\u8bba\u4e0e\u884c\u4e1a\u5b9e\u8df5\u95f4\u7684\u9e3f\u6c9f\uff0c\u5e76\u63a8\u52a8\u516c\u5e73\u6027\u6d4b\u8bd5\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u7814\u7a76\u56e2\u961f\u901a\u8fc7\u5bf922\u4f4d\u53c2\u4e0eAI\u548cML\u9879\u76ee\u7684\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c\u8bbf\u8c08\uff0c\u6536\u96c6\u7b2c\u4e00\u624b\u6570\u636e\uff0c\u5206\u6790\u884c\u4e1a\u5728AI\u7cfb\u7edf\u516c\u5e73\u6027\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9645\u505a\u6cd5\u3001\u6311\u6218\u548c\u9700\u6c42\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5b66\u672f\u754c\u63d0\u51fa\u7684\u516c\u5e73\u6027\u5b9a\u4e49\u96be\u4ee5\u4e3a\u4ece\u4e1a\u8005\u6240\u7406\u89e3\u548c\u64cd\u4f5c\uff0c\u4e14\u7f3a\u4e4f\u4e0e\u884c\u4e1a\u5b9e\u9645\u5bf9\u63a5\u7684\u516c\u5e73\u6027\u6d4b\u8bd5\u5de5\u5177\u3002\u4e3b\u8981\u96be\u70b9\u8fd8\u5305\u62ec\u6570\u636e\u8d28\u91cf\u4e0e\u591a\u6837\u6027\u3001\u65f6\u95f4\u538b\u529b\u3001\u96be\u4ee5\u91cf\u5316\u548c\u5e94\u7528\u7684\u516c\u5e73\u6027\u6307\u6807\uff0c\u4ee5\u53ca\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u517c\u5bb9\u6027\u7b49\u3002", "conclusion": "\u5b66\u672f\u4e0e\u5b9e\u8df5\u5728AI\u7cfb\u7edf\u516c\u5e73\u6027\u6d4b\u8bd5\u4e0a\u7684\u8131\u8282\u660e\u663e\uff0c\u6025\u9700\u66f4\u5177\u5b9e\u7528\u6027\u548c\u53ef\u884c\u6027\u7684\u5de5\u5177\u3001\u6307\u6807\u4e0e\u64cd\u4f5c\u8303\u5f0f\uff0c\u4ee5\u4fbf\u884c\u4e1a\u80fd\u591f\u5207\u5b9e\u800c\u7cfb\u7edf\u5730\u5e94\u5bf9AI\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002"}}
{"id": "2506.16043", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16043", "abs": "https://arxiv.org/abs/2506.16043", "authors": ["Fei Wang", "Xingchen Wan", "Ruoxi Sun", "Jiefeng Chen", "Sercan \u00d6. Ar\u0131k"], "title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling", "comment": null, "summary": "Inference-time scaling has proven effective in boosting large language model\n(LLM) performance through increased test-time computation. Yet, its practical\napplication is often hindered by reliance on external verifiers or a lack of\noptimization for realistic computational constraints. We propose DynScaling,\nwhich addresses these limitations through two primary innovations: an\nintegrated parallel-sequential sampling strategy and a bandit-based dynamic\nbudget allocation framework. The integrated sampling strategy unifies parallel\nand sequential sampling by constructing synthetic sequential reasoning chains\nfrom initially independent parallel responses, promoting diverse and coherent\nreasoning trajectories. The dynamic budget allocation framework formulates the\nallocation of computational resources as a multi-armed bandit problem,\nadaptively distributing the inference budget across queries based on the\nuncertainty of previously sampled responses, thereby maximizing computational\nefficiency. By combining these components, DynScaling effectively improves LLM\nperformance under practical resource constraints without the need for external\nverifiers. Experimental results demonstrate that DynScaling consistently\nsurpasses existing verifier-free inference scaling baselines in both task\nperformance and computational cost.", "AI": {"tldr": "DynScaling\u7ed3\u5408\u521b\u65b0\u91c7\u6837\u548c\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u53d7\u9650\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6027\u80fd\u63d0\u5347\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\uff0c\u6548\u679c\u548c\u6548\u7387\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u589e\u52a0\u8ba1\u7b97\u91cf\u53ef\u63d0\u5347\u8868\u73b0\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u5f80\u5f80\u53d7\u9650\u4e8e\u9700\u8981\u5916\u90e8\u9a8c\u8bc1\u5668\u6216\u672a\u5145\u5206\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\uff0c\u4f7f\u5176\u5b9e\u7528\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDynScaling\u65b9\u6cd5\uff0c\u5305\u62ec\u5e76\u884c-\u987a\u5e8f\u91c7\u6837\u7b56\u7565\u548c\u57fa\u4e8eBandit\u7b97\u6cd5\u7684\u52a8\u6001\u9884\u7b97\u5206\u914d\u3002\u524d\u8005\u5c06\u5e76\u884c\u91c7\u6837\u4e0e\u987a\u5e8f\u91c7\u6837\u7ed3\u5408\uff0c\u901a\u8fc7\u5408\u6210\u987a\u5e8f\u63a8\u7406\u94fe\uff0c\u63d0\u5347\u63a8\u7406\u591a\u6837\u6027\u4e0e\u8fde\u8d2f\u6027\uff1b\u540e\u8005\u5c06\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u89c6\u4e3a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u6839\u636e\u91c7\u6837\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u5206\u914d\u9884\u7b97\uff0c\u63d0\u5347\u6548\u7387\u3002", "result": "DynScaling\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u6548\u679c\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u9a8c\u8bc1\u5668\u63a8\u7406\u6269\u5c55\u65b9\u6cd5\u3002", "conclusion": "DynScaling\u80fd\u591f\u5728\u5b9e\u9645\u8ba1\u7b97\u8d44\u6e90\u7ea6\u675f\u4e0b\uff0c\u660e\u663e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.17120", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17120", "abs": "https://arxiv.org/abs/2506.17120", "authors": ["Atish Kumar Dipongkor", "Ziyu Yao", "Kevin Moran"], "title": "Reassessing Code Authorship Attribution in the Era of Language Models", "comment": "12 pages", "summary": "The study of Code Stylometry, and in particular Code Authorship Attribution\n(CAA), aims to analyze coding styles to identify the authors of code samples.\nCAA is crucial in cybersecurity and software forensics for addressing,\ndetecting plagiarism, and supporting criminal prosecutions. However, CAA is a\ncomplex and error prone task, due to the need for recognizing nuanced\nrelationships between coding patterns. This challenge is compounded in large\nsoftware systems with numerous authors due to the subtle variability of\npatterns that signify the coding style of one author among many. Given the\nchallenges related to this task, researchers have proposed and studied\nautomated approaches that rely upon classical Machine Learning and Deep\nLearning techniques. However, such techniques have historically relied upon\nhand-crafted features, and due to the often intricate interaction of different\nfeatures (e.g., formatting, etc.), have key limitations in properly\ncharacterizing authorship, and are sensitive to adversarial code perturbations.\nRecently, transformer-based Language Models (LMs) have shown remarkable\nefficacy across a range of software engineering tasks, and in the authorship\nattribution on natural language in the NLP domain. However, their effectiveness\nin CAA is not well understood. As such, we conduct the first extensive\nempirical study applying two larger state-of-the-art code LMs, and five smaller\ncode LMs to the task of CAA to 6 diverse datasets that encompass 12k code\nsnippets written by 463 developers. Furthermore, we perform an in-depth\nanalysis of our studied models' performance on CAA using established machine\nlearning interpretability techniques. The results of our analysis illustrate\nimportant findings that illuminate the behavior of LMs in understanding\nstylometric code patterns during the task of CAA, and point towards important\ndirections for future work.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cdSOTA\u4ee3\u7801Transformer\u6a21\u578b\u5728\u4ee3\u7801\u4f5c\u8005\u8bc6\u522b\u4e0a\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u4f18\u4e8e\u4f20\u7edf\u624b\u5de5\u7279\u5f81\u65b9\u6cd5\uff0c\u5e76\u501f\u52a9\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5206\u6790\u6a21\u578b\u884c\u4e3a\uff0c\u6307\u660e\u4e86\u540e\u7eed\u7814\u7a76\u63d0\u5347\u65b9\u5411\u3002", "motivation": "\u4ee3\u7801\u4f5c\u8005\u5f52\u5c5e\uff08CAA\uff09\u662f\u4ee3\u7801\u53d6\u8bc1\u3001\u5b89\u5168\u7b49\u8bf8\u591a\u9886\u57df\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u4f46\u56e0\u4ee3\u7801\u98ce\u683c\u5dee\u5f02\u7ec6\u5fae\u3001\u4f5c\u8005\u4f17\u591a\u3001\u7279\u5f81\u590d\u6742\uff0c\u51c6\u786e\u8bc6\u522b\u4f5c\u8005\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\uff0c\u9762\u5bf9\u590d\u6742\u6837\u5f0f\u548c\u5bf9\u6297\u653b\u51fb\u8868\u73b0\u6709\u9650\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u63a2\u7d22\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u6280\u672f\u3002", "method": "\u672c\u6587\u9996\u6b21\u5bf9\u6bd4\u8bc4\u4f30\u4e86\u4e24\u79cd\u5927\u89c4\u6a21\u3001\u4e94\u79cd\u5c0f\u89c4\u6a21\u7684SOTA\u4ee3\u7801Transformer\u8bed\u8a00\u6a21\u578b\u5728CAA\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8986\u76d66\u4e2a\u5305\u542b463\u4f4d\u5f00\u53d1\u8005\u517112k\u4ee3\u7801\u7247\u6bb5\u7684\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u5229\u7528\u5df2\u6709\u7684\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5bf9\u6a21\u578b\u5728\u5bf9\u5e94\u4efb\u52a1\u4e0b\u7684\u884c\u4e3a\u8fdb\u884c\u6df1\u5ea6\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e3b\u6d41\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u4ee3\u7801\u98ce\u683c\u7279\u5f81\u7684\u80fd\u529b\uff0c\u90e8\u5206\u8d85\u8d8a\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\uff0c\u6307\u51fa\u4e86\u73b0\u6709Transformer\u6a21\u578b\u5728\u4ee3\u7801\u4f5c\u8005\u8bc6\u522b\u9886\u57df\u7684\u4f18\u52bf\u548c\u5c40\u9650\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u6307\u660e\u4e86\u91cd\u8981\u65b9\u5411\u3002", "conclusion": "\u5927\u578bTransformer\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u4f5c\u8005\u5f52\u5c5e\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u8f83\u5f3a\u6f5c\u529b\uff0c\u6bd4\u4ee5\u5f80\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\u7684\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002\u540c\u65f6\uff0c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u5e2e\u52a9\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u4f9d\u636e\uff0c\u5bf9\u672a\u6765CAA\u81ea\u52a8\u5316\u4e0e\u5b89\u5168\u6027\u7814\u7a76\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2506.16052", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16052", "abs": "https://arxiv.org/abs/2506.16052", "authors": ["Devesh Kumar"], "title": "A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text", "comment": null, "summary": "The proliferation of online communication platforms has created unprecedented\nopportunities for global connectivity while simultaneously enabling harmful\nbehaviors such as cyberbullying, which affects approximately 54.4\\% of\nteenagers according to recent research. This paper presents a hybrid\narchitecture that combines the contextual understanding capabilities of\ntransformer-based models with the pattern recognition strengths of broad\nlearning systems for effective cyberbullying detection. This approach\nintegrates a modified DeBERTa model augmented with Squeeze-and-Excitation\nblocks and sentiment analysis capabilities with a Gated Broad Learning System\n(GBLS) classifier, creating a synergistic framework that outperforms existing\napproaches across multiple benchmark datasets. The proposed ModifiedDeBERTa +\nGBLS model achieved good performance on four English datasets: 79.3\\% accuracy\non HateXplain, 95.41\\% accuracy on SOSNet, 91.37\\% accuracy on Mendeley-I, and\n94.67\\% accuracy on Mendeley-II. Beyond performance gains, the framework\nincorporates comprehensive explainability mechanisms including token-level\nattribution analysis, LIME-based local interpretations, and confidence\ncalibration, addressing critical transparency requirements in automated content\nmoderation. Ablation studies confirm the meaningful contribution of each\narchitectural component, while failure case analysis reveals specific\nchallenges in detecting implicit bias and sarcastic content, providing valuable\ninsights for future improvements in cyberbullying detection systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u6539\u8fdb\u578bDeBERTa\u548c\u5e7f\u4e49\u5b66\u4e60\u7cfb\u7edf\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u82f1\u6587\u7f51\u7edc\u6b3a\u51cc\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u53ef\u89e3\u91ca\u6027\u673a\u5236\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u901a\u4fe1\u5e73\u53f0\u7684\u666e\u53ca\uff0c\u9752\u5c11\u5e74\u7f51\u7edc\u6b3a\u51cc\u73b0\u8c61\u6108\u53d1\u4e25\u91cd\uff0c\u5f71\u54cd\u9762\u5e7f\u3002\u5df2\u6709\u7684\u68c0\u6d4b\u65b9\u6cd5\u5728\u7406\u89e3\u4e0a\u4e0b\u6587\u548c\u6a21\u5f0f\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u6025\u9700\u66f4\u9ad8\u6548\u4e14\u5177\u6709\u53ef\u89e3\u91ca\u6027\u7684\u667a\u80fd\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408Transformer\uff08\u5177\u4f53\u4e3a\u6539\u8fdb\u7684DeBERTa\u6a21\u578b\uff0c\u7ed3\u5408Squeeze-and-Excitation\u6a21\u5757\u4e0e\u60c5\u611f\u5206\u6790\uff09\u3001Broad Learning System\uff08GBLS\u5206\u7c7b\u5668\uff09\u7684\u6df7\u5408\u67b6\u6784\u6a21\u578b\u3002\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u89e3\u91ca\u673a\u5236\uff08token\u7ea7\u5f52\u56e0\u5206\u6790\u3001LIME\u672c\u5730\u89e3\u91ca\u3001\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff09\uff0c\u63d0\u5347\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u8be5\u6a21\u578b\u5728\u56db\u4e2a\u82f1\u6587\u6570\u636e\u96c6\uff08HateXplain\u3001SOSNet\u3001Mendeley-I\u3001Mendeley-II\uff09\u4e0a\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5206\u522b\u53d6\u5f9779.3%\u300195.41%\u300191.37%\u548c94.67%\u7684\u51c6\u786e\u7387\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u5404\u90e8\u5206\u8d21\u732e\uff0c\u5931\u8d25\u6848\u4f8b\u4e3b\u8981\u96c6\u4e2d\u5728\u8bbd\u523a\u548c\u9690\u542b\u504f\u89c1\u7684\u68c0\u6d4b\u96be\u70b9\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u4e0d\u4ec5\u663e\u8457\u63d0\u9ad8\u4e86\u7f51\u7edc\u6b3a\u51cc\u68c0\u6d4b\u4efb\u52a1\u7684\u51c6\u786e\u7387\uff0c\u8fd8\u52a0\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u5904\u7406\u8bbd\u523a\u4e0e\u9690\u6027\u504f\u89c1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u76ca\u542f\u793a\u3002"}}
{"id": "2506.17125", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.17125", "abs": "https://arxiv.org/abs/2506.17125", "authors": ["Xue Jiang", "Yihong Dong", "Zheng Fang", "Yingwei Ma", "Tangxinyu Wang", "Rongyu Cao", "Binhua Li", "Zhi Jin", "Wenpin Jiao", "Yongbin Li", "Ge Li"], "title": "Large Language Model Unlearning for Source Code", "comment": null, "summary": "LLM4SE has demonstrated significant success, but LLMs' potential memorization\nof sensitive or outdated training data introduces critical risks to legal\ncompliance, software security, and code quality. LLM unlearning techniques,\nwhich can eliminate the influence of undesired data from LLMs in a\npost-training way, present a promising solution to address these concerns.\nWhile recent efforts in LLM unlearning show effectiveness in natural language,\ntheir applicability to source code remains underexplored. Our empirical study\nreveals that existing LLM unlearning approaches, when applied to source code,\ncause severe model utility degradation, rendering models practically unusable\nfor code generation. In this paper, we propose PROD, a novel unlearning\napproach that enables LLMs to forget undesired code content while effectively\npreserving their code generation capabilities. PROD suppresses the probability\nof forget data in LLMs' output distribution while promoting candidate\ndistributional components, enabling the model to jointly learn to forget\nspecific content and retain its general capabilities. To facilitate this study,\nwe establish a benchmark for code unlearning evaluation, which includes three\ncritical downstream tasks: copyrighted code unlearning, insecure code\nunlearning, and deprecated API unlearning. Our evaluation demonstrates that\nPROD achieves superior balance between forget quality and model utility\ncompared to existing unlearning approaches across three downstream tasks, while\nconsistently exhibiting improvements when applied to LLMs of varying series.\nPROD also exhibits superior robustness against adversarial attacks without\ngenerating or exposing the data to be forgotten. The results underscore that\nour approach not only extends the application boundary of unlearning techniques\nto source code, but also holds significant implications for advancing reliable\ncode generation.", "AI": {"tldr": "\u9488\u5bf9LLM\u9057\u5fd8\u6280\u672f\u5728\u4ee3\u7801\u9886\u57df\u7684\u5e94\u7528\u56f0\u5883\uff0c\u63d0\u51fa\u4e86\u6548\u679c\u4f18\u5f02\u4e14\u9c81\u68d2\u6027\u5f3a\u7684PROD\u7b97\u6cd5\uff0c\u80fd\u5728\u9057\u5fd8\u6709\u98ce\u9669\u5185\u5bb9\u7684\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4e3a\u5b89\u5168\u5408\u89c4\u7684\u4ee3\u7801\u751f\u6210\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\u3002", "motivation": "LLM \u5728\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u53ef\u80fd\u5305\u542b\u654f\u611f\u6216\u8fc7\u65f6\u4fe1\u606f\uff0c\u5e26\u6765\u6cd5\u5f8b\u5408\u89c4\u3001\u8f6f\u4ef6\u5b89\u5168\u4e0e\u4ee3\u7801\u8d28\u91cf\u7b49\u98ce\u9669\u3002\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u201c\u9057\u5fd8\u201d\u6280\u672f\u4e3b\u8981\u5e94\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\uff0c\u5982\u4f55\u4fdd\u969c\u6e90\u4ee3\u7801\u4e2d\u7684\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9057\u5fd8\u7b97\u6cd5\u2014\u2014PROD\uff0c\u53ef\u4ee5\u8ba9LLM\u9057\u5fd8\u4e0d\u9700\u8981\u7684\u4ee3\u7801\u5185\u5bb9\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002PROD\u901a\u8fc7\u6291\u5236\u9700\u8981\u9057\u5fd8\u6570\u636e\u5728\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u4e2d\u7684\u6982\u7387\uff0c\u540c\u65f6\u63d0\u5347\u5176\u4ed6\u5019\u9009\u5206\u5e03\u90e8\u5206\uff0c\u5b9e\u73b0\u9057\u5fd8\u548c\u80fd\u529b\u4fdd\u7559\u7684\u5e73\u8861\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u5efa\u7acb\u4e86\u4ee3\u7801\u9057\u5fd8\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5305\u62ec\u6709\u7248\u6743\u4ee3\u7801\u3001\u4e0d\u5b89\u5168\u4ee3\u7801\u3001\u8fc7\u65f6API\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "PROD\u5728\u7ef4\u6301\u6a21\u578b\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u540c\u65f6\uff0c\u6709\u6548\u9057\u5fd8\u4e86\u6307\u5b9a\u5185\u5bb9\uff0c\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u4e0d\u540c\u7cfb\u5217\u7684LLM\u3002\u6b64\u5916\uff0cPROD\u5728\u4e0d\u66b4\u9732\u88ab\u5fd8\u4fe1\u606f\u7684\u524d\u63d0\u4e0b\uff0c\u5bf9\u6297\u6027\u653b\u51fb\u9c81\u68d2\u6027\u66f4\u5f3a\u3002", "conclusion": "PROD\u65b9\u6cd5\u4e0d\u4ec5\u62d3\u5c55\u4e86\u9057\u5fd8\u6280\u672f\u5728\u6e90\u4ee3\u7801\u9886\u57df\u7684\u5e94\u7528\u8fb9\u754c\uff0c\u4e5f\u4e3a\u5b9e\u73b0\u5b89\u5168\u3001\u5408\u89c4\u3001\u53ef\u9760\u7684\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6491\u3002"}}
{"id": "2506.16055", "categories": ["cs.CL", "cs.FL"], "pdf": "https://arxiv.org/pdf/2506.16055", "abs": "https://arxiv.org/abs/2506.16055", "authors": ["Andy Yang", "Micha\u00ebl Cadilhac", "David Chiang"], "title": "Knee-Deep in C-RASP: A Transformer Depth Hierarchy", "comment": "27 pages, 4 figures", "summary": "It has been observed that transformers with greater depth (that is, more\nlayers) have more capabilities, but can we establish formally which\ncapabilities are gained with greater depth? We answer this question with a\ntheoretical proof followed by an empirical study. First, we consider\ntransformers that round to fixed precision except inside attention. We show\nthat this subclass of transformers is expressively equivalent to the\nprogramming language C-RASP and this equivalence preserves depth. Second, we\nprove that deeper C-RASP programs are more expressive than shallower C-RASP\nprograms, implying that deeper transformers are more expressive than shallower\ntransformers (within the subclass mentioned above). These results are\nestablished by studying a form of temporal logic with counting operators, which\nwas shown equivalent to C-RASP in previous work. Finally, we provide empirical\nevidence that our theory predicts the depth required for transformers without\npositional encodings to length-generalize on a family of sequential dependency\ntasks.", "AI": {"tldr": "\u8bba\u6587\u5f62\u5f0f\u5316\u8bc1\u660e\u4e86\u66f4\u6df1\u5c42\u7684transformer\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u5f3a\u4e8e\u6d45\u5c42transformer\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6df1\u5ea6\u5bf9\u4e8e\u957f\u5ea6\u6cdb\u5316\u80fd\u529b\u4efb\u52a1\u6240\u9700\u7684\u6700\u5c0f\u6df1\u5ea6\u9884\u6d4b\u6548\u679c\u3002", "motivation": "\u6df1\u5c42transformer\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u80fd\u529b\uff0c\u4f46\u8fd8\u672a\u6709\u7406\u8bba\u8bc1\u660e\u5176\u56e0\u6df1\u5ea6\u800c\u83b7\u5f97\u7684\u65b0\u80fd\u529b\uff0c\u8bba\u6587\u65e8\u5728\u63ed\u793a\u6df1\u5ea6transformer\u5b9e\u9645\u83b7\u5f97\u4e86\u54ea\u4e9b\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u4e88\u4ee5\u5f62\u5f0f\u5316\u3002", "method": "\u9996\u5148\u7814\u7a76\u53ea\u5728attention\u4e2d\u975e\u5b9a\u70b9\u8ba1\u7b97\u7684transformer\uff0c\u8bc1\u660e\u8be5\u7c7btransformer\u4e0e\u7f16\u7a0b\u8bed\u8a00C-RASP\u8868\u73b0\u529b\u7b49\u4ef7\uff0c\u5e76\u4e14\u8fd9\u79cd\u7b49\u4ef7\u662f\u6df1\u5ea6\u4fdd\u7559\u7684\uff1b\u5176\u6b21\uff0c\u901a\u8fc7\u5206\u6790\u7b49\u4ef7\u7684\u8ba1\u6570\u65f6\u5e8f\u903b\u8f91\uff0c\u8bc1\u660e\u66f4\u6df1C-RASP\u7a0b\u5e8f\u6bd4\u6d45\u5c42\u66f4\u6709\u8868\u8fbe\u529b\uff0c\u5e76\u5b9e\u8bc1\u5176\u7406\u8bba\u53ef\u9884\u6d4btransformer\u957f\u5ea6\u6cdb\u5316\u80fd\u529b\u6240\u9700\u6df1\u5ea6\u3002", "result": "\u8bc1\u660e\u5728\u8be5\u7c7btransformer\u4e2d\uff0c\u6a21\u578b\u6df1\u5ea6\u589e\u52a0\u4f1a\u63d0\u5347\u5176\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u4e14\u7406\u8bba\u4e0e\u5b9e\u9645\u5b9e\u9a8c\u8868\u73b0\u4e00\u81f4\uff1a\u7406\u8bba\u80fd\u591f\u9884\u6d4b\u5c11\u4f4d\u7f6e\u7f16\u7801\u65f6\uff0ctransformer\u5b8c\u6210\u5e8f\u5217\u4f9d\u8d56\u4efb\u52a1\u6240\u9700\u7684\u6df1\u5ea6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f62\u5f0f\u5316\u3001\u7406\u8bba\u4e0a\u548c\u5b9e\u8bc1\u5730\u8bc1\u660e\u4e86transformer\u6df1\u5ea6\u63d0\u5347\u6a21\u578b\u8868\u8fbe\u529b\uff0c\u63ed\u793a\u4e86\u6df1\u5ea6\u5bf9\u5e8f\u5217\u6cdb\u5316\u80fd\u529b\u7684\u4f5c\u7528\u53ca\u5176\u672c\u8d28\u9650\u5236\u3002"}}
{"id": "2506.17208", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17208", "abs": "https://arxiv.org/abs/2506.17208", "authors": ["Matias Martinez", "Xavier Franch"], "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems", "comment": null, "summary": "The rapid progress in Automated Program Repair (APR) has been driven by\nadvances in AI, particularly large language models (LLMs) and agent-based\nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\nsystems using real issues and pull requests mined from 12 popular open-source\nPython repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench\nVerified, have become central platforms for tracking progress and comparing\nsolutions. However, because the submission process does not require detailed\ndocumentation, the architectural design and origin of many solutions remain\nunclear. In this paper, we present the first comprehensive study of all\nsubmissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)\nleaderboards, analyzing 67 unique approaches across dimensions such as\nsubmitter type, product availability, LLM usage, and system architecture. Our\nfindings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),\nthe presence of both agentic and non-agentic designs, and a contributor base\nspanning from individual developers to large tech companies.", "AI": {"tldr": "\u8be5\u6587\u9996\u6b21\u7cfb\u7edf\u68b3\u7406\u548c\u5206\u6790\u4e86SWE-Bench\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u57fa\u51c6\u4e0a\u7684\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u4e13\u6709\u5927\u6a21\u578b\u4e3b\u5bfc\u3001\u67b6\u6784\u7c7b\u578b\u591a\u6837\u3001\u8d21\u732e\u8005\u591a\u5143\u7b49\u4e3b\u8981\u73b0\u8c61\uff0c\u5bf9\u9886\u57df\u53d1\u5c55\u63d0\u4f9b\u4e86\u5168\u9762\u8ba4\u77e5\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5c24\u5176\u662f\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\u63a8\u52a8\u4e0b\uff0c\u4e9f\u9700\u5bf9\u73b0\u6709LLM\u4fee\u590d\u7cfb\u7edf\u8fdb\u884c\u7cfb\u7edf\u5316\u8bc4\u4f30\u548c\u5206\u6790\u3002SWE-Bench\u6210\u4e3a\u4e3b\u6d41\u8bc4\u6d4b\u57fa\u51c6\uff0c\u4f46\u7531\u4e8e\u63d0\u4ea4\u8fc7\u7a0b\u7f3a\u4e4f\u8be6\u7ec6\u6587\u6863\uff0c\u4f17\u591a\u65b9\u6848\u7684\u67b6\u6784\u548c\u6765\u6e90\u4e0d\u660e\u786e\u3002\u672c\u6587\u52a8\u673a\u5728\u4e8e\u7cfb\u7edf\u68b3\u7406\u548c\u5206\u6790\u8fd9\u4e9b\u7cfb\u7edf\u7684\u73b0\u72b6\u3002", "method": "\u5bf9SWE-Bench Lite\uff0868\u4e2a\u63d0\u4ea4\uff09\u548cSWE-Bench Verified\uff0879\u4e2a\u63d0\u4ea4\uff09\u7684\u6240\u6709\u65b9\u6848\u8fdb\u884c\u5168\u9762\u8c03\u7814\u4e0e\u5206\u6790\uff0c\u4ece\u63d0\u4ea4\u8005\u7c7b\u578b\u3001\u4ea7\u54c1\u53ef\u7528\u6027\u3001LLM\u4f7f\u7528\u60c5\u51b5\u548c\u7cfb\u7edf\u67b6\u6784\u7b49\u591a\u4e2a\u7ef4\u5ea6\u5256\u6790\uff0c\u6db5\u76d667\u79cd\u4e0d\u540c\u6280\u672f\u8def\u7ebf\u3002", "result": "\u5206\u6790\u6307\u51fa\uff0c\u5927\u90e8\u5206\u9876\u5c16\u65b9\u6848\u4f9d\u8d56\u4e13\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982Claude 3.5/3.7\uff09\uff0c\u65b9\u6848\u6db5\u76d6agentic\u548cnon-agentic\u8bbe\u8ba1\uff0c\u53c2\u4e0e\u8005\u65e2\u6709\u4e2a\u4eba\u5f00\u53d1\u8005\u4e5f\u6709\u5927\u578b\u79d1\u6280\u516c\u53f8\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5206\u6790\u4e86SWE-Bench\u4e3b\u6d41\u8bc4\u6d4b\u699c\u5355\u4e2d\u7684\u5404\u79cd\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u7684\u4e3b\u8981\u6280\u672f\u8def\u7ebf\u548c\u53d1\u5c55\u8d8b\u52bf\u3002"}}
{"id": "2506.16064", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16064", "abs": "https://arxiv.org/abs/2506.16064", "authors": ["Duc Hieu Ho", "Chenglin Fan"], "title": "Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning", "comment": null, "summary": "Large language models (LLMs) have demonstrated robust capabilities across\nvarious natural language tasks. However, producing outputs that are\nconsistently honest and helpful remains an open challenge. To overcome this\nchallenge, this paper tackles the problem through two complementary directions.\nIt conducts a comprehensive benchmark evaluation of ten widely used large\nlanguage models, including both proprietary and open-weight models from OpenAI,\nMeta, and Google. In parallel, it proposes a novel prompting strategy,\nself-critique-guided curiosity refinement prompting. The key idea behind this\nstrategy is enabling models to self-critique and refine their responses without\nadditional training. The proposed method extends the curiosity-driven prompting\nstrategy by incorporating two lightweight in-context steps including\nself-critique step and refinement step.\n  The experiment results on the HONESET dataset evaluated using the framework\n$\\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a\njudge of honesty and helpfulness, show consistent improvements across all\nmodels. The approach reduces the number of poor-quality responses, increases\nhigh-quality responses, and achieves relative gains in $\\mathrm{H}^2$ scores\nranging from 1.4% to 4.3% compared to curiosity-driven prompting across\nevaluated models. These results highlight the effectiveness of structured\nself-refinement as a scalable and training-free strategy to improve the\ntrustworthiness of LLMs outputs.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u8bda\u5b9e\u6027\u548c\u6709\u7528\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u81ea\u6211\u6279\u5224\u5f15\u5bfc\u7684\u597d\u5947\u5fc3\u7cbe\u70bc\u63d0\u793a\u65b0\u7b56\u7565\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u6574\u5408\u81ea\u6211\u6279\u5224\u548c\u56de\u7b54\u4f18\u5316\u4e24\u6b65\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u8f93\u51fa\u8d28\u91cf\uff0c\u662f\u4e00\u79cd\u6709\u6548\u3001\u53ef\u6269\u5c55\u7684\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u4e2a\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8f93\u51fa\u6301\u7eed\u53ef\u9760\u548c\u6709\u7528\u5185\u5bb9\u65b9\u9762\u4ecd\u5b58\u5728\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u63d0\u793a\u7b56\u7565\uff0c\u79f0\u4e3a\u81ea\u6211\u6279\u5224\u5f15\u5bfc\u7684\u597d\u5947\u5fc3\u7cbe\u70bc\u63d0\u793a\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u5728\u4e0a\u4e0b\u6587\u4e2d\u52a0\u5165\u81ea\u6211\u6279\u5224\u4e0e\u7cbe\u70bc\u4e24\u4e2a\u6b65\u9aa4\uff0c\u5f15\u5bfc\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u56de\u7b54\u3002\u540c\u65f6\uff0c\u57fa\u4e8eHONESET\u6570\u636e\u96c6\uff0c\u5bf9OpenAI\u3001Meta\u3001Google\u7b49\u5341\u4e2a\u4e3b\u6d41LLM\u8fdb\u884c\u4e86\u7cfb\u7edf\u57fa\u51c6\u8bc4\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728GPT-4o\u5224\u5b9a\u4e0b\u5168\u7ebf\u63d0\u5347\u5404\u6a21\u578b\u8f93\u51fa\u7684\u8bda\u5b9e\u6027\u4e0e\u6709\u7528\u6027\uff0c\u4f4e\u8d28\u91cf\u56de\u590d\u6570\u91cf\u4e0b\u964d\uff0c\u9ad8\u8d28\u91cf\u56de\u590d\u589e\u52a0\uff0c\u76f8\u8f83\u5e38\u89c4\u597d\u5947\u5fc3\u9a71\u52a8\u63d0\u793a\uff0c$\u001b[H^2\u001b$\u5206\u6570\u76f8\u5bf9\u63d0\u53471.4%\u81f34.3%\u3002", "conclusion": "\u7ed3\u6784\u5316\u7684\u81ea\u6211\u7cbe\u70bc\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u6570\u636e\u53ef\u4fe1\u6027\u63d0\u5347\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u8bda\u5b9e\u4e0e\u6709\u7528\u6027\u3002"}}
{"id": "2506.16066", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16066", "abs": "https://arxiv.org/abs/2506.16066", "authors": ["Devesh Kumar"], "title": "Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI", "comment": null, "summary": "The growth of digital communication platforms has led to increased\ncyberbullying incidents worldwide, creating a need for automated detection\nsystems to protect users. The rise of code-mixed Hindi-English (Hinglish)\ncommunication on digital platforms poses challenges for existing cyberbullying\ndetection systems, which were designed primarily for monolingual text. This\npaper presents a framework for cyberbullying detection in Hinglish text using\nthe Multilingual Representations for Indian Languages (MURIL) architecture to\naddress limitations in current approaches. Evaluation across six benchmark\ndatasets -- Bohra \\textit{et al.}, BullyExplain, BullySentemo, Kumar \\textit{et\nal.}, HASOC 2021, and Mendeley Indo-HateSpeech -- shows that the MURIL-based\napproach outperforms existing multilingual models including RoBERTa and\nIndicBERT, with improvements of 1.36 to 13.07 percentage points and accuracies\nof 86.97\\% on Bohra, 84.62\\% on BullyExplain, 86.03\\% on BullySentemo, 75.41\\%\non Kumar datasets, 83.92\\% on HASOC 2021, and 94.63\\% on Mendeley dataset. The\nframework includes explainability features through attribution analysis and\ncross-linguistic pattern recognition. Ablation studies show that selective\nlayer freezing, appropriate classification head design, and specialized\npreprocessing for code-mixed content improve detection performance, while\nfailure analysis identifies challenges including context-dependent\ninterpretation, cultural understanding, and cross-linguistic sarcasm detection,\nproviding directions for future research in multilingual cyberbullying\ndetection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eMURIL\u67b6\u6784\u7684Hinglish\u7f51\u7edc\u6b3a\u51cc\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u516d\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u591a\u8bed\u6a21\u578b\uff0c\u5177\u5907\u53ef\u89e3\u91ca\u6027\u5e76\u5bf9\u672a\u6765\u591a\u8bed\u8a00\u6b3a\u51cc\u68c0\u6d4b\u65b9\u5411\u63d0\u51fa\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u901a\u4fe1\u5e73\u53f0\u7684\u53d1\u5c55\uff0c\u7f51\u7edc\u6b3a\u51cc\u4e8b\u4ef6\u65e5\u76ca\u589e\u591a\uff0c\u6025\u9700\u81ea\u52a8\u68c0\u6d4b\u7cfb\u7edf\u6765\u4fdd\u62a4\u7528\u6237\u3002\u73b0\u6709\u7684\u7f51\u7edc\u6b3a\u51cc\u68c0\u6d4b\u7cfb\u7edf\u4e3b\u8981\u9488\u5bf9\u5355\u8bed\u6587\u672c\uff0c\u96be\u4ee5\u5e94\u5bf9\u5370\u5ea6\u5e38\u89c1\u7684\u5370\u5730\u8bed-\u82f1\u8bed\u6df7\u5408\uff08Hinglish\uff09\u6587\u672c\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u68c0\u6d4b\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9Hinglish\u6587\u672c\u7684\u7f51\u7edc\u6b3a\u51cc\u68c0\u6d4b\u6846\u67b6\uff0c\u57fa\u4e8eMURIL\uff08\u5370\u5ea6\u8bed\u8a00\u591a\u8bed\u8868\u793a\uff09\u67b6\u6784\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u5f52\u56e0\u5206\u6790\u548c\u8de8\u8bed\u8a00\u6a21\u5f0f\u8bc6\u522b\uff0c\u5b9e\u73b0\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u4e0d\u540c\u6280\u672f\u7ec4\u6210\u5bf9\u68c0\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08Bohra\u7b49\u3001BullyExplain\u3001BullySentemo\u3001Kumar\u7b49\u3001HASOC 2021\u3001Mendeley Indo-HateSpeech\uff09\u4e0a\uff0cMURIL\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u591a\u8bed\u6a21\u578b\uff08\u5982RoBERTa\u548cIndicBERT\uff09\uff0c\u51c6\u786e\u7387\u5206\u522b\u4e3a86.97%\u300184.62%\u300186.03%\u300175.41%\u300183.92%\u548c94.63%\uff0c\u76f8\u8f83\u4e8e\u5176\u4ed6\u6a21\u578b\u63d0\u53471.36~13.07\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "MURIL\u67b6\u6784\u5728Hinglish\u7f51\u7edc\u6b3a\u51cc\u68c0\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6548\u679c\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5f3a\u8c03\u4e86\u7279\u5b9a\u5c42\u51bb\u7ed3\u3001\u5206\u7c7b\u5934\u8bbe\u8ba1\u548c\u6df7\u5408\u6587\u672c\u9884\u5904\u7406\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u4e0a\u4e0b\u6587\u3001\u6587\u5316\u7406\u89e3\u4e0e\u8bbd\u523a\u8bc6\u522b\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.16123", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16123", "abs": "https://arxiv.org/abs/2506.16123", "authors": ["Natapong Nitarach", "Warit Sirichotedumrong", "Panop Pitchayarthorn", "Pittawat Taveekitworachai", "Potsawee Manakul", "Kunat Pipatanakul"], "title": "FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning", "comment": null, "summary": "This paper presents FinCoT, a structured chain-of-thought (CoT) prompting\napproach that incorporates insights from domain-specific expert financial\nreasoning to guide the reasoning traces of large language models. We\ninvestigate that there are three main prompting styles in FinNLP: (1) standard\nprompting--zero-shot prompting; (2) unstructured CoT--CoT prompting without an\nexplicit reasoning structure, such as the use of tags; and (3) structured CoT\nprompting--CoT prompting with explicit instructions or examples that define\nstructured reasoning steps. Previously, FinNLP has primarily focused on prompt\nengineering with either standard or unstructured CoT prompting. However,\nstructured CoT prompting has received limited attention in prior work.\nFurthermore, the design of reasoning structures in structured CoT prompting is\noften based on heuristics from non-domain experts. In this study, we\ninvestigate each prompting approach in FinNLP. We evaluate the three main\nprompting styles and FinCoT on CFA-style questions spanning ten financial\ndomains. We observe that FinCoT improves performance from 63.2% to 80.5% and\nQwen-2.5-7B-Instruct from 69.7% to 74.2%, while reducing generated tokens\neight-fold compared to structured CoT prompting. Our findings show that\ndomain-aligned structured prompts not only improve performance and reduce\ninference costs but also yield more interpretable and expert-aligned reasoning\ntraces.", "AI": {"tldr": "FinCoT\u7ed3\u5408\u91d1\u878d\u4e13\u5bb6\u63a8\u7406\u77e5\u8bc6\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91d1\u878d\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51c6\u786e\u7387\u3001\u63a8\u7406\u6548\u7387\u53ca\u89e3\u91ca\u6027\uff0c\u4f18\u4e8e\u4e3b\u6d41\u63d0\u793a\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u7ed3\u6784\u5316\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u5728\u5176\u4ed6\u9886\u57df\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u91d1\u878d\u9886\u57df\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08FinNLP\uff09\u4e3b\u8981\u4f9d\u8d56\u6807\u51c6\u6216\u975e\u7ed3\u6784\u5316CoT\u63d0\u793a\uff0c\u800c\u7ed3\u6784\u5316CoT\u63d0\u793a\u672a\u53d7\u5230\u8db3\u591f\u91cd\u89c6\uff0c\u4e14\u5176\u63a8\u7406\u7ed3\u6784\u901a\u5e38\u7531\u975e\u9886\u57df\u4e13\u5bb6\u57fa\u4e8e\u7ecf\u9a8c\u8bbe\u8ba1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\u6307\u5bfc\u4e0b\u7684\u7ed3\u6784\u5316CoT\uff0c\u5bf9\u63d0\u5347\u91d1\u878d\u4efb\u52a1\u8868\u73b0\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51faFinCoT\u65b9\u6cd5\u2014\u2014\u7ed3\u5408\u91d1\u878d\u9886\u57df\u4e13\u5bb6\u63a8\u7406\u89c1\u89e3\u7684\u7ed3\u6784\u5316\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63d0\u793a\u3002\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e09\u79cd\u4e3b\u8981\u63d0\u793a\u98ce\u683c\uff1a\u6807\u51c6\u63d0\u793a\u3001\u975e\u7ed3\u6784\u5316CoT\u3001\u7ed3\u6784\u5316CoT\uff0c\u5e76\u4ee5CFA\u98ce\u683c\u7684\u5341\u4e2a\u91d1\u878d\u5b50\u9886\u57df\u95ee\u9898\u8bc4\u4f30\u5176\u6027\u80fd\u3002FinCoT\u901a\u8fc7\u8bbe\u8ba1\u660e\u786e\u7684\u7ed3\u6784\u5316\u63a8\u7406\u6b65\u9aa4\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "FinCoT\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u753163.2%\u63d0\u5347\u523080.5%\uff0c\u5e76\u5c06Qwen-2.5-7B-Instruct\u8868\u73b0\u753169.7%\u63d0\u5347\u523074.2%\uff0c\u540c\u65f6\u751f\u6210\u7684token\u6570\u91cf\u76f8\u8f83\u4e8e\u4f20\u7edf\u7ed3\u6784\u5316CoT\u63d0\u793a\u51cf\u5c11\u4e86\u516b\u500d\u3002FinCoT\u80fd\u591f\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3001\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u5e76\u751f\u6210\u66f4\u53ef\u89e3\u91ca\u3001\u4e0e\u4e13\u5bb6\u601d\u8def\u5bf9\u9f50\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "conclusion": "\u9886\u57df\u5bf9\u9f50\u7684\u7ed3\u6784\u5316\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u80fd\u663e\u8457\u63d0\u5347\u91d1\u878d\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u63d0\u9ad8\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u4e13\u4e1a\u6027\uff0c\u4f18\u4e8e\u975e\u7ed3\u6784\u5316\u53ca\u7ecf\u9a8c\u9a71\u52a8\u7684\u7ed3\u6784\u5316CoT\u65b9\u6cd5\u3002"}}
{"id": "2506.16151", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16151", "abs": "https://arxiv.org/abs/2506.16151", "authors": ["Chenxi Wang", "Yixuan Zhang", "Lang Gao", "Zixiang Xu", "Zirui Song", "Yanbo Wang", "Xiuying Chen"], "title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs", "comment": "15 pages, 10 figures", "summary": "Language is not only a tool for communication but also a medium for human\ncognition and reasoning. If, as linguistic relativity suggests, the structure\nof language shapes cognitive patterns, then large language models (LLMs)\ntrained on human language may also internalize the habitual logical structures\nembedded in different languages. To examine this hypothesis, we introduce\nBICAUSE, a structured bilingual dataset for causal reasoning, which includes\nsemantically aligned Chinese and English samples in both forward and reversed\ncausal forms. Our study reveals three key findings: (1) LLMs exhibit\ntypologically aligned attention patterns, focusing more on causes and\nsentence-initial connectives in Chinese, while showing a more balanced\ndistribution in English. (2) Models internalize language-specific preferences\nfor causal word order and often rigidly apply them to atypical inputs, leading\nto degraded performance, especially in Chinese. (3) When causal reasoning\nsucceeds, model representations converge toward semantically aligned\nabstractions across languages, indicating a shared understanding beyond surface\nform. Overall, these results suggest that LLMs not only mimic surface\nlinguistic forms but also internalize the reasoning biases shaped by language.\nRooted in cognitive linguistic theory, this phenomenon is for the first time\nempirically verified through structural analysis of model internals.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u53cc\u8bed\u56e0\u679c\u63a8\u7406\u6570\u636e\u96c6\u5b9e\u8bc1\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u4f1a\u5185\u90e8\u5316\u8bed\u8a00\u7279\u6709\u7684\u8ba4\u77e5\u504f\u7f6e\uff0c\u9996\u6b21\u9a8c\u8bc1\u4e86\u8ba4\u77e5\u8bed\u8a00\u5b66\u7406\u8bba\u5728\u6a21\u578b\u63a8\u7406\u7ed3\u6784\u4e2d\u7684\u4f53\u73b0\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u76f8\u5bf9\u8bba\u5bf9\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u8ba4\u77e5\u4e0e\u63a8\u7406\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u63a2\u7a76LLMs\u662f\u5426\u4f1a\u5185\u90e8\u5316\u4e0d\u540c\u8bed\u8a00\u4e0b\u7684\u56e0\u679c\u63a8\u7406\u4e60\u60ef\u6027\u903b\u8f91\u7ed3\u6784\u3002", "method": "\u5f15\u5165BICAUSE\uff0c\u4e00\u4e2a\u5305\u542b\u4e2d\u82f1\u6587\u8bed\u4e49\u5bf9\u9f50\u7684\u56e0\u679c\u63a8\u7406\u7ed3\u6784\u5316\u53cc\u8bed\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6b63\u5411\u4e0e\u53cd\u5411\u56e0\u679c\u5f62\u5f0f\uff0c\u901a\u8fc7\u5206\u6790LLMs\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u7814\u7a76\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5206\u5e03\u3001\u5bf9\u56e0\u679c\u8bcd\u5e8f\u7684\u504f\u597d\u3001\u53ca\u6a21\u578b\u5185\u90e8\u8bed\u4e49\u62bd\u8c61\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "result": "\u53d1\u73b0LLMs\u8868\u73b0\u51fa\u4e0e\u8bed\u7cfb\u7c7b\u578b\u76f8\u5173\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff08\u5982\u4e2d\u6587\u5173\u6ce8\u56e0\u679c\u4e0e\u53e5\u9996\u8fde\u8bcd\uff0c\u82f1\u6587\u8f83\u5747\u8861\uff09\uff1b\u6a21\u578b\u4f1a\u5185\u90e8\u5316\u8bed\u8a00\u7279\u5b9a\u7684\u56e0\u679c\u8bcd\u5e8f\u504f\u597d\uff0c\u5bf9\u4e0d\u7b26\u5408\u504f\u597d\u7684\u8f93\u5165\u8868\u73b0\u4e0b\u964d\uff08\u4e2d\u6587\u5c24\u751a\uff09\uff1b\u6210\u529f\u63a8\u7406\u65f6\uff0c\u6a21\u578b\u5185\u90e8\u8868\u73b0\u4e3a\u8de8\u8bed\u8a00\u7684\u8bed\u4e49\u5bf9\u9f50\u62bd\u8c61\u3002", "conclusion": "LLMs\u4e0d\u4ec5\u6a21\u4eff\u8868\u5c42\u8bed\u8a00\u5f62\u5f0f\uff0c\u4e5f\u4f1a\u5185\u90e8\u5316\u8bed\u8a00\u5851\u9020\u7684\u63a8\u7406\u504f\u7f6e\u3002\u8be5\u73b0\u8c61\u9996\u6b21\u901a\u8fc7\u6a21\u578b\u7ed3\u6784\u5206\u6790\uff0c\u88ab\u8ba4\u77e5\u8bed\u8a00\u5b66\u7406\u8bba\u5b9e\u8bc1\u9a8c\u8bc1\u3002"}}
{"id": "2506.16172", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16172", "abs": "https://arxiv.org/abs/2506.16172", "authors": ["Guanhua Chen", "Yutong Yao", "Lidia S. Chao", "Xuebo Liu", "Derek F. Wong"], "title": "SGIC: A Self-Guided Iterative Calibration Framework for RAG", "comment": null, "summary": "Recent research in retrieval-augmented generation (RAG) has concentrated on\nretrieving useful information from candidate documents. However, numerous\nmethodologies frequently neglect the calibration capabilities of large language\nmodels (LLMs), which capitalize on their robust in-context reasoning prowess.\nThis work illustrates that providing LLMs with specific cues substantially\nimproves their calibration efficacy, especially in multi-round calibrations. We\npresent a new SGIC: Self-Guided Iterative Calibration Framework that employs\nuncertainty scores as a tool. Initially, this framework calculates uncertainty\nscores to determine both the relevance of each document to the query and the\nconfidence level in the responses produced by the LLMs. Subsequently, it\nreevaluates these scores iteratively, amalgamating them with prior responses to\nrefine calibration. Furthermore, we introduce an innovative approach for\nconstructing an iterative self-calibration training set, which optimizes LLMs\nto efficiently harness uncertainty scores for capturing critical information\nand enhancing response accuracy. Our proposed framework significantly improves\nperformance on both closed-source and open-weight LLMs.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86SGIC\u81ea\u5f15\u5bfc\u8fed\u4ee3\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u591a\u8f6e\u81ea\u6821\u51c6\uff0c\u6709\u6548\u63d0\u5347\u4e86RAG\u573a\u666f\u4e0b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u7c7b\u578bLLM\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u76ee\u524dRAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u4ece\u5019\u9009\u6587\u6863\u4e2d\u68c0\u7d22\u6709\u7528\u4fe1\u606f\uff0c\u8f83\u5c11\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6821\u51c6\u80fd\u529b\u3002\u800c\u826f\u597d\u7684\u6821\u51c6\u80fd\u529b\u5bf9\u4e8e\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u4e86SGIC\uff08Self-Guided Iterative Calibration\uff09\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u8ba1\u7b97\u4e0d\u786e\u5b9a\u6027\u5206\u6570\uff0c\u8bc4\u4f30\u6587\u6863\u4e0e\u67e5\u8be2\u7684\u76f8\u5173\u6027\u53caLLM\u56de\u7b54\u7684\u7f6e\u4fe1\u5ea6\u3002\u7136\u540e\u8fdb\u884c\u591a\u8f6e\u8fed\u4ee3\uff0c\u52a8\u6001\u8c03\u6574\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u5e76\u7ed3\u5408\u4e4b\u524d\u7684\u56de\u7b54\uff0c\u9010\u6b65\u4f18\u5316\u6821\u51c6\u3002\u8fd8\u8bbe\u8ba1\u4e86\u81ea\u6821\u51c6\u8bad\u7ec3\u96c6\uff0c\u4ee5\u8bad\u7ec3LLM\u9ad8\u6548\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u63d0\u5347\u56de\u7b54\u51c6\u786e\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684SGIC\u6846\u67b6\u5728\u95ed\u6e90\u548c\u5f00\u6e90\u7c7b\u578b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u53ca\u81ea\u5f15\u5bfc\u8fed\u4ee3\u6821\u51c6\u6d41\u7a0b\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728RAG\u4efb\u52a1\u4e2d\u7684\u6821\u51c6\u548c\u6574\u4f53\u8868\u73b0\u3002"}}
{"id": "2506.16187", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16187", "abs": "https://arxiv.org/abs/2506.16187", "authors": ["Masashi Takeshita", "Rafal Rzepka"], "title": "JETHICS: Japanese Ethics Understanding Evaluation Dataset", "comment": null, "summary": "In this work, we propose JETHICS, a Japanese dataset for evaluating ethics\nunderstanding of AI models. JETHICS contains 78K examples and is built by\nfollowing the construction methods of the existing English ETHICS dataset. It\nincludes four categories based normative theories and concepts from ethics and\npolitical philosophy; and one representing commonsense morality. Our evaluation\nexperiments on non-proprietary large language models (LLMs) and on GPT-4o\nreveal that even GPT-4o achieves only an average score of about 0.7, while the\nbest-performing Japanese LLM attains around 0.5, indicating a relatively large\nroom for improvement in current LLMs.", "AI": {"tldr": "\u4f5c\u8005\u6784\u5efa\u4e86\u65e5\u8bed\u7248\u7684\u4f26\u7406\u7406\u89e3\u8bc4\u4f30\u6570\u636e\u96c6JETHICS\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cd\u5927\u6a21\u578b\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u6700\u5f3a\u7684GPT-4o\u5728\u6b64\u57fa\u51c6\u4e0b\u8868\u73b0\u4e5f\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5bf9\u5176\u4f26\u7406\u7406\u89e3\u80fd\u529b\u7684\u8bc4\u4f30\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff0c\u5c24\u5176\u5728\u975e\u82f1\u8bed\u8bed\u5883\u4e2d\u7f3a\u4e4f\u76f8\u5173\u57fa\u51c6\u6570\u636e\u96c6\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u4e3a\u65e5\u8bed\u73af\u5883\u63d0\u4f9b\u7c7b\u4f3cETHICS\u7684\u6570\u636e\u96c6\u3002", "method": "\u672c\u7814\u7a76\u501f\u9274\u82f1\u8bedETHICS\u6570\u636e\u96c6\u7684\u6784\u5efa\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5e76\u5236\u4f5c\u4e86\u65e5\u8bed\u4f26\u7406\u8bc4\u4f30\u6570\u636e\u96c6JETHICS\uff0c\u6db5\u76d6\u56db\u7c7b\u57fa\u4e8e\u89c4\u8303\u4f26\u7406\u7406\u8bba\u548c\u653f\u6cbb\u54f2\u5b66\u7684\u8303\u7574\uff0c\u4ee5\u53ca\u4e00\u7c7b\u5e38\u8bc6\u9053\u5fb7\uff0c\u5171\u8ba178,000\u4e2a\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u975e\u4e13\u6709\u5927\u8bed\u8a00\u6a21\u578b\u53caGPT-4o\u5728JETHICS\u4e0a\u7684\u8868\u73b0\u90fd\u4e0d\u7406\u60f3\uff1aGPT-4o\u5e73\u5747\u5f97\u5206\u7ea60.7\uff0c\u6700\u4f18\u7684\u5f00\u6e90\u65e5\u8bedLLM\u5f97\u5206\u7ea60.5\uff0c\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u4f26\u7406\u7406\u89e3\u4e0a\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "conclusion": "JETHICS\u4e3a\u65e5\u8bed\u8bed\u5883\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u4f26\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u516c\u5f00\u57fa\u51c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u66b4\u9732\u51fa\u73b0\u6709\u6a21\u578b\u5728\u4f26\u7406\u7406\u89e3\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u4eca\u540e\u6a21\u578b\u6539\u8fdb\u548c\u4f26\u7406\u8bc4\u4f30\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2506.16190", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16190", "abs": "https://arxiv.org/abs/2506.16190", "authors": ["Luna Wang", "Andrew Caines", "Alice Hutchings"], "title": "Web(er) of Hate: A Survey on How Hate Speech Is Typed", "comment": null, "summary": "The curation of hate speech datasets involves complex design decisions that\nbalance competing priorities. This paper critically examines these\nmethodological choices in a diverse range of datasets, highlighting common\nthemes and practices, and their implications for dataset reliability. Drawing\non Max Weber's notion of ideal types, we argue for a reflexive approach in\ndataset creation, urging researchers to acknowledge their own value judgments\nduring dataset construction, fostering transparency and methodological rigour.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u5206\u6790\u4e86\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u6784\u5efa\u4e2d\u7684\u65b9\u6cd5\u9009\u62e9\u53ca\u5176\u5bf9\u6570\u636e\u96c6\u53ef\u9760\u6027\u7684\u5f71\u54cd\uff0c\u547c\u5401\u7814\u7a76\u8005\u5728\u6570\u636e\u96c6\u521b\u5efa\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u53cd\u601d\u548c\u900f\u660e\u3002", "motivation": "\u5f53\u524d\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u7684\u6784\u5efa\u6d89\u53ca\u590d\u6742\u7684\u8bbe\u8ba1\u51b3\u7b56\uff0c\u9700\u8981\u5728\u591a\u4e2a\u76f8\u4e92\u51b2\u7a81\u7684\u4f18\u5148\u4e8b\u9879\u4e4b\u95f4\u8fdb\u884c\u5e73\u8861\uff0c\u5f71\u54cd\u6570\u636e\u96c6\u7684\u53ef\u9760\u6027\u3002", "method": "\u6279\u5224\u6027\u5206\u6790\u4e86\u591a\u6837\u5316\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u7684\u6784\u5efa\u65b9\u6cd5\uff0c\u501f\u52a9\u793e\u4f1a\u5b66\u5bb6\u9a6c\u514b\u65af\u00b7\u97e6\u4f2f\u7684\u201c\u7406\u60f3\u7c7b\u578b\u201d\u7406\u8bba\u6846\u67b6\u8fdb\u884c\u7406\u8bba\u652f\u6491\u3002", "result": "\u603b\u7ed3\u4e86\u76f8\u5173\u6570\u636e\u96c6\u6784\u5efa\u4e2d\u5e38\u89c1\u7684\u4e3b\u9898\u548c\u5b9e\u8df5\uff0c\u5bf9\u5176\u5bf9\u6570\u636e\u96c6\u53ef\u9760\u6027\u7684\u5f71\u54cd\u8fdb\u884c\u4e86\u8ba8\u8bba\u3002\u63d0\u51fa\u5efa\u8bae\u4fe1\uff1a\u6570\u636e\u96c6\u6784\u5efa\u8005\u9700\u53cd\u601d\u81ea\u8eab\u4ef7\u503c\u5224\u65ad\uff0c\u5e76\u5728\u6574\u4e2a\u8fc7\u7a0b\u4fdd\u6301\u900f\u660e\u4e0e\u4e25\u8c28\u3002", "conclusion": "\u4e3b\u5f20\u5728\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u6784\u5efa\u4e2d\u91c7\u53d6\u53cd\u601d\u6027\u65b9\u6cd5\uff0c\u7814\u7a76\u4eba\u5458\u5e94\u4e3b\u52a8\u62ab\u9732\u4e2a\u4eba\u4ef7\u503c\u7acb\u573a\uff0c\u4ee5\u589e\u5f3a\u6570\u636e\u96c6\u7684\u900f\u660e\u5ea6\u4e0e\u65b9\u6cd5\u5b66\u4e2d\u7684\u4e25\u8c28\u6027\u3002"}}
{"id": "2506.16247", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16247", "abs": "https://arxiv.org/abs/2506.16247", "authors": ["Anindita Bhattacharya", "Tohida Rehman", "Debarshi Kumar Sanyal", "Samiran Chattopadhyay"], "title": "Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports", "comment": "14 pages, 2 figures, 6 tables", "summary": "The findings section of a radiology report is often detailed and lengthy,\nwhereas the impression section is comparatively more compact and captures key\ndiagnostic conclusions. This research explores the use of advanced abstractive\nsummarization models to generate the concise impression from the findings\nsection of a radiology report. We have used the publicly available MIMIC-CXR\ndataset. A comparative analysis is conducted on leading pre-trained and\nopen-source large language models, including T5-base, BART-base,\nPEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network\nwith a coverage mechanism. To ensure a thorough assessment, multiple evaluation\nmetrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and\nBERTScore. By analyzing the performance of these models, this study identifies\ntheir respective strengths and limitations in the summarization of medical\ntext. The findings of this paper provide helpful information for medical\nprofessionals who need automated summarization solutions in the healthcare\nsector.", "AI": {"tldr": "\u672c\u8bba\u6587\u6bd4\u8f83\u4e86\u591a\u79cd\u81ea\u52a8\u6458\u8981\u6a21\u578b\u5728\u653e\u5c04\u5b66\u62a5\u544a\u7b80\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u603b\u7ed3\u4e86\u5404\u6a21\u578b\u7684\u4f18\u52a3\uff0c\u5bf9\u533b\u7597\u81ea\u52a8\u6458\u8981\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u57fa\u7840\u3002", "motivation": "\u653e\u5c04\u5b66\u62a5\u544a\u7684Findings\u90e8\u5206\u5185\u5bb9\u8be6\u5c3d\u5197\u957f\uff0c\u800cImpression\u90e8\u5206\u5219\u7b80\u6d01\u660e\u4e86\u5730\u603b\u7ed3\u4e86\u8bca\u65ad\u7ed3\u8bba\uff0c\u56e0\u800c\u63a2\u7a76\u5982\u4f55\u5229\u7528\u6458\u8981\u6a21\u578b\u81ea\u52a8\u4eceFindings\u751f\u6210\u9ad8\u8d28\u91cf\u7684Impression\u5bf9\u4e8e\u533b\u7597\u5de5\u4f5c\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u53ef\u5927\u5927\u63d0\u9ad8\u4e34\u5e8a\u6548\u7387\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528\u516c\u5f00\u7684MIMIC-CXR\u6570\u636e\u96c6\uff0c\u5bf9\u591a\u79cd\u5148\u8fdb\u7684\u62bd\u8c61\u5f0f\u81ea\u52a8\u6587\u6458\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u5305\u62ecT5-base\u3001BART-base\u3001PEGASUS-x-base\u3001ChatGPT-4\u3001LLaMA-3-8B\u548c\u81ea\u884c\u8bad\u7ec3\u7684Pointer Generator Network\uff08\u5e26\u8986\u76d6\u673a\u5236\uff09\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u8bc4\u4ef7\u6307\u6807\u5982ROUGE-1/2/L\u3001METEOR\u3001BERTScore\u5bf9\u8868\u73b0\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u5206\u6790\u4e86\u591a\u79cd\u9884\u8bad\u7ec3\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u6587\u672c\u81ea\u52a8\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u8fa8\u8bc6\u51fa\u5404\u6a21\u578b\u5728\u6458\u8981\u7cbe\u51c6\u6027\u548c\u8868\u73b0\u4e0a\u7684\u4f18\u7f3a\u70b9\u3002\u5177\u4f53\u7ed3\u679c\u672a\u5728\u6458\u8981\u4e2d\u8be6\u8ff0\uff0c\u4f46\u8868\u660e\u5728\u533b\u7597\u81ea\u52a8\u6458\u8981\u9886\u57df\u80fd\u4e3a\u6a21\u578b\u9009\u62e9\u548c\u5e94\u7528\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u533b\u7597\u9886\u57df\u81ea\u52a8\u6587\u6458\u4efb\u52a1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u6a21\u578b\u5bf9\u6bd4\u53ca\u8bc4\u6d4b\u7ed3\u8bba\uff0c\u5bf9\u533b\u7597\u4e13\u4e1a\u4eba\u58eb\u9009\u62e9\u81ea\u52a8\u6458\u8981\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u4e0e\u6307\u5bfc\u3002"}}
{"id": "2506.16251", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16251", "abs": "https://arxiv.org/abs/2506.16251", "authors": ["Aishwarya Pothula", "Bhavana Akkiraju", "Srihari Bandarupalli", "Charan D", "Santosh Kesiraju", "Anil Kumar Vuppala"], "title": "End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data", "comment": null, "summary": "The scarcity of high-quality annotated data presents a significant challenge\nin developing effective end-to-end speech-to-text translation (ST) systems,\nparticularly for low-resource languages. This paper explores the hypothesis\nthat weakly labeled data can be used to build ST models for low-resource\nlanguage pairs. We constructed speech-to-text translation datasets with the\nhelp of bitext mining using state-of-the-art sentence encoders. We mined the\nmultilingual Shrutilipi corpus to build Shrutilipi-anuvaad, a dataset\ncomprising ST data for language pairs Bengali-Hindi, Malayalam-Hindi,\nOdia-Hindi, and Telugu-Hindi. We created multiple versions of training data\nwith varying degrees of quality and quantity to investigate the effect of\nquality versus quantity of weakly labeled data on ST model performance. Results\ndemonstrate that ST systems can be built using weakly labeled data, with\nperformance comparable to massive multi-modal multilingual baselines such as\nSONAR and SeamlessM4T.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5f31\u6807\u6ce8\u6570\u636e\uff0c\u7ed3\u5408\u53cc\u8bed\u6316\u6398\u6280\u672f\uff0c\u6784\u5efa\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u97f3\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u5e76\u8bc1\u5b9e\u5176\u80fd\u8fbe\u5230\u4e0e\u4e3b\u6d41\u591a\u8bed\u79cd\u7cfb\u7edf\u76f8\u5f53\u7684\u6548\u679c\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u6709\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u97f3\u5230\u6587\u672c\u7ffb\u8bd1\u7cfb\u7edf\u5f00\u53d1\u4e2d\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u5229\u7528\u6700\u5148\u8fdb\u7684\u53e5\u5b50\u7f16\u7801\u5668\u8fdb\u884c\u53cc\u8bed\u6587\u672c\u6316\u6398\uff0c\u4ece\u591a\u8bed\u79cdShrutilipi\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u6570\u636e\uff0c\u6784\u5efa\u4e86Shrutilipi-anuvaad\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u4e0d\u540c\u8d28\u91cf\u548c\u6570\u91cf\u7684\u7248\u672c\u5b9e\u9a8c\u3002", "result": "\u7528\u5f31\u6807\u6ce8\u6570\u636e\u8bad\u7ec3\u7684ST\u7cfb\u7edf\u6027\u80fd\u53ef\u4ee5\u4e0eSONAR\u548cSeamlessM4T\u7b49\u5927\u89c4\u6a21\u591a\u6a21\u6001\u591a\u8bed\u79cd\u57fa\u7ebf\u7cfb\u7edf\u5ab2\u7f8e\u3002", "conclusion": "\u5f31\u6807\u6ce8\u6570\u636e\u53ef\u6709\u6548\u7528\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u8bed\u97f3\u5230\u6587\u672c\u7ffb\u8bd1\u6a21\u578b\uff0c\u5176\u6027\u80fd\u53ef\u8fbe\u5230\u4e3b\u6d41\u591a\u8bed\u79cd\u7cfb\u7edf\u7684\u6c34\u5e73\u3002"}}
{"id": "2506.16285", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16285", "abs": "https://arxiv.org/abs/2506.16285", "authors": ["Hao-Chien Lu", "Jhen-Ke Lin", "Hong-Yun Lin", "Chung-Chun Wang", "Berlin Chen"], "title": "Advancing Automated Speaking Assessment Leveraging Multifaceted Relevance and Grammar Information", "comment": "submitted to the ISCA SLaTE-2025 Workshop", "summary": "Current automated speaking assessment (ASA) systems for use in multi-aspect\nevaluations often fail to make full use of content relevance, overlooking image\nor exemplar cues, and employ superficial grammar analysis that lacks detailed\nerror types. This paper ameliorates these deficiencies by introducing two novel\nenhancements to construct a hybrid scoring model. First, a multifaceted\nrelevance module integrates question and the associated image content,\nexemplar, and spoken response of an L2 speaker for a comprehensive assessment\nof content relevance. Second, fine-grained grammar error features are derived\nusing advanced grammar error correction (GEC) and detailed annotation to\nidentify specific error categories. Experiments and ablation studies\ndemonstrate that these components significantly improve the evaluation of\ncontent relevance, language use, and overall ASA performance, highlighting the\nbenefits of using richer, more nuanced feature sets for holistic speaking\nassessment.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u52a0\u5165\u591a\u6e90\u5185\u5bb9\u76f8\u5173\u6027\u5206\u6790\u548c\u7cbe\u7ec6\u8bed\u6cd5\u9519\u8bef\u68c0\u6d4b\uff0c\u660e\u663e\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u53e3\u8bed\u8bc4\u4f30\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u53e3\u8bed\u8bc4\u4f30\u7cfb\u7edf\u5728\u591a\u65b9\u9762\u8bc4\u4ef7\u65f6\uff0c\u901a\u5e38\u672a\u80fd\u5145\u5206\u5229\u7528\u5185\u5bb9\u76f8\u5173\u6027\uff0c\u5ffd\u89c6\u4e86\u56fe\u50cf\u6216\u8303\u4f8b\u7ebf\u7d22\uff0c\u5e76\u4e14\u5bf9\u4e8e\u8bed\u6cd5\u9519\u8bef\u7684\u5206\u6790\u8fc7\u4e8e\u8868\u9762\uff0c\u7f3a\u4e4f\u8be6\u7ec6\u7684\u9519\u8bef\u7c7b\u578b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e24\u9879\u521b\u65b0\u6539\u8fdb\uff0c\u6784\u5efa\u4e00\u4e2a\u6df7\u5408\u8bc4\u5206\u6a21\u578b\uff1a\uff081\uff09\u591a\u65b9\u9762\u76f8\u5173\u6027\u6a21\u5757\uff0c\u7efc\u5408\u95ee\u9898\u3001\u76f8\u5173\u56fe\u50cf\u3001\u8303\u4f8b\u548cL2\u8bf4\u8bdd\u8005\u7684\u53e3\u8bed\u56de\u7b54\u5bf9\u5185\u5bb9\u76f8\u5173\u6027\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff1b\uff082\uff09\u5229\u7528\u5148\u8fdb\u7684\u8bed\u6cd5\u7ea0\u9519\u6280\u672f\u548c\u8be6\u7ec6\u6807\u6ce8\u63d0\u53d6\u7ec6\u7c92\u5ea6\u8bed\u6cd5\u9519\u8bef\u7279\u5f81\uff0c\u8bc6\u522b\u5177\u4f53\u9519\u8bef\u7c7b\u522b\u3002", "result": "\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u65b0\u5f15\u5165\u7684\u7ec4\u4ef6\u663e\u8457\u63d0\u5347\u4e86\u5185\u5bb9\u76f8\u5173\u6027\u3001\u8bed\u8a00\u4f7f\u7528\u548c\u6574\u4f53\u81ea\u52a8\u5316\u53e3\u8bed\u8bc4\u4f30\u7684\u6548\u679c\u3002", "conclusion": "\u5f15\u5165\u66f4\u52a0\u4e30\u5bcc\u548c\u7ec6\u81f4\u7684\u7279\u5f81\u96c6\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u5168\u9762\u3001\u7cbe\u51c6\u7684\u53e3\u8bed\u8bc4\u4f30\u3002"}}
{"id": "2506.16322", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.16322", "abs": "https://arxiv.org/abs/2506.16322", "authors": ["Aleksandra Krasnod\u0119bska", "Karolina Seweryn", "Szymon \u0141ukasik", "Wojciech Kusa"], "title": "PL-Guard: Benchmarking Language Model Safety for Polish", "comment": "Accepted to the 10th Workshop on Slavic Natural Language Processing", "summary": "Despite increasing efforts to ensure the safety of large language models\n(LLMs), most existing safety assessments and moderation tools remain heavily\nbiased toward English and other high-resource languages, leaving majority of\nglobal languages underexamined. To address this gap, we introduce a manually\nannotated benchmark dataset for language model safety classification in Polish.\nWe also create adversarially perturbed variants of these samples designed to\nchallenge model robustness. We conduct a series of experiments to evaluate\nLLM-based and classifier-based models of varying sizes and architectures.\nSpecifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based\nclassifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B\nmodel. We train these models using different combinations of annotated data and\nevaluate their performance, comparing it against publicly available guard\nmodels. Results demonstrate that the HerBERT-based classifier achieves the\nhighest overall performance, particularly under adversarial conditions.", "AI": {"tldr": "\u4f5c\u8005\u9488\u5bf9LLM\u5b89\u5168\u6027\u5728\u6ce2\u5170\u8bed\u573a\u666f\u4e0b\u8bc4\u4f30\u8584\u5f31\u7684\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u624b\u52a8\u6807\u6ce8\u4e14\u5e26\u5bf9\u6297\u6270\u52a8\u7684\u6570\u636e\u96c6\uff0c\u5e76\u6d4b\u8bd5\u591a\u79cd\u5206\u7c7b\u6a21\u578b\u3002\u7ed3\u679c\u8868\u660e\uff0cHerBERT\u6ce2\u5170\u8bed\u5206\u7c7b\u5668\u5728\u5b89\u5168\u6027\u80fd\u4e0a\u4f18\u4e8e\u540c\u7c7b\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u76ee\u524d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u591a\u96c6\u4e2d\u4e8e\u82f1\u8bed\u7b49\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u7edd\u5927\u591a\u6570\u5176\u4ed6\u8bed\u8a00\uff08\u5982\u6ce2\u5170\u8bed\uff09\u7f3a\u4e4f\u6709\u9488\u5bf9\u6027\u7684\u7814\u7a76\u548c\u5de5\u5177\u3002\u4e3a\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u6539\u5584\u6ce2\u5170\u8bed\u73af\u5883\u4e0bLLM\u7684\u5b89\u5168\u8bc4\u4f30\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u624b\u52a8\u6807\u6ce8\u4e86\u6ce2\u5170\u8bed\u5b89\u5168\u6587\u672c\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u5236\u4f5c\u4e86\u7ecf\u8fc7\u5bf9\u6297\u6027\u6270\u52a8\u7684\u6d4b\u8bd5\u6837\u672c\uff0c\u589e\u5f3a\u8bc4\u4f30\u96be\u5ea6\u3002\u968f\u540e\uff0c\u4f5c\u8005\u5bf9\u5305\u62ecLlama-Guard-3-8B\u3001\u57fa\u4e8eHerBERT\uff08\u6ce2\u5170\u8bedBERT\u53d8\u4f53\uff09\u7684\u5206\u7c7b\u5668\u3001\u4ee5\u53caPLLuM\uff08\u6ce2\u5170\u5316\u7684Llama-8B\uff09\u5728\u5185\u7684\u4e09\u79cd\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u5206\u522b\u5728\u4e0d\u540c\u7ec4\u5408\u7684\u6570\u636e\u4e0b\u8bad\u7ec3\uff0c\u5e76\u540c\u4e3b\u6d41\u516c\u5171\u5b89\u5168\u6a21\u578b\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8eHerBERT\u7684\u5206\u7c7b\u5668\u5728\u603b\u4f53\u6027\u80fd\u4e0a\u6700\u4f73\uff0c\u5c24\u5176\u5728\u5bf9\u6297\u6027\u6d4b\u8bd5\u6761\u4ef6\u4e0b\u8868\u73b0\u7a81\u51fa\u3002\u5176\u4ed6\u6a21\u578b\u4e5f\u6709\u6240\u63d0\u5347\uff0c\u4f46HerBERT\u8868\u73b0\u6700\u7a33\u5b9a\u3002", "conclusion": "\u6ce2\u5170\u8bed\u5b89\u5168\u8bc4\u6d4b\u9886\u57df\u7f3a\u4e4f\u6709\u6548\u5de5\u5177\uff0c\u624b\u52a8\u6807\u6ce8\u6570\u636e\u96c6\u4e0e\u5bf9\u6297\u6027\u6d4b\u8bd5\u7ed3\u5408\u63d0\u5347\u4e86\u8bc4\u4ef7\u51c6\u786e\u6027\u3002\u57fa\u4e8eHerBERT\u7684\u5206\u7c7b\u5668\u5728\u6ce2\u5170\u8bedLLM\u5b89\u5168\u6027\u68c0\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5f53\u524d\u53d1\u5e03\u7684\u9632\u62a4\u6a21\u578b\uff0c\u5177\u6709\u66f4\u597d\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.16337", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16337", "abs": "https://arxiv.org/abs/2506.16337", "authors": ["Agnese Daffara", "Sourabh Dattawad", "Sebastian Pad\u00f3", "Tanise Ceron"], "title": "Generalizability of Media Frames: Corpus creation and analysis across countries", "comment": "8 pages + References (3 pages) and Appendix (4 pages). This paper was\n  submitted to StarSem 2025 and is currently under review", "summary": "Frames capture aspects of an issue that are emphasized in a debate by\ninterlocutors and can help us understand how political language conveys\ndifferent perspectives and ultimately shapes people's opinions. The Media Frame\nCorpus (MFC) is the most commonly used framework with categories and detailed\nguidelines for operationalizing frames. It is, however, focused on a few\nsalient U.S. news issues, making it unclear how well these frames can capture\nnews issues in other cultural contexts. To explore this, we introduce\nFrameNews-PT, a dataset of Brazilian Portuguese news articles covering\npolitical and economic news and annotate it within the MFC framework. Through\nseveral annotation rounds, we evaluate the extent to which MFC frames\ngeneralize to the Brazilian debate issues. We further evaluate how fine-tuned\nand zero-shot models perform on out-of-domain data. Results show that the 15\nMFC frames remain broadly applicable with minor revisions of the guidelines.\nHowever, some MFC frames are rarely used, and novel news issues are analyzed\nusing general 'fall-back' frames. We conclude that cross-cultural frame use\nrequires careful consideration.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u5df4\u897f\u8461\u8bed\u65b0\u95fb\u6570\u636e\u96c6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7f8e\u5f0f\u5a92\u4f53\u6846\u67b6\uff08MFC\uff09\u5728\u8de8\u6587\u5316\u80cc\u666f\u7684\u9002\u7528\u6027\u3002\u7ed3\u679c\u663e\u793aMFC\u6846\u67b6\u5927\u81f4\u53ef\u7528\uff0c\u4f46\u90e8\u5206\u9700\u7ec6\u5fae\u8c03\u6574\uff0c\u5e94\u5173\u6ce8\u65b0\u8bae\u9898\u4e0b\u7684\u901a\u7528\u5206\u7c7b\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u7684\u5a92\u4f53\u6846\u67b6\uff08Media Frame Corpus, MFC\uff09\u4e3b\u8981\u805a\u7126\u4e8e\u7f8e\u56fd\u7684\u65b0\u95fb\u8bae\u9898\uff0c\u5176\u5206\u7c7b\u548c\u64cd\u4f5c\u6307\u5357\u672a\u5fc5\u9002\u7528\u4e8e\u5176\u4ed6\u6587\u5316\u80cc\u666f\u4e0b\u7684\u5a92\u4f53\u62a5\u9053\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76MFC\u6846\u67b6\u5728\u5df4\u897f\u8461\u8404\u7259\u8bed\u65b0\u95fb\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u8461\u8bed\u65b0\u95fb\u6570\u636e\u96c6\uff08FrameNews-PT\uff09\uff0c\u6db5\u76d6\u5df4\u897f\u653f\u6cbb\u548c\u7ecf\u6d4e\u65b0\u95fb\uff0c\u5e76\u91c7\u7528MFC\u6846\u67b6\u8fdb\u884c\u4e86\u591a\u8f6e\u6807\u6ce8\u3002\u901a\u8fc7\u4eba\u5de5\u6ce8\u91ca\u548c\u6a21\u578b\u6d4b\u8bd5\uff08\u5305\u62ec\u5fae\u8c03\u53ca\u96f6\u6837\u672c\u6a21\u578b\uff09\u8bc4\u4f30MFC\u6846\u67b6\u5728\u4e0d\u540c\u6587\u5316\u4e0e\u8bae\u9898\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "MFC\u768415\u79cd\u6846\u67b6\u5728\u5df4\u897f\u80cc\u666f\u4e0b\u5927\u4f53\u9002\u7528\uff0c\u53ea\u9700\u5bf9\u6307\u5357\u505a\u7ec6\u5fae\u8c03\u6574\u3002\u4f46\u90e8\u5206\u6846\u67b6\u4f7f\u7528\u8f83\u5c11\uff0c\u9047\u5230\u65b0\u9896\u8bae\u9898\u65f6\u5219\u591a\u7528\u5230\u201c\u515c\u5e95\u5f0f\u201d\u901a\u7528\u6846\u67b6\u3002", "conclusion": "MFC\u6846\u67b6\u5177\u6709\u8de8\u6587\u5316\u7684\u9002\u7528\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u65f6\u4ecd\u9700\u9488\u5bf9\u5177\u4f53\u8bed\u5883\u505a\u51fa\u5ba1\u614e\u8c03\u6574\uff0c\u4ee5\u786e\u4fdd\u5bf9\u65b0\u8bae\u9898\u7684\u6709\u6548\u8986\u76d6\u3002"}}
{"id": "2506.16343", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.16343", "abs": "https://arxiv.org/abs/2506.16343", "authors": ["Cedric M\u00f6ller", "Ricardo Usbeck"], "title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction", "comment": null, "summary": "We examine the impact of incorporating knowledge graph information on the\nperformance of relation extraction models across a range of datasets. Our\nhypothesis is that the positions of entities within a knowledge graph provide\nimportant insights for relation extraction tasks. We conduct experiments on\nmultiple datasets, each varying in the number of relations, training examples,\nand underlying knowledge graphs. Our results demonstrate that integrating\nknowledge graph information significantly enhances performance, especially when\ndealing with an imbalance in the number of training examples for each relation.\nWe evaluate the contribution of knowledge graph-based features by combining\nestablished relation extraction methods with graph-aware Neural Bellman-Ford\nnetworks. These features are tested in both supervised and zero-shot settings,\ndemonstrating consistent performance improvements across various datasets.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u5c06\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u878d\u5165\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\uff0c\u80fd\u663e\u8457\u6539\u5584\u5728\u6570\u636e\u4e0d\u5747\u8861\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u4e86\u8de8\u6570\u636e\u96c6\u548c\u4e0d\u540c\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u7684\u7a33\u5b9a\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u5173\u7cfb\u62bd\u53d6\u65b9\u6cd5\u5728\u8bad\u7ec3\u6837\u672c\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u4f5c\u8005\u5047\u8bbe\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b9e\u4f53\u7684\u56fe\u7ed3\u6784\u4f4d\u7f6e\u6709\u52a9\u4e8e\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u3002", "method": "\u5c06\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u4f4d\u7f6e\u4fe1\u606f\u4f5c\u4e3a\u7279\u5f81\uff0c\u901a\u8fc7\u56fe\u611f\u77e5\u578b\u795e\u7ecfBellman-Ford\u7f51\u7edc\uff0c\u4e0e\u5df2\u6709\u5173\u7cfb\u62bd\u53d6\u65b9\u6cd5\u7ed3\u5408\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5e76\u5728\u6709\u76d1\u7763\u548c\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5f15\u5165\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u7279\u5f81\u53ef\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u6301\u7eed\u63d0\u5347\u5173\u7cfb\u62bd\u53d6\u6027\u80fd\u3002", "conclusion": "\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4fe1\u606f\u80fd\u663e\u8457\u63d0\u5347\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u5404\u5173\u7cfb\u7c7b\u522b\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u4e0d\u5e73\u8861\u65f6\u6548\u679c\u66f4\u660e\u663e\u3002"}}
{"id": "2506.16348", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16348", "abs": "https://arxiv.org/abs/2506.16348", "authors": ["Cedric M\u00f6ller", "Ricardo Usbeck"], "title": "DISCIE -- Discriminative Closed Information Extraction", "comment": null, "summary": "This paper introduces a novel method for closed information extraction. The\nmethod employs a discriminative approach that incorporates type and\nentity-specific information to improve relation extraction accuracy,\nparticularly benefiting long-tail relations. Notably, this method demonstrates\nsuperior performance compared to state-of-the-art end-to-end generative models.\nThis is especially evident for the problem of large-scale closed information\nextraction where we are confronted with millions of entities and hundreds of\nrelations. Furthermore, we emphasize the efficiency aspect by leveraging\nsmaller models. In particular, the integration of type-information proves\ninstrumental in achieving performance levels on par with or surpassing those of\na larger generative model. This advancement holds promise for more accurate and\nefficient information extraction techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u7c7b\u578b\u548c\u5b9e\u4f53\u4fe1\u606f\u7684\u5224\u522b\u5f0f\u95ed\u96c6\u5408\u4fe1\u606f\u62bd\u53d6\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u4e24\u65b9\u9762\u5747\u8d85\u8fc7\u73b0\u6709\u751f\u6210\u5f0f\u6a21\u578b\uff0c\u5c24\u5176\u9002\u5408\u5927\u89c4\u6a21\u5b9e\u4f53\u548c\u5173\u7cfb\u62bd\u53d6\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u95ed\u96c6\u5408\u4fe1\u606f\u62bd\u53d6\u65b9\u6cd5\u5728\u5904\u7406\u6d77\u91cf\u5b9e\u4f53\u548c\u591a\u79cd\u5173\u7cfb\u65f6\uff0c\u5c24\u5176\u9762\u5bf9\u957f\u5c3e\u5173\u7cfb\u65f6\u8868\u73b0\u6709\u9650\u3002\u5927\u6a21\u578b\u5c3d\u7ba1\u6548\u679c\u597d\uff0c\u4f46\u63a8\u7406\u6548\u7387\u548c\u8d44\u6e90\u6d88\u8017\u9ad8\uff0c\u5b58\u5728\u73b0\u5b9e\u5e94\u7528\u7684\u74f6\u9888\u3002\u8be5\u7814\u7a76\u65e8\u5728\u6539\u8fdb\u5173\u7cfb\u62bd\u53d6\u7684\u51c6\u786e\u7387\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5224\u522b\u5f0f\u95ed\u96c6\u5408\u4fe1\u606f\u62bd\u53d6\u65b0\u65b9\u6cd5\uff0c\u65b9\u6cd5\u878d\u5408\u4e86\u7c7b\u578b\u4fe1\u606f\u548c\u5b9e\u4f53\u7279\u5b9a\u4fe1\u606f\uff0c\u91cd\u70b9\u63d0\u5347\u4e86\u957f\u5c3e\u5173\u7cfb\u7684\u62bd\u53d6\u8868\u73b0\u3002\u540c\u65f6\uff0c\u91c7\u7528\u5c0f\u6a21\u578b\u4ee5\u63d0\u5347\u6548\u7387\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u95ed\u96c6\u5408\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4e2d\uff08\u6db5\u76d6\u767e\u4e07\u5b9e\u4f53\u548c\u4e0a\u767e\u5173\u7cfb\uff09\u8868\u73b0\u4f18\u5f02\uff0c\u51c6\u786e\u7387\u8d85\u8fc7\u73b0\u6709\u4e3b\u6d41\u7684\u7aef\u5230\u7aef\u751f\u6210\u5f0f\u6a21\u578b\u3002\u7ed3\u5408\u7c7b\u578b\u4fe1\u606f\u5c24\u5176\u80fd\u8ba9\u5c0f\u6a21\u578b\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u5927\u6a21\u578b\u7684\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u95ed\u96c6\u5408\u4fe1\u606f\u62bd\u53d6\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u9002\u5408\u5927\u89c4\u6a21\u5e94\u7528\u573a\u666f\uff0c\u662f\u6bd4\u5f53\u524d\u751f\u6210\u5f0f\u65b9\u6cd5\u66f4\u4f18\u7684\u9009\u62e9\u3002"}}
{"id": "2506.16370", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16370", "abs": "https://arxiv.org/abs/2506.16370", "authors": ["Iwan Williams"], "title": "Can structural correspondences ground real world representational content in Large Language Models?", "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4 produce compelling responses to a\nwide range of prompts. But their representational capacities are uncertain.\nMany LLMs have no direct contact with extra-linguistic reality: their inputs,\noutputs and training data consist solely of text, raising the questions (1) can\nLLMs represent anything and (2) if so, what? In this paper, I explore what it\nwould take to answer these questions according to a structural-correspondence\nbased account of representation, and make an initial survey of this evidence. I\nargue that the mere existence of structural correspondences between LLMs and\nworldly entities is insufficient to ground representation of those entities.\nHowever, if these structural correspondences play an appropriate role - they\nare exploited in a way that explains successful task performance - then they\ncould ground real world contents. This requires overcoming a challenge: the\ntext-boundedness of LLMs appears, on the face of it, to prevent them engaging\nin the right sorts of tasks.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u5f81\u80fd\u529b\u95ee\u9898\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u4ec5\u6709\u7ed3\u6784\u5bf9\u5e94\u6027\u4e0d\u591f\uff0c\u53ea\u6709\u5f53\u8fd9\u79cd\u7ed3\u6784\u88ab\u5b9e\u9645\u7528\u4e8e\u89e3\u91ca\u4efb\u52a1\u8868\u73b0\u65f6\uff0cLLMs\u624d\u80fd\u7b97\u5177\u6709\u73b0\u5b9e\u4e16\u754c\u8868\u5f81\uff0c\u4f46\u6587\u672c\u9650\u5236\u963b\u788d\u4e86\u8fd9\u4e00\u76ee\u6807\u7684\u5b9e\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982GPT-4\u867d\u7136\u80fd\u591f\u751f\u6210\u5404\u79cd\u6709\u8bf4\u670d\u529b\u7684\u6587\u672c\uff0c\u4f46\u5176\u8868\u5f81\u73b0\u5b9e\u4e16\u754c\u80fd\u529b\u5b58\u5728\u4e89\u8bae\u3002\u7531\u4e8eLLMs\u4ec5\u4ee5\u6587\u672c\u6570\u636e\u4e3a\u8f93\u5165\u4e0e\u8f93\u51fa\uff0c\u4f5c\u8005\u63d0\u51fa\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1aLLMs\u662f\u5426\u5177\u5907\u8868\u5f81\u80fd\u529b\uff1f\u5982\u679c\u6709\uff0c\u8fd9\u79cd\u8868\u5f81\u7a76\u7adf\u662f\u4ec0\u4e48\uff1f", "method": "\u4f5c\u8005\u91c7\u7528\u57fa\u4e8e\u7ed3\u6784\u5bf9\u5e94\u6027\u7684\u8868\u5f81\u7406\u8bba\uff0c\u5206\u6790LLMs\u662f\u5426\u53ca\u5982\u4f55\u5177\u5907\u4e16\u754c\u5b9e\u4f53\u7684\u8868\u5f81\u80fd\u529b\uff0c\u5e76\u521d\u6b65\u68b3\u7406\u4e86\u76f8\u5173\u8bc1\u636e\u3002", "result": "\u4f5c\u8005\u8ba4\u4e3a\uff1a\u4ec5\u51edLLMs\u4e0e\u4e16\u754c\u5b9e\u4f53\u4e4b\u95f4\u5b58\u5728\u7684\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u4e0d\u8db3\u4ee5\u8bf4\u660e\u62e5\u6709\u5b9e\u4f53\u8868\u5f81\u80fd\u529b\u3002\u53ea\u6709\u5f53\u8fd9\u4e9b\u7ed3\u6784\u5bf9\u5e94\u6027\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u88ab\u6709\u6548\u5229\u7528\u3001\u80fd\u89e3\u91ca\u6210\u529f\u5b8c\u6210\u4efb\u52a1\u65f6\uff0cLLMs\u624d\u53ef\u80fd\u771f\u6b63\u83b7\u5f97\u73b0\u5b9e\u4e16\u754c\u5185\u5bb9\u7684\u8868\u5f81\u3002", "conclusion": "\u8981\u4f7fLLMs\u5728\u7406\u8bba\u4e0a\u5177\u5907\u73b0\u5b9e\u4e16\u754c\u8868\u5f81\uff0c\u9700\u89e3\u51b3LLMs\u201c\u6587\u672c\u8fb9\u754c\u6027\u201d\u5bfc\u81f4\u65e0\u6cd5\u6267\u884c\u67d0\u4e9b\u4efb\u52a1\u7684\u96be\u9898\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5355\u7eaf\u4f9d\u9760\u6587\u672c\u4fe1\u606f\uff0cLLMs\u96be\u4ee5\u771f\u6b63\u5177\u5907\u5168\u9762\u7684\u73b0\u5b9e\u4e16\u754c\u8868\u5f81\u80fd\u529b\u3002"}}
{"id": "2506.16381", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16381", "abs": "https://arxiv.org/abs/2506.16381", "authors": ["Kexin Huang", "Qian Tu", "Liwei Fan", "Chenchen Yang", "Dong Zhang", "Shimin Li", "Zhaoye Fei", "Qinyuan Cheng", "Xipeng Qiu"], "title": "InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems", "comment": "19 pages, 9 figures", "summary": "In modern speech synthesis, paralinguistic information--such as a speaker's\nvocal timbre, emotional state, and dynamic prosody--plays a critical role in\nconveying nuance beyond mere semantics. Traditional Text-to-Speech (TTS)\nsystems rely on fixed style labels or inserting a speech prompt to control\nthese cues, which severely limits flexibility. Recent attempts seek to employ\nnatural-language instructions to modulate paralinguistic features,\nsubstantially improving the generalization of instruction-driven TTS models.\nAlthough many TTS systems now support customized synthesis via textual\ndescription, their actual ability to interpret and execute complex instructions\nremains largely unexplored. In addition, there is still a shortage of\nhigh-quality benchmarks and automated evaluation metrics specifically designed\nfor instruction-based TTS, which hinders accurate assessment and iterative\noptimization of these models. To address these limitations, we introduce\nInstructTTSEval, a benchmark for measuring the capability of complex\nnatural-language style control. We introduce three tasks, namely\nAcoustic-Parameter Specification, Descriptive-Style Directive, and Role-Play,\nincluding English and Chinese subsets, each with 1k test cases (6k in total)\npaired with reference audio. We leverage Gemini as an automatic judge to assess\ntheir instruction-following abilities. Our evaluation of accessible\ninstruction-following TTS systems highlights substantial room for further\nimprovement. We anticipate that InstructTTSEval will drive progress toward more\npowerful, flexible, and accurate instruction-following TTS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86InstructTTSEval\uff0c\u4e00\u4e2a\u7cfb\u7edf\u5316\u8bc4\u4f30TTS\u7cfb\u7edf\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u7684\u5168\u65b0\u57fa\u51c6\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u4e2d\u82f1\u6587\u6d4b\u8bd5\u6837\u4f8b\u548c\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u5f53\u524d\u65b9\u6cd5\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u5c06\u63a8\u52a8\u6307\u4ee4\u9a71\u52a8TTS\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u5408\u6210\uff08TTS\uff09\u7cfb\u7edf\u5728\u8868\u8fbe\u8bf4\u8bdd\u8005\u7684\u97f3\u8272\u3001\u60c5\u611f\u548c\u97f5\u5f8b\u7b49\u526f\u8bed\u8a00\u4fe1\u606f\u65f6\uff0c\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u98ce\u683c\u6807\u7b7e\u6216\u8bed\u97f3\u63d0\u793a\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002\u867d\u7136\u8fd1\u671f\u5f15\u5165\u4e86\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6765\u63d0\u5347\u6a21\u578b\u5bf9\u590d\u6742\u98ce\u683c\u7684\u63a7\u5236\u529b\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u6307\u4ee4\u9a71\u52a8TTS\u7cfb\u7edf\u7684\u9ad8\u8d28\u91cf\u8bc4\u6d4b\u57fa\u51c6\u548c\u81ea\u52a8\u5316\u8bc4\u4ef7\u6307\u6807\uff0c\u9650\u5236\u4e86\u6a21\u578b\u80fd\u529b\u7684\u51c6\u786e\u8bc4\u4f30\u548c\u4f18\u5316\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86InstructTTSEval\u57fa\u51c6\uff0c\u7528\u4e8e\u8861\u91cfTTS\u7cfb\u7edf\u5bf9\u590d\u6742\u81ea\u7136\u8bed\u8a00\u98ce\u683c\u63a7\u5236\u6307\u4ee4\u7684\u54cd\u5e94\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u8bbe\u8ba1\u4e86\u4e09\u7c7b\u4efb\u52a1\uff1a\u58f0\u5b66\u53c2\u6570\u6307\u5b9a\u3001\u63cf\u8ff0\u6027\u98ce\u683c\u6307\u4ee4\u548c\u89d2\u8272\u626e\u6f14\uff0c\u6db5\u76d6\u4e2d\u82f1\u53cc\u8bed\uff0c\u6bcf\u7c7b\u4efb\u52a1\u54041000\u6761\u6d4b\u8bd5\u7528\u4f8b\uff08\u51716000\u6761\uff09\uff0c\u6bcf\u4e2a\u7528\u4f8b\u90fd\u914d\u6709\u53c2\u8003\u97f3\u9891\u3002\u8bc4\u4f30\u91c7\u7528Gemini\u81ea\u52a8\u5224\u522b\u7cfb\u7edf\uff0c\u8bc4\u5224TTS\u7cfb\u7edf\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002", "result": "\u4f7f\u7528InstructTTSEval\u5bf9\u73b0\u6709TTS\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\u540e\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u7cfb\u7edf\u5728\u590d\u6742\u6307\u4ee4\u7406\u89e3\u548c\u6267\u884c\u65b9\u9762\u4ecd\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4\u3002", "conclusion": "InstructTTSEval\u4e3aTTS\u793e\u533a\u63d0\u4f9b\u4e86\u5bf9\u590d\u6742\u81ea\u7136\u8bed\u8a00\u98ce\u683c\u63a7\u5236\u80fd\u529b\u7684\u6807\u51c6\u5316\u3001\u7cfb\u7edf\u5316\u8bc4\u6d4b\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8TTS\u7cfb\u7edf\u5411\u66f4\u5f3a\u5927\u3001\u66f4\u7075\u6d3b\u548c\u66f4\u51c6\u786e\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2506.16383", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16383", "abs": "https://arxiv.org/abs/2506.16383", "authors": ["Hao Li", "Viktor Schlegel", "Yizheng Sun", "Riza Batista-Navarro", "Goran Nenadic"], "title": "Large Language Models in Argument Mining: A Survey", "comment": "Work draft", "summary": "Argument Mining (AM), a critical subfield of Natural Language Processing\n(NLP), focuses on extracting argumentative structures from text. The advent of\nLarge Language Models (LLMs) has profoundly transformed AM, enabling advanced\nin-context learning, prompt-based generation, and robust cross-domain\nadaptability. This survey systematically synthesizes recent advancements in\nLLM-driven AM. We provide a concise review of foundational theories and\nannotation frameworks, alongside a meticulously curated catalog of datasets. A\nkey contribution is our comprehensive taxonomy of AM subtasks, elucidating how\ncontemporary LLM techniques -- such as prompting, chain-of-thought reasoning,\nand retrieval augmentation -- have reconfigured their execution. We further\ndetail current LLM architectures and methodologies, critically assess\nevaluation practices, and delineate pivotal challenges including long-context\nreasoning, interpretability, and annotation bottlenecks. Conclusively, we\nhighlight emerging trends and propose a forward-looking research agenda for\nLLM-based computational argumentation, aiming to strategically guide\nresearchers in this rapidly evolving domain.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bba\u8bc1\u6316\u6398\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u6db5\u76d6\u7406\u8bba\u3001\u6570\u636e\u3001\u4efb\u52a1\u5212\u5206\u3001\u6280\u672f\u5b9e\u73b0\u53ca\u6311\u6218\u5c55\u671b\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u6743\u5a01\u7efc\u8ff0\u548c\u672a\u6765\u7814\u7a76\u5efa\u8bae\u3002", "motivation": "\u8bba\u8bc1\u6316\u6398\uff08AM\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5341\u5206\u91cd\u8981\u3002\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u51fa\u73b0\uff0cAM\u9762\u4e34\u7740\u65b9\u6cd5\u3001\u5de5\u5177\u548c\u5e94\u7528\u7684\u91cd\u5927\u8f6c\u53d8\u3002\u5bf9LLM\u9a71\u52a8\u4e0bAM\u7684\u6700\u65b0\u8fdb\u5c55\u8fdb\u884c\u7cfb\u7edf\u68b3\u7406\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u8005\u628a\u63e1\u53d1\u5c55\u8109\u7edc\u548c\u672a\u6765\u65b9\u5411\u3002", "method": "\u7efc\u8ff0\u6027\u65b9\u6cd5\uff1a\u5bf9\u76f8\u5173\u57fa\u7840\u7406\u8bba\u3001\u6807\u6ce8\u6846\u67b6\u3001\u6570\u636e\u96c6\u53caLLM\u5728AM\u5404\u5b50\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\u4e0e\u6574\u7406\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u3001\u6700\u65b0\u65b9\u6cd5\u548c\u8bc4\u6d4b\u5b9e\u8df5\uff0c\u5e76\u5206\u6790\u4e86\u9762\u4e34\u7684\u6311\u6218\u4e0e\u672a\u6765\u8d8b\u52bf\u3002", "result": "\uff081\uff09\u5f52\u7eb3\u4e86\u76ee\u524dAM\u9886\u57df\u4e3b\u6d41\u7684\u7406\u8bba\u3001\u6807\u6ce8\u4f53\u7cfb\u548c\u6570\u636e\u96c6\u3002\uff082\uff09\u6784\u5efa\u4e86AM\u5b50\u4efb\u52a1\u7684\u5168\u9762\u5206\u7c7b\u4f53\u7cfb\uff0c\u68b3\u7406\u4e86LLM\u6280\u672f\uff08\u5982prompt\u3001\u63a8\u7406\u94fe\u3001\u68c0\u7d22\u589e\u5f3a\u7b49\uff09\u5982\u4f55\u91cd\u5851\u8fd9\u4e9b\u4efb\u52a1\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002\uff083\uff09\u5bf9\u73b0\u6709LLM\u6a21\u578b\u67b6\u6784\u3001\u65b9\u6cd5\u53ca\u8bc4\u6d4b\u65b9\u5f0f\u505a\u4e86\u8be6\u5c3d\u603b\u7ed3\u4e0e\u6279\u5224\u6027\u5206\u6790\u3002\uff084\uff09\u660e\u786e\u6307\u51fa\u957f\u6587\u672c\u63a8\u7406\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6807\u6ce8\u74f6\u9888\u7b49\u5c1a\u5f85\u7a81\u7834\u96be\u9898\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3aLLM\u9a71\u52a8\u7684AM\u7814\u7a76\u9886\u57df\u63d0\u4f9b\u4e86\u6e05\u6670\u8109\u7edc\u3001\u7efc\u5408\u53c2\u8003\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5bf9\u540e\u7eed\u7814\u7a76\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2506.16388", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16388", "abs": "https://arxiv.org/abs/2506.16388", "authors": ["Sani Abdullahi Sani", "Salim Abubakar", "Falalu Ibrahim Lawan", "Abdulhamid Abubakar", "Maryam Bala"], "title": "HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection", "comment": null, "summary": "This paper presents our approach to multi-label emotion detection in Hausa, a\nlow-resource African language, as part of SemEval Track A. We fine-tuned\nAfriBERTa, a transformer-based model pre-trained on African languages, to\nclassify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and\nsurprise. Our methodology involved data preprocessing, tokenization, and model\nfine-tuning using the Hugging Face Trainer API. The system achieved a\nvalidation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the\neffectiveness of transformer-based models for emotion detection in low-resource\nlanguages.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5fae\u8c03AfriBERTa\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8c6a\u8428\u8bed\u6587\u672c\u516d\u79cd\u60c5\u611f\u7684\u591a\u6807\u7b7e\u68c0\u6d4b\uff0c\u5728\u9a8c\u8bc1\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u8868\u660eTransformer\u6a21\u578b\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u60c5\u611f\u5206\u6790\u3002", "motivation": "\u60c5\u611f\u68c0\u6d4b\u5728\u8bb8\u591a\u8bed\u8a00\u4e2d\u5df2\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u8d44\u6e90\u7a00\u7f3a\u7684\u975e\u6d32\u8bed\u8a00\uff08\u5982\u8c6a\u8428\u8bed\uff09\u4e0a\u4ecd\u7136\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u591a\u6807\u7b7e\u60c5\u611f\u8bc6\u522b\u65b9\u9762\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u5347\u81ea\u52a8\u5316\u60c5\u611f\u5206\u6790\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528AfriBERTa\uff0c\u8fd9\u662f\u4e00\u79cd\u5728\u975e\u6d32\u8bed\u8a00\u4e0a\u9884\u8bad\u7ec3\u7684Transformer\u6a21\u578b\u3002\u901a\u8fc7\u6570\u636e\u9884\u5904\u7406\u3001\u5206\u8bcd\uff0c\u5e76\u5229\u7528Hugging Face\u7684Trainer API\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u5176\u80fd\u591f\u5bf9\u8c6a\u8428\u8bed\u6587\u672c\u4e2d\u7684\u516d\u79cd\u60c5\u611f\uff08\u6124\u6012\u3001\u538c\u6076\u3001\u6050\u60e7\u3001\u5feb\u4e50\u3001\u60b2\u4f24\u3001\u60ca\u8bb6\uff09\u8fdb\u884c\u591a\u6807\u7b7e\u5206\u7c7b\u3002", "result": "\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u53d6\u5f97\u4e8674.00%\u7684\u51c6\u786e\u7387\u548c73.50%\u7684F1\u5206\u6570\uff0c\u663e\u793aTransformer\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u611f\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08\u5982AfriBERTa\uff09\uff0c\u7ecf\u8fc7\u6070\u5f53\u8bad\u7ec3\u540e\uff0c\u80fd\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u8c6a\u8428\u8bed\uff09\u4e0a\u8fbe\u5230\u8f83\u9ad8\u7684\u591a\u6807\u7b7e\u60c5\u611f\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2506.16389", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16389", "abs": "https://arxiv.org/abs/2506.16389", "authors": ["Chenyi Zhou", "Zhengyan Shi", "Yuan Yao", "Lei Liang", "Huajun Chen", "Qiang Zhang"], "title": "RiOT: Efficient Prompt Refinement with Residual Optimization Tree", "comment": null, "summary": "Recent advancements in large language models (LLMs) have highlighted their\npotential across a variety of tasks, but their performance still heavily relies\non the design of effective prompts. Existing methods for automatic prompt\noptimization face two challenges: lack of diversity, limiting the exploration\nof valuable and innovative directions and semantic drift, where optimizations\nfor one task can degrade performance in others. To address these issues, we\npropose Residual Optimization Tree (RiOT), a novel framework for automatic\nprompt optimization. RiOT iteratively refines prompts through text gradients,\ngenerating multiple semantically diverse candidates at each step, and selects\nthe best prompt using perplexity. Additionally, RiOT incorporates the text\nresidual connection to mitigate semantic drift by selectively retaining\nbeneficial content across optimization iterations. A tree structure efficiently\nmanages the optimization process, ensuring scalability and flexibility.\nExtensive experiments across five benchmarks, covering commonsense,\nmathematical, logical, temporal, and semantic reasoning, demonstrate that RiOT\noutperforms both previous prompt optimization methods and manual prompting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6b8b\u5dee\u4f18\u5316\u6811\uff08RiOT\uff09\u65b9\u6cd5\uff0c\u81ea\u52a8\u4f18\u5316LLM\u63d0\u793a\u8bcd\uff0c\u901a\u8fc7\u591a\u6837\u6027\u751f\u6210\u4e0e\u6b8b\u5dee\u8fde\u63a5\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728\u4e94\u9879\u63a8\u7406\u4efb\u52a1\u57fa\u51c6\u4e0a\u8868\u73b0\u8d85\u8fc7\u5df2\u6709\u65b9\u6cd5\u548c\u4eba\u5de5\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u63d0\u793a\u8bcd\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u4e00\u662f\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86\u6709\u4ef7\u503c\u548c\u521b\u65b0\u65b9\u5411\u7684\u63a2\u7d22\uff1b\u4e8c\u662f\u8bed\u4e49\u6f02\u79fb\uff0c\u5bfc\u81f4\u5728\u4f18\u5316\u67d0\u4e00\u4efb\u52a1\u65f6\uff0c\u5176\u4ed6\u4efb\u52a1\u7684\u8868\u73b0\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u6b8b\u5dee\u4f18\u5316\u6811\uff08Residual Optimization Tree, RiOT\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u68af\u5ea6\u9012\u8fdb\u5f0f\u5730\u7ec6\u5316\u63d0\u793a\u8bcd\uff0c\u6bcf\u6b65\u751f\u6210\u591a\u4e2a\u5177\u6709\u8bed\u4e49\u591a\u6837\u6027\u7684\u5019\u9009\u63d0\u793a\u8bcd\uff0c\u5e76\u57fa\u4e8e\u56f0\u60d1\u5ea6\u9009\u62e9\u6700\u4f73\u63d0\u793a\uff0c\u8fd8\u5f15\u5165\u4e86\u6587\u672c\u6b8b\u5dee\u8fde\u63a5\uff0c\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u4fdd\u7559\u6709\u76ca\u5185\u5bb9\u4ee5\u51cf\u8f7b\u8bed\u4e49\u6f02\u79fb\uff0c\u5229\u7528\u6811\u5f62\u7ed3\u6784\u9ad8\u6548\u7ba1\u7406\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u5e38\u8bc6\u3001\u6570\u5b66\u3001\u903b\u8f91\u3001\u65f6\u5e8f\u548c\u8bed\u4e49\u63a8\u7406\u4e94\u5927\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eRiOT\u4f18\u4e8e\u73b0\u6709\u81ea\u52a8\u548c\u4eba\u5de5\u63d0\u793a\u8bcd\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "RiOT\u80fd\u591f\u6709\u6548\u63d0\u5347LLMs\u5728\u591a\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u517c\u987e\u591a\u6837\u6027\u4e0e\u8bed\u4e49\u7a33\u5b9a\u6027\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u63d0\u793a\u8bcd\u4f18\u5316\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.16393", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16393", "abs": "https://arxiv.org/abs/2506.16393", "authors": ["Yao Lu", "Zhaiyuan Ji", "Jiawei Du", "Yu Shanqing", "Qi Xuan", "Tianyi Zhou"], "title": "From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling", "comment": null, "summary": "Although the annotation paradigm based on Large Language Models (LLMs) has\nmade significant breakthroughs in recent years, its actual deployment still has\ntwo core bottlenecks: first, the cost of calling commercial APIs in large-scale\nannotation is very expensive; second, in scenarios that require fine-grained\nsemantic understanding, such as sentiment classification and toxicity\nclassification, the annotation accuracy of LLMs is even lower than that of\nSmall Language Models (SLMs) dedicated to this field. To address these\nproblems, we propose a new paradigm of multi-model cooperative annotation and\ndesign a fully automatic annotation framework AutoAnnotator based on this.\nSpecifically, AutoAnnotator consists of two layers. The upper-level\nmeta-controller layer uses the generation and reasoning capabilities of LLMs to\nselect SLMs for annotation, automatically generate annotation code and verify\ndifficult samples; the lower-level task-specialist layer consists of multiple\nSLMs that perform annotation through multi-model voting. In addition, we use\nthe difficult samples obtained by the secondary review of the meta-controller\nlayer as the reinforcement learning set and fine-tune the SLMs in stages\nthrough a continual learning strategy, thereby improving the generalization of\nSLMs. Extensive experiments show that AutoAnnotator outperforms existing\nopen-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings.\nNotably, AutoAnnotator reduces the annotation cost by 74.15% compared to\ndirectly annotating with GPT-3.5-turbo, while still improving the accuracy by\n6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684AutoAnnotator\u7cfb\u7edf\u91c7\u7528\u591a\u6a21\u578b\u534f\u540c\u3001\u81ea\u52a8\u751f\u6210\u548c\u590d\u67e5\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u6210\u672c\u5927\u5e45\u964d\u4f4e\u548c\u51c6\u786e\u7387\u63d0\u5347\uff0c\u6539\u8fdb\u4e86\u5927\u6a21\u578b\u6807\u6ce8\u5e94\u7528\u5728\u7ec6\u7c92\u5ea6\u4efb\u52a1\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6807\u6ce8\u65b9\u5f0f\u5b58\u5728\u4e24\u5927\u74f6\u9888\uff1a\u5927\u89c4\u6a21\u8c03\u7528\u5546\u4e1aAPI\u6210\u672c\u9ad8\uff0c\u4ee5\u53ca\u5728\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7406\u89e3\uff08\u5982\u60c5\u611f/\u6bd2\u6027\u5206\u7c7b\uff09\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u4e0d\u8db3\uff0c\u751a\u81f3\u4f4e\u4e8e\u4e13\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u578b\u534f\u540c\u6807\u6ce8\u7684\u65b0\u8303\u5f0f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5168\u81ea\u52a8\u6807\u6ce8\u6846\u67b6AutoAnnotator\u3002\u8be5\u6846\u67b6\u5305\u62ec\u4e24\u5c42\u7ed3\u6784\uff1a\u4e0a\u5c42\u5143\u63a7\u5236\u5668\u5229\u7528LLM\u8d1f\u8d23SLM\u9009\u62e9\u3001\u81ea\u52a8\u751f\u6210\u6807\u6ce8\u4ee3\u7801\u548c\u56f0\u96be\u6837\u672c\u590d\u6838\uff0c\u4e0b\u5c42\u7531\u591a\u4e2aSLM\u7ec4\u6210\uff0c\u91c7\u7528\u591a\u6a21\u578b\u6295\u7968\u6267\u884c\u6807\u6ce8\u3002\u540c\u65f6\uff0c\u96be\u4f8b\u901a\u8fc7\u5143\u63a7\u5236\u5668\u4e8c\u6b21\u590d\u6838\u5e76\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\uff0c\u5206\u9636\u6bb5\u6301\u7eed\u5b66\u4e60\u4ee5\u63d0\u5347SLM\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eAutoAnnotator\u5728zero-shot\u3001one-shot\u3001CoT\u53ca\u591a\u6570\u6295\u7968\u7b49\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90/API LLM\u3002\u4e0e\u76f4\u63a5\u91c7\u7528GPT-3.5-turbo\u76f8\u6bd4\uff0c\u6807\u6ce8\u6210\u672c\u964d\u4f4e74.15%\uff0c\u51c6\u786e\u7387\u63d0\u53476.21%\u3002", "conclusion": "AutoAnnotator\u663e\u8457\u63d0\u5347\u4e86\u6807\u6ce8\u7684\u6210\u672c\u6548\u80fd\u6bd4\u5e76\u63d0\u5347\u4e86\u51c6\u786e\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u81ea\u52a8\u6807\u6ce8\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u4f18\u65b0\u65b9\u6848\u3002"}}
{"id": "2506.16395", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16395", "abs": "https://arxiv.org/abs/2506.16395", "authors": ["Zhexu Wang", "Yiping Liu", "Yejie Wang", "Wenyang He", "Bofei Gao", "Muxi Diao", "Yanxu Chen", "Kelin Fu", "Flood Sung", "Zhilin Yang", "Tianyu Liu", "Weiran Xu"], "title": "OJBench: A Competition Level Code Benchmark For Large Language Models", "comment": "9 pages, 5 figures", "summary": "Recent advancements in large language models (LLMs) have demonstrated\nsignificant progress in math and code reasoning capabilities. However, existing\ncode benchmark are limited in their ability to evaluate the full spectrum of\nthese capabilities, particularly at the competitive level. To bridge this gap,\nwe introduce OJBench, a novel and challenging benchmark designed to assess the\ncompetitive-level code reasoning abilities of LLMs. OJBench comprises 232\nprogramming competition problems from NOI and ICPC, providing a more rigorous\ntest of models' reasoning skills. We conducted a comprehensive evaluation using\nOJBench on 37 models, including both closed-source and open-source models,\nreasoning-oriented and non-reasoning-oriented models. Our results indicate that\neven state-of-the-art reasoning-oriented models, such as o4-mini and\nGemini-2.5-pro-exp, struggle with highly challenging competition-level\nproblems. This highlights the significant challenges that models face in\ncompetitive-level code reasoning.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faOJBench\u65b0\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u4e8637\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ade\u8d5b\u7ea7\u7f16\u7a0b\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u6700\u597d\u7684\u6a21\u578b\u9762\u5bf9\u9ad8\u96be\u5ea6\u4efb\u52a1\u4f9d\u7136\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u7684\u4ee3\u7801\u8bc4\u6d4b\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u8fd9\u4e9b\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u7ade\u8d5b\u6c34\u5e73\u4e0a\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u7f3a\u9677\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86OJBench\uff0c\u4e00\u5957\u65b0\u7684\u57fa\u51c6\uff0c\u6536\u96c6\u81eaNOI\u548cICPC\u5171232\u9053\u7f16\u7a0b\u7ade\u8d5b\u9898\uff0c\u5e76\u7528\u5176\u5bf937\u4e2a\u4e0d\u540c\u7c7b\u578b\u7684\u5927\u6a21\u578b\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u6d4b\u3002", "result": "\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u63a8\u7406\u578b\u6a21\u578b\uff08\u5982o4-mini\u4e0eGemini-2.5-pro-exp\uff09\u5728\u9ad8\u96be\u5ea6\u7ade\u8d5b\u9898\u9762\u524d\u4e5f\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u73b0\u6709\u5927\u6a21\u578b\u5728\u9762\u5bf9\u7ade\u8d5b\u7ea7\u4ee3\u7801\u63a8\u7406\u9898\u65f6\u4ecd\u5b58\u5728\u8f83\u5927\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u80fd\u529b\u3002"}}
{"id": "2506.16399", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16399", "abs": "https://arxiv.org/abs/2506.16399", "authors": ["Shushanta Pudasaini", "Aman Shakya", "Siddhartha Shrestha", "Sahil Bhatta", "Sunil Thapa", "Sushmita Palikhe"], "title": "NepaliGPT: A Generative Language Model for the Nepali Language", "comment": "11 pages, 9 figures", "summary": "After the release of ChatGPT, Large Language Models (LLMs) have gained huge\npopularity in recent days and thousands of variants of LLMs have been released.\nHowever, there is no generative language model for the Nepali language, due to\nwhich other downstream tasks, including fine-tuning, have not been explored\nyet. To fill this research gap in the Nepali NLP space, this research proposes\n\\textit{NepaliGPT}, a generative large language model tailored specifically for\nthe Nepali language. This research introduces an advanced corpus for the Nepali\nlanguage collected from several sources, called the Devanagari Corpus.\nLikewise, the research introduces the first NepaliGPT benchmark dataset\ncomprised of 4,296 question-answer pairs in the Nepali language. The proposed\nLLM NepaliGPT achieves the following metrics in text generation: Perplexity of\n26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\\%, and causal\nconsistency of 85.41\\%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u7b2c\u4e00\u6b3e\u4e13\u4e3a\u5c3c\u6cca\u5c14\u8bed\u6784\u5efa\u7684\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578bNepaliGPT\uff0c\u5efa\u7acb\u4e86\u76f8\u5173\u8bed\u6599\u5e93\u548c\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5e76\u8bc1\u660e\u8be5\u6a21\u578b\u5177\u6709\u826f\u597d\u7684\u6587\u672c\u751f\u6210\u6027\u80fd\uff0c\u4e3a\u5c3c\u6cca\u5c14\u8bedNLP\u7814\u7a76\u5e26\u6765\u7a81\u7834\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5168\u7403\u8303\u56f4\u5185\u53d6\u5f97\u5de8\u5927\u6210\u529f\uff0c\u4f46\u5c3c\u6cca\u5c14\u8bed\u9886\u57df\u4e00\u76f4\u7f3a\u4e4f\u4e13\u95e8\u7684\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u3002\u8fd9\u5bfc\u81f4\u8be5\u8bed\u8a00\u540e\u7eed\u76f8\u5173\u4efb\u52a1\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e13\u95e8\u9002\u7528\u4e8e\u5c3c\u6cca\u5c14\u8bed\u7684\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86NepaliGPT\uff0c\u8fd9\u662f\u4e00\u6b3e\u4e13\u95e8\u4e3a\u5c3c\u6cca\u5c14\u8bed\u5b9a\u5236\u7684\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u4f5c\u8005\u6536\u96c6\u548c\u6574\u7406\u4e86\u591a\u4e2a\u6765\u6e90\u7684\u5c3c\u6cca\u5c14\u8bed\u6587\u672c\uff0c\u6784\u5efa\u4e86\u9ad8\u7ea7\u522b\u7684Devanagari\u8bed\u6599\u5e93\uff0c\u8fd8\u9996\u6b21\u63a8\u51fa\u4e86\u5305\u542b4,296\u4e2a\u5c3c\u6cca\u5c14\u8bed\u95ee\u7b54\u5bf9\u7684NepaliGPT\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "NepaliGPT\u5728\u6587\u672c\u751f\u6210\u4e0a\u53d6\u5f97\u4e86\u5982\u4e0b\u8bc4\u6d4b\u6307\u6807\uff1a\u56f0\u60d1\u5ea6\u4e3a26.32245\uff0cROUGE-1\u5f97\u5206\u4e3a0.2604\uff0c\u56e0\u679c\u8fde\u8d2f\u6027\u8fbe\u523081.25%\uff0c\u56e0\u679c\u4e00\u81f4\u6027\u8fbe\u523085.41%\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u5c3c\u6cca\u5c14\u8bed\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684NepaliGPT\u5c55\u793a\u4e86\u826f\u597d\u7684\u751f\u6210\u80fd\u529b\u548c\u76f8\u5173\u8bc4\u6d4b\u6307\u6807\uff0c\u5728\u5c3c\u6cca\u5c14\u8bedNLP\u9886\u57df\u8fc8\u51fa\u4e86\u5173\u952e\u4e00\u6b65\uff0c\u4e3a\u540e\u7eed\u4efb\u52a1\u6253\u4e0b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.16411", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16411", "abs": "https://arxiv.org/abs/2506.16411", "authors": ["Zhen Xu", "Shang Zhu", "Jue Wang", "Junlin Wang", "Ben Athiwaratkun", "Chi Wang", "James Zou", "Ce Zhang"], "title": "When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework", "comment": "under review", "summary": "We investigate the challenge of applying Large Language Models (LLMs) to long\ntexts. We propose a theoretical framework that distinguishes the failure modes\nof long context tasks into three categories: cross-chunk dependence (task\nnoise), confusion that grows with context size (model noise), and the imperfect\nintegration of partial results (aggregator noise). Under this view, we analyze\nwhen it is effective to use multi-agent chunking, i.e., dividing a length\nsequence into smaller chunks and aggregating the processed results of each\nchunk. Our experiments on tasks such as retrieval, question answering, and\nsummarization confirm both the theoretical analysis and the conditions that\nfavor multi-agent chunking. By exploring superlinear model noise growth with\ninput length, we also explain why, for large inputs, a weaker model configured\nwith chunk-based processing can surpass a more advanced model like GPT4o\napplied in a single shot. Overall, we present a principled understanding\nframework and our results highlight a direct pathway to handling long contexts\nin LLMs with carefully managed chunking and aggregator strategies.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86LLM\u5904\u7406\u957f\u6587\u672c\u7684\u4e09\u7c7b\u566a\u58f0\u6765\u6e90\uff0c\u63d0\u51fa\u591a\u4ee3\u7406\u5206\u5757\u4e0e\u805a\u5408\u7b56\u7565\u80fd\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u4f18\u4e8e\u5355\u6a21\u578b\u5904\u7406\uff0c\u5c24\u5176\u5728\u4e0a\u4e0b\u6587\u6781\u957f\u65f6\u3002\u7406\u8bba\u4e0e\u5b9e\u9a8c\u8bc1\u5b9e\u6b64\u65b9\u6cd5\u53ef\u7a81\u7834\u957f\u6587\u672c\u5904\u7406\u74f6\u9888\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5904\u7406\u957f\u6587\u672c\u65f6\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff0c\u4f46\u5176\u5177\u4f53\u5931\u8d25\u673a\u5236\u4e0d\u660e\u786e\uff0c\u9700\u8981\u6709\u7406\u8bba\u6846\u67b6\u7cfb\u7edf\u6027\u5206\u6790\u95ee\u9898\u6765\u6e90\uff0c\u5e76\u63a2\u7a76\u5982\u4f55\u6709\u6548\u5229\u7528\u5206\u5757\u548c\u805a\u5408\u65b9\u6cd5\u63d0\u5347\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u957f\u6587\u672c\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u5206\u4e3a\u4e09\u7c7b\uff1a\u5206\u5757\u95f4\u4f9d\u8d56\uff08\u4efb\u52a1\u566a\u58f0\uff09\u3001\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u7684\u6df7\u6dc6\uff08\u6a21\u578b\u566a\u58f0\uff09\u3001\u5206\u5757\u7ed3\u679c\u6574\u5408\u4e0d\u5b8c\u7f8e\uff08\u805a\u5408\u5668\u566a\u58f0\uff09\u3002\u57fa\u4e8e\u6b64\uff0c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u91c7\u7528\u591a\u4ee3\u7406\u5206\u5757\uff08multi-agent chunking\uff09\u5e76\u5bf9\u5404\u5757\u7ed3\u679c\u8fdb\u884c\u805a\u5408\u53ef\u4ee5\u63d0\u5347\u4efb\u52a1\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u7406\u8bba\u6846\u67b6\u6709\u6548\uff0c\u5e76\u6307\u51fa\u5728\u68c0\u7d22\u3001\u95ee\u7b54\u3001\u6458\u8981\u7b49\u4efb\u52a1\u4e2d\uff0c\u5f53\u6a21\u578b\u566a\u58f0\u968f\u8f93\u5165\u957f\u5ea6\u8d85\u7ebf\u6027\u589e\u957f\u65f6\uff0c\u5206\u5757\u5f31\u6a21\u578b+\u805a\u5408\u7b56\u7565\u751a\u81f3\u53ef\u4ee5\u8d85\u8d8a\u5982GPT4o\u8fd9\u7c7b\u5355\u6b21\u5927\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u7ec6\u8bbe\u8ba1\u7684\u5206\u5757\u4e0e\u805a\u5408\u5668\u7b56\u7565\uff0c\u53ef\u4e3aLLMs\u9ad8\u6548\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u63d0\u4f9b\u76f4\u63a5\u53ef\u884c\u8def\u5f84\u3002\u672c\u6587\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u591a\u4ee3\u7406\u5206\u5757\u6cd5\u503c\u5f97\u63a8\u5e7f\u3002"}}
{"id": "2506.16444", "categories": ["cs.CL", "cs.AR", "cs.DB", "H.3.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.16444", "abs": "https://arxiv.org/abs/2506.16444", "authors": ["Kangqi Chen", "Andreas Kosmas Kakolyris", "Rakesh Nadig", "Manos Frouzakis", "Nika Mansouri Ghiasi", "Yu Liang", "Haiyu Mao", "Jisung Park", "Mohammad Sadrosadati", "Onur Mutlu"], "title": "REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing", "comment": "Extended version of our publication at the 52nd International\n  Symposium on Computer Architecture (ISCA-52), 2025", "summary": "Large Language Models (LLMs) face an inherent challenge: their knowledge is\nconfined to the data that they have been trained on. To overcome this issue,\nRetrieval-Augmented Generation (RAG) complements the static training-derived\nknowledge of LLMs with an external knowledge repository. RAG consists of three\nstages: indexing, retrieval, and generation. The retrieval stage of RAG becomes\na significant bottleneck in inference pipelines. In this stage, a user query is\nmapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)\nalgorithm searches for similar vectors in the database to identify relevant\nitems. Due to the large database sizes, ANNS incurs significant data movement\noverheads between the host and the storage system. To alleviate these\noverheads, prior works propose In-Storage Processing (ISP) techniques that\naccelerate ANNS by performing computations inside storage. However, existing\nworks that leverage ISP for ANNS (i) employ algorithms that are not tailored to\nISP systems, (ii) do not accelerate data retrieval operations for data selected\nby ANNS, and (iii) introduce significant hardware modifications, limiting\nperformance and hindering their adoption. We propose REIS, the first ISP system\ntailored for RAG that addresses these limitations with three key mechanisms.\nFirst, REIS employs a database layout that links database embedding vectors to\ntheir associated documents, enabling efficient retrieval. Second, it enables\nefficient ANNS by introducing an ISP-tailored data placement technique that\ndistributes embeddings across the planes of the storage system and employs a\nlightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that\nuses the existing computational resources inside the storage system. Compared\nto a server-grade system, REIS improves the performance (energy efficiency) of\nretrieval by an average of 13x (55x).", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9RAG\u63a8\u7406\u4e2d\u7684\u68c0\u7d22\u74f6\u9888\uff0c\u8bbe\u8ba1\u4e86\u517c\u5bb9\u73b0\u6709\u5b58\u50a8\u7cfb\u7edf\u7684ISP\u65b9\u6848REIS\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\u548c\u80fd\u6548\uff0c\u5177\u5907\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ea\u80fd\u5229\u7528\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u77e5\u8bc6\uff0c\u5b58\u5728\u77e5\u8bc6\u8fb9\u754c\u95ee\u9898\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u5e93\u6269\u5c55LLM\u77e5\u8bc6\uff0c\u4f46\u5176\u68c0\u7d22\u9636\u6bb5\u5728\u786c\u4ef6\u5c42\u9762\u4e0a\u7684\u6570\u636e\u79fb\u52a8\u5e26\u6765\u663e\u8457\u6027\u80fd\u74f6\u9888\u3002\u73b0\u6709\u7684\u5b58\u50a8\u5185\u5904\u7406\uff08ISP\uff09\u65b9\u6cd5\u5b58\u5728\u7b97\u6cd5\u4e0d\u9002\u914d\u3001\u672a\u52a0\u901f\u6570\u636e\u68c0\u7d22\u4ee5\u53ca\u9700\u5927\u5e45\u786c\u4ef6\u6539\u52a8\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86REIS\u2014\u2014\u7b2c\u4e00\u4e2a\u4e3aRAG\u91cf\u8eab\u5b9a\u5236\u7684ISP\u7cfb\u7edf\u3002REIS\u91c7\u7528\u4e09\u9879\u5173\u952e\u673a\u5236\uff1a1\uff09\u6570\u636e\u5e93\u5e03\u5c40\u5c06\u5411\u91cf\u4e0e\u6587\u6863\u9ad8\u6548\u5173\u8054\uff0c\u4fbf\u4e8e\u53d6\u56de\uff1b2\uff09\u6570\u636e\u6309ISP\u53cb\u597d\u539f\u5219\u8de8\u5b58\u50a8\u9762\u5206\u5e03\u4e14\u4f7f\u7528\u8f7b\u91cf\u5316\u7684Flash Translation Layer\uff0c\u63d0\u5347\u5411\u91cf\u68c0\u7d22\u6548\u7387\uff1b3\uff09\u5229\u7528\u5b58\u50a8\u7cfb\u7edf\u73b0\u6709\u7684\u8ba1\u7b97\u8d44\u6e90\u5b9e\u73b0ANNS\u5f15\u64ce\uff0c\u65e0\u987b\u5927\u786c\u4ef6\u4fee\u6539\u3002", "result": "\u76f8\u6bd4\u670d\u52a1\u5668\u7ea7\u7cfb\u7edf\uff0cREIS\u5728\u68c0\u7d22\u6027\u80fd\u4e0e\u80fd\u6548\u4e0a\u5206\u522b\u5e73\u5747\u63d0\u5347\u4e8613\u500d\u4e0e55\u500d\u3002", "conclusion": "REIS\u80fd\u591f\u6709\u6548\u89e3\u51b3RAG\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u5411\u91cf\u68c0\u7d22\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u63d0\u5347\u6574\u4f53\u6548\u7387\u4e14\u786c\u4ef6\u6539\u52a8\u5c0f\uff0c\u63a8\u52a8\u4e86RAG\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.16445", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16445", "abs": "https://arxiv.org/abs/2506.16445", "authors": ["Haotian Xia", "Hao Peng", "Yunjia Qi", "Xiaozhi Wang", "Bin Xu", "Lei Hou", "Juanzi Li"], "title": "StoryWriter: A Multi-Agent Framework for Long Story Generation", "comment": null, "summary": "Long story generation remains a challenge for existing large language models\n(LLMs), primarily due to two main factors: (1) discourse coherence, which\nrequires plot consistency, logical coherence, and completeness in the long-form\ngeneration, and (2) narrative complexity, which requires an interwoven and\nengaging narrative. To address these challenges, we propose StoryWriter, a\nmulti-agent story generation framework, which consists of three main modules:\n(1) outline agent, which generates event-based outlines containing rich event\nplots, character, and event-event relationships. (2) planning agent, which\nfurther details events and plans which events should be written in each chapter\nto maintain an interwoven and engaging story. (3) writing agent, which\ndynamically compresses the story history based on the current event to generate\nand reflect new plots, ensuring the coherence of the generated story. We\nconduct both human and automated evaluation, and StoryWriter significantly\noutperforms existing story generation baselines in both story quality and\nlength. Furthermore, we use StoryWriter to generate a dataset, which contains\nabout $6,000$ high-quality long stories, with an average length of $8,000$\nwords. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning\non LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which\ndemonstrates advanced performance in long story generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7684StoryWriter\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u7bc7\u6545\u4e8b\u751f\u6210\u7684\u8fde\u8d2f\u6027\u548c\u590d\u6742\u5ea6\uff0c\u5e76\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u957f\u7bc7\u6545\u4e8b\u751f\u6210\u5bf9\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u8bf4\u4ecd\u662f\u6311\u6218\uff0c\u4e3b\u8981\u9762\u4e34\u8bdd\u8bed\u8fde\u8d2f\u6027\u548c\u53d9\u4e8b\u590d\u6742\u6027\u4e24\u5927\u96be\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u4fdd\u8bc1\u6545\u4e8b\u7684\u60c5\u8282\u4e00\u81f4\u3001\u903b\u8f91\u8fde\u8d2f\u548c\u5185\u5bb9\u4e30\u5bcc\u3002", "method": "\u63d0\u51faStoryWriter\u591a\u667a\u80fd\u4f53\u6545\u4e8b\u751f\u6210\u6846\u67b6\uff0c\u7531\u5927\u7eb2\u4ee3\u7406\u3001\u89c4\u5212\u4ee3\u7406\u548c\u5199\u4f5c\u4ee3\u7406\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u8d1f\u8d23\u4e8b\u4ef6\u7eb2\u8981\u751f\u6210\u3001\u8be6\u7ec6\u60c5\u8282\u89c4\u5212\u548c\u57fa\u4e8e\u52a8\u6001\u538b\u7f29\u4fdd\u8bc1\u8fde\u8d2f\u7684\u6545\u4e8b\u751f\u6210\u3002", "result": "StoryWriter\u5728\u4eba\u5de5\u548c\u81ea\u52a8\u8bc4\u4ef7\u4e2d\uff0c\u5728\u6545\u4e8b\u8d28\u91cf\u548c\u957f\u5ea6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u751f\u6210\u57fa\u7ebf\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u5305\u542b\u7ea66000\u7bc7\u3001\u5e73\u57478000\u5b57\u9ad8\u8d28\u91cf\u957f\u6545\u4e8b\u7684\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u8be5\u6570\u636e\u96c6\u5fae\u8c03Llama3.1-8B\u548cGLM4-9B\uff0c\u5f00\u53d1\u4e86StoryWriter_GLM\u7b49\u6a21\u578b\uff0c\u5c55\u73b0\u4e86\u5148\u8fdb\u7684\u957f\u7bc7\u6545\u4e8b\u751f\u6210\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5206\u5de5\u534f\u4f5c\u673a\u5236\uff0cStoryWriter\u6709\u6548\u63d0\u5347\u4e86\u957f\u7bc7\u6545\u4e8b\u751f\u6210\u7684\u8fde\u8d2f\u6027\u548c\u590d\u6742\u6027\uff0c\u63a8\u52a8\u4e86\u957f\u6587\u672c\u751f\u6210\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2506.16476", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16476", "abs": "https://arxiv.org/abs/2506.16476", "authors": ["Saad Almohaimeed", "Saleh Almohaimeed", "Damla Turgut", "Ladislau B\u00f6l\u00f6ni"], "title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection", "comment": null, "summary": "Implicit hate speech has recently emerged as a critical challenge for social\nmedia platforms. While much of the research has traditionally focused on\nharmful speech in general, the need for generalizable techniques to detect\nveiled and subtle forms of hate has become increasingly pressing. Based on\nlexicon analysis, we hypothesize that implicit hate speech is already present\nin publicly available harmful speech datasets but may not have been explicitly\nrecognized or labeled by annotators. Additionally, crowdsourced datasets are\nprone to mislabeling due to the complexity of the task and often influenced by\nannotators' subjective interpretations. In this paper, we propose an approach\nto address the detection of implicit hate speech and enhance generalizability\nacross diverse datasets by leveraging existing harmful speech datasets. Our\nmethod comprises three key components: influential sample identification,\nreannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental\nresults demonstrate the effectiveness of our approach in improving implicit\nhate detection, achieving a +12.9-point F1 score improvement compared to the\nbaseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u7ed3\u5408\u6837\u672c\u7b5b\u9009\u3001\u91cd\u6807\u6ce8\u4e0e\u5927\u6a21\u578b\u589e\u5f3a\uff0c\u6709\u6548\u63d0\u5347\u9690\u6027\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u80fd\u529b\uff0cF1\u5206\u6570\u63d0\u534712.9\u70b9\u3002", "motivation": "\u9690\u6027\u4ec7\u6068\u8a00\u8bba\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u65e5\u76ca\u4e25\u5cfb\uff0c\u4e14\u4f20\u7edf\u7814\u7a76\u591a\u805a\u7126\u4e8e\u666e\u904d\u6709\u5bb3\u8a00\u8bba\uff0c\u7f3a\u4e4f\u80fd\u68c0\u6d4b\u9690\u6666\u3001\u7ec6\u5fae\u4ec7\u6068\u7684\u901a\u7528\u6280\u672f\u3002\u540c\u65f6\uff0c\u516c\u5f00\u6709\u5bb3\u8a00\u8bba\u6570\u636e\u96c6\u4e2d\u53ef\u80fd\u5df2\u5305\u542b\u9690\u6027\u4ec7\u6068\u8a00\u8bba\u4f46\u672a\u88ab\u6807\u6ce8\uff0c\u800c\u4f17\u5305\u6570\u636e\u53d7\u4e3b\u89c2\u5f71\u54cd\u6613\u8bef\u6807\uff0c\u4e3a\u6b64\u9700\u8981\u6539\u8fdb\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u5927\u6b65\u9aa4\uff1a\u5f71\u54cd\u6837\u672c\u8bc6\u522b\u3001\u6570\u636e\u91cd\u65b0\u6807\u6ce8\u3001\u4ee5\u53ca\u5229\u7528Llama-3 70B\u548cGPT-4o\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u5728\u73b0\u6709\u6709\u5bb3\u8a00\u8bba\u6570\u636e\u57fa\u7840\u4e0a\u63d0\u5347\u9690\u6027\u4ec7\u6068\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u9690\u6027\u4ec7\u6068\u68c0\u6d4b\u6548\u679c\uff0cF1\u5206\u6570\u63d0\u534712.9\u70b9\uff0c\u76f8\u8f83\u57fa\u7ebf\u65b9\u6cd5\u4f18\u52bf\u660e\u663e\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u6837\u672c\u7b5b\u9009\u3001\u91cd\u6807\u6ce8\u548c\u5927\u6a21\u578b\u589e\u5f3a\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u53ef\u6709\u6548\u63d0\u5347\u5bf9\u9690\u6027\u4ec7\u6068\u8a00\u8bba\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u589e\u5f3a\u6a21\u578b\u8de8\u6570\u636e\u96c6\u7684\u6cdb\u5316\u6027\u3002"}}
{"id": "2506.16502", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16502", "abs": "https://arxiv.org/abs/2506.16502", "authors": ["Soumya Suvra Ghosal", "Vaibhav Singh", "Akash Ghosh", "Soumyabrata Pal", "Subhadip Baidya", "Sriparna Saha", "Dinesh Manocha"], "title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples", "comment": null, "summary": "Reward models are essential for aligning large language models (LLMs) with\nhuman preferences. However, most open-source multilingual reward models are\nprimarily trained on preference datasets in high-resource languages, resulting\nin unreliable reward signals for low-resource Indic languages. Collecting\nlarge-scale, high-quality preference data for these languages is prohibitively\nexpensive, making preference-based training approaches impractical. To address\nthis challenge, we propose RELIC, a novel in-context learning framework for\nreward modeling in low-resource Indic languages. RELIC trains a retriever with\na pairwise ranking objective to select in-context examples from auxiliary\nhigh-resource languages that most effectively highlight the distinction between\npreferred and less-preferred responses. Extensive experiments on three\npreference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art\nopen-source reward models demonstrate that RELIC significantly improves reward\nmodel accuracy for low-resource Indic languages, consistently outperforming\nexisting example selection methods. For example, on Bodo-a low-resource Indic\nlanguage-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13%\nimprovement in accuracy over zero-shot prompting and state-of-the-art example\nselection method, respectively.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faRELIC\u6846\u67b6\uff0c\u5229\u7528\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u793a\u4f8b\u6539\u8fdb\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u672c\u5730\u504f\u597d\u6570\u636e\u5373\u53ef\u5927\u5e45\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u5f00\u6e90\u591a\u8bed\u79cd\u5956\u52b1\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u5bfc\u81f4\u5728\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u4e0d\u4f73\uff1b\u800c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u6536\u96c6\u5927\u91cf\u9ad8\u8d28\u91cf\u504f\u597d\u6570\u636e\u6210\u672c\u6781\u9ad8\uff0c\u4f20\u7edf\u57fa\u4e8e\u504f\u597d\u6570\u636e\u7684\u8bad\u7ec3\u65b9\u5f0f\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5RELIC\uff0c\u5176\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u68c0\u7d22\u5668\uff0c\u5229\u7528\u914d\u5bf9\u6392\u5e8f\u76ee\u6807\u4ece\u9ad8\u8d44\u6e90\u8f85\u52a9\u8bed\u8a00\u4e2d\u9009\u62e9\u80fd\u6700\u597d\u533a\u5206\u4f18\u9009\u548c\u6b21\u4f18\u54cd\u5e94\u7684\u4e0a\u4e0b\u6587\u793a\u4f8b\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002", "result": "RELIC\u5728\u4e09\u4e2a\u504f\u597d\u6570\u636e\u96c6\u4e0a\u7ecf\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u76f8\u8f83\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u548c\u5f53\u524d\u6700\u597d\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u79cd\u4e0a\u5956\u52b1\u6a21\u578b\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff08\u4ee5Bodo\u8bed\u8a00\u4e3a\u4f8b\uff0cLLaMA-3.2-3B\u5956\u52b1\u6a21\u578b\u51c6\u786e\u7387\u5206\u522b\u63d0\u5347\u4e8612.81%\u548c10.13%\uff09\u3002", "conclusion": "RELIC\u6846\u67b6\u5728\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00\u5956\u52b1\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0c\u80fd\u591f\u6709\u6548\u514b\u670d\u9ad8\u8d28\u91cf\u504f\u597d\u6570\u636e\u7f3a\u4e4f\u7684\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u5956\u52b1\u6a21\u578b\u5bf9\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u8868\u73b0\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.16558", "categories": ["cs.CL", "cs.CY", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16558", "abs": "https://arxiv.org/abs/2506.16558", "authors": ["Dana Serditova", "Kevin Tang", "Jochen Steffens"], "title": "Automatic Speech Recognition Biases in Newcastle English: an Error Analysis", "comment": "Submitted to Interspeech 2025", "summary": "Automatic Speech Recognition (ASR) systems struggle with regional dialects\ndue to biased training which favours mainstream varieties. While previous\nresearch has identified racial, age, and gender biases in ASR, regional bias\nremains underexamined. This study investigates ASR performance on Newcastle\nEnglish, a well-documented regional dialect known to be challenging for ASR. A\ntwo-stage analysis was conducted: first, a manual error analysis on a subsample\nidentified key phonological, lexical, and morphosyntactic errors behind ASR\nmisrecognitions; second, a case study focused on the systematic analysis of ASR\nrecognition of the regional pronouns ``yous'' and ``wor''. Results show that\nASR errors directly correlate with regional dialectal features, while social\nfactors play a lesser role in ASR mismatches. We advocate for greater dialectal\ndiversity in ASR training data and highlight the value of sociolinguistic\nanalysis in diagnosing and addressing regional biases.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0ASR\u7cfb\u7edf\u5bf9Newcastle\u5730\u533a\u65b9\u8a00\u8868\u73b0\u8f83\u5dee\uff0c\u4e3b\u8981\u53d7\u5730\u65b9\u6027\u8bed\u8a00\u7279\u5f81\u5f71\u54cd\u3002\u5efa\u8bae\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u65b9\u8a00\uff0c\u5e76\u7ed3\u5408\u793e\u4f1a\u8bed\u8a00\u5b66\u65b9\u6cd5\u51cf\u5c11\u533a\u57df\u6027\u8bc6\u522b\u504f\u89c1\u3002", "motivation": "\u5927\u591a\u6570\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\u8bad\u7ec3\u6570\u636e\u66f4\u504f\u5411\u4e3b\u6d41\u65b9\u8a00\uff0c\u5bfc\u81f4\u5176\u5bf9\u5730\u533a\u65b9\u8a00\uff08\u5982Newcastle\u82f1\u8bed\uff09\u8bc6\u522b\u6548\u679c\u4e0d\u4f73\u3002\u5c3d\u7ba1\u5148\u524d\u7814\u7a76\u5173\u6ce8\u4e86\u79cd\u65cf\u3001\u5e74\u9f84\u548c\u6027\u522b\u7b49\u504f\u89c1\uff0c\u4f46\u5730\u533a\u6027\u504f\u89c1\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5206\u6790\uff1a\u9996\u5148\u5bf9\u90e8\u5206\u6837\u672c\u8fdb\u884c\u4eba\u5de5\u9519\u8bef\u5206\u6790\uff0c\u8bc6\u522bASR\u8bef\u8bc6\u522b\u7684\u5173\u952e\u8bed\u97f3\u3001\u8bcd\u6c47\u548c\u5f62\u6001\u53e5\u6cd5\u9519\u8bef\uff1b\u5176\u6b21\uff0c\u5bf9\u5730\u533a\u4ee3\u8bcd\u201cyous\u201d\u548c\u201cwor\u201d\u7684\u8bc6\u522b\u8fdb\u884c\u7cfb\u7edf\u6848\u4f8b\u7814\u7a76\u3002", "result": "ASR\u7684\u8bc6\u522b\u9519\u8bef\u4e0e\u5730\u65b9\u6027\u65b9\u8a00\u7279\u5f81\u76f4\u63a5\u76f8\u5173\uff0c\u800c\u793e\u4f1a\u56e0\u7d20\u7684\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u5efa\u8bae\u5728ASR\u8bad\u7ec3\u6570\u636e\u4e2d\u589e\u52a0\u65b9\u8a00\u591a\u6837\u6027\uff0c\u5e76\u5f3a\u8c03\u793e\u4f1a\u8bed\u8a00\u5b66\u5206\u6790\u5728\u8bca\u65ad\u548c\u89e3\u51b3\u533a\u57df\u6027\u504f\u89c1\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2506.16574", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16574", "abs": "https://arxiv.org/abs/2506.16574", "authors": ["Enes Yavuz Ugan", "Ngoc-Quan Pham", "Alexander Waibel"], "title": "Weight Factorization and Centralization for Continual Learning in Speech Recognition", "comment": "Accepted to INTERSPEECH 2025", "summary": "Modern neural network based speech recognition models are required to\ncontinually absorb new data without re-training the whole system, especially in\ndownstream applications using foundation models, having no access to the\noriginal training data. Continually training the models in a rehearsal-free,\nmultilingual, and language agnostic condition, likely leads to catastrophic\nforgetting, when a seemingly insignificant disruption to the weights can\ndestructively harm the quality of the models. Inspired by the ability of human\nbrains to learn and consolidate knowledge through the waking-sleeping cycle, we\npropose a continual learning approach with two distinct phases: factorization\nand centralization, learning and merging knowledge accordingly. Our experiments\non a sequence of varied code-switching datasets showed that the centralization\nstage can effectively prevent catastrophic forgetting by accumulating the\nknowledge in multiple scattering low-rank adapters.", "AI": {"tldr": "\u9488\u5bf9\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u6301\u7eed\u5b66\u4e60\u65f6\u65e0\u6cd5\u8bbf\u95ee\u65e7\u6570\u636e\u4e14\u5bb9\u6613\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u6a21\u4eff\u4eba\u8111\u7761\u7720\u8fc7\u7a0b\u7684\u5206\u89e3-\u96c6\u4e2d\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11\u9057\u5fd8\uff0c\u5728\u591a\u8bed\u5883\u4e0b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u9700\u8981\u80fd\u591f\u6301\u7eed\u5438\u6536\u65b0\u6570\u636e\uff0c\u4e14\u901a\u5e38\u65e0\u6cd5\u8bbf\u95ee\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u3002\u8fd9\u8981\u6c42\u6a21\u578b\u80fd\u5728\u591a\u8bed\u8a00\u3001\u65e0\u56de\u987e\uff08rehearsal-free\uff09\u6761\u4ef6\u4e0b\u6301\u7eed\u8bad\u7ec3\uff0c\u4f46\u8fd9\u6837\u5bb9\u6613\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff08catastrophic forgetting\uff09\u7684\u95ee\u9898\u3002", "method": "\u53d7\u4eba\u8111\u901a\u8fc7\u9192-\u7761\u5468\u671f\u5b66\u4e60\u548c\u5de9\u56fa\u77e5\u8bc6\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff08\u5206\u89e3factorization\u548c\u96c6\u4e2dcentralization\uff09\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u548c\u878d\u5408\u77e5\u8bc6\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u4e0d\u540c\u7684\u8bed\u7801\u8f6c\u6362\uff08code-switching\uff09\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660ecentralization\u9636\u6bb5\u80fd\u901a\u8fc7\u591a\u91cd\u5206\u6563\u7684\u4f4e\u79e9\u9002\u914d\u5668\u6709\u6548\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u79ef\u7d2f\u591a\u79cd\u77e5\u8bc6\u3002", "conclusion": "\u63d0\u51fa\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff08\u5206\u89e3+\u96c6\u4e2d\u9636\u6bb5\uff09\u6709\u6548\u51cf\u8f7b\u4e86\u5728\u590d\u6742\u6761\u4ef6\u4e0b\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u6ca1\u6709\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u60c5\u51b5\u4e0b\u7684\u6a21\u578b\u6301\u7eed\u4f18\u5316\u3002"}}
{"id": "2506.16580", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16580", "abs": "https://arxiv.org/abs/2506.16580", "authors": ["Tuan-Nam Nguyen", "Ngoc-Quan Pham", "Seymanur Akti", "Alexander Waibel"], "title": "Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement", "comment": "Accepted to INTERSPEECH 2025", "summary": "We propose a first streaming accent conversion (AC) model that transforms\nnon-native speech into a native-like accent while preserving speaker identity,\nprosody and improving pronunciation. Our approach enables stream processing by\nmodifying a previous AC architecture with an Emformer encoder and an optimized\ninference mechanism. Additionally, we integrate a native text-to-speech (TTS)\nmodel to generate ideal ground-truth data for efficient training. Our streaming\nAC model achieves comparable performance to the top AC models while maintaining\nstable latency, making it the first AC system capable of streaming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u652f\u6301\u6d41\u5f0f\u5904\u7406\u7684\u53e3\u97f3\u8f6c\u6362\u6a21\u578b\uff0c\u80fd\u591f\u5b9e\u65f6\u5c06\u975e\u6bcd\u8bed\u53e3\u97f3\u8f6c\u6362\u4e3a\u672c\u5730\u5316\u53e3\u97f3\uff0c\u5e76\u4e14\u4fdd\u8bc1\u8bf4\u8bdd\u4eba\u8eab\u4efd\u548c\u97f5\u5f8b\u7279\u5f81\uff0c\u6027\u80fd\u4e0e\u9876\u7ea7\u6a21\u578b\u6301\u5e73\uff0c\u540c\u65f6\u62e5\u6709\u7a33\u5b9a\u7684\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524d\u53e3\u97f3\u8f6c\u6362\uff08AC\uff09\u7cfb\u7edf\u96be\u4ee5\u5b9e\u65f6\u5904\u7406\u8bed\u97f3\u6d41\uff0c\u4e14\u9700\u8981\u5728\u6539\u5584\u53d1\u97f3\u3001\u4fdd\u6301\u8bf4\u8bdd\u4eba\u7279\u5f81\u548c\u97f5\u5f8b\u4e4b\u95f4\u6743\u8861\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u6d41\u5f0f\u5904\u7406\u7684\u9ad8\u6548\u53e3\u97f3\u8f6c\u6362\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9996\u4e2a\u652f\u6301\u6d41\u5f0f\u5904\u7406\u7684\u53e3\u97f3\u8f6c\u6362\u6a21\u578b\u3002\u901a\u8fc7\u5c06\u73b0\u6709AC\u67b6\u6784\u4e2d\u7684\u7f16\u7801\u5668\u66ff\u6362\u4e3aEmformer\uff0c\u5e76\u4f18\u5316\u63a8\u7406\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u6d41\u5f0f\u8bed\u97f3\u8f6c\u6362\u3002\u6b64\u5916\uff0c\u7ed3\u5408\u539f\u751fTTS\u6a21\u578b\u751f\u6210\u7406\u60f3\u7684\u8bad\u7ec3\u6570\u636e\u4ee5\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u8be5\u6d41\u5f0fAC\u6a21\u578b\u5728\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u9876\u7ea7AC\u6a21\u578b\u76f8\u5f53\uff0c\u662f\u9996\u4e2a\u652f\u6301\u6d41\u5f0f\u5904\u7406\u7684\u53e3\u97f3\u8f6c\u6362\u7cfb\u7edf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6d41\u5f0f\u53e3\u97f3\u8f6c\u6362\u6a21\u578b\uff0c\u4e0d\u4ec5\u6539\u5584\u4e86\u53d1\u97f3\uff0c\u4e14\u80fd\u591f\u5b9e\u65f6\u5904\u7406\u8f93\u5165\u8bed\u97f3\uff0c\u517c\u987e\u4e86\u8bf4\u8bdd\u4eba\u4fe1\u606f\u53ca\u97f5\u5f8b\u7b49\u591a\u4e2a\u56e0\u7d20\uff0c\u4e3a\u53e3\u97f3\u8f6c\u6362\u6280\u672f\u7684\u53d1\u5c55\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.16584", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 68T05", "I.2.7; I.2.6; I.5.1"], "pdf": "https://arxiv.org/pdf/2506.16584", "abs": "https://arxiv.org/abs/2506.16584", "authors": ["Nadav Kunievsky", "James A. Evans"], "title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework", "comment": null, "summary": "Understanding whether large language models (LLMs) possess a world model-a\nstructured understanding of the world that supports generalization beyond\nsurface-level patterns-is central to assessing their reliability, especially in\nhigh-stakes applications. We propose a formal framework for evaluating whether\nan LLM exhibits a sufficiently robust world model, defined as producing\nconsistent outputs across semantically equivalent prompts while distinguishing\nbetween prompts that express different intents. We introduce a new evaluation\napproach to measure this that decomposes model response variability into three\ncomponents: variability due to user purpose, user articulation, and model\ninstability. An LLM with a strong world model should attribute most of the\nvariability in its responses to changes in foundational purpose rather than\nsuperficial changes in articulation. This approach allows us to quantify how\nmuch of a model's behavior is semantically grounded rather than driven by model\ninstability or alternative wording. We apply this framework to evaluate LLMs\nacross diverse domains. Our results show how larger models attribute a greater\nshare of output variability to changes in user purpose, indicating a more\nrobust world model. This improvement is not uniform, however: larger models do\nnot consistently outperform smaller ones across all domains, and their\nadvantage in robustness is often modest. These findings highlight the\nimportance of moving beyond accuracy-based benchmarks toward semantic\ndiagnostics that more directly assess the structure and stability of a model's\ninternal understanding of the world.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u91cf\u5316LLM\u4e16\u754c\u6a21\u578b\u80fd\u529b\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u6cdb\u5316\u4e0e\u7a33\u5b9a\u6027\u63d0\u5347\u6709\u9650\uff0c\u5efa\u8bae\u672a\u6765\u8bc4\u6d4b\u5173\u6ce8\u6a21\u578b\u7684\u5185\u5728\u8bed\u4e49\u7406\u89e3\u800c\u975e\u5355\u4e00\u51c6\u786e\u7387\u3002", "motivation": "\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u5177\u5907\u201c\u4e16\u754c\u6a21\u578b\u201d\uff0c\u5373\u80fd\u652f\u6301\u8bed\u4e49\u6cdb\u5316\u3001\u7406\u89e3\u8d85\u8d8a\u8868\u5c42\u6a21\u5f0f\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u4f53\u7cfb\u3002\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u573a\u666f\uff0c\u8bc4\u4f30LLMs\u7684\u53ef\u9760\u6027\u6210\u4e3a\u5173\u952e\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6a21\u578b\u8f93\u51fa\u7684\u53d8\u5f02\u6027\uff08\u7528\u6237\u76ee\u7684\u3001\u8868\u8ff0\u65b9\u5f0f\u3001\u6a21\u578b\u81ea\u8eab\u4e0d\u7a33\u5b9a\u6027\uff09\u6765\u5224\u65adLLM\u662f\u5426\u5177\u6709\u7a33\u5065\u7684\u4e16\u754c\u6a21\u578b\u3002\u8bc4\u4f30\u65b9\u6cd5\u65e8\u5728\u68c0\u6d4b\u6a21\u578b\u662f\u5426\u80fd\u5bf9\u4e0d\u540c\u8bed\u4e49\u7684\u63d0\u793a\u8868\u73b0\u51fa\u5dee\u5f02\uff0c\u540c\u65f6\u5bf9\u8bed\u4e49\u7b49\u4ef7\u4f46\u8868\u8ff0\u4e0d\u540c\u7684\u63d0\u793a\u7ed9\u51fa\u4e00\u81f4\u8f93\u51fa\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5927\u6a21\u578b\u5728\u8f93\u51fa\u53d8\u5f02\u6027\u4e0a\uff0c\u66f4\u591a\u5f52\u56e0\u4e8e\u7528\u6237\u76ee\u7684\u7684\u53d8\u5316\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u4e16\u754c\u6a21\u578b\u80fd\u529b\u3002\u4f46\u8fd9\u4e00\u63d0\u5347\u5e76\u975e\u5728\u6240\u6709\u9886\u57df\u90fd\u660e\u663e\uff0c\u4e14\u5927\u578b\u6a21\u578b\u7684\u7a33\u5065\u6027\u4f18\u52bf\u591a\u6570\u60c5\u51b5\u4e0b\u4ec5\u4e3a\u9002\u5ea6\u63d0\u5347\u3002", "conclusion": "\u4ec5\u4f9d\u9760\u51c6\u786e\u7387\u7684\u57fa\u51c6\u8bc4\u6d4b\u5df2\u7ecf\u4e0d\u591f\uff0c\u672a\u6765\u5e94\u66f4\u5173\u6ce8\u6a21\u578b\u5185\u5728\u7406\u89e3\u4e16\u754c\u7ed3\u6784\u4e0e\u7a33\u5b9a\u6027\u7684\u8bed\u4e49\u5c42\u9762\u8bca\u65ad\u3002\u6846\u67b6\u63ed\u793a\u4e86\u6a21\u578b\u5728\u8bed\u4e49\u6cdb\u5316\u4e0e\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u771f\u5b9e\u8868\u73b0\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8LLMs\u8bc4\u6d4b\u66f4\u79d1\u5b66\u3001\u66f4\u8d34\u5408\u9ad8\u98ce\u9669\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2506.16594", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16594", "abs": "https://arxiv.org/abs/2506.16594", "authors": ["Hanshu Rao", "Weisi Liu", "Haohan Wang", "I-Chan Huang", "Zhe He", "Xiaolei Huang"], "title": "A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications", "comment": null, "summary": "Synthetic data generation--mitigating data scarcity, privacy concerns, and\ndata quality challenges in biomedical fields--has been facilitated by rapid\nadvances of large language models (LLMs). This scoping review follows\nPRISMA-ScR guidelines and synthesizes 59 studies, published between 2020 and\n2025 and collected from PubMed, ACM, Web of Science, and Google Scholar. The\nreview systematically examines biomedical research and application trends in\nsynthetic data generation, emphasizing clinical applications, methodologies,\nand evaluations. Our analysis identifies data modalities of unstructured texts\n(78.0%), tabular data (13.6%), and multimodal sources (8.4%); generation\nmethods of prompting (72.9%), fine-tuning (22.0%) LLMs and specialized model\n(5.1%); and heterogeneous evaluations of intrinsic metrics (27.1%),\nhuman-in-the-loop assessments (55.9%), and LLM-based evaluations (13.6%). The\nanalysis addresses current limitations in what, where, and how health\nprofessionals can leverage synthetic data generation for biomedical domains.\nOur review also highlights challenges in adaption across clinical domains,\nresource and model accessibility, and evaluation standardizations.", "AI": {"tldr": "\u7efc\u8ff0\u4e862020-2025\u5e74\u751f\u7269\u533b\u5b66\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7814\u7a76\u8fdb\u5c55\uff0c\u6307\u51fa\u5f53\u524d\u5e94\u7528\u591a\u96c6\u4e2d\u4e8e\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e0eprompt\u751f\u6210\uff0c\u4eba\u7c7b\u8bc4\u4ef7\u4e3a\u4e3b\u3002\u672a\u6765\u9700\u7a81\u7834\u6a21\u578b\u9002\u5e94\u6027\u3001\u53ef\u83b7\u5f97\u6027\u4e0e\u6807\u51c6\u5316\u7b49\u74f6\u9888\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u533b\u5b66\u9886\u57df\u5e7f\u6cdb\u5b58\u5728\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u6570\u636e\u8d28\u91cf\u7b49\u6311\u6218\u3002\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u9762\u7684\u5feb\u901f\u8fdb\u5c55\uff0c\u4e3a\u8be5\u9886\u57df\u5e26\u6765\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002\u8be5\u7efc\u8ff0\u65e8\u5728\u7cfb\u7edf\u68b3\u7406LLM\u9a71\u52a8\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5728\u751f\u7269\u533b\u5b66\u4e2d\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u73b0\u72b6\u3002", "method": "\u672c\u7efc\u8ff0\u9075\u5faaPRISMA-ScR\u6307\u5357\uff0c\u4ecePubMed\u3001ACM\u3001Web of Science\u548cGoogle Scholar\u6536\u96c62020\u81f32025\u5e74\u95f4\u53d1\u8868\u7684\u76f8\u5173\u6587\u732e\uff0c\u5171\u7eb3\u516559\u9879\u7814\u7a76\uff0c\u5bf9\u6587\u732e\u4e2d\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5e94\u7528\u3001\u65b9\u6cd5\u548c\u8bc4\u4f30\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u88ab\u7814\u7a76\u6570\u636e\u7c7b\u578b\u4e3b\u8981\u4e3a\u975e\u7ed3\u6784\u5316\u6587\u672c\uff0878.0%\uff09\u3001\u8868\u683c\u6570\u636e\uff0813.6%\uff09\u3001\u591a\u6a21\u6001\u6570\u636e\uff088.4%\uff09\uff1b\u5e38\u7528\u751f\u6210\u65b9\u6cd5\u5305\u62ecPrompting\uff0872.9%\uff09\u3001\u5fae\u8c03\uff0822.0%\uff09\u548c\u4e13\u7528\u6a21\u578b\uff085.1%\uff09\uff1b\u8bc4\u4f30\u65b9\u5f0f\u4e3b\u8981\u6709\u4eba\u7c7b\u8bc4\u4ef7\uff0855.9%\uff09\u3001\u5185\u5728\u6307\u6807\uff0827.1%\uff09\u548c\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u8bc4\u4ef7\uff0813.6%\uff09\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5df2\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u5f97\u5230\u521d\u6b65\u5e94\u7528\uff0c\u5c55\u73b0\u51fa\u8f83\u5927\u6f5c\u529b\uff0c\u4f46\u76ee\u524d\u5728\u8de8\u4e34\u5e8a\u9886\u57df\u9002\u5e94\u6027\u3001\u8d44\u6e90\u4e0e\u6a21\u578b\u53ef\u83b7\u5f97\u6027\u3001\u8bc4\u4f30\u65b9\u6cd5\u6807\u51c6\u5316\u7b49\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\u3002\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u8bc4\u4f30\u6807\u51c6\u7edf\u4e00\u548c\u6280\u672f\u666e\u53ca\u3002"}}
{"id": "2506.16622", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.16622", "abs": "https://arxiv.org/abs/2506.16622", "authors": ["Jiaxin Pei", "Dustin Wright", "Isabelle Augenstin", "David Jurgens"], "title": "Modeling Public Perceptions of Science in Media", "comment": null, "summary": "Effectively engaging the public with science is vital for fostering trust and\nunderstanding in our scientific community. Yet, with an ever-growing volume of\ninformation, science communicators struggle to anticipate how audiences will\nperceive and interact with scientific news. In this paper, we introduce a\ncomputational framework that models public perception across twelve dimensions,\nsuch as newsworthiness, importance, and surprisingness. Using this framework,\nwe create a large-scale science news perception dataset with 10,489 annotations\nfrom 2,101 participants from diverse US and UK populations, providing valuable\ninsights into public responses to scientific information across domains. We\nfurther develop NLP models that predict public perception scores with a strong\nperformance. Leveraging the dataset and model, we examine public perception of\nscience from two perspectives: (1) Perception as an outcome: What factors\naffect the public perception of scientific information? (2) Perception as a\npredictor: Can we use the estimated perceptions to predict public engagement\nwith science? We find that individuals' frequency of science news consumption\nis the driver of perception, whereas demographic factors exert minimal\ninfluence. More importantly, through a large-scale analysis and carefully\ndesigned natural experiment on Reddit, we demonstrate that the estimated public\nperception of scientific information has direct connections with the final\nengagement pattern. Posts with more positive perception scores receive\nsignificantly more comments and upvotes, which is consistent across different\nscientific information and for the same science, but are framed differently.\nOverall, this research underscores the importance of nuanced perception\nmodeling in science communication, offering new pathways to predict public\ninterest and engagement with scientific content.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u591a\u7ef4\u611f\u77e5\u5efa\u6a21\u4e0e\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u79d1\u5b66\u65b0\u95fb\u7684\u79ef\u6781\u611f\u77e5\u80fd\u591f\u663e\u8457\u9884\u6d4b\u516c\u4f17\u53c2\u4e0e\uff0c\u63a8\u8fdb\u4e86\u79d1\u5b66\u4f20\u64ad\u7684\u6548\u679c\u8bc4\u4f30\u4e0e\u4f18\u5316\u3002", "motivation": "\u79d1\u5b66\u4f20\u64ad\u8005\u96be\u4ee5\u9884\u6d4b\u516c\u4f17\u5982\u4f55\u770b\u5f85\u548c\u4e92\u52a8\u79d1\u5b66\u65b0\u95fb\uff0c\u800c\u6709\u6548\u7684\u516c\u4f17\u53c2\u4e0e\u5bf9\u4e8e\u5efa\u7acb\u5bf9\u79d1\u5b66\u7684\u4fe1\u4efb\u548c\u7406\u89e3\u81f3\u5173\u91cd\u8981\u3002\u4fe1\u606f\u4f53\u91cf\u8d8a\u6765\u8d8a\u5927\uff0c\u9884\u6d4b\u516c\u4f17\u611f\u77e5\u53d8\u5f97\u6108\u53d1\u56f0\u96be\uff0c\u56e0\u6b64\u4e9f\u9700\u65b0\u7684\u65b9\u6cd5\u5bf9\u516c\u4f17\u611f\u77e5\u8fdb\u884c\u7cfb\u7edf\u5efa\u6a21\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5efa\u6a21\u516c\u4f17\u611f\u77e5\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u6db5\u76d6\u4f8b\u5982\u65b0\u95fb\u4ef7\u503c\u3001\u91cd\u8981\u6027\u3001\u60ca\u5947\u6027\u7b4912\u4e2a\u7ef4\u5ea6\u3002\u57fa\u4e8e\u8be5\u6846\u67b6\u6784\u5efa\u4e86\u5305\u542b\u6765\u81ea\u7f8e\u56fd\u548c\u82f1\u56fd2,101\u4f4d\u53c2\u4e0e\u8005\u300110,489\u4e2a\u6ce8\u91ca\u7684\u5927\u89c4\u6a21\u79d1\u5b66\u65b0\u95fb\u611f\u77e5\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u51fa\u80fd\u591f\u9884\u6d4b\u611f\u77e5\u8bc4\u5206\u7684NLP\u6a21\u578b\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5927\u6570\u636e\u5206\u6790\u548cReddit\u7684\u81ea\u7136\u5b9e\u9a8c\uff0c\u63a2\u8ba8\u611f\u77e5\u7684\u5f71\u54cd\u56e0\u7d20\u53ca\u5176\u5bf9\u79d1\u5b66\u5185\u5bb9\u53c2\u4e0e\u5ea6\u7684\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u516c\u4f17\u5bf9\u79d1\u5b66\u65b0\u95fb\u7684\u611f\u77e5\u6700\u4e3b\u8981\u53d7\u5230\u5176\u83b7\u53d6\u79d1\u5b66\u65b0\u95fb\u9891\u7387\u7684\u5f71\u54cd\uff0c\u4eba\u53e3\u7edf\u8ba1\u56e0\u7d20\u5f71\u54cd\u8f83\u5c0f\u3002\u5229\u7528\u6784\u5efa\u7684\u6a21\u578b\u4e0e\u6570\u636e\uff0c\u53d1\u73b0\u5177\u6709\u66f4\u79ef\u6781\u611f\u77e5\u5206\u6570\u7684\u5e16\u5b50\u5728Reddit\u4e0a\u663e\u8457\u83b7\u5f97\u66f4\u591a\u8bc4\u8bba\u548c\u70b9\u8d5e\uff0c\u8fd9\u4e00\u73b0\u8c61\u5728\u4e0d\u540c\u79d1\u5b66\u5185\u5bb9\u548c\u4e0d\u540c\u8868\u8ff0\u65b9\u5f0f\u4e2d\u5747\u4e00\u81f4\u3002", "conclusion": "\u7ec6\u81f4\u5efa\u6a21\u516c\u4f17\u5bf9\u79d1\u5b66\u4fe1\u606f\u7684\u611f\u77e5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u516c\u4f17\u7684\u5174\u8da3\u4e0e\u53c2\u4e0e\u5ea6\uff0c\u4e3a\u79d1\u5b66\u4f20\u64ad\u63d0\u4f9b\u9884\u6d4b\u548c\u63d0\u5347\u516c\u4f17\u53c2\u4e0e\u7684\u65b0\u8def\u5f84\u3002"}}
{"id": "2506.16628", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16628", "abs": "https://arxiv.org/abs/2506.16628", "authors": ["Jianlin Shi", "Brian T. Bucher"], "title": "Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System", "comment": null, "summary": "Despite advances in machine learning (ML) and large language models (LLMs),\nrule-based natural language processing (NLP) systems remain active in clinical\nsettings due to their interpretability and operational efficiency. However,\ntheir manual development and maintenance are labor-intensive, particularly in\ntasks with large linguistic variability. To overcome these limitations, we\nproposed a novel approach employing LLMs solely during the rule-based systems\ndevelopment phase. We conducted the initial experiments focusing on the first\ntwo steps of developing a rule-based NLP pipeline: find relevant snippets from\nthe clinical note; extract informative keywords from the snippets for the\nrule-based named entity recognition (NER) component. Our experiments\ndemonstrated exceptional recall in identifying clinically relevant text\nsnippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.\nThis study sheds light on a promising new direction for NLP development,\nenabling semi-automated or automated development of rule-based systems with\nsignificantly faster, more cost-effective, and transparent execution compared\nwith deep learning model-based solutions.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u5f00\u53d1\u4e34\u5e8a\u57fa\u4e8e\u89c4\u5219\u7684NLP\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u5927\u5e45\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u8fd8\u63d0\u9ad8\u4e86\u53ec\u56de\u7387\u548c\u900f\u660e\u5ea6\uff0c\u4e3a\u76f8\u5173\u7cfb\u7edf\u5efa\u8bbe\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u4f18\u7684\u65b0\u9014\u5f84\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7531\u4e8e\u53ef\u89e3\u91ca\u6027\u548c\u9ad8\u6548\u6027\uff0c\u57fa\u4e8e\u89c4\u5219\u7684NLP\u7cfb\u7edf\u5728\u4e34\u5e8a\u9886\u57df\u4ecd\u7136\u88ab\u5e7f\u6cdb\u5e94\u7528\u3002\u7136\u800c\uff0c\u8fd9\u7c7b\u7cfb\u7edf\u7684\u624b\u52a8\u5f00\u53d1\u4e0e\u7ef4\u62a4\u975e\u5e38\u7e41\u7410\uff0c\u5c24\u5176\u5728\u9762\u5bf9\u9ad8\u5ea6\u8bed\u8a00\u591a\u6837\u6027\u7684\u4efb\u52a1\u65f6\u66f4\u662f\u5982\u6b64\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u5728\u57fa\u4e8e\u89c4\u5219NLP\u7cfb\u7edf\u5f00\u53d1\u9636\u6bb5\u5f15\u5165LLMs\uff0c\u4ec5\u5728\u5f00\u53d1\u671f\u95f4\u4f7f\u7528LLMs\u3002\u521d\u6b65\u5b9e\u9a8c\u805a\u7126\u4e8e\u57fa\u4e8e\u89c4\u5219NLP\u6d41\u6c34\u7ebf\u7684\u524d\u4e24\u4e2a\u6b65\u9aa4\uff1a\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u627e\u5230\u76f8\u5173\u7247\u6bb5\uff0c\u5e76\u4ece\u7247\u6bb5\u4e2d\u63d0\u53d6\u7528\u4e8e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u5173\u952e\u8bcd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528\u6240\u63d0\u65b9\u6cd5\u5728\u4e34\u5e8a\u76f8\u5173\u6587\u672c\u7247\u6bb5\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u51fa\u6781\u9ad8\u7684\u53ec\u56de\u7387\uff08Deepseek: 0.98, Qwen: 0.99\uff09\uff0c\u5728\u5173\u952e\u672f\u8bed\u63d0\u53d6\u7528\u4e8eNER\u65b9\u9762\u4e5f\u8fbe\u5230\u4e861.0\u7684\u53ec\u56de\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u65b9\u6cd5\u4e3aNLP\u7cfb\u7edf\u5f00\u53d1\u5f00\u8f9f\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u65b0\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u89c4\u5219\u7cfb\u7edf\u7684\u534a\u81ea\u52a8\u5316\u6216\u81ea\u52a8\u5316\u5f00\u53d1\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65b9\u6848\u66f4\u5feb\u901f\u3001\u7ecf\u6d4e\u4e14\u66f4\u5177\u900f\u660e\u6027\u3002"}}
{"id": "2506.16633", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.16633", "abs": "https://arxiv.org/abs/2506.16633", "authors": ["Fenghua Cheng", "Jinxiang Wang", "Sen Wang", "Zi Huang", "Xue Li"], "title": "GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View", "comment": null, "summary": "Multimodal reasoning is a process of understanding, integrating and inferring\ninformation across different data modalities. It has recently attracted surging\nacademic attention as a benchmark for Artificial Intelligence (AI). Although\nthere are various tasks for evaluating multimodal reasoning ability, they still\nhave limitations. Lack of reasoning on hierarchical visual clues at different\nlevels of granularity, e.g., local details and global context, is of little\ndiscussion, despite its frequent involvement in real scenarios. To bridge the\ngap, we introduce a novel and challenging task for multimodal reasoning, namely\nGeoGuess. Given a street view image, the task is to identify its location and\nprovide a detailed explanation. A system that succeeds in GeoGuess should be\nable to detect tiny visual clues, perceive the broader landscape, and associate\nwith vast geographic knowledge. Therefore, GeoGuess would require the ability\nto reason between hierarchical visual information and geographic knowledge. In\nthis work, we establish a benchmark for GeoGuess by introducing a specially\ncurated dataset GeoExplain which consists of\npanoramas-geocoordinates-explanation tuples. Additionally, we present a\nmultimodal and multilevel reasoning method, namely SightSense which can make\nprediction and generate comprehensive explanation based on hierarchy of visual\ninformation and external knowledge. Our analysis and experiments demonstrate\ntheir outstanding performance in GeoGuess.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8857\u666f\u5b9a\u4f4d\u548c\u8bf4\u660e\u4efb\u52a1GeoGuess\uff0c\u6784\u5efa\u4e13\u7528\u7684\u6570\u636e\u96c6\u548c\u591a\u5c42\u7ea7\u63a8\u7406\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\uff0c\u63a8\u52a8\u4e86\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u5728\u8bc4\u6d4b\u4e0a\u5b58\u5728\u7f3a\u9677\uff0c\u5c24\u5176\u662f\u5f88\u5c11\u5173\u6ce8\u5bf9\u4e0d\u540c\u7ec6\u7c92\u5ea6\u5c42\u7ea7\u7684\u89c6\u89c9\u7ebf\u7d22\u8fdb\u884c\u63a8\u7406\uff0c\u800c\u8fd9\u7c7b\u63a8\u7406\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u9891\u7e41\u51fa\u73b0\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u5bf9\u6b64\u7c7b\u591a\u5c42\u7ea7\u89c6\u89c9\u63a8\u7406\u7684\u8003\u91cf\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u4efb\u52a1GeoGuess\uff1a\u7cfb\u7edf\u9700\u6839\u636e\u8857\u666f\u56fe\u7247\u63a8\u6d4b\u5176\u62cd\u6444\u5730\u70b9\u5e76\u7ed9\u51fa\u8be6\u7ec6\u89e3\u91ca\u3002\u4e3a\u4e86\u652f\u6491\u8be5\u4efb\u52a1\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u5305\u542b\u5168\u666f\u56fe-\u5730\u7406\u5750\u6807-\u89e3\u91ca\u4e09\u5143\u7ec4\u7684\u6570\u636e\u96c6GeoExplain\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u65b9\u6cd5SightSense\uff0c\u80fd\u591f\u57fa\u4e8e\u5206\u5c42\u89c6\u89c9\u4fe1\u606f\u548c\u5916\u90e8\u5730\u7406\u77e5\u8bc6\u8fdb\u884c\u63a8\u7406\u548c\u89e3\u91ca\u751f\u6210\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u548c\u5b9e\u9a8c\uff0cGeoExplain\u6570\u636e\u96c6\u548cSightSense\u65b9\u6cd5\u5728GeoGuess\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "GeoGuess\u4efb\u52a1\u53ca\u5176\u914d\u5957\u6570\u636e\u96c6\u548c\u65b9\u6cd5\uff0c\u6709\u6548\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u5c42\u7ea7\u63a8\u7406\u4e0e\u5730\u7406\u77e5\u8bc6\u7ed3\u5408\u7684\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5bf9\u5b9e\u9645\u590d\u6742\u573a\u666f\u7684\u5904\u7406\u4e0e\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2506.16640", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16640", "abs": "https://arxiv.org/abs/2506.16640", "authors": ["Pavlo Vasylenko", "Marcos Treviso", "Andr\u00e9 F. T. Martins"], "title": "Long-Context Generalization with Sparse Attention", "comment": null, "summary": "Transformer-based architectures traditionally employ softmax to compute\nattention weights, which produces dense distributions over all tokens in a\nsequence. While effective in many settings, this density has been shown to be\ndetrimental for tasks that demand precise focus on fixed-size patterns: as\nsequence length increases, non-informative tokens accumulate attention\nprobability mass, leading to dispersion and representational collapse. We show\nin this paper that sparse attention mechanisms using $\\alpha$-entmax can avoid\nthese issues, due to their ability to assign exact zeros to irrelevant tokens.\nFurthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows\n$\\alpha$-entmax with a learnable temperature parameter, allowing the attention\ndistribution to interpolate between sparse (pattern-focused) and dense\n(softmax-like) regimes. Finally, we show that the ability to locate and\ngeneralize fixed-size patterns can be further improved through a careful design\nof position encodings, which impacts both dense and sparse attention methods.\nBy integrating ASEntmax into standard transformer layers alongside proper\npositional encodings, we show that our models greatly outperform softmax,\nscalable softmax, and fixed-temperature $\\alpha$-entmax baselines on\nlong-context generalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u9002\u5e94\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236ASEntmax\uff0c\u5e76\u4f18\u5316\u4f4d\u7f6e\u7f16\u7801\uff0c\u4f7fTransformer\u5728\u957f\u6587\u672c\u548c\u56fa\u5b9a\u6a21\u5f0f\u8bc6\u522b\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4f20\u7edfsoftmax\u548c\u5176\u5b83\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edfTransformer\u5229\u7528softmax\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u5bfc\u81f4\u6ce8\u610f\u529b\u5206\u5e03\u7a20\u5bc6\u3002\u5f53\u5e8f\u5217\u53d8\u957f\u65f6\uff0c\u5f88\u591a\u65e0\u5173token\u4e5f\u5206\u5f97\u6ce8\u610f\u529b\u6982\u7387\uff0c\u5bb9\u6613\u5bfc\u81f4\u8868\u5f81\u80fd\u529b\u4e0b\u964d\uff0c\u5c24\u5176\u5728\u9700\u8981\u5173\u6ce8\u56fa\u5b9a\u6a21\u5f0f\u4efb\u52a1\u65f6\u66f4\u4e3a\u660e\u663e\u3002", "method": "\u63d0\u51fa\u91c7\u7528\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236$\u0006alpha$-entmax\uff0c\u5b83\u80fd\u7ed9\u4e0d\u76f8\u5173token\u5206\u914d\u7cbe\u786e\u96f6\u6982\u7387\u3002\u8fdb\u4e00\u6b65\u63d0\u51faAdaptive-Scalable Entmax(ASEntmax)\uff0c\u4e3a$\u0006alpha$-entmax\u8bbe\u8ba1\u53ef\u5b66\u4e60\u7684\u6e29\u5ea6\u53c2\u6570\uff0c\u4f7f\u5176\u6ce8\u610f\u529b\u5206\u5e03\u80fd\u5728\u7a00\u758f\u4e0e\u7a20\u5bc6\u4e4b\u95f4\u81ea\u9002\u5e94\u3002\u8fd8\u4f18\u5316\u4e86\u4f4d\u7f6e\u7f16\u7801\u8bbe\u8ba1\uff0c\u63d0\u5347\u5bf9\u56fa\u5b9a\u6a21\u5f0f\u7684\u5b9a\u4f4d\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5c06ASEntmax\u4e0e\u6807\u51c6Transformer\u5c42\u548c\u4f18\u5316\u7684\u4f4d\u7f6e\u7f16\u7801\u7ed3\u5408\u540e\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u6cdb\u5316\u4efb\u52a1\u4e0a\uff0c\u6a21\u578b\u6027\u80fd\u5927\u5e45\u4f18\u4e8esoftmax\u3001scalable softmax\u4e0e\u56fa\u5b9a\u6e29\u5ea6\u7684$\u0006alpha$-entmax\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u7a00\u758f\u6ce8\u610f\u529b\u548c\u81ea\u9002\u5e94\u6e29\u5ea6\u53c2\u6570\u7684\u65b0\u65b9\u6cd5\uff08ASEntmax\uff09\uff0c\u914d\u5408\u5408\u9002\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u80fd\u6709\u6548\u63d0\u5347Transformer\u6a21\u578b\u5728\u957f\u5e8f\u5217\u548c\u56fa\u5b9a\u6a21\u5f0f\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2506.16655", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16655", "abs": "https://arxiv.org/abs/2506.16655", "authors": ["Co Tran", "Salman Paracha", "Adil Hafeez", "Shuguang Chen"], "title": "Arch-Router: Aligning LLM Routing with Human Preferences", "comment": null, "summary": "With the rapid proliferation of large language models (LLMs) -- each\noptimized for different strengths, style, or latency/cost profile -- routing\nhas become an essential technique to operationalize the use of different\nmodels. However, existing LLM routing approaches are limited in two key ways:\nthey evaluate performance using benchmarks that often fail to capture human\npreferences driven by subjective evaluation criteria, and they typically select\nfrom a limited pool of models. In this work, we propose a preference-aligned\nrouting framework that guides model selection by matching queries to\nuser-defined domains (e.g., travel) or action types (e.g., image editing) --\noffering a practical mechanism to encode preferences in routing decisions.\nSpecifically, we introduce \\textbf{Arch-Router}, a compact 1.5B model that\nlearns to map queries to domain-action preferences for model routing decisions.\nOur approach also supports seamlessly adding new models for routing without\nrequiring retraining or architectural modifications. Experiments on\nconversational datasets demonstrate that our approach achieves state-of-the-art\n(SOTA) results in matching queries with human preferences, outperforming top\nproprietary models. Our approach captures subjective evaluation criteria and\nmakes routing decisions more transparent and flexible. Our model is available\nat: \\texttt{https://huggingface.co/katanemo/Arch-Router-1.5B}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u5c06\u67e5\u8be2\u6839\u636e\u7528\u6237\u4e3b\u89c2\u504f\u597d\u8def\u7531\u5230\u6700\u4f73\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u8def\u7531\u5668Arch-Router\uff0c\u5e76\u5728\u4e3b\u89c2\u504f\u597d\u5339\u914d\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e3b\u6d41\u5546\u7528\u6a21\u578b\uff0c\u652f\u6301\u65e0\u7f1d\u6269\u5c55\u65b0\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8def\u7531\u65b9\u6cd5\u5728\u4e24\u4e2a\u65b9\u9762\u6709\u9650\uff1a\u4e00\u662f\u7528\u7684\u8bc4\u6d4b\u65b9\u6cd5\u96be\u4ee5\u53cd\u6620\u57fa\u4e8e\u4e3b\u89c2\u6807\u51c6\u7684\u4eba\u7c7b\u504f\u597d\uff0c\u4e8c\u662f\u53ef\u9009\u6a21\u578b\u79cd\u7c7b\u53d7\u9650\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u8868\u8fbe\u7528\u6237\u4f18\u5148\u7ea7\u3001\u4e14\u80fd\u7075\u6d3b\u9009\u62e9\u4e0d\u540c\u6a21\u578b\u7684\u8def\u7531\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u2018\u57fa\u4e8e\u504f\u597d\u5bf9\u9f50\u7684\u8def\u7531\u6846\u67b6\u2019\uff0c\u5c06\u67e5\u8be2\u6620\u5c04\u5230\u7528\u6237\u5b9a\u4e49\u7684\u9886\u57df\uff08\u5982\u65c5\u884c\uff09\u6216\u64cd\u4f5c\u7c7b\u578b\uff08\u5982\u56fe\u7247\u7f16\u8f91\uff09\uff0c\u5b9e\u73b0\u504f\u597d\u7684\u7f16\u7801\u3002\u5177\u4f53\u5b9e\u73b0\u4e3a\u4e00\u4e2a1.5B\u53c2\u6570\u7684Arch-Router\u6a21\u578b\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u6216\u7ed3\u6784\u4fee\u6539\u5373\u53ef\u652f\u6301\u65b0\u6a21\u578b\u63a5\u5165\u3002", "result": "\u5728\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5339\u914d\u67e5\u8be2\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86SOTA\u6548\u679c\uff0c\u8d85\u8fc7\u4e86\u4e3b\u6d41\u7684\u5546\u4e1a\u4e13\u6709\u6a21\u578b\uff0c\u63d0\u5347\u4e86\u8def\u7531\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Arch-Router\u6a21\u578b\u901a\u8fc7\u4e3b\u89c2\u504f\u597d\u5bf9\u9f50\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8def\u7531\uff0c\u652f\u6301\u9ad8\u6548\u7075\u6d3b\u5730\u5f15\u5165\u65b0\u6a21\u578b\uff0c\u5e76\u63d0\u5347\u8def\u7531\u51b3\u7b56\u7684\u900f\u660e\u5ea6\u4e0e\u5339\u914d\u6548\u679c\u3002"}}
{"id": "2506.16678", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16678", "abs": "https://arxiv.org/abs/2506.16678", "authors": ["Ananth Agarwal", "Jasper Jian", "Christopher D. Manning", "Shikhar Murty"], "title": "Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations", "comment": null, "summary": "Large Language Models (LLMs) exhibit a robust mastery of syntax when\nprocessing and generating text. While this suggests internalized understanding\nof hierarchical syntax and dependency relations, the precise mechanism by which\nthey represent syntactic structure is an open area within interpretability\nresearch. Probing provides one way to identify the mechanism of syntax being\nlinearly encoded in activations, however, no comprehensive study has yet\nestablished whether a model's probing accuracy reliably predicts its downstream\nsyntactic performance. Adopting a \"mechanisms vs. outcomes\" framework, we\nevaluate 32 open-weight transformer models and find that syntactic features\nextracted via probing fail to predict outcomes of targeted syntax evaluations\nacross English linguistic phenomena. Our results highlight a substantial\ndisconnect between latent syntactic representations found via probing and\nobservable syntactic behaviors in downstream tasks.", "AI": {"tldr": "\u63a2\u9488\u63ed\u793a\u7684\u53e5\u6cd5\u8868\u793a\u65e0\u6cd5\u6709\u6548\u9884\u6d4b\u5927\u6a21\u578b\u7684\u5b9e\u9645\u53e5\u6cd5\u80fd\u529b\uff0c\u6f5c\u5728\u673a\u5236\u4e0e\u5b9e\u9645\u8868\u73b0\u5b58\u5728\u660e\u663e\u8131\u8282\u3002", "motivation": "\u5c3d\u7ba1\u5927\u6a21\u578b\u5728\u53e5\u6cd5\u5904\u7406\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5185\u90e8\u5982\u4f55\u8868\u5f81\u53e5\u6cd5\u7ed3\u6784\u4ecd\u662f\u89e3\u91ca\u6027\u7814\u7a76\u7684\u5f00\u653e\u95ee\u9898\u3002\u63a2\u9488\u5206\u6790\u867d\u7136\u88ab\u5e7f\u6cdb\u7528\u4ee5\u63ed\u793a\u6a21\u578b\u5185\u90e8\u53e5\u6cd5\u8868\u793a\uff0c\u4f46\u76ee\u524d\u5c1a\u65e0\u7cfb\u7edf\u6027\u7814\u7a76\u8bc1\u5b9e\uff0c\u63a2\u9488\u51c6\u786e\u7387\u662f\u5426\u80fd\u591f\u53ef\u9760\u9884\u6d4b\u6a21\u578b\u7684\u4e0b\u6e38\u53e5\u6cd5\u6027\u80fd\u3002", "method": "\u672c\u6587\u91c7\u7528\u201c\u673a\u5236\u4e0e\u7ed3\u679c\u201d\u7684\u6846\u67b6\uff0c\u8bc4\u4f30\u4e8632\u4e2a\u5f00\u6e90Transformer\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u63a2\u9488\uff08probing\uff09\u6280\u672f\u63d0\u53d6\u6a21\u578b\u5185\u90e8\u7684\u53e5\u6cd5\u7279\u5f81\uff0c\u518d\u5c06\u8fd9\u4e9b\u7279\u5f81\u4e0e\u4e0b\u6e38\u7279\u5b9a\u53e5\u6cd5\u8bc4\u6d4b\u7684\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u63a2\u9488\u5f97\u5230\u7684\u53e5\u6cd5\u7279\u5f81\u96be\u4ee5\u9884\u6d4b\u6a21\u578b\u5728\u9762\u5411\u82f1\u8bed\u591a\u79cd\u8bed\u8a00\u73b0\u8c61\u7684\u4e0b\u6e38\u53e5\u6cd5\u8bc4\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u8868\u660e\u6a21\u578b\u6f5c\u5728\u8868\u793a\u548c\u5b9e\u9645\u8f93\u51fa\u53e5\u6cd5\u80fd\u529b\u95f4\u5b58\u5728\u663e\u8457\u65ad\u5c42\u3002", "conclusion": "\u901a\u8fc7\u5bf932\u4e2a\u5f00\u6e90Transformer\u6a21\u578b\u7684\u5206\u6790\uff0c\u7814\u7a76\u53d1\u73b0\uff0c\u7528\u63a2\u6d4b\u65b9\u6cd5\u5f97\u5230\u7684\u6f5c\u5728\u53e5\u6cd5\u7279\u5f81\uff0c\u5e76\u4e0d\u80fd\u5f88\u597d\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u9645\u53e5\u6cd5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u63a2\u6d4b\u5206\u6790\u4e0b\u83b7\u5f97\u7684\u6a21\u578b\u53e5\u6cd5\u77e5\u8bc6\u4e0e\u4e0b\u6e38\u53ef\u89c2\u6d4b\u7684\u53e5\u6cd5\u884c\u4e3a\u5b58\u5728\u8f83\u5927\u8131\u8282\u3002"}}
{"id": "2506.16692", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16692", "abs": "https://arxiv.org/abs/2506.16692", "authors": ["Hyunsoo Yun", "Eun Hak Lee"], "title": "LegiGPT: Party Politics and Transport Policy with Large Language Model", "comment": null, "summary": "Given the significant influence of lawmakers' political ideologies on\nlegislative decision-making, understanding their impact on policymaking is\ncritically important. We introduce a novel framework, LegiGPT, which integrates\na large language model (LLM) with explainable artificial intelligence (XAI) to\nanalyze transportation-related legislative proposals. LegiGPT employs a\nmulti-stage filtering and classification pipeline using zero-shot prompting\nwith GPT-4. Using legislative data from South Korea's 21st National Assembly,\nwe identify key factors - including sponsor characteristics, political\naffiliations, and geographic variables - that significantly influence\ntransportation policymaking. The LLM was used to classify\ntransportation-related bill proposals through a stepwise filtering process\nbased on keywords, phrases, and contextual relevance. XAI techniques were then\napplied to examine relationships between party affiliation and associated\nattributes. The results reveal that the number and proportion of conservative\nand progressive sponsors, along with district size and electoral population,\nare critical determinants shaping legislative outcomes. These findings suggest\nthat both parties contributed to bipartisan legislation through different forms\nof engagement, such as initiating or supporting proposals. This integrated\napproach provides a valuable tool for understanding legislative dynamics and\nguiding future policy development, with broader implications for infrastructure\nplanning and governance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLegiGPT\u6846\u67b6\uff0c\u5229\u7528GPT-4\u548cXAI\u5206\u6790\u97e9\u56fd\u4ea4\u901a\u7acb\u6cd5\uff0c\u63ed\u793a\u515a\u6d3e\u4e0e\u9009\u533a\u7279\u5f81\u5bf9\u7acb\u6cd5\u7ed3\u679c\u7684\u5173\u952e\u5f71\u54cd\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u4e0e\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u7acb\u6cd5\u8005\u7684\u653f\u6cbb\u610f\u8bc6\u5f62\u6001\u6781\u5927\u5f71\u54cd\u4e86\u7acb\u6cd5\u51b3\u7b56\uff0c\u56e0\u6b64\u7406\u89e3\u5176\u5bf9\u653f\u7b56\u5236\u5b9a\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u5de5\u5177\u6df1\u5165\u5206\u6790\u8fd9\u79cd\u5f71\u54cd\u673a\u5236\uff0c\u5c24\u5176\u5728\u4ea4\u901a\u653f\u7b56\u7acb\u6cd5\u9886\u57df\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6LegiGPT\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u76f8\u7ed3\u5408\uff0c\u5206\u6790\u4e0e\u4ea4\u901a\u76f8\u5173\u7684\u7acb\u6cd5\u63d0\u6848\u3002\u65b9\u6cd5\u5305\u62ec\u5229\u7528GPT-4\u8fdb\u884c\u96f6\u6837\u672c\u591a\u9636\u6bb5\u7b5b\u9009\u4e0e\u5206\u7c7b\uff0c\u901a\u8fc7\u9010\u6b65\u8fc7\u6ee4\uff08\u5173\u952e\u8bcd\u3001\u77ed\u8bed\u3001\u8bed\u5883\u76f8\u5173\u6027\uff09\u7504\u522b\u4ea4\u901a\u7c7b\u63d0\u6848\uff0c\u5e76\u7ed3\u5408XAI\u6280\u672f\u63a2\u7a76\u515a\u6d3e\u5c5e\u6027\u4e0e\u7acb\u6cd5\u7279\u5f81\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u901a\u8fc7\u5206\u6790\u97e9\u56fd\u7b2c21\u5c4a\u56fd\u4f1a\u7acb\u6cd5\u6570\u636e\uff0c\u53d1\u73b0\u4fdd\u5b88\u6d3e\u4e0e\u8fdb\u6b65\u6d3e\u63d0\u6848\u4eba\u6570\u91cf\u548c\u6bd4\u4f8b\u3001\u9009\u533a\u89c4\u6a21\u53ca\u9009\u6c11\u4eba\u6570\u662f\u5f71\u54cd\u7acb\u6cd5\u7ed3\u679c\u7684\u5173\u952e\u56e0\u7d20\u3002\u4e24\u515a\u90fd\u901a\u8fc7\u4e0d\u540c\u65b9\u5f0f\uff08\u5982\u53d1\u8d77\u6216\u652f\u6301\u63d0\u6848\uff09\u79ef\u6781\u53c2\u4e0e\u4e24\u515a\u5408\u4f5c\u7684\u7acb\u6cd5\u3002", "conclusion": "LegiGPT\u96c6\u6210LLM\u4e0eXAI\u4e3a\u7406\u89e3\u7acb\u6cd5\u52a8\u529b\u548c\u5236\u5b9a\u653f\u7b56\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u5bf9\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u6cbb\u7406\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.16712", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16712", "abs": "https://arxiv.org/abs/2506.16712", "authors": ["Bin Chen", "Xinzge Gao", "Chuanrui Hu", "Penghang Yu", "Hua Zhang", "Bing-Kun Bao"], "title": "ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models", "comment": null, "summary": "Generative Reward Models (GRMs) provide greater flexibility than scalar\nreward models in capturing human preferences, but their effectiveness is\nlimited by poor reasoning capabilities. This often results in incomplete or\noverly speculative reasoning paths, leading to hallucinations or missing key\ninformation in complex tasks. We address this challenge with ReasonGRM, a\nthree-stage generative reward modeling framework. In the first stage, Zero-RL\nis used to generate concise, outcome-directed reasoning paths that reduce the\nlikelihood of critical omissions. In the second stage, we introduce a novel\nevaluation metric, $R^\\star$, which scores reasoning paths based on their\ngeneration likelihood. This favors paths that reach correct answers with\nminimal exploration, helping to reduce hallucination-prone data during\ntraining. In the final stage, the model is further refined through\nreinforcement learning on challenging examples to enhance its preference\ndiscrimination capabilities. Experiments on three public benchmarks show that\nReasonGRM achieves competitive or state-of-the-art performance, outperforming\nprevious best GRMs by 1.8\\% on average and surpassing proprietary models such\nas GPT-4o by up to 5.6\\%. These results demonstrate the effectiveness of\nreasoning-aware training and highlight the importance of high-quality rationale\nselection for reliable preference modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u9636\u6bb5ReasonGRM\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u63a8\u7406\u8def\u5f84\u751f\u6210\u548c\u4f18\u5316\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\uff08GRMs\uff09\u5728\u6355\u6349\u4eba\u7c7b\u504f\u597d\u65b9\u9762\u6bd4\u6807\u91cf\u5956\u52b1\u6a21\u578b\u66f4\u7075\u6d3b\uff0c\u4f46\u7531\u4e8e\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u5bfc\u81f4\u63a8\u7406\u8def\u5f84\u4e0d\u5b8c\u6574\u3001\u8fc7\u5ea6\u81c6\u6d4b\uff0c\u8fdb\u800c\u9020\u6210\u5e7b\u89c9\u6216\u5173\u952e\u4fe1\u606f\u7f3a\u5931\uff0c\u5f71\u54cd\u4e86\u590d\u6742\u4efb\u52a1\u4e0b\u7684\u6548\u679c\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3GRMs\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u77ed\u677f\u3002", "method": "\u63d0\u51faReasonGRM\uff0c\u4e00\u4e2a\u4e09\u9636\u6bb5\u7684\u751f\u6210\u5f0f\u5956\u52b1\u5efa\u6a21\u6846\u67b6\u3002\u7b2c\u4e00\u9636\u6bb5\u7528Zero-RL\u751f\u6210\u7b80\u6d01\u4e14\u7ed3\u679c\u5bfc\u5411\u7684\u63a8\u7406\u8def\u5f84\u4ee5\u51cf\u5c11\u5173\u952e\u9057\u6f0f\u3002\u7b2c\u4e8c\u9636\u6bb5\u91c7\u7528\u65b0\u9896\u7684\u8bc4\u4ef7\u6307\u6807R*\uff0c\u4f9d\u636e\u751f\u6210\u6982\u7387\u5bf9\u63a8\u7406\u8def\u5f84\u6253\u5206\uff0c\u4f18\u5148\u9009\u62e9\u7528\u66f4\u5c11\u63a2\u7d22\u5c31\u80fd\u5f97\u5230\u6b63\u786e\u7b54\u6848\u7684\u8def\u5f84\uff0c\u51cf\u5c11\u8bad\u7ec3\u4e2d\u7684\u5e7b\u89c9\u6570\u636e\u3002\u7b2c\u4e09\u9636\u6bb5\u901a\u8fc7\u5728\u6311\u6218\u6027\u6837\u672c\u4e0a\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u5bf9\u504f\u597d\u7684\u533a\u5206\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u57fa\u51c6\u4e0a\uff0cReasonGRM\u8fbe\u5230\u4e86\u6709\u7ade\u4e89\u529b\u6216\u6700\u4f18\u7684\u8868\u73b0\uff0c\u5e73\u5747\u6bd4\u4e4b\u524d\u6700\u4f73\u7684GRMs\u9ad81.8%\uff0c\u6bd4GPT-4o\u7b49\u5546\u4e1a\u6a21\u578b\u9ad85.6%\u3002", "conclusion": "ReasonGRM\u901a\u8fc7\u63a8\u7406\u611f\u77e5\u8bad\u7ec3\u548c\u9ad8\u8d28\u91cf\u63a8\u7406\u8def\u5f84\u9009\u62e9\uff0c\u6709\u6548\u63d0\u5347\u4e86\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5f3a\u8c03\u4e86\u63a8\u7406\u8def\u5f84\u5728\u53ef\u9760\u504f\u597d\u5efa\u6a21\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.16724", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16724", "abs": "https://arxiv.org/abs/2506.16724", "authors": ["Xinyi Liu", "Weiguang Wang", "Hangfeng He"], "title": "The Role of Model Confidence on Bias Effects in Measured Uncertainties", "comment": null, "summary": "With the growing adoption of Large Language Models (LLMs) for open-ended\ntasks, accurately assessing epistemic uncertainty, which reflects a model's\nlack of knowledge, has become crucial to ensuring reliable outcomes. However,\nquantifying epistemic uncertainty in such tasks is challenging due to the\npresence of aleatoric uncertainty, which arises from multiple valid answers.\nWhile bias can introduce noise into epistemic uncertainty estimation, it may\nalso reduce noise from aleatoric uncertainty. To investigate this trade-off, we\nconduct experiments on Visual Question Answering (VQA) tasks and find that\nmitigating prompt-introduced bias improves uncertainty quantification in\nGPT-4o. Building on prior work showing that LLMs tend to copy input information\nwhen model confidence is low, we further analyze how these prompt biases affect\nmeasured epistemic and aleatoric uncertainty across varying bias-free\nconfidence levels with GPT-4o and Qwen2-VL. We find that all considered biases\ninduce greater changes in both uncertainties when bias-free model confidence is\nlower. Moreover, lower bias-free model confidence leads to greater\nunderestimation of epistemic uncertainty (i.e. overconfidence) due to bias,\nwhereas it has no significant effect on the direction of changes in aleatoric\nuncertainty estimation. These distinct effects deepen our understanding of bias\nmitigation for uncertainty quantification and potentially inform the\ndevelopment of more advanced techniques.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u63d0\u793a\u504f\u5dee\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u4e24\u7c7b\u4e0d\u786e\u5b9a\u6027\uff08\u8ba4\u77e5\u4e0e\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff09\u8bc4\u4f30\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u53bb\u9664\u63d0\u793a\u504f\u5dee\u80fd\u63d0\u5347\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8868\u73b0\uff0c\u4e14\u6a21\u578b\u4fe1\u5fc3\u8f83\u4f4e\u65f6\u504f\u5dee\u5f71\u54cd\u66f4\u5927\uff0c\u7279\u522b\u5bb9\u6613\u5bfc\u81f4\u5bf9\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u4f4e\u4f30\u3002\u8be5\u7ed3\u8bba\u6709\u52a9\u4e8e\u7406\u89e3\u504f\u5dee\u7f13\u89e3\u5728\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u4e2d\u7684\u4f5c\u7528\uff0c\u4e3a\u76f8\u5173\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u601d\u8def\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5f00\u653e\u5f0f\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u51c6\u786e\u8bc4\u4f30\u53cd\u6620\u6a21\u578b\u77e5\u8bc6\u7f3a\u4e4f\u7684\u201c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u201d\u53d8\u5f97\u975e\u5e38\u91cd\u8981\uff0c\u4ee5\u4fdd\u8bc1\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002\u7531\u4e8e\u4efb\u52a1\u4e2d\u5b58\u5728\u591a\u79cd\u6709\u6548\u7b54\u6848\uff0c\u6240\u4ee5\u201c\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u201d\u4f7f\u5f97\u8bc4\u4f30\u6311\u6218\u52a0\u5927\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u63d0\u793a\u504f\u5dee\u5bf9\u4e24\u7c7b\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u7684\u5f71\u54cd\u53ca\u5176\u6743\u8861\u3002", "method": "\u5728\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u4efb\u52a1\u4e0b\uff0c\u5b9e\u9a8c\u7814\u7a76\u6d88\u51cf\u63d0\u793a\uff08prompt\uff09\u5f15\u5165\u504f\u5dee\u5bf9GPT-4o\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5f71\u54cd\u3002\u8fdb\u4e00\u6b65\uff0c\u5bf9GPT-4o\u548cQwen2-VL\u6a21\u578b\uff0c\u5728\u4e0d\u540c\u53bb\u504f\u7f6e\u4fe1\u5fc3\u60c5\u51b5\u4e0b\uff0c\u5206\u6790\u5404\u79cd\u63d0\u793a\u504f\u5dee\u5bf9\u8ba4\u77e5\u4e0e\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u6d4b\u91cf\u7684\u5f71\u54cd\u3002", "result": "\uff081\uff09\u6d88\u51cf\u7531\u63d0\u793a\u5f15\u5165\u7684\u504f\u5dee\u53ef\u4ee5\u6539\u5584GPT-4o\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6548\u679c\uff1b\uff082\uff09\u5728\u4fe1\u5fc3\u8f83\u4f4e\u65f6\uff0c\u5404\u79cd\u504f\u5dee\u5bf9\u4e24\u7c7b\u4e0d\u786e\u5b9a\u6027\u7684\u53d8\u5316\u5f71\u54cd\u66f4\u5927\uff1b\uff083\uff09\u4fe1\u5fc3\u8d8a\u4f4e\u65f6\uff0c\u504f\u5dee\u5bfc\u81f4\u6a21\u578b\u5bf9\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u4f4e\u4f30\uff08\u5373\u8fc7\u5ea6\u81ea\u4fe1\uff09\uff0c\u4f46\u5bf9\u5076\u7136\u4e0d\u786e\u5b9a\u6027\u65e0\u663e\u8457\u65b9\u5411\u6027\u5f71\u54cd\u3002", "conclusion": "\u63d0\u793a\u504f\u5dee\u5bf9\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6709\u72ec\u7279\u4e14\u4e0d\u540c\u7684\u5f71\u54cd\u3002\u8ba4\u8bc6\u8fd9\u4e9b\u5f71\u54cd\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u5148\u8fdb\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u4e0e\u504f\u5dee\u7f13\u89e3\u6280\u672f\u3002"}}
{"id": "2506.16738", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16738", "abs": "https://arxiv.org/abs/2506.16738", "authors": ["Daejin Jo", "Jeeyoung Yun", "Byungseok Roh", "Sungwoong Kim"], "title": "LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization", "comment": null, "summary": "With the rapid progress of speech language models (SLMs), discrete speech\ntokens have emerged as a core interface between speech and text, enabling\nunified modeling across modalities. Recent speech tokenization approaches aim\nto isolate semantic information from low-level acoustics to better align with\nlanguage models. In particular, previous methods use SSL teachers such as\nHuBERT to extract semantic representations, which are then distilled into a\nsemantic quantizer to suppress acoustic redundancy as well as capture\ncontent-related latent structures. However, they still produce speech token\nsequences significantly longer than their textual counterparts, creating\nchallenges for efficient speech-language modeling. Reducing the frame rate is a\nnatural solution, but standard techniques, such as rigid average pooling across\nframes, can distort or dilute the semantic structure required for effective LM\nalignment. To address this, we propose LM-SPT, a speech tokenization method\nthat introduces a novel semantic distillation. Instead of directly matching\nteacher and student features via pooling, we reconstruct speech solely from\nsemantic tokens and minimize the discrepancy between the encoded\nrepresentations of the original and reconstructed waveforms, obtained from a\nfrozen automatic speech recognition (ASR) encoder. This indirect yet\ndata-driven supervision enables the tokenizer to learn discrete units that are\nmore semantically aligned with language models. LM-SPT further incorporates\narchitectural improvements to the encoder and decoder for speech tokenization,\nand supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz.\nExperimental results show that LM-SPT achieves superior reconstruction fidelity\ncompared to baselines, and that SLMs trained with LM-SPT tokens achieve\ncompetitive performances on speech-to-text and consistently outperform\nbaselines on text-to-speech tasks.", "AI": {"tldr": "LM-SPT\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u8bed\u97f3\u5206\u8bcd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u84b8\u998f\u53ca\u7ed3\u6784\u6539\u8fdb\uff0c\u5b9e\u73b0\u8bed\u97f3token\u66f4\u597d\u5730\u4e0e\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u5728\u591a\u79cd\u5e27\u7387\u548c\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u968f\u7740\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5982\u4f55\u5b9e\u73b0\u8bed\u97f3\u4e0e\u6587\u672c\u4e4b\u95f4\u66f4\u6709\u6548\u7684\u5bf9\u9f50\u6210\u4e3a\u6838\u5fc3\u95ee\u9898\u3002\u5f53\u524d\u8bed\u97f3\u5206\u8bcd\u65b9\u6cd5\u901a\u8fc7\u533a\u5206\u8bed\u4e49\u4fe1\u606f\u4e0e\u58f0\u5b66\u4fe1\u606f\u6765\u63d0\u9ad8\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u517c\u5bb9\u6027\uff0c\u4f46\u8bed\u97f3token\u5e8f\u5217\u901a\u5e38\u8fdc\u957f\u4e8e\u6587\u672c\uff0c\u5bf9\u5efa\u6a21\u6548\u7387\u9020\u6210\u6311\u6218\u3002\u964d\u4f4e\u5e27\u7387\u867d\u53ef\u7f29\u77ed\u5e8f\u5217\uff0c\u4f46\u5e38\u89c4\u6c60\u5316\u6cd5\u6613\u635f\u5bb3\u8bed\u4e49\u7ed3\u6784\u3002", "method": "\u672c\u6587\u63d0\u51faLM-SPT\u8bed\u97f3\u5206\u8bcd\u65b9\u6cd5\uff0c\u91c7\u7528\u65b0\u9896\u7684\u8bed\u4e49\u84b8\u998f\u7b56\u7565\uff1a\u975e\u76f4\u63a5\u5339\u914d\u6559\u5e08-\u5b66\u751f\u7279\u5f81\uff0c\u800c\u662f\u4ec5\u7528\u8bed\u4e49token\u91cd\u6784\u8bed\u97f3\uff0c\u5e76\u6700\u5c0f\u5316\u539f\u59cb\u4e0e\u91cd\u6784\u6ce2\u5f62\u7ecfASR\u7f16\u7801\u5668\u540e\u7684\u8868\u793a\u5dee\u5f02\u3002\u6b64\u5916\uff0c\u6539\u8fdb\u4e86\u5206\u8bcd\u5668\u7ed3\u6784\uff0c\u652f\u6301\u591a\u79cd\u5e27\u7387\uff0c\u63d0\u5347\u8bed\u97f3\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLM-SPT\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5177\u5907\u66f4\u9ad8\u7684\u91cd\u6784\u4fdd\u771f\u5ea6\u3002\u57fa\u4e8eLM-SPT token\u8bad\u7ec3\u7684SLM\u5728\u8bed\u97f3\u8f6c\u6587\u672c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u826f\uff0c\u4e14\u5728\u6587\u672c\u8f6c\u8bed\u97f3\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "LM-SPT\u901a\u8fc7\u95f4\u63a5\u3001\u6570\u636e\u9a71\u52a8\u7684\u8bed\u4e49\u5bf9\u9f50\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u97f3token\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\u6548\u679c\uff0c\u5728\u8de8\u6a21\u6001\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u8bed\u97f3token\u5e8f\u5217\u8fc7\u957f\u548c\u8bed\u4e49\u635f\u5931\u7684\u53cc\u91cd\u95ee\u9898\u3002"}}
{"id": "2506.16755", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16755", "abs": "https://arxiv.org/abs/2506.16755", "authors": ["Lance Ying", "Ryan Truong", "Katherine M. Collins", "Cedegao E. Zhang", "Megan Wei", "Tyler Brooke-Wilson", "Tan Zhi-Xuan", "Lionel Wong", "Joshua B. Tenenbaum"], "title": "Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly", "comment": "5 figures, 19 pages", "summary": "Drawing real world social inferences usually requires taking into account\ninformation from multiple modalities. Language is a particularly powerful\nsource of information in social settings, especially in novel situations where\nlanguage can provide both abstract information about the environment dynamics\nand concrete specifics about an agent that cannot be easily visually observed.\nIn this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a\nframework for drawing context-specific social inferences that integrate\nlinguistic and visual inputs. LIRAS frames multimodal social reasoning as a\nprocess of constructing structured but situation-specific agent and environment\nrepresentations - leveraging multimodal language models to parse language and\nvisual inputs into unified symbolic representations, over which a Bayesian\ninverse planning engine can be run to produce granular probabilistic judgments.\nOn a range of existing and new social reasoning tasks derived from cognitive\nscience experiments, we find that our model (instantiated with a comparatively\nlightweight VLM) outperforms ablations and state-of-the-art models in capturing\nhuman judgments across all domains.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86LIRAS\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u8bed\u8a00\u548c\u89c6\u89c9\u4fe1\u606f\u5e76\u8fdb\u884c\u8d1d\u53f6\u65af\u9006\u5411\u89c4\u5212\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u7b26\u5408\u4eba\u7c7b\u5224\u65ad\u7684\u793e\u4f1a\u63a8\u65ad\u80fd\u529b\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8d85\u8fc7\u73b0\u6709\u6700\u4f18\u6a21\u578b\u3002", "motivation": "\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\uff0c\u793e\u4f1a\u63a8\u65ad\u5f80\u5f80\u4f9d\u8d56\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5c24\u5176\u5728\u65b0\u5947\u60c5\u5883\u4e0b\u8bed\u8a00\u80fd\u5f25\u8865\u89c6\u89c9\u96be\u4ee5\u89c2\u6d4b\u7684\u4fe1\u606f\u3002\u76ee\u524d\u7f3a\u4e4f\u80fd\u6709\u6548\u6574\u5408\u8bed\u8a00\u548c\u89c6\u89c9\u8fdb\u884c\u793e\u4f1a\u63a8\u7406\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa LIRAS \u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u793e\u4f1a\u63a8\u7406\u5efa\u6a21\u4e3a\u6784\u5efa\u60c5\u5883\u5316\u7684\u4ee3\u7406\u4e0e\u73af\u5883\u8868\u793a\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u8bed\u8a00\u548c\u89c6\u89c9\u8f93\u5165\uff0c\u5e76\u5229\u7528\u8d1d\u53f6\u65af\u9006\u5411\u89c4\u5212\u8fdb\u884c\u6982\u7387\u6027\u63a8\u65ad\u3002", "result": "LIRAS \u5728\u591a\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u5b9e\u9a8c\u7684\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u4f18\u4e8e\u6d88\u878d\u6a21\u578b\u53ca\u5176\u5b83\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u66f4\u8d34\u8fd1\u4eba\u7c7b\u5224\u65ad\u3002", "conclusion": "LIRAS \u6846\u67b6\u80fd\u591f\u6574\u5408\u8bed\u8a00\u548c\u89c6\u89c9\u8f93\u5165\uff0c\u6709\u6548\u8fdb\u884c\u60c5\u5883\u76f8\u5173\u7684\u793e\u4f1a\u63a8\u65ad\uff0c\u5e76\u5728\u591a\u9879\u793e\u4f1a\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u548c\u6d88\u878d\u7248\u672c\u3002"}}
{"id": "2506.16756", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16756", "abs": "https://arxiv.org/abs/2506.16756", "authors": ["Zhuang Chen", "Yaru Cao", "Guanqun Bi", "Jincenzi Wu", "Jinfeng Zhou", "Xiyao Xiao", "Si Chen", "Hongning Wang", "Minlie Huang"], "title": "SocialSim: Towards Socialized Simulation of Emotional Support Conversation", "comment": "AAAI 2025 Paper #32116 (Without Publication Edits)", "summary": "Emotional support conversation (ESC) helps reduce people's psychological\nstress and provide emotional value through interactive dialogues. Due to the\nhigh cost of crowdsourcing a large ESC corpus, recent attempts use large\nlanguage models for dialogue augmentation. However, existing approaches largely\noverlook the social dynamics inherent in ESC, leading to less effective\nsimulations. In this paper, we introduce SocialSim, a novel framework that\nsimulates ESC by integrating key aspects of social interactions: social\ndisclosure and social awareness. On the seeker side, we facilitate social\ndisclosure by constructing a comprehensive persona bank that captures diverse\nand authentic help-seeking scenarios. On the supporter side, we enhance social\nawareness by eliciting cognitive reasoning to generate logical and supportive\nresponses. Building upon SocialSim, we construct SSConv, a large-scale\nsynthetic ESC corpus of which quality can even surpass crowdsourced ESC data.\nWe further train a chatbot on SSConv and demonstrate its state-of-the-art\nperformance in both automatic and human evaluations. We believe SocialSim\noffers a scalable way to synthesize ESC, making emotional care more accessible\nand practical.", "AI": {"tldr": "\u63d0\u51faSocialSim\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u793e\u4ea4\u62ab\u9732\u548c\u793e\u4f1a\u610f\u8bc6\u751f\u6210\u9ad8\u8d28\u91cf\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u6570\u636e\uff0c\u6240\u5408\u6210\u6570\u636e\u548c\u5bf9\u8bdd\u673a\u5668\u4eba\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63a8\u52a8\u60c5\u611f\u5173\u6000\u5bf9\u8bdd\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\uff08ESC\uff09\u80fd\u6709\u6548\u5e2e\u52a9\u4eba\u4eec\u51cf\u8f7b\u5fc3\u7406\u538b\u529b\uff0c\u4f46\u6784\u5efa\u5927\u89c4\u6a21ESC\u6570\u636e\u96c6\u7684\u4f17\u5305\u65b9\u5f0f\u6210\u672c\u5f88\u9ad8\uff0c\u4e14\u73b0\u6709\u5229\u7528\u5927\u6a21\u578b\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5ffd\u89c6\u4e86ESC\u4e2d\u7684\u793e\u4ea4\u52a8\u6001\uff0c\u5bfc\u81f4\u6a21\u62df\u6548\u679c\u6709\u9650\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86SocialSim\u6846\u67b6\uff0c\u5728\u6a21\u62dfESC\u65f6\u5f15\u5165\u4e86\u793e\u4ea4\u4e92\u52a8\u7684\u4e24\u4e2a\u5173\u952e\u8981\u7d20\uff1a\u793e\u4f1a\u62ab\u9732\uff08\u901a\u8fc7\u6784\u5efa\u591a\u6837\u4e14\u771f\u5b9e\u7684\u6c42\u52a9\u8005\u89d2\u8272\u5e93\uff09\u548c\u793e\u4f1a\u610f\u8bc6\uff08\u901a\u8fc7\u8ba4\u77e5\u63a8\u7406\u751f\u6210\u652f\u6301\u6027\u56de\u5e94\uff09\uff0c\u4ece\u800c\u63d0\u5347\u589e\u5f3a\u5bf9\u8bdd\u7684\u771f\u5b9e\u6027\u548c\u8d28\u91cf\u3002\u57fa\u4e8eSocialSim\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u5408\u6210ESC\u8bed\u6599\u5e93SSConv\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u804a\u5929\u673a\u5668\u4eba\u3002", "result": "SSConv\u8bed\u6599\u5e93\u5728\u8d28\u91cf\u4e0a\u751a\u81f3\u4f18\u4e8e\u4f17\u5305ESC\u8bed\u6599\uff0c\u57fa\u4e8e\u5176\u8bad\u7ec3\u7684\u5bf9\u8bdd\u673a\u5668\u4eba\u5728\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u6d4b\u4e2d\u5747\u8fbe\u5230\u6700\u65b0\u6700\u4f18\u6c34\u5e73\u3002", "conclusion": "SocialSim\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u5408\u6210ESC\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u6709\u671b\u5927\u5e45\u63d0\u5347\u60c5\u611f\u5173\u6000\u670d\u52a1\u7684\u53ef\u53ca\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.16760", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16760", "abs": "https://arxiv.org/abs/2506.16760", "authors": ["Lei Jiang", "Zixun Zhang", "Zizhou Wang", "Xiaobing Sun", "Zhen Li", "Liangli Zhen", "Xiaohua Xu"], "title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "comment": "15 pages, 9 figures", "summary": "Large Vision-Language Models (LVLMs) demonstrate exceptional performance\nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass\nbuilt-in safety mechanisms to elicit restricted content generation. Existing\nblack-box jailbreak methods primarily rely on adversarial textual prompts or\nimage perturbations, yet these approaches are highly detectable by standard\ncontent filtering systems and exhibit low query and computational efficiency.\nIn this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO),\na novel black-box jailbreak attack framework that decomposes malicious prompts\ninto semantically benign visual and textual fragments. By leveraging LVLMs'\ncross-modal reasoning abilities, CAMO covertly reconstructs harmful\ninstructions through multi-step reasoning, evading conventional detection\nmechanisms. Our approach supports adjustable reasoning complexity and requires\nsignificantly fewer queries than prior attacks, enabling both stealth and\nefficiency. Comprehensive evaluations conducted on leading LVLMs validate\nCAMO's effectiveness, showcasing robust performance and strong cross-model\ntransferability. These results underscore significant vulnerabilities in\ncurrent built-in safety mechanisms, emphasizing an urgent need for advanced,\nalignment-aware security and safety solutions in vision-language systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8de8\u6a21\u6001\u9ed1\u76d2\u653b\u51fb\uff08CAMO\uff09\uff0c\u901a\u8fc7\u5c06\u6076\u610f\u6307\u4ee4\u5206\u89e3\u4e3a\u826f\u6027\u56fe\u7247\u548c\u6587\u672c\u7247\u6bb5\uff0c\u5229\u7528LVLM\u63a8\u7406\u91cd\u7ec4\u540e\u9003\u907f\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u73b0\u6709\u5b89\u5168\u673a\u5236\u5b58\u5728\u91cd\u5927\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u5bb9\u6613\u88ab\u6240\u8c13\u7684jailbreak\u653b\u51fb\u7ed5\u8fc7\u5176\u5185\u7f6e\u5b89\u5168\u673a\u5236\uff0c\u4ece\u800c\u751f\u6210\u53d7\u9650\u5185\u5bb9\u3002\u76ee\u524d\u7684\u9ed1\u76d2jailbreak\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u5bf9\u6297\u6027\u7684\u6587\u672c\u63d0\u793a\u6216\u56fe\u50cf\u6270\u52a8\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5bb9\u6613\u88ab\u5e38\u89c4\u5185\u5bb9\u8fc7\u6ee4\u7cfb\u7edf\u68c0\u6d4b\uff0c\u6548\u7387\u8f83\u4f4e\u3002\u4f5c\u8005\u5e0c\u671b\u6539\u8fdb\u653b\u51fb\u7684\u9690\u853d\u6027\u548c\u6548\u7387\uff0c\u63ed\u793a\u73b0\u6709LVLM\u5b89\u5168\u673a\u5236\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCross-modal Adversarial Multimodal Obfuscation\uff08CAMO\uff09\u7684\u65b0\u578b\u9ed1\u76d2jailbreak\u653b\u51fb\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5c06\u6076\u610f\u6307\u4ee4\u5206\u89e3\u6210\u8bed\u4e49\u4e0a\u826f\u6027\u7684\u89c6\u89c9\u548c\u6587\u672c\u7247\u6bb5\uff0c\u5229\u7528LVLM\u7684\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u591a\u6b65\u63a8\u7406\u9690\u853d\u5730\u91cd\u6784\u6709\u5bb3\u6307\u4ee4\uff0c\u4ece\u800c\u89c4\u907f\u68c0\u6d4b\u3002\u8be5\u65b9\u6cd5\u53ef\u8c03\u8282\u63a8\u7406\u590d\u6742\u6027\uff0c\u67e5\u8be2\u6b21\u6570\u663e\u8457\u5c11\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u3002", "result": "\u5728\u4e3b\u6d41LVLMs\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\uff0cCAMO\u663e\u793a\u51fa\u5f3a\u5927\u7684\u653b\u51fb\u6709\u6548\u6027\u548c\u8de8\u6a21\u578b\u8fc1\u79fb\u80fd\u529b\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u7684\u5185\u5bb9\u8fc7\u6ee4\u548c\u5b89\u5168\u673a\u5236\u3002", "conclusion": "LVLM\u7684\u5185\u7f6e\u5b89\u5168\u673a\u5236\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c\u4f9d\u9760\u5bf9\u6297\u6027\u8f93\u5165\u5206\u89e3\u548c\u8de8\u6a21\u6001\u63a8\u7406\u7684\u653b\u51fb\u80fd\u591f\u9ad8\u6548\u4e14\u9690\u853d\u5730\u7ed5\u5f00\u8fd9\u4e9b\u9632\u62a4\u3002\u9700\u8981\u66f4\u52a0\u9ad8\u7ea7\u4e14\u5bf9\u9f50\u611f\u77e5\u7684\u5b89\u5168\u65b9\u6848\u6765\u62b5\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2506.16777", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.16777", "abs": "https://arxiv.org/abs/2506.16777", "authors": ["Heloisa Oss Boll", "Antonio Oss Boll", "Leticia Puttlitz Boll", "Ameen Abu Hanna", "Iacer Calixto"], "title": "DistillNote: LLM-based clinical note summaries improve heart failure diagnosis", "comment": null, "summary": "Large language models (LLMs) offer unprecedented opportunities to generate\nconcise summaries of patient information and alleviate the burden of clinical\ndocumentation that overwhelms healthcare providers. We present Distillnote, a\nframework for LLM-based clinical note summarization, and generate over 64,000\nadmission note summaries through three techniques: (1) One-step, direct\nsummarization, and a divide-and-conquer approach involving (2) Structured\nsummarization focused on independent clinical insights, and (3) Distilled\nsummarization that further condenses the Structured summaries. We test how\nuseful are the summaries by using them to predict heart failure compared to a\nmodel trained on the original notes. Distilled summaries achieve 79% text\ncompression and up to 18.2% improvement in AUPRC compared to an LLM trained on\nthe full notes. We also evaluate the quality of the generated summaries in an\nLLM-as-judge evaluation as well as through blinded pairwise comparisons with\nclinicians. Evaluations indicate that one-step summaries are favoured by\nclinicians according to relevance and clinical actionability, while distilled\nsummaries offer optimal efficiency (avg. 6.9x compression-to-performance ratio)\nand significantly reduce hallucinations. We release our summaries on PhysioNet\nto encourage future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDistillnote\u6846\u67b6\uff0c\u5229\u7528LLM\u591a\u79cd\u65b9\u5f0f\u751f\u6210\u4e34\u5e8a\u7b14\u8bb0\u6458\u8981\uff0c\u663e\u8457\u63d0\u9ad8\u6587\u6863\u538b\u7f29\u6548\u7387\uff0c\u540c\u65f6\u5728\u5fc3\u529b\u8870\u7aed\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002\u76f8\u5173\u4e34\u5e8a\u6570\u636e\u5df2\u5f00\u653e\uff0c\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u7cbe\u70bc\u60a3\u8005\u4fe1\u606f\u6458\u8981\u548c\u51cf\u8f7b\u533b\u7597\u6587\u6863\u8d1f\u62c5\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u5f53\u524d\u533b\u7597\u5de5\u4f5c\u8005\u9762\u5bf9\u7e41\u91cd\u7684\u4e34\u5e8a\u4e66\u5199\u4efb\u52a1\uff0c\u8be5\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u5347\u6587\u6863\u5904\u7406\u6548\u7387\u548c\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86Distillnote\u6846\u67b6\uff0c\u5229\u7528LLM\u8fdb\u884c\u4e34\u5e8a\u7b14\u8bb0\u603b\u7ed3\u3002\u65b9\u6cd5\u5305\u62ec\uff1a(1) \u4e00\u6b65\u76f4\u8bd1\uff08One-step\uff09\u603b\u7ed3\uff1b(2) \u9488\u5bf9\u72ec\u7acb\u4e34\u5e8a\u89c1\u89e3\u7684\u7ed3\u6784\u5316\uff08Structured\uff09\u603b\u7ed3\uff1b(3) \u8fdb\u4e00\u6b65\u538b\u7f29\u7ed3\u6784\u5316\u603b\u7ed3\u7684\u7cbe\u70bc\uff08Distilled\uff09\u603b\u7ed3\u3002\u4f7f\u7528\u751f\u6210\u7684\u6458\u8981\u6570\u636e\u8bc4\u4f30\u6a21\u578b\u5728\u5fc3\u529b\u8870\u7aed\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u53ca\u4e0e\u539f\u59cb\u4e34\u5e8a\u7b14\u8bb0\u6a21\u578b\u505a\u5bf9\u6bd4\uff0c\u540c\u65f6\u8fd8\u91c7\u7528LLM\u6253\u5206\u4e0e\u4e34\u5e8a\u533b\u751f\u53cc\u76f2\u914d\u5bf9\u5bf9\u6bd4\u8bc4\u4ef7\u603b\u7ed3\u8d28\u91cf\u3002", "result": "\u7cbe\u70bc\uff08Distilled\uff09\u603b\u7ed3\u5b9e\u73b0\u4e8679%\u7684\u6587\u672c\u538b\u7f29\u7387\uff0c\u5e76\u5728AUPRC\u6307\u6807\u4e0a\u6bd4\u7528\u539f\u59cb\u7b14\u8bb0\u8bad\u7ec3\u7684LLM\u63d0\u9ad8\u4e86\u6700\u591a18.2%\u3002\u4f7f\u7528LLM\u548c\u533b\u751f\u8bc4\u4f30\u53d1\u73b0\uff0c\u4e34\u5e8a\u533b\u751f\u66f4\u503e\u5411\u4e8e\u4e00\u6b65\u76f4\u8bd1\u603b\u7ed3\u7684\u76f8\u5173\u6027\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u4f46\u7cbe\u70bc\u603b\u7ed3\u5728\u6548\u7387\u548c\u51cf\u5c11\u5e7b\u89c9\uff08\u9519\u8bef\u5185\u5bb9\uff09\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "Distillnote\u901a\u8fc7\u4e0d\u540c\u5c42\u6b21\u7684LLM\u751f\u6210\u6458\u8981\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u4e34\u5e8a\u6587\u6863\u5904\u7406\u6548\u7387\uff0c\u5728\u5fc3\u529b\u8870\u7aed\u9884\u6d4b\u7b49\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u538b\u7f29\u5185\u5bb9\u540e\u4ecd\u53ef\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u8be5\u5de5\u4f5c\u4e3a\u672a\u6765\u81ea\u52a8\u5316\u533b\u7597\u6587\u6863\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u653e\u6570\u636e\u548c\u65b9\u6cd5\u3002"}}
{"id": "2506.16792", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16792", "abs": "https://arxiv.org/abs/2506.16792", "authors": ["Muyang Zheng", "Yuanzhi Yao", "Changting Lin", "Rui Wang", "Meng Han"], "title": "MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning", "comment": "12 pages, 3 figures", "summary": "Despite efforts to align large language models (LLMs) with societal and moral\nvalues, these models remain susceptible to jailbreak attacks--methods designed\nto elicit harmful responses. Jailbreaking black-box LLMs is considered\nchallenging due to the discrete nature of token inputs, restricted access to\nthe target LLM, and limited query budget. To address the issues above, we\npropose an effective method for jailbreaking black-box large language Models\nvia Iterative Semantic Tuning, named MIST. MIST enables attackers to\niteratively refine prompts that preserve the original semantic intent while\ninducing harmful content. Specifically, to balance semantic similarity with\ncomputational efficiency, MIST incorporates two key strategies: sequential\nsynonym search, and its advanced version--order-determining optimization.\nExtensive experiments across two open-source models and four closed-source\nmodels demonstrate that MIST achieves competitive attack success rates and\nattack transferability compared with other state-of-the-art white-box and\nblack-box jailbreak methods. Additionally, we conduct experiments on\ncomputational efficiency to validate the practical viability of MIST.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMIST\u65b9\u6cd5\uff0c\u53ef\u901a\u8fc7\u8bed\u4e49\u5fae\u8c03\u9ad8\u6548\u5730\u5b9e\u73b0\u5bf9\u9ed1\u76d2LLM\u7684\u8d8a\u72f1\u3002MIST\u5728\u591a\u79cd\u4e3b\u6d41\u6a21\u578b\u4e0a\u7684\u653b\u9632\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u4f18\u79c0\uff0c\u5e76\u517c\u987e\u653b\u51fb\u6210\u529f\u7387\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u5bf9LLM\u5b89\u5168\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7ecf\u8fc7\u4ef7\u503c\u5bf9\u9f50\u8bad\u7ec3\uff0c\u4f46\u4ecd\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u4ece\u800c\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\u3002\u5bf9\u4e8e\u9ed1\u76d2LLM\uff0c\u7531\u4e8e\u5176\u8f93\u5165\u662f\u79bb\u6563\u5b57\u7b26\u3001\u8bbf\u95ee\u53d7\u9650\u4e14\u67e5\u8be2\u6b21\u6570\u6709\u9650\uff0c\u8d8a\u72f1\u96be\u5ea6\u66f4\u5927\u3002", "method": "\u63d0\u51faMIST\u65b9\u6cd5\uff08Iterative Semantic Tuning\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bed\u4e49\u8c03\u6574\uff0c\u5728\u4fdd\u6301\u539f\u59cb\u8bed\u4e49\u610f\u56fe\u7684\u57fa\u7840\u4e0a\uff0c\u4f7fLLM\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u3002MIST\u7ed3\u5408\u4e86\u987a\u5e8f\u540c\u4e49\u8bcd\u641c\u7d22\u53ca\u5176\u4f18\u5316\u7248\u672c\uff08\u987a\u5e8f\u51b3\u5b9a\u4f18\u5316\uff09\uff0c\u4ee5\u5e73\u8861\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u4e24\u79cd\u5f00\u6e90\u6a21\u578b\u548c\u56db\u79cd\u95ed\u6e90\u6a21\u578b\u4e0a\uff0cMIST\u5728\u653b\u51fb\u6210\u529f\u7387\u548c\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\u65b9\u9762\u5747\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u76ee\u524d\u4e3b\u6d41\u767d\u76d2\u548c\u9ed1\u76d2\u8d8a\u72f1\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u5b9e\u9a8c\u8fd8\u9a8c\u8bc1\u4e86MIST\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "MIST\u4e3a\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u65b9\u6848\uff0c\u5bf9\u76ee\u524dAI\u5b89\u5168\u9886\u57df\u7684\u5bf9\u6297\u653b\u51fb\u4e0e\u9632\u5fa1\u5177\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2506.16912", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16912", "abs": "https://arxiv.org/abs/2506.16912", "authors": ["Daniel Christoph", "Max Ploner", "Patrick Haller", "Alan Akbik"], "title": "From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts", "comment": "Accepted to the First Workshop on Large Language Model Memorization\n  (L2M2), co-located with ACL 2025 in Vienna", "summary": "Sample efficiency is a crucial property of language models with practical\nimplications for training efficiency. In real-world text, information follows a\nlong-tailed distribution. Yet, we expect models to learn and recall frequent\nand infrequent facts. Sample-efficient models are better equipped to handle\nthis challenge of learning and retaining rare information without requiring\nexcessive exposure. This study analyzes multiple models of varying\narchitectures and sizes, all trained on the same pre-training data. By\nannotating relational facts with their frequencies in the training corpus, we\nexamine how model performance varies with fact frequency. Our findings show\nthat most models perform similarly on high-frequency facts but differ notably\non low-frequency facts. This analysis provides new insights into the\nrelationship between model architecture, size, and factual learning efficiency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9ad8\u9891\u548c\u4f4e\u9891\u4e8b\u5b9e\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9ad8\u9891\u4e8b\u5b9e\u5b66\u4e60\u76f8\u4f3c\uff0c\u4f46\u4f4e\u9891\u4e8b\u5b9e\u5b58\u5728\u660e\u663e\u5dee\u8ddd\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u67b6\u6784\u548c\u5927\u5c0f\u5bf9\u5b66\u4e60\u7a00\u6709\u77e5\u8bc6\u80fd\u529b\u7684\u4e0d\u540c\u5f71\u54cd\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u7684\u6837\u672c\u6548\u7387\u5bf9\u4e8e\u5b9e\u9645\u8bad\u7ec3\u6210\u672c\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u4fe1\u606f\u5206\u5e03\u5448\u957f\u5c3e\u7684\u771f\u5b9e\u6587\u672c\u73af\u5883\u4e0b\uff0c\u9700\u8981\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b66\u4e60\u5e76\u4fdd\u6301\u7f55\u89c1\u4e8b\u5b9e\u3002", "method": "\u5bf9\u4e0d\u540c\u67b6\u6784\u548c\u89c4\u6a21\u7684\u6a21\u578b\uff0c\u57fa\u4e8e\u540c\u4e00\u9884\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u7528\u4e8b\u5b9e\u5728\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387\u8fdb\u884c\u6807\u6ce8\uff0c\u8fdb\u800c\u8bc4\u4ef7\u6a21\u578b\u5728\u4e0d\u540c\u9891\u7387\u4e8b\u5b9e\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5927\u90e8\u5206\u6a21\u578b\u5728\u9ad8\u9891\u4e8b\u5b9e\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u5728\u4f4e\u9891\u4e8b\u5b9e\u8868\u73b0\u6709\u660e\u663e\u5dee\u5f02\uff0c\u4ece\u800c\u63ed\u793a\u4e86\u6a21\u578b\u67b6\u6784\u3001\u89c4\u6a21\u4e0e\u4e8b\u5b9e\u5b66\u4e60\u6548\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u6a21\u578b\u5728\u5b66\u4e60\u9ad8\u9891\u4e8b\u5b9e\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u4e0d\u5927\uff0c\u4f46\u5728\u4f4e\u9891\u4e8b\u5b9e\u7684\u5b66\u4e60\u4e0e\u4fdd\u6301\u80fd\u529b\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u533a\u522b\u3002"}}
{"id": "2506.16982", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.16982", "abs": "https://arxiv.org/abs/2506.16982", "authors": ["Antonin Berthon", "Mihaela van der Schaar"], "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond", "comment": null, "summary": "Accurately assessing student knowledge is critical for effective education,\nyet traditional Knowledge Tracing (KT) methods rely on opaque latent\nembeddings, limiting interpretability. Even LLM-based approaches generate\ndirect predictions or summaries that may hallucinate without any accuracy\nguarantees. We recast KT as an inverse problem: learning the minimum\nnatural-language summary that makes past answers explainable and future answers\npredictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM\nthat writes an interpretable knowledge summary and a frozen decoder LLM that\nmust reconstruct and predict student responses using only that summary text. By\nconstraining all predictive information to pass through a short\nnatural-language bottleneck, LBMs ensure that the summary contains accurate\ninformation while remaining human-interpretable. Experiments on synthetic\narithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the\naccuracy of state-of-the-art KT and direct LLM methods while requiring\norders-of-magnitude fewer student trajectories. We demonstrate that training\nthe encoder with group-relative policy optimization, using downstream decoding\naccuracy as a reward signal, effectively improves summary quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u8bed\u8a00\u74f6\u9888\u6a21\u578b\uff08LBM\uff09\u4ee5\u81ea\u7136\u8bed\u8a00\u6458\u8981\u89e3\u91ca\u548c\u9884\u6d4b\u5b66\u751f\u8868\u73b0\uff0c\u5728\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u6570\u636e\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u7684\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u65b9\u6cd5\u867d\u7136\u80fd\u8bc4\u4f30\u5b66\u751f\u77e5\u8bc6\uff0c\u4f46\u7531\u4e8e\u4f9d\u8d56\u96be\u4ee5\u89e3\u91ca\u7684\u9690\u5f0f\u5411\u91cf\u8868\u793a\uff0c\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002\u5373\u4fbf\u662f\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u4e5f\u5bb9\u6613\u4ea7\u751f\u865a\u6784\u5185\u5bb9\u4e14\u65e0\u6cd5\u4fdd\u8bc1\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u51c6\u786e\u7684\u77e5\u8bc6\u8ffd\u8e2a\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5c06\u77e5\u8bc6\u8ffd\u8e2a\u5efa\u6a21\u4e3a\u4e00\u4e2a\u9006\u95ee\u9898\uff1a\u901a\u8fc7\u5b66\u4e60\u6700\u7b80\u6d01\u7684\u81ea\u7136\u8bed\u8a00\u6458\u8981\uff0c\u4f7f\u5f97\u5b66\u751f\u7684\u5386\u53f2\u56de\u7b54\u80fd\u88ab\u89e3\u91ca\u4e14\u672a\u6765\u56de\u7b54\u53ef\u88ab\u9884\u6d4b\u3002\u5177\u4f53\u63d0\u51fa\u4e86\u201c\u8bed\u8a00\u74f6\u9888\u6a21\u578b\uff08LBM\uff09\u201d\uff0c\u5305\u62ec\u4e00\u4e2a\u7f16\u7801\u5668LLM\u7528\u4e8e\u751f\u6210\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\u6458\u8981\uff0c\u4ee5\u53ca\u4e00\u4e2a\u51bb\u7ed3\u7684\u89e3\u7801\u5668LLM\uff0c\u4ec5\u4ee5\u8be5\u6458\u8981\u91cd\u5efa\u548c\u9884\u6d4b\u5b66\u751f\u7b54\u9898\u60c5\u51b5\u3002\u901a\u8fc7\u8ba9\u6240\u6709\u9884\u6d4b\u4fe1\u606f\u4ec5\u901a\u8fc7\u7b80\u77ed\u6458\u8981\u4f20\u9012\uff0c\u4fdd\u8bc1\u4fe1\u606f\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6a21\u578b\u8bad\u7ec3\u4e2d\u91c7\u7528\u201c\u76f8\u5bf9\u5206\u7ec4\u7b56\u7565\u4f18\u5316\u201d\uff0c\u7528\u4e0b\u6e38\u89e3\u7801\u51c6\u786e\u7387\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u63d0\u5347\u6458\u8981\u8d28\u91cf\u3002", "result": "\u5728\u7b97\u672f\u7c7b\u5408\u6210\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21Eedi\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cLBM\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4e0e\u6700\u5148\u8fdb\u7684KT\u6216\u76f4\u63a5LLM\u65b9\u6cd5\u6301\u5e73\uff0c\u4f46\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u5b66\u751f\u7b54\u9898\u8f68\u8ff9\u6570\u636e\u91cf\u7684\u9700\u6c42\u3002\u4f7f\u7528\u5206\u7ec4\u7b56\u7565\u4f18\u5316\u80fd\u6709\u6548\u63d0\u5347\u6458\u8981\u7684\u8d28\u91cf\u548c\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8bed\u8a00\u74f6\u9888\u6a21\u578b\uff08LBM\uff09\u5728\u4fdd\u8bc1\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u6781\u5927\u63d0\u5347\u4e86\u77e5\u8bc6\u8ffd\u8e2a\u4efb\u52a1\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e14\u6240\u9700\u7684\u5b66\u751f\u6570\u636e\u66f4\u5c11\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.16990", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16990", "abs": "https://arxiv.org/abs/2506.16990", "authors": ["Sahil Kale", "Vijaykant Nadadur"], "title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs", "comment": "Accepted to the SDProc Workshop @ ACL 2025", "summary": "LaTeX's precision and flexibility in typesetting have made it the gold\nstandard for the preparation of scientific documentation. Large Language Models\n(LLMs) present a promising opportunity for researchers to produce\npublication-ready material using LaTeX with natural language instructions, yet\ncurrent benchmarks completely lack evaluation of this ability. By introducing\nTeXpert, our benchmark dataset with natural language prompts for generating\nLaTeX code focused on components of scientific documents across multiple\ndifficulty levels, we conduct an in-depth analysis of LLM performance in this\nregard and identify frequent error types. Our evaluation across open and\nclosed-source LLMs highlights multiple key findings: LLMs excelling on standard\nbenchmarks perform poorly in LaTeX generation with a significant accuracy\ndrop-off as the complexity of tasks increases; open-source models like DeepSeek\nv3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks;\nand formatting and package errors are unexpectedly prevalent, suggesting a lack\nof diverse LaTeX examples in the training datasets of most LLMs. Our dataset,\ncode, and model evaluations are available at\nhttps://github.com/knowledge-verse-ai/TeXpert.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faTeXpert\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u751f\u6210\u79d1\u5b66\u6587\u6863LaTeX\u4ee3\u7801\u7684\u80fd\u529b\u3002\u7ed3\u679c\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u6b64\u9879\u4efb\u52a1\u8868\u73b0\u6709\u9650\uff0c\u9519\u8bef\u5982\u683c\u5f0f\u548c\u5305\u7ba1\u7406\u666e\u904d\u3002\u5f00\u6e90\u6a21\u578b\u7ade\u4e89\u529b\u5f3a\u3002TeXpert\u4e3a\u63d0\u5347LLM\u8f85\u52a9\u79d1\u5b66\u5199\u4f5c\u5960\u5b9a\u4e86\u8bc4\u6d4b\u57fa\u7840\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u4ee5\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210LaTeX\u4ee3\u7801\uff0c\u5e2e\u52a9\u79d1\u7814\u5199\u4f5c\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4e13\u95e8\u8bc4\u4f30LLM\u751f\u6210LaTeX\u80fd\u529b\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86TeXpert\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u9488\u5bf9\u79d1\u5b66\u6587\u6863\u4e0d\u540c\u96be\u5ea6\u7ec4\u4ef6\u7684\u81ea\u7136\u8bed\u8a00\u63d0\u793a\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u4e2aLLM\uff08\u5305\u62ec\u5f00\u6e90\u4e0e\u95ed\u6e90\u6a21\u578b\uff09\u5728LaTeX\u4ee3\u7801\u751f\u6210\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1\u67d0\u4e9bLLM\u5728\u73b0\u6709\u901a\u7528\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728LaTeX\u4ee3\u7801\u751f\u6210\u4e0a\u51c6\u786e\u7387\u660e\u663e\u4e0b\u964d\uff0c\u5c24\u5176\u662f\u4efb\u52a1\u590d\u6742\u5ea6\u63d0\u5347\u65f6\u3002\u5f00\u6e90\u6a21\u578b\uff08\u5982DeepSeek v3\u4e0eDeepSeek Coder\uff09\u5728LaTeX\u4efb\u52a1\u4e0a\u4e0e\u95ed\u6e90\u6a21\u578b\u8868\u73b0\u76f8\u5f53\u3002\u6b64\u5916\uff0c\u683c\u5f0f\u548c\u5305\u7ba1\u7406\u9519\u8bef\u5e38\u89c1\uff0c\u53cd\u6620\u51fa\u5927\u591a\u6570\u6a21\u578b\u8bad\u7ec3\u96c6\u4e2dLaTeX\u793a\u4f8b\u591a\u6837\u6027\u4e0d\u8db3\u3002", "conclusion": "TeXpert\u6570\u636e\u96c6\u7cfb\u7edf\u63ed\u793a\u4e86LLM\u5728LaTeX\u751f\u6210\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u6539\u8fdb\u8bad\u7ec3\u6570\u636e\u548c\u8bc4\u6d4b\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u63d0\u5347LLM\u5728\u79d1\u5b66\u5199\u4f5c\u81ea\u52a8\u5316\u9886\u57df\u7684\u5b9e\u9645\u6548\u7528\u3002"}}
{"id": "2506.17001", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.17001", "abs": "https://arxiv.org/abs/2506.17001", "authors": ["Mikhail Menschikov", "Dmitry Evseev", "Ruslan Kostoev", "Ilya Perepechkin", "Ilnaz Salimov", "Victoria Dochkina", "Petr Anokhin", "Evgeny Burnaev", "Nikita Semenov"], "title": "PersonalAI: Towards digital twins in the graph form", "comment": null, "summary": "The challenge of personalizing language models, specifically the ability to\naccount for a user's history during interactions, is of significant interest.\nDespite recent advancements in large language models (LLMs) and Retrieval\nAugmented Generation that have enhanced the factual base of LLMs, the task of\nretaining extensive personal information and using it to generate personalized\nresponses remains pertinent. To address this, we propose utilizing external\nmemory in the form of knowledge graphs, which are constructed and updated by\nthe LLM itself. We have expanded upon ideas of AriGraph architecture and for\nthe first time introduced a combined graph featuring both standard edges and\ntwo types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and\nDiaASQ benchmarks indicates that this approach aids in making the process of\ngraph construction and knowledge extraction unified and robust. Furthermore, we\naugmented the DiaASQ benchmark by incorporating parameters such as time into\ndialogues and introducing contradictory statements made by the same speaker at\ndifferent times. Despite these modifications, the performance of the\nquestion-answering system remained robust, demonstrating the proposed\narchitecture's ability to maintain and utilize temporal dependencies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdLLM\u81ea\u6784\u5efa\u548c\u66f4\u65b0\u7684\u77e5\u8bc6\u56fe\u8c31\uff08\u5e26\u8d85\u8fb9\uff09\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u4fe1\u606f\u5b58\u50a8\u3001\u63d0\u53d6\u53ca\u65f6\u95f4\u5173\u7cfb\u5904\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\u3002", "motivation": "\u4e2a\u6027\u5316\u8bed\u8a00\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u4e92\u52a8\u4e2d\u80fd\u591f\u987e\u53ca\u7528\u6237\u5386\u53f2\u4fe1\u606f\uff0c\u662f\u5f53\u524d\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e8b\u5b9e\u638c\u63e1\u80fd\u529b\uff0c\u4f46\u6301\u7eed\u5b58\u50a8\u548c\u5229\u7528\u5927\u91cf\u4e2a\u4eba\u4fe1\u606f\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u56de\u590d\u4ecd\u662f\u4e00\u5927\u96be\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5229\u7528\u5916\u90e8\u5185\u5b58\u2014\u2014\u7531LLMs\u81ea\u884c\u6784\u5efa\u548c\u66f4\u65b0\u7684\u77e5\u8bc6\u56fe\u8c31\u6765\u89e3\u51b3\u4e0a\u8ff0\u6311\u6218\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u6269\u5c55\u4e86AriGraph\u67b6\u6784\uff0c\u9996\u6b21\u5f15\u5165\u6807\u51c6\u8fb9\u4e0e\u4e24\u7c7b\u8d85\u8fb9\u76f8\u7ed3\u5408\u7684\u56fe\u7ed3\u6784\uff0c\u7528\u4e8e\u7edf\u4e00\u548c\u589e\u5f3a\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u4e0e\u77e5\u8bc6\u62bd\u53d6\u8fc7\u7a0b\u3002", "result": "\u5728TriviaQA\u3001HotpotQA\u548cDiaASQ\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u5b9e\u73b0\u56fe\u7ed3\u6784\u6784\u5efa\u4e0e\u77e5\u8bc6\u62bd\u53d6\u7684\u7edf\u4e00\u548c\u5065\u58ee\u6027\u3002\u53e6\u5916\uff0c\u4f5c\u8005\u8fd8\u589e\u5f3a\u4e86DiaASQ\u57fa\u51c6\u6570\u636e\u96c6\uff1a\u5982\u5f15\u5165\u5bf9\u8bdd\u65f6\u95f4\u53c2\u6570\u53ca\u540c\u4e00\u8bf4\u8bdd\u4eba\u5728\u4e0d\u540c\u65f6\u95f4\u7684\u77db\u76fe\u9648\u8ff0\u3002\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u95ee\u7b54\u7cfb\u7edf\u5bf9\u8fd9\u4e9b\u53d8\u5316\u5177\u6709\u5f88\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u6709\u6548\u7ef4\u62a4\u548c\u5229\u7528\u65f6\u5e8f\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7ed3\u5408\u6807\u51c6\u8fb9\u4e0e\u591a\u79cd\u8d85\u8fb9\u7684\u77e5\u8bc6\u56fe\u8c31\u67b6\u6784\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u5bf9\u8bdd\u4e2d\u7684\u4fe1\u606f\u5b58\u50a8\u4e0e\u5229\u7528\u80fd\u529b\uff0c\u8fd8\u5c55\u73b0\u51fa\u5728\u5904\u7406\u590d\u6742\u65f6\u5e8f\u548c\u81ea\u76f8\u77db\u76fe\u4fe1\u606f\u4e0a\u7684\u6027\u80fd\u7a33\u5b9a\u6027\uff0c\u56e0\u6b64\u5bf9\u4e2a\u6027\u5316LLM\u7cfb\u7edf\u5177\u5907\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2506.17006", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.17006", "abs": "https://arxiv.org/abs/2506.17006", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Shambhavi Bhushan", "Erin Gatz", "Shivang Gupta", "Kenneth R. Koedinger"], "title": "LLM-Generated Feedback Supports Learning If Learners Choose to Use It", "comment": "Full research paper accepted at EC-TEL '25", "summary": "Large language models (LLMs) are increasingly used to generate feedback, yet\ntheir impact on learning remains underexplored, especially compared to existing\nfeedback methods. This study investigates how on-demand LLM-generated\nexplanatory feedback influences learning in seven scenario-based tutor training\nlessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we\ncompare posttest performance among learners across three groups: learners who\nreceived feedback generated by gpt-3.5-turbo, those who declined it, and those\nwithout access. All groups received non-LLM corrective feedback. To address\npotential selection bias-where higher-performing learners may be more inclined\nto use LLM feedback-we applied propensity scoring. Learners with a higher\npredicted likelihood of engaging with LLM feedback scored significantly higher\nat posttest than those with lower propensity. After adjusting for this effect,\ntwo out of seven lessons showed statistically significant learning benefits\nfrom LLM feedback with standardized effect sizes of 0.28 and 0.33. These\nmoderate effects suggest that the effectiveness of LLM feedback depends on the\nlearners' tendency to seek support. Importantly, LLM feedback did not\nsignificantly increase completion time, and learners overwhelmingly rated it as\nhelpful. These findings highlight LLM feedback's potential as a low-cost and\nscalable way to improve learning on open-ended tasks, particularly in existing\nsystems already providing feedback without LLMs. This work contributes open\ndatasets, LLM prompts, and rubrics to support reproducibility.", "AI": {"tldr": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u5bfc\u5e08\u57f9\u8bad\u8bfe\u7a0b\uff0c\u53d1\u73b0\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u53cd\u9988\u6709\u52a9\u4e8e\u63a8\u52a8\u90e8\u5206\u8bfe\u7a0b\u7684\u5b66\u4e60\u6210\u679c\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5bf9\u4e3b\u52a8\u5bfb\u6c42\u5e2e\u52a9\u7684\u5b66\u4e60\u8005\uff0c\u4e14\u4e0d\u663e\u8457\u589e\u52a0\u5b66\u4e60\u65f6\u95f4\uff0c\u5177\u5907\u4f4e\u6210\u672c\u9ad8\u53ef\u6269\u5c55\u6027\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u6765\u751f\u6210\u5b66\u4e60\u53cd\u9988\u4fe1\u606f\uff0c\u4f46\u5173\u4e8e\u5176\u5b9e\u9645\u5bf9\u5b66\u4e60\u6210\u6548\u7684\u5f71\u54cd\u4ecd\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u5c24\u5176\u4e0e\u73b0\u6709\u7684\u53cd\u9988\u65b9\u5f0f\u76f8\u6bd4\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5bf9\u4e03\u4e2a\u57fa\u4e8e\u60c5\u666f\u7684\u5bfc\u5e08\u57f9\u8bad\u8bfe\u7a0b\u4e2d\u76842,600\u591a\u6b21\u8bfe\u7a0b\u5b8c\u6210\u60c5\u51b5\uff08\u5171885\u540d\u5b66\u4e60\u8005\uff09\u8fdb\u884c\u5206\u6790\u3002\u4f9d\u636e\u53cd\u9988\u83b7\u53d6\u65b9\u5f0f\u5c06\u5b66\u4e60\u8005\u5206\u4e3a\u4e09\u7ec4\uff1a\u4f7f\u7528GPT-3.5-turbo\u751f\u6210\u53cd\u9988\u7684\u7ec4\u3001\u62d2\u7edd\u4f7f\u7528LLM\u53cd\u9988\u7684\u7ec4\u53ca\u672a\u63a5\u89e6LLM\u53cd\u9988\u7684\u5bf9\u7167\u7ec4\uff08\u6240\u6709\u7ec4\u90fd\u83b7\u5f97\u975eLLM\u7ea0\u6b63\u6027\u53cd\u9988\uff09\u3002\u901a\u8fc7\u503e\u5411\u8bc4\u5206\u8c03\u6574\u9009\u62e9\u504f\u5dee\uff0c\u6bd4\u8f83\u5404\u7ec4\u8bfe\u540e\u6d4b\u8bd5\u8868\u73b0\u3002", "result": "\u503e\u5411\u4e8e\u4f7f\u7528LLM\u53cd\u9988\u7684\u5b66\u4e60\u8005\uff0c\u8bfe\u540e\u6d4b\u8bd5\u6210\u7ee9\u663e\u8457\u9ad8\u4e8e\u4e0d\u592a\u4f7f\u7528LLM\u53cd\u9988\u7684\u5b66\u4e60\u8005\u3002\u5728\u6821\u6b63\u504f\u5dee\u540e\uff0c\u4e03\u95e8\u8bfe\u7a0b\u4e2d\u6709\u4e24\u95e8\u663e\u793aLLM\u53cd\u9988\u5bf9\u5b66\u4e60\u6210\u6548\u5b58\u5728\u7edf\u8ba1\u663e\u8457\u63d0\u5347\uff08\u6548\u5e94\u91cf\u5206\u522b\u4e3a0.28\u548c0.33\uff09\uff0c\u4f46\u65e0\u663e\u8457\u589e\u52a0\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\uff0c\u4e14\u5b66\u4e60\u8005\u666e\u904d\u8ba4\u4e3aLLM\u53cd\u9988\u6709\u5e2e\u52a9\u3002", "conclusion": "LLM\u751f\u6210\u7684\u53cd\u9988\uff0c\u7279\u522b\u662f\u89e3\u91ca\u6027\u53cd\u9988\uff0c\u5bf9\u6709\u5bfb\u6c42\u652f\u6301\u503e\u5411\u7684\u5b66\u4e60\u8005\u80fd\u591f\u5e26\u6765\u4e2d\u7b49\u5f3a\u5ea6\u7684\u5b66\u4e60\u6210\u6548\u63d0\u5347\uff0c\u5bf9\u63d0\u5347\u5f00\u653e\u4efb\u52a1\u5b66\u4e60\u6548\u679c\u6709\u6f5c\u529b\uff0c\u540c\u65f6\u6548\u7387\u9ad8\u3001\u6210\u672c\u4f4e\uff0c\u9002\u5b9c\u96c6\u6210\u81f3\u73b0\u6709\u53cd\u9988\u7cfb\u7edf\u3002\u8bba\u6587\u8fd8\u8d21\u732e\u4e86\u5f00\u653e\u6570\u636e\u96c6\u3001LLM\u63d0\u793a\u8bcd\u4e0e\u8bc4\u5206\u91cf\u8868\uff0c\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2506.17019", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17019", "abs": "https://arxiv.org/abs/2506.17019", "authors": ["Giuseppe Attanasio", "Sonal Sannigrahi", "Ben Peters", "Andr\u00e9 F. T. Martins"], "title": "Instituto de Telecomunica\u00e7\u00f5es at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning", "comment": "7 pages, 1 figure, IWSLT 2025", "summary": "This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on\nInstruction Following Speech Processing. We submit results for the Short Track,\ni.e., speech recognition, translation, and spoken question answering. Our model\nis a unified speech-to-text model that integrates a pre-trained continuous\nspeech encoder and text decoder through a first phase of modality alignment and\na second phase of instruction fine-tuning. Crucially, we focus on using\nsmall-scale language model backbones (< 2B) and restrict to high-quality, CC-BY\ndata along with synthetic data generation to supplement existing resources.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e00\u79cd\u5c0f\u6a21\u578b\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u9a71\u52a8\u7684\u7edf\u4e00\u8bed\u97f3\u5230\u6587\u672c\u6a21\u578b\uff0c\u5e76\u5728IWSLT 2025\u591a\u4efb\u52a1\u8d5b\u9053\u4e0a\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u8fd1\u5e74\u6765\u6307\u4ee4\u5f0f\u8bed\u97f3\u5904\u7406\u4efb\u52a1\u6108\u53d1\u53d7\u5230\u5173\u6ce8\uff0cIWSLT 2025\u4e3e\u529e\u76f8\u5173\u7ade\u8d5b\uff0c\u4ee5\u63a8\u52a8\u96c6\u6210\u5316\u3001\u591a\u4efb\u52a1\u8bed\u97f3\u5230\u6587\u672c\u7cfb\u7edf\u6280\u672f\u8fdb\u6b65\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u590d\u7528\u7684\u7edf\u4e00\u6a21\u578b\u9002\u5e94\u5b9e\u9645\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bed\u97f3\u5230\u6587\u672c\u6a21\u578b\uff0c\u4e3b\u8981\u5206\u4e24\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5bf9\u8bed\u97f3\u7f16\u7801\u5668\u548c\u6587\u672c\u89e3\u7801\u5668\u8fdb\u884c\u6a21\u6001\u5bf9\u9f50\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\u3002\u6240\u7528\u7684\u6a21\u578b\u4ec5\u91c7\u7528\u53c2\u6570\u91cf\u5c0f\u4e8e2B\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4e25\u683c\u9650\u5236\u8bad\u7ec3\u6570\u636e\u4e3a\u9ad8\u8d28\u91cf\u3001\u5f00\u653e\u8bb8\u53ef\u7684CC-BY\u6570\u636e\uff0c\u540c\u65f6\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5f3a\u3002", "result": "\u8be5\u56e2\u961f\u5728IWSLT 2025\u6307\u4ee4\u5f0f\u8bed\u97f3\u5904\u7406\u4efb\u52a1\u7684Short Track\uff08\u5305\u62ec\u8bed\u97f3\u8bc6\u522b\u3001\u7ffb\u8bd1\u548c\u53e3\u8bed\u95ee\u7b54\uff09\u4e2d\u63d0\u4ea4\u4e86\u6a21\u578b\u7ed3\u679c\uff0c\u5c55\u73b0\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u4e0b\u7684\u9002\u5e94\u6027\u548c\u9ad8\u6548\u6027\u3002", "conclusion": "\u4ee5\u5c0f\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u4e0e\u5c0f\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u4e3a\u57fa\u7840\uff0c\u901a\u8fc7\u6a21\u6001\u5bf9\u9f50\u548c\u6307\u4ee4\u5fae\u8c03\uff0c\u53ef\u5b9e\u73b0\u7edf\u4e00\u5e76\u9ad8\u6548\u7684\u8bed\u97f3\u5230\u6587\u672c\u591a\u4efb\u52a1\u5904\u7406\u6a21\u578b\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u573a\u666f\u7684\u8d44\u6e90\u9650\u5236\u6761\u4ef6\u3002"}}
{"id": "2506.17046", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17046", "abs": "https://arxiv.org/abs/2506.17046", "authors": ["Xiaolong Wang", "Zhaolu Kang", "Wangyuxuan Zhai", "Xinyue Lou", "Yunghwei Lai", "Ziyue Wang", "Yawen Wang", "Kaiyu Huang", "Yile Wang", "Peng Li", "Yang Liu"], "title": "MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\nadvances across numerous vision-language tasks. Due to their strong image-text\nalignment capability, MLLMs can effectively understand image-text pairs with\nclear meanings. However, effectively resolving the inherent ambiguities in\nnatural language and visual contexts remains challenging. Existing multimodal\nbenchmarks typically overlook linguistic and visual ambiguities, relying mainly\non unimodal context for disambiguation and thus failing to exploit the mutual\nclarification potential between modalities. To bridge this gap, we introduce\nMUCAR, a novel and challenging benchmark designed explicitly for evaluating\nmultimodal ambiguity resolution across multilingual and cross-modal scenarios.\nMUCAR includes: (1) a multilingual dataset where ambiguous textual expressions\nare uniquely resolved by corresponding visual contexts, and (2) a\ndual-ambiguity dataset that systematically pairs ambiguous images with\nambiguous textual contexts, with each combination carefully constructed to\nyield a single, clear interpretation through mutual disambiguation. Extensive\nevaluations involving 19 state-of-the-art multimodal models--encompassing both\nopen-source and proprietary architectures--reveal substantial gaps compared to\nhuman-level performance, highlighting the need for future research into more\nsophisticated cross-modal ambiguity comprehension methods, further pushing the\nboundaries of multimodal reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMUCAR\u57fa\u51c6\uff0c\u4e13\u7528\u4e8e\u8bc4\u6d4b\u591a\u6a21\u6001\u6b67\u4e49\u6d88\u89e3\u80fd\u529b\u3002\u901a\u8fc7\u591a\u8bed\u79cd\u4e0e\u53cc\u5411\u6b67\u4e49\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u4e8619\u4e2a\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5747\u8fdc\u900a\u4e8e\u4eba\u7c7b\u8868\u73b0\uff0c\u672a\u6765\u9700\u5728\u591a\u6a21\u6001\u6b67\u4e49\u7406\u89e3\u4e0a\u5f00\u5c55\u66f4\u591a\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u56fe\u6587\u4efb\u52a1\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5bf9\u672c\u8eab\u542b\u7cca\u6216\u6b67\u4e49\u7684\u81ea\u7136\u8bed\u8a00\u548c\u89c6\u89c9\u5185\u5bb9\u7406\u89e3\u529b\u4e0d\u8db3\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u96c6\u51e0\u4e4e\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u6b67\u4e49\u7684\u8003\u5bdf\uff0c\u7f3a\u4e4f\u901a\u8fc7\u591a\u6a21\u6001\u4e92\u76f8\u6d88\u9664\u6b67\u4e49\u7684\u4efb\u52a1\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u4e86MUCAR\u57fa\u51c6\uff1a1\uff09\u5305\u542b\u591a\u8bed\u79cd\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u5883\u552f\u4e00\u89e3\u6790\u6587\u672c\u6b67\u4e49\uff1b2\uff09\u6784\u5efa\u53cc\u91cd\u6b67\u4e49\u96c6\uff0c\u5c06\u6b67\u4e49\u56fe\u7247\u4e0e\u6b67\u4e49\u6587\u672c\u6210\u5bf9\u7ec4\u5408\uff0c\u4ec5\u901a\u8fc7\u4e8c\u8005\u4ea4\u4e92\u53ef\u5f97\u552f\u4e00\u660e\u786e\u89e3\u91ca\u3002\u5229\u752819\u4e2a\u591a\u6a21\u6001SOTA\u6a21\u578b\u5f00\u5c55\u7cfb\u7edf\u8bc4\u6d4b\u3002", "result": "\u73b0\u670919\u4e2a\u591a\u6a21\u6001SOTA\u6a21\u578b\u5728\u8be5\u57fa\u51c6\u4e0b\u4e0e\u4eba\u7c7b\u6c34\u5e73\u5b58\u5728\u660e\u663e\u5dee\u8ddd\uff0c\u53cd\u6620\u51fa\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u826f\u597d\u5904\u7406\u8de8\u6a21\u6001\u6b67\u4e49\u6d88\u89e3\u95ee\u9898\u3002", "conclusion": "MUCAR\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5904\u7406\u6b67\u4e49\u80fd\u529b\u7684\u4e0d\u8db3\uff0c\u8868\u660e\u672a\u6765\u9700\u5f00\u53d1\u66f4\u590d\u6742\u4e14\u6709\u6548\u7684\u8de8\u6a21\u6001\u6b67\u4e49\u7406\u89e3\u65b9\u6cd5\uff0c\u4ee5\u63a8\u52a8\u591a\u6a21\u6001\u63a8\u7406\u4e0e\u7406\u89e3\u7684\u8fb9\u754c\u3002"}}
{"id": "2506.17077", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17077", "abs": "https://arxiv.org/abs/2506.17077", "authors": ["Dominik Mach\u00e1\u010dek", "Peter Pol\u00e1k"], "title": "Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025", "comment": "IWSLT 2025", "summary": "This paper describes Charles University submission to the Simultaneous Speech\nTranslation Task of the IWSLT 2025. We cover all four language pairs with a\ndirect or cascade approach. The backbone of our systems is the offline Whisper\nspeech model, which we use for both translation and transcription in\nsimultaneous mode with the state-of-the-art simultaneous policy AlignAtt. We\nfurther improve the performance by prompting to inject in-domain terminology,\nand we accommodate context. Our cascaded systems further use EuroLLM for\nunbounded simultaneous translation. Compared to the Organizers' baseline, our\nsystems improve by 2 BLEU points on Czech to English and 13-22 BLEU points on\nEnglish to German, Chinese and Japanese on the development sets. Additionally,\nwe also propose a new enhanced measure of speech recognition latency.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u67e5\u7406\u5927\u5b66\u5728IWSLT 2025\u591a\u8bed\u8a00\u540c\u65f6\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u7684\u7cfb\u7edf\uff0c\u91c7\u7528Whisper\u4e0eAlignAtt\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5728\u591a\u8bed\u8a00\u65b9\u5411\u663e\u8457\u63d0\u5347BLEU\u6210\u7ee9\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u5ef6\u8fdf\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u63d0\u5347IWSLT 2025\u540c\u671f\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u7cfb\u7edf\u6027\u80fd\uff0c\u514b\u670d\u73b0\u6709\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u548c\u5ef6\u8fdf\u65b9\u9762\u7684\u5c40\u9650\u3002", "method": "\u91c7\u7528Whisper\u79bb\u7ebf\u8bed\u97f3\u6a21\u578b\uff0c\u901a\u8fc7\u76f4\u63a5\u6216\u7ea7\u8054\u7cfb\u7edf\u8fdb\u884c\u591a\u8bed\u79cd\uff08\u5171\u56db\u79cd\u8bed\u8a00\u5bf9\uff09\u540c\u65f6\u7ffb\u8bd1\uff0c\u5e76\u91c7\u7528AlignAtt\u524d\u6cbf\u540c\u65f6\u7ffb\u8bd1\u7b56\u7565\u4f18\u5316\u6a21\u578b\u3002\u5728\u7ea7\u8054\u7cfb\u7edf\u4e2d\u7ed3\u5408EuroLLM\u5b9e\u73b0\u65e0\u754c\u540c\u65f6\u7ffb\u8bd1\uff0c\u5e76\u901a\u8fc7prompt\u65b9\u6cd5\u6ce8\u5165\u9886\u57df\u4e13\u5c5e\u672f\u8bed\u5e76\u5bf9\u4e0a\u4e0b\u6587\u8fdb\u884c\u5904\u7406\u3002\u540c\u65f6\u63d0\u51fa\u65b0\u7684\u8bed\u97f3\u8bc6\u522b\u5ef6\u8fdf\u8bc4\u6d4b\u65b9\u6cd5\u3002", "result": "\u4e0e\u7ec4\u7ec7\u8005\u57fa\u7ebf\u7cfb\u7edf\u76f8\u6bd4\uff0c\u6377\u514b\u8bed\u5230\u82f1\u8bed\u63d0\u53472\u4e2aBLEU\uff0c\u82f1\u8bed\u5230\u5fb7\u8bed\u3001\u4e2d\u6587\u3001\u65e5\u8bed\u63d0\u534713\u523022\u4e2aBLEU\u3002\u8fd8\u63d0\u51fa\u4e86\u65b0\u7684\u65f6\u5ef6\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u6240\u63d0\u51fa\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u540c\u65f6\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\uff0c\u5e76\u80fd\u6709\u6548\u5f15\u5165\u672f\u8bed\u548c\u4e0a\u4e0b\u6587\u3002\u8fd8\u5e26\u6765\u4e86\u66f4\u5148\u8fdb\u7684\u5ef6\u8fdf\u6d4b\u8bc4\u65b9\u6cd5\u3002"}}
{"id": "2506.17080", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17080", "abs": "https://arxiv.org/abs/2506.17080", "authors": ["Ricardo Rei", "Nuno M. Guerreiro", "Jos\u00e9 Pombal", "Jo\u00e3o Alves", "Pedro Teixeirinha", "Amin Farajian", "Andr\u00e9 F. T. Martins"], "title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs", "comment": null, "summary": "Fine-tuning pretrained LLMs has been shown to be an effective strategy for\nreaching state-of-the-art performance on specific tasks like machine\ntranslation. However, this process of adaptation often implies sacrificing\ngeneral-purpose capabilities, such as conversational reasoning and\ninstruction-following, hampering the utility of the system in real-world\napplications that require a mixture of skills. In this paper, we introduce\nTower+, a suite of models designed to deliver strong performance across both\ntranslation and multilingual general-purpose text capabilities. We achieve a\nPareto frontier between translation specialization and multilingual\ngeneral-purpose capabilities by introducing a novel training recipe that builds\non Tower (Alves et al., 2024), comprising continued pretraining, supervised\nfine-tuning, preference optimization, and reinforcement learning with\nverifiable rewards. At each stage of training, we carefully generate and curate\ndata to strengthen performance on translation as well as general-purpose tasks\ninvolving code generation, mathematics problem solving, and general\ninstruction-following. We develop models at multiple scales: 2B, 9B, and 72B.\nOur smaller models often outperform larger general-purpose open-weight and\nproprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers\nbest-in-class translation performance for high-resource languages and top\nresults in multilingual Arena Hard evaluations and in IF-MT, a benchmark we\nintroduce for evaluating both translation and instruction-following. Our\nfindings highlight that it is possible to rival frontier models in general\ncapabilities, while optimizing for specific business domains, such as\ntranslation and localization.", "AI": {"tldr": "Tower+\u6a21\u578b\u901a\u8fc7\u521b\u65b0\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5728\u4e0d\u635f\u5931\u901a\u7528\u80fd\u529b\u7684\u524d\u63d0\u4e0b\u5927\u5e45\u63d0\u5347\u4e86\u7ffb\u8bd1\u7b49\u4e13\u7cbe\u4efb\u52a1\u8868\u73b0\uff0c\u5c0f\u578b\u6a21\u578b\u5df2\u8d85\u8d8a\u540c\u7c7b\u4ea7\u54c1\uff0c\u6700\u5927\u6a21\u578b\u5728\u591a\u9879\u9886\u57df\u6811\u7acb\u65b0\u6807\u6746\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u5b9e\u73b0\u4efb\u52a1\u4e0a\u7684\u51fa\u8272\u8868\u73b0\u5f80\u5f80\u4ee5\u727a\u7272\u901a\u7528\u80fd\u529b\u4e3a\u4ee3\u4ef7\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u9700\u8981\u591a\u80fd\u529b\u7684\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u8bba\u6587\u65e8\u5728\u7a81\u7834\u8be5\u56f0\u5883\uff0c\u5bfb\u6c42\u63d0\u5347\u6a21\u578b\u4e13\u7cbe\u4efb\u52a1\u4e0e\u901a\u7528\u80fd\u529b\u7684\u6700\u4f73\u5e73\u8861\u3002", "method": "\u57fa\u4e8eTower\u67b6\u6784\uff0c\u91c7\u7528\u4e86\u4e00\u5957\u521b\u65b0\u8bad\u7ec3\u7b56\u7565\uff0c\u5305\u62ec\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u3001\u504f\u597d\u4f18\u5316\u548c\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u3002\u5728\u6bcf\u4e00\u9636\u6bb5\u7cbe\u5fc3\u6784\u5efa\u6570\u636e\u96c6\uff0c\u63d0\u5347\u7ffb\u8bd1\u3001\u4ee3\u7801\u751f\u6210\u3001\u6570\u5b66\u9898\u6c42\u89e3\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u591a\u9879\u80fd\u529b\u3002\u6a21\u578b\u5f00\u53d1\u6db5\u76d62B\u30019B\u53ca72B\u591a\u79cd\u89c4\u6a21\uff0c\u5e76\u5728\u4e0d\u540c\u9636\u6bb5\u5747\u91cd\u89c6\u591a\u80fd\u529b\u517c\u987e\u3002", "result": "Tower+\u5c0f\u578b\u6a21\u578b\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u89c4\u6a21\u66f4\u5927\u7684\u5f00\u653e\u6216\u5546\u7528\u6a21\u578b\uff08\u5982Llama 3 70B\u3001GPT-4o\uff09\uff0c\u800c\u6700\u5927\u6a21\u578b\u5728\u9ad8\u8d44\u6e90\u8bed\u79cd\u7ffb\u8bd1\u3001Multilingual Arena Hard\u8bc4\u6d4b\u4ee5\u53ca\u6240\u65b0\u63d0\u51fa\u7684IF-MT\u57fa\u51c6\u4e0a\u5747\u53d6\u5f97\u6700\u4f73\u6210\u7ee9\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7ffb\u8bd1\u80fd\u529b\u548c\u591a\u8bed\u79cd\u901a\u7528\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\uff0c\u5373\u65e0\u9700\u5728\u7279\u5b9a\u9886\u57df\uff08\u5982\u7ffb\u8bd1\uff09\u548c\u901a\u7528\u63a8\u7406\u3001\u6307\u4ee4\u8ddf\u968f\u7b49\u80fd\u529b\u95f4\u505a\u53d6\u820d\u3002\u6240\u5f00\u53d1\u7684Tower+\u6a21\u578b\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\uff0c\u8bc1\u660e\u4e86\u517c\u987e\u4e24\u7c7b\u80fd\u529b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.17088", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17088", "abs": "https://arxiv.org/abs/2506.17088", "authors": ["Jiahao Cheng", "Tiancheng Su", "Jia Yuan", "Guoxiu He", "Jiawei Liu", "Xinqi Tao", "Jingwen Xie", "Huaxia Li"], "title": "Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation", "comment": null, "summary": "Large Language Models (LLMs) often exhibit \\textit{hallucinations},\ngenerating factually incorrect or semantically irrelevant content in response\nto prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by\nencouraging step-by-step reasoning, but its impact on hallucination detection\nremains underexplored. To bridge this gap, we conduct a systematic empirical\nevaluation. We begin with a pilot experiment, revealing that CoT reasoning\nsignificantly affects the LLM's internal states and token probability\ndistributions. Building on this, we evaluate the impact of various CoT\nprompting methods on mainstream hallucination detection methods across both\ninstruction-tuned and reasoning-oriented LLMs. Specifically, we examine three\nkey dimensions: changes in hallucination score distributions, variations in\ndetection accuracy, and shifts in detection confidence. Our findings show that\nwhile CoT prompting helps reduce hallucination frequency, it also tends to\nobscure critical signals used for detection, impairing the effectiveness of\nvarious detection methods. Our study highlights an overlooked trade-off in the\nuse of reasoning. Code is publicly available at:\nhttps://anonymous.4open.science/r/cot-hallu-detect.", "AI": {"tldr": "\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u867d\u7136\u80fd\u51cf\u5c11\u5927\u6a21\u578b\u5e7b\u89c9\uff0c\u4f46\u4e5f\u4f1a\u5e72\u6270\u5e7b\u89c9\u68c0\u6d4b\u80fd\u529b\uff0c\u63d0\u793a\u5e94\u7528\u9700\u6743\u8861\u4e8c\u8005\u5f71\u54cd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u5185\u5bb9\u65f6\u5e38\u89c1\u201c\u5e7b\u89c9\u201d\u73b0\u8c61\uff0c\u5373\u751f\u6210\u4e8b\u5b9e\u9519\u8bef\u6216\u8bed\u4e49\u65e0\u5173\u7684\u5185\u5bb9\u3002\u5c3d\u7ba1\u94fe\u5f0f\u601d\u7ef4\uff08Chain-of-Thought, CoT\uff09\u63d0\u793a\u80fd\u591f\u901a\u8fc7\u9f13\u52b1\u9010\u6b65\u63a8\u7406\u6765\u51cf\u5c11\u5e7b\u89c9\uff0c\u4f46\u5176\u5bf9\u5e7b\u89c9\u68c0\u6d4b\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30CoT\u5bf9\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u9996\u5148\u8fdb\u884c\u4e86\u4e00\u9879\u8bd5\u70b9\u5b9e\u9a8c\uff0c\u8bc1\u660eCoT\u63a8\u7406\u663e\u8457\u5f71\u54cd\u4e86LLM\u7684\u5185\u90e8\u72b6\u6001\u548ctoken\u6982\u7387\u5206\u5e03\u3002\u968f\u540e\uff0c\u9488\u5bf9\u4e3b\u6d41\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u7ecf\u8fc7\u6307\u4ee4\u8c03\u4f18\u548c\u63a8\u7406\u4f18\u5316\u7684LLMs\u4e0a\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540cCoT\u63d0\u793a\u65b9\u5f0f\u7684\u5f71\u54cd\u3002\u8bc4\u4f30\u89d2\u5ea6\u5305\u62ec\u5e7b\u89c9\u5206\u6570\u5206\u5e03\u53d8\u5316\u3001\u68c0\u6d4b\u51c6\u786e\u7387\u53d8\u5316\u53ca\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u53d8\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136CoT\u63d0\u793a\u80fd\u51cf\u5c11\u5e7b\u89c9\u53d1\u751f\u9891\u7387\uff0c\u4f46\u4e5f\u4f1a\u524a\u5f31\u7528\u4e8e\u68c0\u6d4b\u5e7b\u89c9\u7684\u5173\u952e\u4fe1\u53f7\uff0c\u4ece\u800c\u964d\u4f4e\u591a\u79cd\u68c0\u6d4b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5728\u5229\u7528\u63a8\u7406\u51cf\u7f13\u5e7b\u89c9\u7684\u540c\u65f6\uff0c\u53ef\u80fd\u4f1a\u5f71\u54cd\u5e7b\u89c9\u68c0\u6d4b\u6027\u80fd\uff0c\u63d0\u793a\u8be5\u9886\u57df\u5b58\u5728\u9700\u8981\u6743\u8861\u7684\u65b0\u6311\u6218\u3002"}}
{"id": "2506.17090", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17090", "abs": "https://arxiv.org/abs/2506.17090", "authors": ["Murtaza Nazir", "Matthew Finlayson", "John X. Morris", "Xiang Ren", "Swabha Swayamdipta"], "title": "Better Language Model Inversion by Compactly Representing Next-Token Distributions", "comment": null, "summary": "Language model inversion seeks to recover hidden prompts using only language\nmodel outputs. This capability has implications for security and accountability\nin language model deployments, such as leaking private information from an\nAPI-protected language model's system message. We propose a new method --\nprompt inversion from logprob sequences (PILS) -- that recovers hidden prompts\nby gleaning clues from the model's next-token probabilities over the course of\nmultiple generation steps. Our method is enabled by a key insight: The\nvector-valued outputs of a language model occupy a low-dimensional subspace.\nThis enables us to losslessly compress the full next-token probability\ndistribution over multiple generation steps using a linear map, allowing more\noutput information to be used for inversion. Our approach yields massive gains\nover previous state-of-the-art methods for recovering hidden prompts, achieving\n2--3.5 times higher exact recovery rates across test sets, in one case\nincreasing the recovery rate from 17% to 60%. Our method also exhibits\nsurprisingly good generalization behavior; for instance, an inverter trained on\n16 generations steps gets 5--27 points higher prompt recovery when we increase\nthe number of steps to 32 at test time. Furthermore, we demonstrate strong\nperformance of our method on the more challenging task of recovering hidden\nsystem messages. We also analyze the role of verbatim repetition in prompt\nrecovery and propose a new method for cross-family model transfer for\nlogit-based inverters. Our findings show that next-token probabilities are a\nconsiderably more vulnerable attack surface for inversion attacks than\npreviously known.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPILS\u65b9\u6cd5\uff0c\u57fa\u4e8e\u591a\u6b65\u751f\u6210token\u6982\u7387\u5206\u5e03\uff0c\u6781\u5927\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u8bcd\u9006\u63a8\u51c6\u786e\u7387\uff0c\u66b4\u9732\u51fa\u66f4\u4e25\u91cd\u7684\u6a21\u578b\u8f93\u51fa\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e7f\u6cdb\u5e94\u7528\u5e26\u6765\u4e86\u6a21\u578b\u9690\u79c1\u4e0e\u5b89\u5168\u7684\u65b0\u6311\u6218\uff0c\u7279\u522b\u662f\u5728API\u63a5\u53e3\u4fdd\u62a4\u4e0b\uff0c\u7cfb\u7edf\u63d0\u793a\u8bcd\u7b49\u9690\u79c1\u5185\u5bb9\u53ef\u80fd\u901a\u8fc7\u8f93\u51fa\u88ab\u63a8\u65ad\u6cc4\u9732\u3002\u5982\u4f55\u4eceLLM\u8f93\u51fa\u9006\u63a8\u51fa\u9690\u85cf\u63d0\u793a\u8bcd\u5bf9\u4e8e\u8bc4\u4f30\u4e0e\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027\u6781\u4e3a\u5173\u952e\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u51c6\u786e\u7387\u6709\u9650\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8elog\u6982\u7387\u5e8f\u5217\u7684\u63d0\u793a\u9006\u63a8\u65b9\u6cd5\uff08PILS\uff09\uff0c\u5229\u7528LLM\u591a\u6b65\u751f\u6210\u8fc7\u7a0b\u4e2d\u6bcf\u4e00\u6b65\u7684\u4e0b\u4e00\u4e2atoken\u6982\u7387\u5206\u5e03\u4f5c\u4e3a\u7ebf\u7d22\u3002\u6838\u5fc3\u89c1\u89e3\u5728\u4e8eLLM\u8f93\u51fa\u5411\u91cf\u4f4d\u4e8e\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\uff0c\u56e0\u800c\u80fd\u901a\u8fc7\u7ebf\u6027\u6620\u5c04\u5bf9\u591a\u6b65\u751f\u6210\u7684\u5168\u90e8\u6982\u7387\u5206\u5e03\u8fdb\u884c\u65e0\u635f\u538b\u7f29\uff0c\u4ece\u800c\u4fdd\u7559\u66f4\u591a\u7528\u4e8e\u9006\u63a8\u7684\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u8fd8\u80fd\u8fc1\u79fb\u81f3\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u95f4\u3002", "result": "\u65b0\u65b9\u6cd5PILS\u5728\u63d0\u793a\u9006\u63a8\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u4ee5\u5f80\u6280\u672f\uff0c\u90e8\u5206\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u753117%\u63d0\u5347\u81f360%\uff0c\u5e73\u5747\u63d0\u53472--3.5\u500d\uff0c\u540c\u65f6\u5728\u66f4\u96be\u7684\u7cfb\u7edf\u6d88\u606f\u9006\u63a8\u4efb\u52a1\u4e0a\u4e5f\u6709\u5f3a\u8868\u73b0\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u663e\u793a\u8bad\u7ec3\u65f6\u4f7f\u7528\u8f83\u5c11\u751f\u6210\u6b65\u6570\uff0c\u9884\u6d4b\u65f6\u589e\u52a0\u6b65\u6570\u80fd\u989d\u5916\u63d0\u5347\u51c6\u786e\u7387\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u63a2\u8ba8\u4e86\u63d0\u793a\u8bcd\u91cd\u590d\u73b0\u8c61\u5bf9\u9006\u63a8\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u8de8\u6a21\u578b\u5bb6\u65cf\u8fc1\u79fb\u65b9\u6cd5\u3002", "conclusion": "LLM\u7684\u4e0b\u4e00\u4e2atoken\u6982\u7387\u5206\u5e03\u6bd4\u4ee5\u5f80\u8ba4\u8bc6\u7684\u66f4\u6613\u88ab\u9006\u63a8\u51fa\u8f93\u5165\u63d0\u793a\u8bcd\uff0c\u63d0\u793a\u8bcd\u7684\u4fdd\u5bc6\u6027\u98ce\u9669\u4e25\u91cd\uff0cPILS\u65b9\u6cd5\u4e3a\u9006\u63a8\u653b\u51fb\u53ca\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5de5\u5177\u3002"}}
{"id": "2506.17121", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17121", "abs": "https://arxiv.org/abs/2506.17121", "authors": ["Adithya Bhaskar", "Alexander Wettig", "Tianyu Gao", "Yihe Dong", "Danqi Chen"], "title": "Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?", "comment": "We release our code publicly at\n  https://github.com/princeton-pli/PruLong", "summary": "Language models handle increasingly long contexts for tasks such as book\nsummarization, but this leads to growing memory costs for the key-value (KV)\ncache. Many prior works have proposed ways of discarding KVs from memory, but\ntheir approaches are tailored to favorable settings, obscuring caveats like\nhigh peak memory and performance degradation, and a fair comparison between\nmethods is difficult. In this paper, we propose the *KV footprint* as a unified\nmetric, which accounts for both the amount of KV entries stored and their\nlifespan in memory. We evaluate methods based on the smallest footprint they\nattain while preserving performance in both long-context understanding and\ngeneration, with context lengths of up to 128K tokens. This metric reveals the\nhigh peak memory of prior KV eviction methods. One class of methods --\n*post-fill eviction* -- has a high footprint due to being incompatible with\neviction during pre-filling. We adapt these methods to be able to evict KVs\nduring pre-filling, achieving substantially lower KV footprints. We then turn\nto *recency eviction* methods, wherein we propose PruLong, an end-to-end\noptimization method for learning which attention heads need to retain the full\nKV cache and which do not. PruLong saves memory while preserving long-context\nperformance, achieving 12% smaller KV footprint than prior methods while\nretaining performance in challenging recall tasks. Our paper clarifies the\ncomplex tangle of long-context inference methods and paves the way for future\ndevelopment to minimize the KV footprint.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u5927\u6a21\u578b\u957f\u6587\u672c\u4e0a\u4e0b\u6587KV\u7f13\u5b58\u7684\u5185\u5b58\u4f18\u5316\u96be\u9898\uff0c\u63d0\u51fa\u5e76\u7edf\u4e00\u8bc4\u4ef7\u4e86KV footprint\u6307\u6807\uff0c\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u5e76\u521b\u65b0\u6027\u63d0\u51faPruLong\uff0c\u6700\u7ec8\u5728\u4e0d\u635f\u4f24\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u6d88\u8017\uff0c\u662f\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u9886\u57df\u7684\u91cd\u8981\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7684\u4e0a\u4e0b\u6587\u8d8a\u6765\u8d8a\u957f\uff0c\u5982\u56fe\u4e66\u6458\u8981\u4efb\u52a1\uff0c\u5bfc\u81f4KV\u7f13\u5b58\u7684\u5185\u5b58\u9700\u6c42\u8fc5\u901f\u589e\u52a0\u3002\u5f53\u524d\u5df2\u6709\u8bb8\u591a\u65b9\u6cd5\u8bd5\u56fe\u533a\u5206\u6216\u4f18\u5316KV\u7f13\u5b58\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u9002\u7528\u4e8e\u7279\u5b9a\u573a\u666f\uff0c\u5e76\u5b58\u5728\u9ad8\u5cf0\u503c\u5185\u5b58\u6d88\u8017\u4e0e\u6027\u80fd\u4e0b\u964d\u7b49\u9690\u60a3\uff0c\u540c\u65f6\u7f3a\u4e4f\u7edf\u4e00\u7684\u516c\u5e73\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6307\u6807KV footprint\uff0c\u6db5\u76d6\u5b58\u50a8\u7684KV\u6761\u76ee\u6570\u91cf\u53ca\u5176\u5728\u5185\u5b58\u4e2d\u7684\u5bff\u547d\u3002\u7528\u8fd9\u4e00\u6307\u6807\u5728\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\uff08\u6700\u957f\u81f3128K tokens\uff09\u4e0b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709KV\u7f13\u5b58\u6dd8\u6c70\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u5176\u9ad8\u5185\u5b58\u5cf0\u503c\u3002\u540c\u65f6\uff0c\u521b\u65b0\u6027\u5730\u5c06\u65e0\u6cd5\u5728\u9884\u586b\u5145\u671f\u95f4\u6dd8\u6c70KV\u7684post-fill eviction\u65b9\u6cd5\u8fdb\u884c\u9002\u914d\uff0c\u652f\u6301\u9884\u586b\u5145\u671f\u95f4\u6dd8\u6c70\uff0c\u663e\u8457\u964d\u4f4eKV footprint\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86PruLong\uff0c\u4e00\u79cd\u4f18\u5316recency eviction\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u54ea\u4e9battention head\u9700\u4fdd\u7559\u5b8c\u6574KV\u7f13\u5b58\u4ee5\u8fdb\u4e00\u6b65\u8282\u7701\u5185\u5b58\u3002", "result": "\u5bf9\u6bd4\u5206\u6790\u53d1\u73b0\uff0c\u8bb8\u591a\u73b0\u6709KV\u6dd8\u6c70\u65b9\u6cd5\u6709\u9ad8\u5cf0\u503cKV footprint\uff0c\u5c24\u5176\u662f\u4f20\u7edf\u7684post-fill eviction\u5728\u9884\u586b\u5145\u671f\u95f4\u5185\u5b58\u6d88\u8017\u5927\u3002\u7ecf\u8fc7\u6539\u8fdb\uff0c\u9884\u586b\u5145\u6dd8\u6c70\u673a\u5236\u6709\u6548\u964d\u4f4e\u4e86footprint\u3002PruLong\u65b9\u6cd5\u5219\u5728\u51cf\u5c11\u7ea612% KV footprint\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u957f\u4e0a\u4e0b\u6587\u6027\u80fd\uff0c\u5728\u9ad8\u96be\u5ea6\u53ec\u56de\u4efb\u52a1\u4e2d\u672a\u635f\u5931\u6027\u80fd\u3002", "conclusion": "\u5f15\u5165KV footprint\u4f5c\u4e3a\u7edf\u4e00\u6307\u6807\u6f84\u6e05\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u6cd5\u7684\u5185\u5b58\u6027\u80fd\u4f18\u52a3\uff0c\u521b\u65b0\u7684\u9884\u586b\u5145\u6dd8\u6c70\u548cPruLong\u65b9\u6cd5\u6709\u6548\u964d\u4f4eKV footprint\uff0c\u4e3aKV\u7f13\u5b58\u4f18\u5316\u548c\u957f\u6587\u672c\u63a8\u7406\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u65b9\u5411\u3002"}}
{"id": "2506.17180", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17180", "abs": "https://arxiv.org/abs/2506.17180", "authors": ["Naiming Liu", "Richard Baraniuk", "Shashank Sonkar"], "title": "CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models", "comment": null, "summary": "We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions\ndesigned to evaluate whether language models can determine if one statement\ncausally explains another. Each question present an assertion-reason pair and\nchallenge language models to distinguish between semantic relatedness and\ngenuine causal explanatory relationships. Through comprehensive evaluation of\n21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we\nidentify two fundamental findings. First, language models frequently confuse\nsemantic similarity with causality, relying on lexical and semantic overlap\ninstead of inferring actual causal explanatory relationships. Second, as\nparameter size increases, models tend to shift from being overly skeptical\nabout causal relationships to being excessively permissive in accepting them.\nDespite this shift, performance measured by the Matthews Correlation\nCoefficient plateaus at just 0.55, even for the best-performing models.Hence,\nCLEAR-3K provides a crucial benchmark for developing and evaluating genuine\ncausal reasoning in language models, which is an essential capability for\napplications that require accurate assessment of causal relationships.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CLEAR-3K\u6570\u636e\u96c6\u7528\u4e8e\u6d4b\u8bd5\u5927\u6a21\u578b\u5bf9\u56e0\u679c\u89e3\u91ca\u5173\u7cfb\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u663e\u793a\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u5e38\u6df7\u6dc6\u8bed\u4e49\u76f8\u5173\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u6700\u4f18\u8868\u73b0\u4e5f\u6709\u9650\uff0c\u6307\u51fa\u56e0\u679c\u63a8\u7406\u662f\u4e9f\u5f85\u89e3\u51b3\u7684\u6280\u672f\u96be\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u8fdb\u884c\u590d\u6742\u7684\u8bed\u4e49\u63a8\u7406\uff0c\u4f46\u5bf9\u201c\u56e0\u679c\u89e3\u91ca\u201d\u80fd\u529b\u7684\u8bc4\u4f30\u624b\u6bb5\u4e0d\u8db3\uff0c\u73b0\u6709\u4efb\u52a1\u591a\u504f\u91cd\u8bed\u4e49\u76f8\u5173\u6027\u800c\u4e0d\u662f\u771f\u6b63\u7684\u56e0\u679c\u63a8\u65ad\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u6709\u65b0\u7684\u57fa\u51c6\u7528\u4ee5\u533a\u5206\u6a21\u578b\u5bf9\u8bed\u4e49\u76f8\u5173\u548c\u56e0\u679c\u5173\u7cfb\u7684\u5224\u65ad\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86CLEAR-3K\u6570\u636e\u96c6\uff0c\u5305\u62ec3,000\u4e2a\u58f0\u660e-\u63a8\u7406\u578b\u95ee\u9898\uff0c\u6d4b\u8bd5\u6a21\u578b\u5bf9\u4e8e\u65ad\u8a00\u4e0e\u539f\u56e0\u662f\u5426\u5b58\u5728\u56e0\u679c\u89e3\u91ca\u5173\u7cfb\u7684\u5224\u522b\u80fd\u529b\u3002\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e8621\u4e2a\u53c2\u6570\u91cf\u4e0d\u540c\uff080.5B-72B\uff09\u7684\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u5e38\u5c06\u8bed\u4e49\u76f8\u4f3c\u548c\u56e0\u679c\u5173\u7cfb\u6df7\u6dc6\uff0c\u5f80\u5f80\u4f9d\u8d56\u8bcd\u6c47\u548c\u8bed\u4e49\u91cd\u53e0\uff0c\u800c\u975e\u5b9e\u9645\u63a8\u65ad\u56e0\u679c\u89e3\u91ca\u5173\u7cfb\u3002\u53c2\u6570\u91cf\u63d0\u5347\u540e\uff0c\u6a21\u578b\u5224\u65ad\u56e0\u679c\u5173\u7cfb\u7684\u503e\u5411\u6027\u4ece\u2018\u8fc7\u4e8e\u6000\u7591\u2019\u8f6c\u4e3a\u2018\u8fc7\u4e8e\u5bbd\u5bb9\u2019\uff0c\u4f46\u6574\u4f53\u8868\u73b0\uff08Matthews Correlation Coefficient\uff09\u5728\u6700\u4f18\u6a21\u578b\u4e0a\u4e5f\u4ec5\u4e3a0.55\uff0c\u51fa\u73b0\u6027\u80fd\u74f6\u9888\u3002", "conclusion": "CLEAR-3K\u4e3a\u68c0\u9a8c\u548c\u63a8\u52a8\u8bed\u8a00\u6a21\u578b\u56e0\u679c\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u57fa\u51c6\u5de5\u5177\uff0c\u8bf4\u660e\u5f53\u4e0b\u6a21\u578b\u5bf9\u7cbe\u51c6\u56e0\u679c\u5173\u7cfb\u7684\u8bc6\u522b\u4ecd\u5177\u6311\u6218\uff0c\u672a\u6765\u76f8\u5173\u80fd\u529b\u7684\u63d0\u5347\u5bf9\u5b9e\u9645\u5e94\u7528\u5c24\u4e3a\u91cd\u8981\u3002"}}
{"id": "2506.17188", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.17188", "abs": "https://arxiv.org/abs/2506.17188", "authors": ["Yuchen Li", "Hengyi Cai", "Rui Kong", "Xinran Chen", "Jiamin Chen", "Jun Yang", "Haojie Zhang", "Jiayi Li", "Jiayi Wu", "Yiqun Chen", "Changle Qu", "Keyi Kong", "Wenwen Ye", "Lixin Su", "Xinyu Ma", "Long Xia", "Daiting Shi", "Jiashu Zhao", "Haoyi Xiong", "Shuaiqiang Wang", "Dawei Yin"], "title": "Towards AI Search Paradigm", "comment": null, "summary": "In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint\nfor next-generation search systems capable of emulating human information\nprocessing and decision-making. The paradigm employs a modular architecture of\nfour LLM-powered agents (Master, Planner, Executor and Writer) that dynamically\nadapt to the full spectrum of information needs, from simple factual queries to\ncomplex multi-stage reasoning tasks. These agents collaborate dynamically\nthrough coordinated workflows to evaluate query complexity, decompose problems\ninto executable plans, and orchestrate tool usage, task execution, and content\nsynthesis. We systematically present key methodologies for realizing this\nparadigm, including task planning and tool integration, execution strategies,\naligned and robust retrieval-augmented generation, and efficient LLM inference,\nspanning both algorithmic techniques and infrastructure-level optimizations. By\nproviding an in-depth guide to these foundational components, this work aims to\ninform the development of trustworthy, adaptive, and scalable AI search\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7531\u56db\u4e2a\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\u7684\u5168\u65b0AI\u641c\u7d22\u67b6\u6784\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u5b9e\u73b0\u590d\u6742\u4eba\u7c7b\u7ea7\u4fe1\u606f\u68c0\u7d22\u548c\u51b3\u7b56\u652f\u6301\u7684\u5173\u952e\u6280\u672f\uff0c\u65e8\u5728\u63a8\u52a8AI\u641c\u7d22\u7cfb\u7edf\u7684\u80fd\u529b\u8fdb\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u641c\u7d22\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u548c\u6a21\u62df\u4eba\u7c7b\u51b3\u7b56\u4fe1\u606f\u5904\u7406\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u96be\u4ee5\u6ee1\u8db3\u4ece\u7b80\u5355\u4e8b\u5b9e\u5230\u590d\u6742\u63a8\u7406\u7b49\u591a\u6837\u5316\u4fe1\u606f\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86AI\u641c\u7d22\u8303\u5f0f\uff08AI Search Paradigm\uff09\uff0c\u91c7\u7528\u7531\u56db\u7c7b\u5927\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff08Master\u3001Planner\u3001Executor\u3001Writer\uff09\u7ec4\u6210\u7684\u6a21\u5757\u5316\u67b6\u6784\u3002\u901a\u8fc7\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u52a8\u6001\u5206\u5de5\uff0c\u5b9e\u73b0\u4efb\u52a1\u89c4\u5212\u3001\u5de5\u5177\u96c6\u6210\u3001\u63a8\u7406\u6267\u884c\u3001\u5185\u5bb9\u751f\u6210\uff0c\u5e76\u5728\u57fa\u7840\u8bbe\u65bd\u5c42\u8fdb\u884c\u4e00\u7cfb\u5217\u7b97\u6cd5\u548c\u6548\u7387\u4f18\u5316\u3002", "result": "\u7cfb\u7edf\u6027\u9610\u8ff0\u4e86\u5b9e\u73b0\u4e0a\u8ff0\u8303\u5f0f\u7684\u65b9\u6cd5\u5b66\uff0c\u5305\u62ec\u4efb\u52a1\u7ec6\u5206\u3001\u5de5\u5177\u534f\u540c\u3001\u6267\u884c\u7b56\u7565\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u53ca\u9ad8\u6548\u63a8\u7406\u7b49\u5173\u952e\u8981\u7d20\u3002", "conclusion": "\u6b64\u8303\u5f0f\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u3001\u53ef\u9002\u914d\u548c\u53ef\u6269\u5c55\u7684\u65b0\u4e00\u4ee3AI\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u84dd\u56fe\u548c\u5b9e\u8df5\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u641c\u7d22\u7cfb\u7edf\u5411\u66f4\u63a5\u8fd1\u4eba\u7c7b\u80fd\u529b\u8fdb\u5316\u3002"}}
{"id": "2506.17209", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17209", "abs": "https://arxiv.org/abs/2506.17209", "authors": ["Kathleen C. Fraser", "Hillary Dawkins", "Isar Nejadgholi", "Svetlana Kiritchenko"], "title": "Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency", "comment": "to appear at LLMSEC 2025", "summary": "Fine-tuning a general-purpose large language model (LLM) for a specific\ndomain or task has become a routine procedure for ordinary users. However,\nfine-tuning is known to remove the safety alignment features of the model, even\nwhen the fine-tuning data does not contain any harmful content. We consider\nthis to be a critical failure mode of LLMs due to the widespread uptake of\nfine-tuning, combined with the benign nature of the \"attack\". Most\nwell-intentioned developers are likely unaware that they are deploying an LLM\nwith reduced safety. On the other hand, this known vulnerability can be easily\nexploited by malicious actors intending to bypass safety guardrails. To make\nany meaningful progress in mitigating this issue, we first need reliable and\nreproducible safety evaluations. In this work, we investigate how robust a\nsafety benchmark is to trivial variations in the experimental procedure, and\nthe stochastic nature of LLMs. Our initial experiments expose surprising\nvariance in the results of the safety evaluation, even when seemingly\ninconsequential changes are made to the fine-tuning setup. Our observations\nhave serious implications for how researchers in this field should report\nresults to enable meaningful comparisons in the future.", "AI": {"tldr": "\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u5f71\u54cd\u6a21\u578b\u5b89\u5168\uff0c\u5373\u4fbf\u6570\u636e\u65e0\u5bb3\u3002\u5f53\u524d\u5b89\u5168\u8bc4\u4f30\u7ed3\u679c\u53d7\u5b9e\u9a8c\u7ec6\u8282\u5f71\u54cd\u6ce2\u52a8\u5927\uff0c\u9700\u6539\u8fdb\u8bc4\u4f30\u6807\u51c6\u4ee5\u4fdd\u8bc1\u53ef\u91cd\u590d\u6027\u548c\u5bf9\u6bd4\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7279\u5b9a\u9886\u57df\u6216\u4efb\u52a1\u4e0a\u7684\u5fae\u8c03\u53d8\u5f97\u666e\u904d\uff0c\u4f46\u5fae\u8c03\u4f1a\u524a\u5f31\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\uff0c\u5373\u4f7f\u5fae\u8c03\u6570\u636e\u65e0\u5bb3\u3002\u7531\u4e8e\u5fae\u8c03\u666e\u53ca\uff0c\u7528\u6237\u5bf9\u8fd9\u79cd\u201c\u653b\u51fb\u201d\u4e0d\u77e5\u60c5\uff0c\u8fd9\u5bf9\u6a21\u578b\u90e8\u7f72\u5b89\u5168\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002\u6b64\u5916\uff0c\u6076\u610f\u884c\u4e3a\u8005\u53ef\u4ee5\u5229\u7528\u6b64\u6f0f\u6d1e\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6709\u6548\u4e14\u53ef\u590d\u73b0\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5b9e\u8bc1\u5206\u6790\u4e86\u5f53\u524d\u7528\u4e8e\u8bc4\u4f30LLM\u5b89\u5168\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8003\u5bdf\u5176\u5bf9\u5b9e\u9a8c\u8bbe\u7f6e\u5fae\u5c0f\u53d8\u5316\u548c\u6a21\u578b\u968f\u673a\u6027\u7684\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u63a7\u5236\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u7ec6\u8282\u53d8\u52a8\uff0c\u89c2\u5bdf\u5b89\u5168\u8bc4\u4f30\u7ed3\u679c\u7684\u6ce2\u52a8\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5728\u5fae\u8c03\u8bbe\u7f6e\u53d1\u751f\u4e00\u4e9b\u770b\u4f3c\u65e0\u5173\u7d27\u8981\u7684\u53d8\u5316\u65f6\uff0c\u5b89\u5168\u6027\u8bc4\u6d4b\u7ed3\u679c\u6ce2\u52a8\u8f83\u5927\uff0c\u8868\u73b0\u51fa\u663e\u8457\u7684\u65b9\u5dee\u3002\u8fd9\u66b4\u9732\u51fa\u73b0\u6709\u5b89\u5168\u6027\u8bc4\u4f30\u96be\u4ee5\u4fdd\u6301\u4e00\u81f4\u6027\u548c\u53ef\u6bd4\u6027\u7684\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cLLM\u5b89\u5168\u6027\u8bc4\u4f30\u53d7\u5b9e\u9a8c\u7ec6\u8282\u5f71\u54cd\u6781\u5927\uff0c\u7ed3\u679c\u4e0d\u6613\u590d\u73b0\uff0c\u5a01\u80c1\u5230\u540e\u7eed\u7814\u7a76\u548c\u6a21\u578b\u516c\u5f00\u5b89\u5168\u6027\u58f0\u660e\u7684\u53ef\u4fe1\u5ea6\u3002\u672a\u6765\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u9700\u66f4\u52a0\u6807\u51c6\u5316\u5b9e\u9a8c\u6d41\u7a0b\uff0c\u660e\u786e\u62a5\u544a\u7ec6\u8282\uff0c\u4ee5\u5b9e\u73b0\u6709\u610f\u4e49\u7684\u6a2a\u5411\u6bd4\u8f83\u3002"}}
{"id": "2506.15655", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.15655", "abs": "https://arxiv.org/abs/2506.15655", "authors": ["Yilin Zhang", "Xinran Zhao", "Zora Zhiruo Wang", "Chenyang Yang", "Jiayi Wei", "Tongshuang Wu"], "title": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become essential for large-scale\ncode generation, grounding predictions in external code corpora to improve\nactuality. However, a critical yet underexplored aspect of RAG pipelines is\nchunking -- the process of dividing documents into retrievable units. Existing\nline-based chunking heuristics often break semantic structures, splitting\nfunctions or merging unrelated code, which can degrade generation quality. We\npropose chunking via Abstract Syntax Trees (\\ourwork), a structure-aware method\nthat recursively breaks large AST nodes into smaller chunks and merges sibling\nnodes while respecting size limits. This approach generates self-contained,\nsemantically coherent units across programming languages and tasks, improving\nperformance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3\npoints on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.\nOur work highlights the importance of structure-aware chunking for scaling\nretrieval-enhanced code intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eAST\u7684\u7ed3\u6784\u611f\u77e5\u4ee3\u7801\u5207\u5206\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86RAG\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u7684\u68c0\u7d22\u53ca\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u884c\u7684chunking\u5bb9\u6613\u6253\u65ad\u4ee3\u7801\u7ed3\u6784\uff0c\u5bfc\u81f4\u751f\u6210\u8d28\u91cf\u4e0b\u964d\uff1b\u9700\u8981\u4e00\u79cd\u66f4\u80fd\u4fdd\u6301\u4ee3\u7801\u8bed\u4e49\u5b8c\u6574\u6027\u7684chunking\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u7684chunking\u65b9\u6cd5\uff0c\u9012\u5f52\u62c6\u5206\u5927AST\u8282\u70b9\u5e76\u5408\u5e76\u5144\u5f1f\u8282\u70b9\uff0c\u4fdd\u8bc1\u6bcf\u5757\u4ee3\u7801\u7684\u7ed3\u6784\u8bed\u4e49\u5b8c\u6574\u5e76\u63a7\u5236\u5927\u5c0f\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u591a\u9879\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u6027\u80fd\uff1a\u5728RepoEval\u68c0\u7d22Recall@5\u63d0\u53474.3\u70b9\uff0c\u5728SWE-bench\u751f\u6210Pass@1\u63d0\u53472.67\u70b9\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u5728RAG\u5e94\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u65f6\uff0c\u91c7\u7528\u7ed3\u6784\u611f\u77e5\uff08AST\u4e3a\u57fa\u7840\uff09\u7684chunking\u7b56\u7565\u66f4\u52a0\u6709\u6548\uff0c\u5bf9\u7f29\u653e\u68c0\u7d22\u589e\u5f3a\u7684\u4ee3\u7801\u667a\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
