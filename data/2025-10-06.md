<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 14]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 15]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Designing Walrus: Relational Programming with Rich Types, On-Demand Laziness, and Structured Traces](https://arxiv.org/abs/2510.02579)
*Santiago Cuéllar,Naomi Spargo,Jonathan Daugherty,David Darais*

Main category: cs.PL

TL;DR: 本文提出了嵌入于Haskell的功能关系编程语言Walrus，相较传统miniKanren模型，在类型统一、惰性计算、调试追踪、代码简化和产品类型支持等方面大幅提升了可用性，并通过实际编译器开发应用展示了其实用价值和面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的miniKanren模型在功能关系编程中存在类型不灵活、代码模板繁琐和调试不便等实际开发局限。作者旨在改进编程体验，使该范式对实际应用更具可用性。

Method: 在Haskell中设计并实现了Walrus语言，通过引入类型多态统一（type-polymorphic unification）、按需惰性（on-demand laziness）以及丰富的可用性方案（如Haskell Generics减少样板代码、结构化调试、产物类型的友好支持），并结合实际构建双向编译器的经验验证其设计和实用性。

Result: Walrus显著提升了miniKanren模型在实际开发中的灵活性和易用性。实际开发双向编译器过程中，验证了其类型系统、调试能力和代码简化特性的有效性，但也总结了部分设计和可用性上的挑战。

Conclusion: Walrus在保有miniKanren范式强大表达力的同时，通过多项功能增强，显著提高了面向实际功能关系程序开发的可用性和便利性，为类似系统设计和应用提供了参考。

Abstract: We present Walrus, a functional relational programming language embedded in
Haskell that extends the miniKanren model with type-polymorphic unification,
on-demand laziness, and a range of usability features aimed at practical
development. These include use of Haskell Generics for boilerplate reduction,
structured debugging traces, and ergonomic support for product types. We
describe the design and implementation of Walrus through the lens of our
experience developing bidirectional compilers, and reflect on key design
decisions and recurring usability challenges encountered in practice.

</details>


### [2] [Beyond Cons: Purely Relational Data Structures](https://arxiv.org/abs/2510.03170)
*Rafaello Sanna,William E. Byrd,Nada Amin*

Main category: cs.PL

TL;DR: {Kanren} 扩展 miniKanren，加了集合和关联列表的约束，能更高效表达和操作抽象数据结构，提升逻辑程序的表达力和性能，尤其适合处理集合内容相等的场景。


<details>
  <summary>Details</summary>
Motivation: miniKanren 在处理集合和关联列表等抽象数据时，原有机制（如结构编码和急切搜索）表现出局限性，因此需要更高效、表达性更强的方式来声明和操作这些数据结构。

Method: 提出并实现了名为 {Kanren} 的新系统，向 miniKanren 扩展了对集合与关联列表的约束支持。新增了一整套集合约束（如成员、并集、不相交）及对关联列表（支持屏蔽与作用域查找）的约束，相关设计和实现均基于约束增强版的 miniKanren。

Result: {Kanren} 允许程序员以声明式、惰性方式描述集合及关联列表，不必依赖结构编码或急切搜索，提升了程序的表达能力和运行性能，尤其在实现解释器等抽象数据操作中效果明显。其集合相等基于内容判定，支持有限失败机制。通过典型例子说明其实际用法。

Conclusion: 通过向 miniKanren 引入集合与关联列表约束，{Kanren} 显著提升了声明性逻辑编程中操作抽象数据的能力与运行效率，特别适合对集合语义敏感的领域，如解释器实现。

Abstract: We present {Kanren} (read: set-Kanren), an extension to miniKanren with
constraints for reasoning about sets and association lists. {Kanren} includes
first-class set objects, a functionally complete family of set-theoretic
constraints (including membership, union, and disjointedness), and new
constraints for reasoning about association lists with shadowing and scoped
lookup. These additions allow programmers to describe collections declaratively
and lazily, without relying on structural encodings and eager search over
representation spaces. The result is improved expressiveness and operational
behavior in programs that manipulate abstract data -- particularly interpreters
-- by supporting set equality based on contents, enabling finite failure. We
describe the design and implementation of {Kanren} in a constraint-enabled
miniKanren system and illustrate its use in representative examples.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [CWM: An Open-Weights LLM for Research on Code Generation with World Models](https://arxiv.org/abs/2510.02387)
*FAIR CodeGen team,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve*

Main category: cs.SE

TL;DR: CWM是一个规模庞大的开源代码生成模型，通过动态环境下的中期训练和多任务强化学习，实现了更强的编码与推理能力，并在多项代码、数学任务中取得优异成绩，模型权重开放助力后续相关研究。


<details>
  <summary>Details</summary>
Motivation: 当前代码生成模型主要依靠静态代码训练，缺乏实际环境下的交互及推理能力。作者希望通过世界模型，提升代码生成在复杂环境中的理解与推理表现，赋能智能体自主编程。

Method: 提出了Code World Model (CWM)，一个拥有320亿参数的开放权重大语言模型。通过在Python解释器和Docker环境的观察-行动轨迹上进行中期训练，并采用多任务推理的强化学习训练（涵盖可验证编程、数学、多轮软件工程任务），提升模型对动态执行环境的理解与推理能力。模型采用解码器结构，支持最多131k上下文长度。

Result: CWM在一般编码和数学任务上表现优异：SWE-bench Verified（pass@1）得分65.8%，LiveCodeBench 68.6%，Math-500 96.6%，AIME 2024 76.0%。此外，展示了利用世界模型进行逐步代码执行模拟，提升推理能力的初步结果，相关模型权重也开放发布。

Conclusion: 通过引入世界模型与复杂环境推理训练，CWM不仅在传统编码及数学任务上取得高分，更为智能体自主编程及代码推理探索提供了强有力的测试平台，有望推动相关领域进一步发展。

Abstract: We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,
to advance research on code generation with world models. To improve code
understanding beyond what can be learned from training on static code alone, we
mid-train CWM on a large amount of observation-action trajectories from Python
interpreter and agentic Docker environments, and perform extensive multi-task
reasoning RL in verifiable coding, math, and multi-turn software engineering
environments. With CWM, we provide a strong testbed for researchers to explore
the opportunities world modeling affords for improving code generation with
reasoning and planning in computational environments. We present first steps of
how world models can benefit agentic coding, enable step-by-step simulation of
Python code execution, and show early results of how reasoning can benefit from
the latter. CWM is a dense, decoder-only LLM trained with a context size of up
to 131k tokens. Independent of its world modeling capabilities, CWM offers
strong performance on general coding and math tasks: it reaches pass@1 scores
of 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on
LiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further
research on code world modeling, we release model checkpoints after
mid-training, SFT, and RL.

</details>


### [4] [From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization](https://arxiv.org/abs/2510.02389)
*Haoran Xi,Minghao Shao,Brendan Dolan-Gavitt,Muhammad Shafique,Ramesh Karri*

Main category: cs.SE

TL;DR: 该工作提出了T2L-Agent，一种可针对项目实现端到端、行级漏洞定位的AI框架，并提供了T2L-ARVO基准进行评测。结果显示该方法在检测准确率和定位精度上领先现有方法，有助于实现更精准、更高效的软件漏洞修复。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在发现代码漏洞方面展示了潜力，但现有方法多是对孤立的代码进行分析，难以处理长上下文，且多聚焦于函数或文件级别的粗略检测，难以为工程师在真实软件开发中提供精确行级定位和针对性修复方案。因此，亟需一种能实现精细粒度分析，并提供可操作建议的新方法。

Method: 提出了T2L-Agent（Trace-to-Line Agent）框架，支持项目级、端到端的漏洞发现分析。其通过自身规划分析流程、逐步缩小范围，从模块级到具体存在漏洞的代码行。T2L-Agent结合多轮反馈机制及Agentic Trace Analyzer（ATA），将运行时证据（如崩溃点、堆栈追踪、覆盖率变化等）与基于AST的代码分块融合，实现迭代优化，能够将出现的异常症状转化为可操作的行级诊断。并引入了新基准集T2L-ARVO，用于评估漏洞检测和定位性能。

Result: 在T2L-ARVO基准测试上，T2L-Agent的漏洞检测准确率达到了58.0%，行级定位准确率达54.8%，明显优于现有基线方法。

Conclusion: T2L-Agent及T2L-ARVO基准推动了基于LLM的漏洞检测从粗粒度识别迈向可落地、鲁棒且高精度的诊断，显著减少噪声、提高修复效率，并有望加速开源软件的漏洞修补流程。

Abstract: Large language models show promise for vulnerability discovery, yet
prevailing methods inspect code in isolation, struggle with long contexts, and
focus on coarse function- or file-level detections - offering limited
actionable guidance to engineers who need precise line-level localization and
targeted patches in real-world software development. We present T2L-Agent
(Trace-to-Line Agent), a project-level, end-to-end framework that plans its own
analysis and progressively narrows scope from modules to exact vulnerable
lines. T2L-Agent couples multi-round feedback with an Agentic Trace Analyzer
(ATA) that fuses runtime evidence - crash points, stack traces, and coverage
deltas - with AST-based code chunking, enabling iterative refinement beyond
single pass predictions and translating symptoms into actionable, line-level
diagnoses. To benchmark line-level vulnerability discovery, we introduce
T2L-ARVO, a diverse, expert-verified 50-case benchmark spanning five crash
families and real-world projects. T2L-ARVO is specifically designed to support
both coarse-grained detection and fine-grained localization, enabling rigorous
evaluation of systems that aim to move beyond file-level predictions. On
T2L-ARVO, T2L-Agent achieves up to 58.0% detection and 54.8% line-level
localization, substantially outperforming baselines. Together, the framework
and benchmark push LLM-based vulnerability detection from coarse identification
toward deployable, robust, precision diagnostics that reduce noise and
accelerate patching in open-source software workflows.

</details>


### [5] [AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization](https://arxiv.org/abs/2510.02393)
*Jianqing Zhang,Wei Xia,Hande Dong,Qiang Lin,Jian Cao*

Main category: cs.SE

TL;DR: 本文提出了一种专注于错误类型的自适应递进偏好优化方法（AP2O-Coder），能显著提升LLM代码生成质量，并减少所需的训练数据。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在代码生成任务上取得了显著进步，但其生成的代码仍存在编译和运行错误。现有的偏好优化方法多只关注代码能否通过（pass/fail信号），忽略了代码失败背后的具体错误类型。

Method: 提出了自适应递进偏好优化（AP2O），具体为AP2O-Coder。方法包括：1）从失败代码中构建错误笔记本，逐类优化LLM以矫正特定错误类型；2）在训练过程中根据模型弱点的变化，自适应重复某些错误类型的优化，以提升改正效果。

Result: 在Llama、Qwen、DeepSeek等参数范围从0.5B到34B的多种模型上广泛实验，AP2O-Coder能以更少的偏好数据将代码生成性能（pass@k指标）提升最多3%。

Conclusion: AP2O-Coder能够有效减少LLM代码生成中的错误，通过针对性和递进优化进一步提升模型性能，相比传统方法更高效。

Abstract: LLMs' code generation capabilities have yielded substantial improvements in
the effectiveness of programming tasks. However, LLM-generated code still
suffers from compilation and runtime errors. Existing offline preference
optimization methods primarily focus on enhancing LLMs' coding abilities using
pass/fail signals in the preference data, overlooking the deep-level error
types in the failed codes. To address this, we propose Adaptively Progressive
Preference Optimization (AP2O) for coding (i.e., AP2O-Coder), a method that
guides LLMs adaptively and methodically to reduce code errors for code
generation. Specifically, we construct an error notebook from failed codes and
progressively optimize the LLM to correct errors type by type. Furthermore, we
adaptively replay error types to tailor to the LLM's changing weaknesses
throughout the training process. Through extensive experiments on both code and
general LLMs (Llama, Qwen, and DeepSeek series) with parameters ranging from
0.5B to 34B, our AP2O-Coder improves code generation performance by up to 3% in
pass@k while using less preference data. Code: https://github.com/TsingZ0/AP2O

</details>


### [6] [Dynamic Function Configuration and its Management in Serverless Computing: A Taxonomy and Future Directions](https://arxiv.org/abs/2510.02404)
*Siddharth Agarwal,Maria A. Rodriguez,Rajkumar Buyya*

Main category: cs.SE

TL;DR: 本文综述了无服务器FaaS资源配置问题，提出了影响因素的分类体系，分析了现有研究进展与不足，并指明了未来提升函数性能和平台能力的研究方向。


<details>
  <summary>Details</summary>
Motivation: 在无服务器计算模型（如FaaS）下，资源分配直接影响性能与成本。然而，由于平台透明度不足，开发者通常缺少准确的资源配置指导，导致资源配置过程复杂且难以优化。

Method: 本文梳理了FaaS资源配置相关的研究，提出了影响函数设计、配置、运行成本和性能保障的因素分类体系。通过文献综述，对现有函数资源配置方法进行了系统性分析。

Result: 文章总结了当前FaaS资源配置领域的研究成果，明确了研究空白，并提出了未来的研究方向，以提升函数配置的智能化水平和无服务器计算环境的能力。

Conclusion: 作者强调，提升资源配置效率和平台能力是推动无服务器计算广泛应用的关键。本文的分类体系和综述为相关研究提供了理论基础，也明确了未来的发展方向。

Abstract: The serverless cloud computing model offers a framework where the service
provider abstracts the underlying infrastructure management from developers. In
this serverless model, FaaS provides an event-driven, function-oriented
computing service characterised by fine-grained, usage-based pricing that
eliminates cost for idle resources. Platforms like AWS Lambda, Azure Functions,
and Cloud Run Functions require developers to configure their function(s) with
minimum operational resources for its successful execution. This resource
allocation influences both the operational expense and the performance quality
of these functions. However, a noticeable lack of platform transparency forces
developers to rely on expert knowledge or experience-based ad-hoc decisions to
request desired function resources. This makes optimal resource configuration a
non-trivial task while adhering to performance constraints. Furthermore, while
commercial platforms often scale resources like CPU and network bandwidth
proportional to memory, open-source frameworks permit independent configuration
of function resources, introducing additional complexity for developers aiming
to optimise their functions. These complexities have directed researchers to
resolve developer challenges and advance towards an efficient server-less
execution model. In this article, we identify different aspects of resource
configuration techniques in FaaS settings and propose a taxonomy of factors
that influence function design, configuration, run-time cost, and performance
guarantees. We conduct an analysis of existing literature on resource
configuration to present a comprehensive review of current studies on function
configuration. We also identify existing research gaps and suggest future
research directions to enhance function configuration and strengthen the
capabilities of serverless computing environments to drive its broader
adoption.

</details>


### [7] [Product Manager Practices for Delegating Work to Generative AI: "Accountability must not be delegated to non-human actors"](https://arxiv.org/abs/2510.02504)
*Mara Ulloa,Jenna L. Butler,Sankeerti Haniyur,Courtney Miller,Barrett Amos,Advait Sarkar,Margaret-Anne Storey*

Main category: cs.SE

TL;DR: 本研究调研微软PM关于生成式AI的使用与影响，总结其采纳率、应用场景、带来的角色变化及未来软件开发流程的启示。


<details>
  <summary>Details</summary>
Motivation: 当前关于生成式AI在软件开发的影响，主要聚焦于开发者，缺乏对产品经理影响的系统研究。作者希望填补该领域的知识空白。

Method: 作者采用了混合方法：对885位PM进行问卷调查，分析其中731位PM的遥测数据，并深度访谈了15位PM。

Result: （1）统计了GenAI在PM中的采纳率、使用场景和他们感知的收益与障碍；（2）提出了一个框架，描述PM如何评估哪些任务适合让GenAI承担；（3）总结了PM在融合GenAI进工作中的适应措施及其对职业角色变化的看法，并讨论了对整个软件开发流程和职业的启示。

Conclusion: 本文发现生成式AI（GenAI）正在推动产品经理（PM）角色和工作内容的转变，包括工作任务的重分配和技能要求的变化。GenAI的普及影响了软件开发中的PM职责。

Abstract: Generative AI (GenAI) is changing the nature of knowledge work, particularly
for Product Managers (PMs) in software development teams. While much software
engineering research has focused on developers' interactions with GenAI, there
is less understanding of how the work of PMs is evolving due to GenAI. To
address this gap, we conducted a mixed-methods study at Microsoft, a large,
multinational software company: surveying 885 PMs, analyzing telemetry data for
a subset of PMs (N=731), and interviewing a subset of 15 PMs. We contribute:
(1) PMs' current GenAI adoption rates, uses cases, and perceived benefits and
barriers and; (2) a framework capturing how PMs assess which tasks to delegate
to GenAI; (3) PMs adaptation practices for integrating GenAI into their roles
and perceptions of how their role is evolving. We end by discussing
implications on the broader GenAI workflow adoption process and software
development roles.

</details>


### [8] [ZeroFalse: Improving Precision in Static Analysis with LLMs](https://arxiv.org/abs/2510.02534)
*Mohsen Iranmanesh,Sina Moradi Sabet,Sina Marefat,Ali Javidi Ghasr,Allison Wilson,Iman Sharafaldin,Mohammad A. Tayebi*

Main category: cs.SE

TL;DR: 本文提出ZeroFalse方法，利用大模型推理能力，有效减少SAST工具误报，验证了其在多个数据集上的高准确性，适合实际工程使用。


<details>
  <summary>Details</summary>
Motivation: 静态应用安全测试（SAST）工具虽然在现代软件开发中很重要，但因误报率高，降低了开发者信任，需要耗费大量人力筛查。本文旨在解决SAST误报过多的问题，提高其实用性和信任度。

Method: 提出ZeroFalse框架，将静态分析结果与大型语言模型（LLM）结合。框架将静态分析产出结构化，补充流程敏感的追踪信息、上下文证据和CWE相关知识，然后交由LLM判断，实现既保留静态分析全覆盖优势，又利用LLM推理能力降低误报。

Result: 在OWASP Java Benchmark上获得0.912的F1-score，在OpenVuln数据集上获得0.955，召回率和精度均超过90%。CWE专用提示词比通用提示效果更佳，擅长推理的LLM能更好平衡精度和召回。

Conclusion: ZeroFalse显著降低SAST误报，提升精度和召回，适合大规模集成到实际CI/CD流程。

Abstract: Static Application Security Testing (SAST) tools are integral to modern
software development, yet their adoption is undermined by excessive false
positives that weaken developer trust and demand costly manual triage. We
present ZeroFalse, a framework that integrates static analysis with large
language models (LLMs) to reduce false positives while preserving coverage.
ZeroFalse treats static analyzer outputs as structured contracts, enriching
them with flow-sensitive traces, contextual evidence, and CWE-specific
knowledge before adjudication by an LLM. This design preserves the systematic
reach of static analysis while leveraging the reasoning capabilities of LLMs.
We evaluate ZeroFalse across both benchmarks and real-world projects using ten
state-of-the-art LLMs. Our best-performing models achieve F1-scores of 0.912 on
the OWASP Java Benchmark and 0.955 on the OpenVuln dataset, maintaining recall
and precision above 90%. Results further show that CWE-specialized prompting
consistently outperforms generic prompts, and reasoning-oriented LLMs provide
the most reliable precision-recall balance. These findings position ZeroFalse
as a practical and scalable approach for enhancing the reliability of SAST and
supporting its integration into real-world CI/CD pipelines.

</details>


### [9] [Key Considerations for Auto-Scaling: Lessons from Benchmark Microservices](https://arxiv.org/abs/2510.02585)
*Majid Dashtbani,Ladan Tahvildari*

Main category: cs.SE

TL;DR: 论文指出，不同生命周期阶段（架构、实现、部署）的问题严重影响微服务自动伸缩的效果。通过案例验证，强调生命周期整体工程考虑对于高性能自动伸缩至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的自动伸缩方法评估多忽略了微服务系统在生命周期各阶段的现实考虑，导致基准与实际应用场景存在脱节。该研究旨在找出影响自动伸缩效果的关键生命周期因素，以提升评价和应用的现实性。

Method: 通过对Sock-Shop基准应用多种最先进的自动伸缩方法（包括阈值型、控制理论、学习型、黑盒优化和依赖感知方法），总结并分类在架构、实现和部署阶段所遇到的问题，并进行实证验证分析。

Result: 忽视生命周期相关因素（如服务拆分、依赖、初始化、指标监控和运行时配置）会降低自动伸缩性能。相反，系统性地关注这些问题可以带来更稳定和高效的伸缩表现。

Conclusion: 论文表明许多现有微服务自动弹性伸缩基准忽略了架构、实现和部署等生命周期关键问题，容易导致伸缩器性能下降。只有关注整个生命周期的工程实践，才能真正实现高效、稳定的自动伸缩。

Abstract: Microservices have become the dominant architectural paradigm for building
scalable and modular cloud-native systems. However, achieving effective
auto-scaling in such systems remains a non-trivial challenge, as it depends not
only on advanced scaling techniques but also on sound design, implementation,
and deployment practices. Yet, these foundational aspects are often overlooked
in existing benchmarks, making it difficult to evaluate autoscaling methods
under realistic conditions. In this paper, we identify a set of practical
auto-scaling considerations by applying several state-of-the-art autoscaling
methods to widely used microservice benchmarks. To structure these findings, we
classify the issues based on when they arise during the software lifecycle:
Architecture, Implementation, and Deployment. The Architecture phase covers
high-level decisions such as service decomposition and inter-service
dependencies. The Implementation phase includes aspects like initialization
overhead, metrics instrumentation, and error propagation. The Deployment phase
focuses on runtime configurations such as resource limits and health checks. We
validate these considerations using the Sock-Shop benchmark and evaluate
diverse auto-scaling strategies, including threshold-based, control-theoretic,
learning-based, black-box optimization, and dependency-aware approaches. Our
findings show that overlooking key lifecycle concerns can degrade autoscaler
performance, while addressing them leads to more stable and efficient scaling.
These results underscore the importance of lifecycle-aware engineering for
unlocking the full potential of auto-scaling in microservice-based systems.

</details>


### [10] [RedCodeAgent: Automatic Red-teaming Agent against Diverse Code Agents](https://arxiv.org/abs/2510.02609)
*Chengquan Guo,Chulin Xie,Yu Yang,Zhaorun Chen,Zinan Lin,Xander Davies,Yarin Gal,Dawn Song,Bo Li*

Main category: cs.SE

TL;DR: RedCodeAgent是一款新型自动化红队代理，能智能组合红队工具，动态挖掘代码智能体中的安全漏洞，其在多类代码助手中的表现大幅优于现有红队方法，并发掘了多项未被发现的真实安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有用于评测代码智能体安全性的基准与红队工具往往局限于静态检测，且覆盖面不够，难以应对真实复杂场景下的边界安全威胁，如多种工具联合绕过型的攻击。因此，亟需一种智能且动态的自动化红队系统，全面挖掘和验证代码智能体中的安全隐患。

Method: 本文提出了一种具有自适应记忆模块的自动化红队代理系统RedCodeAgent，能够动态整合和选择多种现有红队工具及其组合，自动化检出代码智能体中潜在的安全漏洞。同时，设计了模拟沙箱环境对代码实际执行结果进行评估，减轻静态分析及LLM裁决带来的偏差。

Result: RedCodeAgent在多种主流代码智能体、风险场景和编程语言中，表现出高于现有方法的攻击成功率、更低的拦截拒绝率及较好的高效性，且在真实产品（如Cursor和Codeium）中发现了此前未公开的安全风险，展示了其强大的泛化性和实用价值。

Conclusion: RedCodeAgent不仅提高了对代码智能体的安全性评估效率，还能发现传统方法难以检测到的新型安全隐患，在多个主流代码智能体和编程助手上的实验表现优越，有效推动了代码智能体的安全性研究。

Abstract: Code agents have gained widespread adoption due to their strong code
generation capabilities and integration with code interpreters, enabling
dynamic execution, debugging, and interactive programming capabilities. While
these advancements have streamlined complex workflows, they have also
introduced critical safety and security risks. Current static safety benchmarks
and red-teaming tools are inadequate for identifying emerging real-world risky
scenarios, as they fail to cover certain boundary conditions, such as the
combined effects of different jailbreak tools. In this work, we propose
RedCodeAgent, the first automated red-teaming agent designed to systematically
uncover vulnerabilities in diverse code agents. With an adaptive memory module,
RedCodeAgent can leverage existing jailbreak knowledge, dynamically select the
most effective red-teaming tools and tool combinations in a tailored toolbox
for a given input query, thus identifying vulnerabilities that might otherwise
be overlooked. For reliable evaluation, we develop simulated sandbox
environments to additionally evaluate the execution results of code agents,
mitigating potential biases of LLM-based judges that only rely on static code.
Through extensive evaluations across multiple state-of-the-art code agents,
diverse risky scenarios, and various programming languages, RedCodeAgent
consistently outperforms existing red-teaming methods, achieving higher attack
success rates and lower rejection rates with high efficiency. We further
validate RedCodeAgent on real-world code assistants, e.g., Cursor and Codeium,
exposing previously unidentified security risks. By automating and optimizing
red-teaming processes, RedCodeAgent enables scalable, adaptive, and effective
safety assessments of code agents.

</details>


### [11] [Automatic Building Code Review: A Case Study](https://arxiv.org/abs/2510.02634)
*Hanlong Wan,Weili Xu,Michael Rosenberg,Jian Zhang,Aysha Siddika*

Main category: cs.SE

TL;DR: 本文提出一种结合BIM和大语言模型，整合API与知识推理的新型自动化审核框架。GPT-4o模型表现最佳，MCP审核流程更可靠，为自动建筑规范审核提供了生产级解决方案。


<details>
  <summary>Details</summary>
Motivation: 建筑官员在资源受限或农村地区经常面临随着项目规模和复杂性增加，人工审查设计文档既费时、易出错且成本高。随着BIM和大型语言模型(LLM)的逐步应用，带来了自动化规范审核(ACR)的可能性。

Method: 提出一种新型基于代理的框架，将BIM数据提取与自动化验证相结合，使用RAG和MCP代理管道。通过LLM代理抽取几何、计划和系统属性，结合(1)通过API调用COMcheck引擎进行确定性审核，(2)RAG方式对规范条文进行灵活解读。

Result: 通过案例演示，包括自动提取几何属性、解析操作计划、验证照明配额等，并与多个LLM模型对比测试，发现GPT-4o在效率与稳定性上表现最佳。MCP管道在严谨性和可靠性上优于RAG管道。

Conclusion: 本研究提出的框架是可拓展、互操作且可生产部署，技术上实现了BIM数据与权威审核工具的高效集成，推动了建筑自动规范审核领域的发展。

Abstract: Building officials, particularly those in resource-constrained or rural
jurisdictions, face labor-intensive, error-prone, and costly manual reviews of
design documents as projects increase in size and complexity. The growing
adoption of Building Information Modeling (BIM) and Large Language Models
(LLMs) presents opportunities for automated code review (ACR) solutions. This
study introduces a novel agent-driven framework that integrates BIM-based data
extraction with automated verification using both retrieval-augmented
generation (RAG) and Model Context Protocol (MCP) agent pipelines. The
framework employs LLM-enabled agents to extract geometry, schedules, and system
attributes from heterogeneous file types, which are then processed for building
code checking through two complementary mechanisms: (1) direct API calls to the
US Department of Energy COMcheck engine, providing deterministic and
audit-ready outputs, and (2) RAG-based reasoning over rule provisions, enabling
flexible interpretation where coverage is incomplete or ambiguous.
  The framework was evaluated through case demonstrations, including automated
extraction of geometric attributes (such as surface area, tilt, and insulation
values), parsing of operational schedules, and validation of lighting
allowances under ASHRAE Standard 90.1-2022. Comparative performance tests
across multiple LLMs showed that GPT-4o achieved the best balance of efficiency
and stability, while smaller models exhibited inconsistencies or failures.
Results confirm that MCP agent pipelines outperform RAG reasoning pipelines in
rigor and reliability. This work advances ACR research by demonstrating a
scalable, interoperable, and production-ready approach that bridges BIM with
authoritative code review tools.

</details>


### [12] [Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing](https://arxiv.org/abs/2510.02718)
*Ali Ghanbari,Sasan Tavakkol*

Main category: cs.SE

TL;DR: 本文提出了一种基于傅里叶分析的DNN变异测试加速方法DM#，可有效减少测试成本，提升效率，同时保证测试准确性。


<details>
  <summary>Details</summary>
Motivation: 变异测试可以评估深度神经网络测试集的充分性，但需要对大量变异体和数据进行测试，计算成本极高，因此亟需高效变异测试方法降成本。

Method: 利用傅里叶分析量化变异体行为，将行为相似的变异体聚类，每组只选一个代表进行测试，其余变异体复用代表结果，从而减少测试量。

Result: DM#方法在14个不同数据集和模型上实证，平均能加速变异测试28.38%，仅带来0.72%的变异分数误差；其误差远低于随机、边界、随机样本选取法，且提速类似。

Conclusion: 文中提出的DM#方法能显著加速深度神经网络的变异测试过程，同时保证极低的变异分数误差，并且相比现有基线方法有更优异的性能表现。

Abstract: Deep neural network (DNN) mutation analysis is a promising approach to
evaluating test set adequacy. Due to the large number of generated mutants that
must be tested on large datasets, mutation analysis is costly. In this paper,
we present a technique, named DM#, for accelerating DNN mutation testing using
Fourier analysis. The key insight is that DNN outputs are real-valued functions
suitable for Fourier analysis that can be leveraged to quantify mutant behavior
using only a few data points. DM# uses the quantified mutant behavior to
cluster the mutants so that the ones with similar behavior fall into the same
group. A representative from each group is then selected for testing, and the
result of the test, e.g., whether the mutant is killed or survived, is reused
for all other mutants represented by the selected mutant, obviating the need
for testing other mutants. 14 DNN models of sizes ranging from thousands to
millions of parameters, trained on different datasets, are used to evaluate DM#
and compare it to several baseline techniques. Our results provide empirical
evidence on the effectiveness of DM# in accelerating mutation testing by
28.38%, on average, at the average cost of only 0.72% error in mutation score.
Moreover, on average, DM# incurs 11.78, 15.16, and 114.36 times less mutation
score error compared to random mutant selection, boundary sample selection, and
random sample selection techniques, respectively, while generally offering
comparable speed-up.

</details>


### [13] [Automated Repair of OpenID Connect Programs (Extended Version)](https://arxiv.org/abs/2510.02773)
*Tamjid Al Rahat,Yanju Chen,Yu Feng,Yuan Tian*

Main category: cs.SE

TL;DR: OpenID Connect存在严重安全漏洞，作者提出了基于LLM和Petri网的自动补丁生成系统AuthFix，能准确定位和修复大部分漏洞，实验显示该方法高效且效果接近人工修复。


<details>
  <summary>Details</summary>
Motivation: OpenID Connect广泛用于单点登录（SSO），极大地方便了多服务访问，但其安全漏洞导致了财产损失和信息泄露，亟需更加自动化和稳健的修复方案。

Method: 提出AuthFix系统，结合LLM进行自动程序修复，集成了故障定位、补丁合成和补丁验证三大模块。通过创新型基于Petri网的模型检测技术，保证生成补丁的正确性。

Result: 在23个OpenID真实漏洞上测试，AuthFix为其中17个漏洞（约74%）生成了正确的修复补丁，且高比例补丁和开发者自行修复的效果一致。

Conclusion: AuthFix展示了LLM结合形式化验证在修复OpenID类安全漏洞上的潜力与有效性，为安全领域的自动化补丁生成提供了新方向。

Abstract: OpenID Connect has revolutionized online authentication based on single
sign-on (SSO) by providing a secure and convenient method for accessing
multiple services with a single set of credentials. Despite its widespread
adoption, critical security bugs in OpenID Connect have resulted in significant
financial losses and security breaches, highlighting the need for robust
mitigation strategies. Automated program repair presents a promising solution
for generating candidate patches for OpenID implementations. However,
challenges such as domain-specific complexities and the necessity for precise
fault localization and patch verification must be addressed. We propose
AuthFix, a counterexample-guided repair engine leveraging LLMs for automated
OpenID bug fixing. AuthFix integrates three key components: fault localization,
patch synthesis, and patch verification. By employing a novel Petri-net-based
model checker, AuthFix ensures the correctness of patches by effectively
modeling interactions. Our evaluation on a dataset of OpenID bugs demonstrates
that AuthFix successfully generated correct patches for 17 out of 23 bugs
(74%), with a high proportion of patches semantically equivalent to
developer-written fixes.

</details>


### [14] [C2|Q>: A Robust Framework for Bridging Classical and Quantum Software Development](https://arxiv.org/abs/2510.02854)
*Boshuai Ye,Arif Ali Khan,Teemu Pihkakoski,Peng Liang,Muhammad Azeem Akbar,Matti Silveri,Lauri Malmi*

Main category: cs.SE

TL;DR: 本文提出C2|Q>量子软件开发框架，借助模块化设计实现从经典代码到量子程序的自动化转换。实验显示该工具显著降低了实现门槛和开发成本，提升了量子软件工程的易用性。


<details>
  <summary>Details</summary>
Motivation: 当前量子软件开发环境要求开发者熟悉底层细节（如问题编码、量子电路构建、算法配置、硬件选择和结果解释），使得传统软件工程师难以使用。为降低使用门槛、推动量子计算更广泛落地，迫切需要新的量子软件工程方法和工具。

Method: 提出并实现了C2|Q>框架，这是一种与硬件无关的量子软件开发框架。框架利用模块化的软件工程原则，将工作流分为编码器、部署模块和解码器三大核心模块，对应地实现问题分类、量子格式生成、电路构建、硬件推荐及量子输出解释等功能。

Result: 实验证明，编码器模块完成率为93.8%；硬件推荐模块对于规模最高达56量子的工作负载均能选出合适量子设备；整个C2|Q>框架处理Python代码片段（434个）和JSON输入（100个）的完成率分别为93.8%和100%。在公开NISQ硬件上，框架能将开发工作量降低近40倍。

Conclusion: C2|Q>极大简化了量子软件开发流程，并有效降低了门槛，使传统软件工程师能够高效、系统地开发量子应用，具有良好的扩展和推广潜力。

Abstract: Quantum Software Engineering (QSE) is emerging as a critical discipline to
make quantum computing accessible to a broader developer community; however,
most quantum development environments still require developers to engage with
low-level details across the software stack - including problem encoding,
circuit construction, algorithm configuration, hardware selection, and result
interpretation - making them difficult for classical software engineers to use.
To bridge this gap, we present C2|Q>: a hardware-agnostic quantum software
development framework that translates classical specifications (code) into
quantum-executable programs while preserving methodological rigor. The
framework applies modular software engineering principles by classifying the
workflow into three core modules: an encoder that classifies problems, produces
Quantum-Compatible Formats (QCFs), and constructs quantum circuits, a
deployment module that generates circuits and recommends hardware based on
fidelity, runtime, and cost, and a decoder that interprets quantum outputs into
classical solutions. In evaluation, the encoder module achieved a 93.8%
completion rate, the hardware recommendation module consistently selected the
appropriate quantum devices for workloads scaling up to 56 qubits, and the full
C2|Q>: workflow successfully processed classical specifications (434 Python
snippets and 100 JSON inputs) with completion rates of 93.8% and 100%,
respectively. For case study problems executed on publicly available NISQ
hardware, C2|Q>: reduced the required implementation effort by nearly 40X
compared to manual implementations using low-level quantum software development
kits (SDKs), with empirical runs limited to small- and medium-sized instances
consistent with current NISQ capabilities. The open-source implementation of
C2|Q>: is available at https://github.com/C2-Q/C2Q

</details>


### [15] [GramTrans: A Better Code Representation Approach in Code Generation](https://arxiv.org/abs/2510.02887)
*Zhao Zhang,Qingyuan Liang,Zeyu Sun,Yizhou Chen,Guoqing Wang,Yican Sun,Lu Zhang,Ge Li,Yingfei Xiong*

Main category: cs.SE

TL;DR: 论文系统探讨了代码表示解析难度对生成模型性能的影响，提出并验证了易解析表示更优的猜想，并通过GramTrans方法自动改进表示，在多个实验中显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成领域对代码表示本身对模型性能的影响关注不够，尤其是缺乏对解析难度和模型效果关系的系统理解。

Method: 通过对Python和Java的代码，采用不同的表示（包括新提出的方法GramTrans，以及多种现有表示），并在多个主流代码生成模型中进行对比实验，定量分析了解析难度与模型性能间的关系。

Result: 提出了自动化将上下文无关语言转换为易于解析（LL(1)类）表示的方法GramTrans，并在多个模型和基准上显著提升性能，且再度验证了解析难度与模型性能的强相关性。

Conclusion: 文中提出并验证了一个猜想：越容易解析的代码表示能够帮助模型获得更好的性能，且通过实验证明该猜想的正确性。

Abstract: Code generation has shown great promise in assisting software development. A
fundamental yet underexplored question is how the choice of code representation
affects model performance. While existing studies employ various
representations, such as treating code as plain text, grammar rule sequences,
or syntax tree sequences, they lack a principled understanding of the
relationship between parsing difficulty and model effectiveness. This paper
proposes a conjecture: the easier a representation is to parse, the better
performance the model achieves. We formalize this idea using grammar classes,
where representations in simpler classes (e.g., LL(1)) are easier to parse.
Through a controlled experiment on a Python-based DSL, we show that parsing
difficulty strongly correlates with model performance. Motivated by this
finding, we present GramTrans, a general approach that automatically transforms
a context-free language into a representation within the LL(1) class. GramTrans
introduces a novel hierarchical conflict elimination algorithm, enabling a
flexible trade-off between syntactic simplicity and token efficiency. We
evaluate GramTrans on both Python and Java using three code generation models:
StarCoder 1B, DeepSeek-Coder 1.3B, and Qwen2.5 1.5B. Across multiple
benchmarks, GramTrans consistently delivers significant improvements over
baseline representations. Furthermore, our analysis of existing representations
reconfirms the strong alignment between parsing difficulty and model
performance, providing additional support for the conjecture.

</details>


### [16] [Mechanistic Interpretability of Code Correctness in LLMs via Sparse Autoencoders](https://arxiv.org/abs/2510.02917)
*Kriz Tahimic,Charibeth Cheng*

Main category: cs.SE

TL;DR: 通过对LLM内部表征的稀疏分解，本文揭示了代码正确性方向可用于预测和修正错误，同时为提升代码生成质量与安全性，提出了测试用例优先的提示和选择性引导等实用建议。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛用于代码生成，并有大量AI建议代码进入实际生产，了解其内部正确性机制变得至关重要，以确保安全有效的部署。

Method: 该研究应用稀疏自编码器对LLM内部表征进行分解，通过t统计量选择预测方向，并用分离分数筛选可引导方向，随后利用引导（steering）、注意力分析和权重正交化等方法剖析它们的机理特性。

Result: 实验发现，LLMs中编码的正确性方向能有效预测错误代码。修复错误的能力虽显著，但可能带来修正与保留已正确信息的权衡。模型生成代码时主要依赖对测试用例的关注，其在基础模型中学到的正确性方向能迁移到指令微调后模型。此外，这些方向既可作为错误警报信号，也能引导模型进行有选择的干预，从而防止持续引导带来的代码破坏。

Conclusion: LLM中的代码正确性机制与模型预训练时学到的表征紧密相关，这些机制可在不同下游任务中重用。通过选择性干预和新的提示策略，可有效提升代码生成的正确性与安全性。

Abstract: As Large Language Models become integral to software development, with
substantial portions of AI-suggested code entering production, understanding
their internal correctness mechanisms becomes critical for safe deployment. We
apply sparse autoencoders to decompose LLM representations, identifying
directions that correspond to code correctness. We select predictor directions
using t-statistics and steering directions through separation scores from base
model representations, then analyze their mechanistic properties through
steering, attention analysis, and weight orthogonalization. We find that code
correctness directions in LLMs reliably predict incorrect code, while
correction capabilities, though statistically significant, involve tradeoffs
between fixing errors and preserving correct code. Mechanistically, successful
code generation depends on attending to test cases rather than problem
descriptions. Moreover, directions identified in base models retain their
effectiveness after instruction-tuning, suggesting code correctness mechanisms
learned during pre-training are repurposed during fine-tuning. Our mechanistic
insights suggest three practical applications: prompting strategies should
prioritize test examples over elaborate problem descriptions, predictor
directions can serve as error alarms for developer review, and these same
predictors can guide selective steering, intervening only when errors are
anticipated to prevent the code corruption from constant steering.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Axiomatisation for an asynchronous epistemic logic with sending and receiving messages](https://arxiv.org/abs/2510.02890)
*Philippe Balbiani,Hans van Ditmarsch,Clara Lerouvillois*

Main category: cs.LO

TL;DR: 本文针对环境发送公告与个体异步接收公告的情形，提出了更一般化的异步公告逻辑公理化体系，提升了多智能体中知识动态变化的刻画能力，但带来了体系的非约化性和无限性。


<details>
  <summary>Details</summary>
Motivation: 现有的公众公告逻辑假设公告的发送和接收是同步的，但实际多智能体系统中公告的发送和各个体的接收往往是异步发生的。该文尝试刻画并完善描述异步公告下的知识变化及其公理化。

Method: 作者引入了两种不同的模态，用以区分公告的发送与接收动作，并基于Kripke模型提出了一种描述历史公告与接收过程的逻辑语义。同时，在已有AA公理体系基础上，提出了一种更加一般化的AA*公理体系，允许在任意历史公告接收情境下推理。

Result: AA*公理体系能够在包含已有公告和接收历史的更一般情境下成立，但它不再如AA那样是约化体系，也不再适用于所有初始假设条件如“没人接收过公告”。AA*还是个无限公理体系，形式上比AA更为复杂。

Conclusion: 文章扩展了异步公告逻辑的公理体系，使其适用于任意历史情境，加强了对多智能体同步与异步知识动态变化的逻辑表达能力。

Abstract: We investigate a public announcement logic for asynchronous public
announcements wherein the sending of the announcements by the environment is
separated from the reception of the announcements by the individual agents.
Both come with different modalities. In the logical semantics, formulas are
interpreted in a world of a Kripke model but given a history of prior
announcements and receptions of announcements that already happened. An
axiomatisation AA for such a logic has been given in prior work, for the
formulas that are valid when interpreted in the Kripke model before any such
announcements have taken place. This axiomatisation is a reduction system
wherein one can show that every formula is equivalent to a purely epistemic
formula without dynamic modalities for announcements and receptions. We propose
a generalisation AA* of this axiomatisation, for the formulas that are valid
when interpreted in the Kripke model given any history of prior announcements
and receptions of announcements. It does not extend the axiomatisation AA, for
example it is no longer valid that nobody has received any announcement. Unlike
AA, this axiomatisation AA* is infinitary and it is not a reduction system.

</details>


### [18] [A Graded Modal Type Theory for Pulse Schedules](https://arxiv.org/abs/2510.03130)
*Robin Adams*

Main category: cs.LO

TL;DR: 该论文提出了一种用于描述超导量子计算机脉冲调度的类型理论语言PSTT，通过引入grade机制表达时序，并具备良好的理论基础。


<details>
  <summary>Details</summary>
Motivation: 目前对超导量子计算机的脉冲调度缺乏系统化语言描述，现有方法难以精确表达资源时序与调度需求。

Method: 利用分级模态类型理论（graded modal type theory），为每个变量赋予参数（grade），以代表时序信息，并结合范畴语义进行理论证明。

Result: PSTT语言有效地描述了脉冲调度问题，并能通过grade参数实现时序的信息表达，理论上的充分性和完备性也已得到证明。

Conclusion: 提出了一种名为PSTT（Pulse Schedule Type Theory）的新型类型理论语言，可以用于描述超导量子计算机的脉冲调度输入，其语义在范畴论下得到解释，并证明该系统的充分性与完备性。

Abstract: We propose a language for representing the pulse schedules that a
superconducting quantum computer accepts as input. The language is a graded
modal type theory named PSTT (Pulse Schedule Type Theory). Graded modals type
theories are type systems where each variable is annotated with a parameter or
grade. These can be used to represent, for example, resource usage, where the
grade denotes how many times a given resource may be used; or privacy levels,
whether a resource is private or public. In this system, we use the grades to
represent timing information. We give categorical semantics to the system and
prove soundness and completeness.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning](https://arxiv.org/abs/2510.02324)
*Wannan Yang,Xinchi Qiu,Lei Yu,Yuchen Zhang,Oliver Aobo Yang,Narine Kokhlikyan,Nicola Cancedda,Diego Garcia-Olano*

Main category: cs.CL

TL;DR: 本文提出了CASAL算法，通过轻量级激活引导训练，能高效降低LLM幻觉，提升泛化能力，适用于多种场景和模型类型，具备强实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然表现出强大能力，但在不知道答案时仍经常自信地给出错误回答（幻觉），而不是承认不知道。以往的激活引导方法虽然可以减少幻觉，但需要在推理过程中实时监控和干预，实际应用较为困难。

Method: 提出了对比激活引导的自适应学习算法（CASAL），将激活引导的优势直接整合进模型权重。训练时仅需微调单个 transformer 层的一个子模块。无需实时干预，方法轻量高效。

Result: CASAL可使模型在知道答案时作答，不知道时选择回避。相比强LORA基线如SFT和DPO，CASAL在短文本QA基准上可将幻觉率降低30%-40%，计算效率提升30倍，数据效率提升20倍。在文本和视觉-语言模型以及OOD场景均表现出良好泛化能力。

Conclusion: CASAL是一种高效的解释性驱动训练方法，既可减少LLM幻觉，又利于在实际生产系统中落地部署，并首次在稠密与专家混合（MoE）模型上都验证其有效性。

Abstract: Large Language Models (LLMs) exhibit impressive capabilities but often
hallucinate, confidently providing incorrect answers instead of admitting
ignorance. Prior work has shown that models encode linear representations of
their own knowledge and that activation steering can reduce hallucinations.
These approaches, however, require real-time monitoring and intervention during
inference. We introduce Contrastive Activation Steering for Amortized Learning
(CASAL), an efficient algorithm that connects interpretability with amortized
optimization. CASAL directly bakes the benefits of activation steering into
model's weights. Once trained, LLMs answer questions they know while abstaining
from answering those they do not. CASAL's light-weight design requires training
only a submodule of a single transformer layer and yet reduces hallucination by
30%-40% across multiple short-form QA benchmarks. CASAL is 30x more
compute-efficient and 20x more data-efficient than strong LoRA-based baselines
such as SFT and DPO, boosting its practical applicability in data scarce
domains. Importantly, CASAL also generalizes effectively to out-of-distribution
(OOD) domains. We showcase CASAL's flexibility in mitigating hallucinations in
both text-only and vision-language models. To our knowledge, CASAL is the first
steering-based training method that has been shown to be effective for both
dense and Mixture-of-Experts (MoE) models. CASAL represents a promising step
forward for applying interpretability-inspired method for practical deployment
in production systems.

</details>


### [20] [Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval](https://arxiv.org/abs/2510.02326)
*Vivek Bhavsar,Joseph Ereifej,Aravanan Gurusami*

Main category: cs.CL

TL;DR: RA-FSM通过有限状态控制与检索增强技术，显著提升了LLM在科研领域的回应可靠性与文献引用准确性，被专家认为优于传统Notebook LM与基线模型，具备广泛推广价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能加速文献综述，但存在幻觉和错误引用的问题，限制了其在专家流程中的应用。该研究试图提升LLM在科学研究领域的可靠性和引证准确性。

Method: 提出了一种模块化的GPT型研究助手（RA-FSM），将生成过程包裹在有限状态控制环路中（相关性-> 置信度-> 知识）。系统结合向量检索与确定性引用流程，通过有限状态机控制查询过滤、问题分解、检索触发等，同时生成带有置信度标签并去重的文献引用。知识库以多源渠道构建，包括期刊、会议、专利等，并写入向量索引和结构化数据库。系统针对光子学领域，在六类任务中与Notebook LM及GPT基线模型进行对比评测。

Result: 在盲测A/B测试中，领域专家更喜欢RA-FSM系统，认为其边界条件处理更优且引用可靠性更高。系统能够在保证延迟和成本可调控的情况下，比传统Notebook LM具备更强的探索与发现能力。

Conclusion: RA-FSM 能够为高要求的技术领域提供透明、可溯源的答案，且系统设计具备向其他科学领域泛化的潜力。

Abstract: Large language models accelerate literature synthesis but can hallucinate and
mis-cite, limiting their usefulness in expert workflows. We present RA-FSM
(Research Assistant - Finite State Machine), a modular GPT-based research
assistant that wraps generation in a finite-state control loop: Relevance ->
Confidence -> Knowledge. The system is grounded in vector retrieval and a
deterministic citation pipeline. The controller filters out-of-scope queries,
scores answerability, decomposes questions, and triggers retrieval only when
needed, and emits answers with confidence labels and in-corpus, de-duplicated
references. A ranked-tier ingestion workflow constructs a domain knowledge base
from journals, conferences, indices, preprints, and patents, writing both to a
dense vector index and to a relational store of normalized metrics. We
implement the system for photonics and evaluate it on six task categories:
analytical reasoning, numerical analysis, methodological critique, comparative
synthesis, factual extraction, and application design. In blinded A/B reviews,
domain experts prefer RA-FSM to both a strong Notebook LM (NLM) and a vanilla
Default GPT API call single-pass baseline, citing stronger boundary-condition
handling and more defensible evidence use. Coverage and novelty analyses
indicate that RA-FSM explores beyond the NLM while incurring tunable latency
and cost overheads. The design emphasizes transparent, well-cited answers for
high-stakes technical work and is generalizable to other scientific domains.

</details>


### [21] [KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI](https://arxiv.org/abs/2510.02327)
*So Kuroki,Yotaro Kubo,Takuya Akiba,Yujin Tang*

Main category: cs.CL

TL;DR: 提出一种把后端LLM知识实时注入S2S模型的新混合架构，在保证低延迟的同时大幅提升了语音交互系统的知识正确性。


<details>
  <summary>Details</summary>
Motivation: 现有的实时语音到语音（S2S）模型能够实现自然、低延迟的对话响应，但缺乏深层知识与语义理解。相反，基于级联系统（包括自动语音识别、基于文本的大语言模型（LLM）及文本转语音）的解决方案虽然知识表现更优，但延迟较高，影响自然交互流程。亟需一种结合两者优势，兼具低延迟与知识深度的方法。

Method: 提出了一种新颖的混合架构：用户语音输入首先通过S2S Transformer进行即时响应，同时将查询发送给后端强大的LLM。LLM返回文本后，实时注入并指导S2S模型的语音生成，从而在不增加级联系统全部延迟的情况下，将丰富的知识融入输出。

Result: 在基于语音合成的MT-Bench基准（多轮问答）上的实验表明，所提出系统在回答正确性上显著优于普通S2S基线，接近级联系统水平，同时延迟与S2S基线相当。

Conclusion: 创新混合架构能够有效结合S2S的低延迟和LLM的知识优势，实现既高效又智能的语音对话系统，突破了传统方法在响应速度和知识深度上的权衡限制。

Abstract: Real-time speech-to-speech (S2S) models excel at generating natural,
low-latency conversational responses but often lack deep knowledge and semantic
understanding. Conversely, cascaded systems combining automatic speech
recognition, a text-based Large Language Model (LLM), and text-to-speech
synthesis offer superior knowledge representation at the cost of high latency,
which disrupts the flow of natural interaction. This paper introduces a novel
hybrid architecture that bridges the gap between these two paradigms. Our
framework processes user speech through an S2S transformer for immediate
responsiveness while concurrently relaying the query to a powerful back-end
LLM. The LLM's text-based response is then injected in real time to guide the
S2S model's speech generation, effectively infusing its output with rich
knowledge without the full latency penalty of a cascaded system. We evaluated
our method using a speech-synthesized variant of the MT-Bench benchmark that
consists of multi-turn question-answering sessions. The results demonstrate
that our system substantially outperforms a baseline S2S model in response
correctness, approaching that of a cascaded system, while maintaining a latency
on par with the baseline.

</details>


### [22] [AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering](https://arxiv.org/abs/2510.02328)
*Ziqing Wang,Chengsheng Mao,Xiaole Wen,Yuan Luo,Kaize Ding*

Main category: cs.CL

TL;DR: AMANDA能在医学视觉问答中不依赖大量标注数据，通过问题分解与知识图谱检索提升医学推理能力，实验验证其明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前医学多模态大模型（Med-MLLMs）在医学视觉问答任务中有良好表现，但在缺乏标注数据的低资源环境下会因医学推理能力瓶颈而失效。具体包括：模型未能细致理解医学图像与未能整合专业医学知识。

Method: 提出了AMANDA框架，无需额外训练，利用LLM代理进行医学知识增强。方法包括：通过问题分解进行内在医学知识增强、通过生物医学知识图谱检索进行外在医学知识增强。

Result: 在八个医学视觉问答基准上进行了大量实验，AMANDA在零样本和少样本任务中都显著提升了表现。

Conclusion: AMANDA框架能有效解决Med-MLLMs在低资源设置下的推理瓶颈，提升医学视觉问答的准确性和可靠性。

Abstract: Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise
in medical visual question answering (Med-VQA). However, when deployed in
low-resource settings where abundant labeled data are unavailable, existing
Med-MLLMs commonly fail due to their medical reasoning capability bottlenecks:
(i) the intrinsic reasoning bottleneck that ignores the details from the
medical image; (ii) the extrinsic reasoning bottleneck that fails to
incorporate specialized medical knowledge. To address those limitations, we
propose AMANDA, a training-free agentic framework that performs medical
knowledge augmentation via LLM agents. Specifically, our intrinsic medical
knowledge augmentation focuses on coarse-to-fine question decomposition for
comprehensive diagnosis, while extrinsic medical knowledge augmentation grounds
the reasoning process via biomedical knowledge graph retrieval. Extensive
experiments across eight Med-VQA benchmarks demonstrate substantial
improvements in both zero-shot and few-shot Med-VQA settings. The code is
available at https://github.com/REAL-Lab-NU/AMANDA.

</details>


### [23] [SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification](https://arxiv.org/abs/2510.02329)
*Kanghoon Yoon,Minsub Kim,Sungjae Lee,Joonhyung Lee,Sunghyeon Woo,Yeonjun In,Se Jung Kwon,Chanyoung Park,Dongsoo Lee*

Main category: cs.CL

TL;DR: SelfJudge实现了无需人工标注的语义判断，加快大模型推理速度，并在多个任务测试中表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有judge decoding虽能加速推理，但需人工注释或特定真值，难以推广。希望发明自动化、泛化性好、无需人工参与的推理加速方法。

Method: 通过自监督训练，让目标大模型对比替换token前后的语义一致性，从而自动获得训练judge verifier的数据，无需依赖人工标注或特定任务的真值。

Result: 在多种NLP任务实验中，SelfJudge的推理速度和准确率权衡明显优于现有judge decoding基线方法。

Conclusion: SelfJudge提供了一种通用的方法，通过自监督训练判断器，在保持语义一致性的前提下，加速大模型推理，且无需人工标注或明确的任务真值。实验证明其推理速度与准确率权衡优于现有baseline。

Abstract: Speculative decoding accelerates LLM inference by verifying candidate tokens
from a draft model against a larger target model. Recent judge decoding boosts
this process by relaxing verification criteria by accepting draft tokens that
may exhibit minor discrepancies from target model output, but existing methods
are restricted by their reliance on human annotations or tasks with verifiable
ground truths, limiting generalizability across diverse NLP tasks. We propose
SelfJudge, which trains judge verifiers via self-supervision of the target
model. Our method measures semantic preservation by assessing whether
token-substituted responses preserve the meaning of original responses,
enabling automatic verifier training across diverse NLP tasks. Our experiments
show SelfJudge achieves superior inference-accuracy trade-offs than judge
decoding baselines, offering a broadly applicable solution for faster LLM
inference.

</details>


### [24] [EntropyLong: Effective Long-Context Training via Predictive Uncertainty](https://arxiv.org/abs/2510.02330)
*Junlong Jia,Ziyang Chen,Xing Wu,Chaochen Gao,Zijia Lin,Debing Zhang,Songlin Hu,Binghui Guo*

Main category: cs.CL

TL;DR: 论文提出了一种结合模型预测熵用于有效构建真实长距离依赖数据的新方法，并实验证明其能显著提升长上下文语言模型在相关任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有长文本上下文语言模型训练方法通常通过简单拼接或启发式手段构造长依赖，但无法保证生成的依赖是真实且有益的。作者旨在提高训练样本中长距离依赖的真实性和有效性，进而提升模型长文本理解能力。

Method: 提出EntropyLong方法：首先检测文本中高熵（即模型预测不确定性高）的位置，从大规模语料中检索语义相关上下文，并通过模型循环验证这些上下文能否降低预测熵，确保加入的依赖有实际信息增益。构造包含真实长距离依赖的数据，用于模型训练和性能测试。

Result: 基于EntropyLong生成的数据集显著提升了模型在RULER、LongBenchv2等长依赖任务评测中的准确度，尤其是在需要远距离信息判别的测项中效果突出。消融实验进一步验证了基于熵的依赖验证机制的有效性和必要性。

Conclusion: 通过引入基于预测熵的依赖验证与数据构造方法，作者成功提升了长上下文语言模型在长距离依赖任务中的表现，证明其对提升模型长文本理解能力有效。

Abstract: Training long-context language models to capture long-range dependencies
requires specialized data construction. Current approaches, such as generic
text concatenation or heuristic-based variants, frequently fail to guarantee
genuine long-range dependencies. We propose EntropyLong, a novel data
construction method that leverages predictive uncertainty to verify dependency
quality. Our approach identifies high-entropy positions in documents, retrieves
semantically relevant contexts from large corpora, and verifies their utility
by assessing whether they reduce prediction entropy. This model-in-the-loop
verification ensures each dependency represents measurable information gain
rather than spurious correlation. We construct training samples with long-range
dependencies by combining original documents with these verified contextual
supplements. Using FineWebEdu and Cosmopedia, we generate a dataset of
128K-length sequences with verified dependencies. Models trained on this data
demonstrate significant improvements on RULER benchmarks, particularly in tasks
requiring distant information. Following instruction fine-tuning, our models
also achieve substantial gains on LongBenchv2, demonstrating enhanced
long-context understanding. Extensive ablation studies further validate the
necessity and effectiveness of entropybased verification for long-context
training.

</details>


### [25] [Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)](https://arxiv.org/abs/2510.02331)
*Moonkyung Ryu,Chih-Wei Hsu,Yinlam Chow,Mohammad Ghavamzadeh,Craig Boutilier*

Main category: cs.CL

TL;DR: 针对推荐系统缺乏数据的问题，作者提出用行为模拟器及语言模型提示生成高质量对话数据，并公开了大规模数据集，评估结果表明生成数据自然、一致且事实性高。


<details>
  <summary>Details</summary>
Motivation: 现有可公开获取的对话式推荐系统数据稀缺，导致难以用这些数据对语言模型进行微调以提升推荐系统表现。

Method: 开发了一种结合行为模拟器和语言模型提示的方法，据此生成与用户状态一致的自然对话数据。

Result: 生成了一个包含用户偏好获取和例子批判的大规模开源对话式推荐系统数据集；人工评价显示生成对话在一致性、事实性和自然性等方面表现突出。

Conclusion: 结合行为模拟与语言模型提示能够有效生成高质量推荐对话数据，缓解数据稀缺难题，为对话式推荐系统训练提供新的途径。

Abstract: While language models (LMs) offer great potential for conversational
recommender systems (CRSs), the paucity of public CRS data makes fine-tuning
LMs for CRSs challenging. In response, LMs as user simulators qua data
generators can be used to train LM-based CRSs, but often lack behavioral
consistency, generating utterance sequences inconsistent with those of any real
user. To address this, we develop a methodology for generating natural
dialogues that are consistent with a user's underlying state using behavior
simulators together with LM-prompting. We illustrate our approach by generating
a large, open-source CRS data set with both preference elicitation and example
critiquing. Rater evaluation on some of these dialogues shows them to exhibit
considerable consistency, factuality and naturalness.

</details>


### [26] [A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography](https://arxiv.org/abs/2510.02332)
*Yapei Feng,Feng Jiang,Shanhao Wu,Hua Zhong*

Main category: cs.CL

TL;DR: 提出了一种新型同步机制，提高了神经语言隐写的信息承载能力，并确保安全性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 神经语言隐写术（Neural linguistic steganography）需要在自然文本中嵌入信息但又保持不可被检测性。现代分词器存在分词歧义，会造成灾难性的解码失败，这成为该领域核心难题。

Method: 提出了一种名为look-ahead Sync的新方法，仅在真正不可区分的token序列上进行最小同步采样，其他可区分路径保留以最大化嵌入容量；并提供了理论安全性证明和容量分析。

Result: 实验表明，在英文（Llama 3）和中文（Qwen 2.5）基准上，该方法嵌入容量比SyncPool大大提升。特别是在候选 token 较多时，英文提升超160%，中文提升超25%。

Conclusion: look-ahead Sync方法兼顾了信息嵌入容量和理论安全性，大幅提升了神经语言隐写的实际性能和实用性。

Abstract: Neural linguistic steganography aims to embed information
  into natural text while preserving statistical undetectability. A fundamental
challenge in this ffeld stems from tokenization ambiguity in modern tokenizers,
which can lead to catastrophic decoding failures. The recent method, SyncPool,
addresses this ambiguity
  by employing a coarse-grained synchronization mechanism over groups of
ambiguous candidates. However, SyncPool sacriffces embedding capacity, as it
utilizes the entire Shannon entropy of an ambiguous group solely for
synchronization rather than for payload embedding. We propose a method named
look-ahead Sync, which overcomes the capacity limitation of SyncPool while
retaining its provable security guarantees. Our approach performs minimal
synchronized sampling only on truly indistinguishable token sequences, while
strategically preserving all other discernible paths to maximize embedding
capacity. We provide theoretical proofs for the security of our method and
analyze the gap between its achievable embedding capacity and the theoretical
upper bound. Experiments on English (using Llama 3) and Chinese (using Qwen
2.5) benchmarks show that our method consistently approaches the theoretical
capacity upper bound and signiffcantly outperforms SyncPool. The improvement in
embedding rate exceeds 160% in English and 25% in Chinese, particularly in
settings with larger candidate pools. This work represents a signiffcant step
toward practical high-capacity provably secure linguistic steganography.

</details>


### [27] [Human Mobility Datasets Enriched With Contextual and Social Dimensions](https://arxiv.org/abs/2510.02333)
*Chiara Pugliese,Francesco Lettich,Guido Rocchietti,Chiara Renso,Fabio Pinelli*

Main category: cs.CL

TL;DR: 本文发布了首个融合了多重语义增强和LLM生成社交文本的人类轨迹开放数据集，涵盖巴黎和纽约，支持行为建模和语义推理等多种研究任务，并附开源工具。


<details>
  <summary>Details</summary>
Motivation: 现有的人类轨迹数据集往往缺乏丰富的语义信息和可扩展性，难以支持语义推理和多模态分析，限制了行为建模、知识图谱等领域的深入研究。作者希望通过丰富的数据集和工具推动该领域的发展。

Method: 该工作发布了两个人类轨迹的开放数据集（巴黎和纽约），所有轨迹基于OpenStreetMap的GPS轨迹。对数据进行了多层次语义丰富，包括停留点、移动段、兴趣点（POIs）、交通方式推断、天气数据，并利用大语言模型（LLM）生成合成与现实相符的社交媒体文本。数据集以表格式和RDF格式发布，附带开源的可复现生成流程，便于自定义。

Result: 提供了带多重语义标签的真实人类移动数据集，支持语义推理和多模态分析，覆盖两大典型城市。数据可灵活应用于行为建模、出行预测、知识图谱和LLM应用等领域。数据开放且可复用。

Conclusion: 该研究首次整合了真实世界移动数据、结构化语义增强、LLM生成文本及语义网兼容，构建了可复用、可拓展的开源人类轨迹数据集资源，有望推动多领域相关研究。

Abstract: In this resource paper, we present two publicly available datasets of
semantically enriched human trajectories, together with the pipeline to build
them. The trajectories are publicly available GPS traces retrieved from
OpenStreetMap. Each dataset includes contextual layers such as stops, moves,
points of interest (POIs), inferred transportation modes, and weather data. A
novel semantic feature is the inclusion of synthetic, realistic social media
posts generated by Large Language Models (LLMs), enabling multimodal and
semantic mobility analysis. The datasets are available in both tabular and
Resource Description Framework (RDF) formats, supporting semantic reasoning and
FAIR data practices. They cover two structurally distinct, large cities: Paris
and New York. Our open source reproducible pipeline allows for dataset
customization, while the datasets support research tasks such as behavior
modeling, mobility prediction, knowledge graph construction, and LLM-based
applications. To our knowledge, our resource is the first to combine real-world
movement, structured semantic enrichment, LLM-generated text, and semantic web
compatibility in a reusable framework.

</details>


### [28] [Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing](https://arxiv.org/abs/2510.02334)
*Zhe Li,Wei Zhao,Yige Li,Jun Sun*

Main category: cs.CL

TL;DR: 作者提出了一种基于模型激活空间的新方法，高效诊断并归因LLM不良行为，支持样本与token级别分析，可用于提升大模型的可解释性与安全性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在实际部署时常常出现有害内容生成、事实错误及社会偏见等不良行为，而这些问题的根本成因难以诊断，严重威胁AI安全。现有参数梯度归因方法信号噪声大、计算复杂度高，难以有效追溯和分析模型不良行为的根源，因此亟需一种高效且有意义的归因诊断工具。

Method: 作者提出了一种新颖高效的诊断框架，通过分析LLM激活空间中的表征及其梯度，直接在激活空间实现样本与输出之间的语义关联。该方法无需依赖参数梯度，而是利用模型的激活表示和梯度，系统性地应用于追踪有害内容、检测后门投毒和识别知识污染等任务，并能实现精确到token级别的归因分析。

Result: 实验结果表明，该方法不仅在样本级归因上表现出色，还能进行精细的token级分析，准确定位影响模型行为的具体样本和短语。该框架在多项任务中验证了其实用性和高效性，并且工具代码已公开。

Conclusion: 该研究为理解、审计和减缓LLM相关风险提供了一种强大的诊断工具，有助于促进模型安全性和可控性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities, yet
their deployment is frequently undermined by undesirable behaviors such as
generating harmful content, factual inaccuracies, and societal biases.
Diagnosing the root causes of these failures poses a critical challenge for AI
safety. Existing attribution methods, particularly those based on parameter
gradients, often fall short due to prohibitive noisy signals and computational
complexity. In this work, we introduce a novel and efficient framework that
diagnoses a range of undesirable LLM behaviors by analyzing representation and
its gradients, which operates directly in the model's activation space to
provide a semantically meaningful signal linking outputs to their training
data. We systematically evaluate our method for tasks that include tracking
harmful content, detecting backdoor poisoning, and identifying knowledge
contamination. The results demonstrate that our approach not only excels at
sample-level attribution but also enables fine-grained token-level analysis,
precisely identifying the specific samples and phrases that causally influence
model behavior. This work provides a powerful diagnostic tool to understand,
audit, and ultimately mitigate the risks associated with LLMs. The code is
available at https://github.com/plumprc/RepT.

</details>


### [29] [FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory](https://arxiv.org/abs/2510.02335)
*Xiao-Wen Yang,Zihao Zhang,Jianuo Cao,Zhi Zhou,Zenan Li,Lan-Zhe Guo,Yuan Yao,Taolue Chen,Yu-Feng Li,Xiaoxing Ma*

Main category: cs.CL

TL;DR: 本文提出正式的机器学习理论子目标补全集基准数据集FormalML，并分析当前定理证明器在此任务上的不足，表明未来需要更强大的大模型推动该领域进步。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在形式定理证明方面取得进展，但其在复杂证明中帮助数学家补全缺失步骤（子目标补全）的能力尚未深入探索，因此需要一个专门的评测基准来刻画这一难题。

Method: 提出一种新基准FormalML，包括将过程化证明转化为声明式证明的方法，构建了涵盖机器学习基础理论的4937个子目标补全集问题，同时结合前提检索和复杂背景，对现有证明器进行实验评估。

Result: FormalML提出后，评测了主流证明器，发现它们在准确率和效率方面均存在不足，暴露了当前方法的局限性。

Conclusion: 当前最先进的证明器在子目标补全任务上的准确性和效率依然有限，表明需要开发更强大的基于大模型的定理证明工具。

Abstract: Large language models (LLMs) have recently demonstrated remarkable progress
in formal theorem proving. Yet their ability to serve as practical assistants
for mathematicians, filling in missing steps within complex proofs, remains
underexplored. We identify this challenge as the task of subgoal completion,
where an LLM must discharge short but nontrivial proof obligations left
unresolved in a human-provided sketch. To study this problem, we introduce
FormalML, a Lean 4 benchmark built from foundational theories of machine
learning. Using a translation tactic that converts procedural proofs into
declarative form, we extract 4937 problems spanning optimization and
probability inequalities, with varying levels of difficulty. FormalML is the
first subgoal completion benchmark to combine premise retrieval and complex
research-level contexts. Evaluation of state-of-the-art provers highlights
persistent limitations in accuracy and efficiency, underscoring the need for
more capable LLM-based theorem provers for effective subgoal completion,

</details>


### [30] [KurdSTS: The Kurdish Semantic Textual Similarity](https://arxiv.org/abs/2510.02336)
*Abdulhady Abas Abdullah,Hadi Veisi,Hussein M. Al*

Main category: cs.CL

TL;DR: 作者首次发布了库尔德语STS数据集，并对主流模型做了基准评测，不仅获得了有竞争力的结果，还分析了库尔德语的特殊挑战，为该领域后续研究提供了资源和方法论基础。


<details>
  <summary>Details</summary>
Motivation: 库尔德语等低资源语言缺乏充分的STS数据集，制约了相关NLP任务的发展。本文旨在填补库尔德语语义文本相似性资源的空白。

Method: 构建包含1万对句子的库尔德语STS数据集，涵盖正式和非正式文体，并为每对句子标注语义相似度。采用Sentence-BERT、多语言BERT等主流模型进行基准测试。

Result: 模型基准测试取得了有竞争力的结果，并揭示了库尔德语形态结构、异体书写和代码混杂等带来的挑战。数据集和基线模型为后续库尔德语语义研究和低资源NLP任务奠定了基础。

Conclusion: 本文首次发布了库尔德语的语义文本相似性（STS）数据集，并建立了可重复评测基准，为低资源库尔德语语义相关性研究提供了基础。

Abstract: Semantic Textual Similarity (STS) measures the degree of meaning overlap
between two texts and underpins many NLP tasks. While extensive resources exist
for high-resource languages, low-resource languages such as Kurdish remain
underserved. We present, to our knowledge, the first Kurdish STS dataset:
10,000 sentence pairs spanning formal and informal registers, each annotated
for similarity. We benchmark Sentence-BERT, multilingual BERT, and other strong
baselines, obtaining competitive results while highlighting challenges arising
from Kurdish morphology, orthographic variation, and code-mixing. The dataset
and baselines establish a reproducible evaluation suite and provide a strong
starting point for future research on Kurdish semantics and low-resource NLP.

</details>


### [31] [CRACQ: A Multi-Dimensional Approach To Automated Document Assessment](https://arxiv.org/abs/2510.02337)
*Ishak Soltani,Francisco Belo,Bernardo Tavares*

Main category: cs.CL

TL;DR: 本文提出了面向五个维度的自动评估框架CRACQ，相较于大模型直接评分具备更稳定、可解释的trait-level打分，对丰富多样的生成文本具实际评估价值，但仍有可靠性和适用范围需改进。


<details>
  <summary>Details</summary>
Motivation: 当前大多数自动文本评估方法通常采用单一评分，难以细致、解释性地评价文本各方面特征，尤其是在面对多样化的机器生成文本时更显不足。该论文旨在解决文本多维 trait 评估的需求，提高评估的细致性与可解释性。

Method: 提出了CRACQ评估框架，从连贯性、严谨性、适切性、完整性和质量五个维度对文档进行评价。该方法融合了语言、语义及结构特征信号，将其整合为累积式评估体系，既能提供整体分数，也可做trait-level分析。作者对500份合成科研资助项目提案训练模型，并与LLM直评法进行比较，测试不同真实应用案例。

Result: 实验结果表明，CRACQ在trait-level判定上的稳定性与可解释性优于直接用LLM评价，但系统在可靠性和适用领域的广度上依然存在挑战。

Conclusion: CRACQ框架为机器生成文本的多维、可解释性自动评估提供了新思路和更高的稳定性，但进一步提升其可靠性及领域适应性仍需努力。

Abstract: This paper presents CRACQ, a multi-dimensional evaluation framework tailored
to evaluate documents across f i v e specific traits: Coherence, Rigor,
Appropriateness, Completeness, and Quality. Building on insights from
traitbased Automated Essay Scoring (AES), CRACQ expands its fo-cus beyond
essays to encompass diverse forms of machine-generated text, providing a
rubricdriven and interpretable methodology for automated evaluation. Unlike
singlescore approaches, CRACQ integrates linguistic, semantic, and structural
signals into a cumulative assessment, enabling both holistic and trait-level
analysis. Trained on 500 synthetic grant pro-posals, CRACQ was benchmarked
against an LLM-as-a-judge and further tested on both strong and weak real
applications. Preliminary results in-dicate that CRACQ produces more stable and
interpretable trait-level judgments than direct LLM evaluation, though
challenges in reliability and domain scope remain

</details>


### [32] [Optimizing Long-Form Clinical Text Generation with Claim-Based Rewards](https://arxiv.org/abs/2510.02338)
*Samyak Jhaveri,Praphul Singh,Jangwon Kim,Tara Taghavi,Krishnaram Kenthapadi*

Main category: cs.CL

TL;DR: 该研究提出了结合GRPO与DocLens的强化学习框架，无需额外奖励模型即可提升自动化临床文本的准确性和完整性，实验与GPT-5评估均证实有效，具有实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 自动化临床文档生成需高度关注内容的完整性和事实准确性，但现有大模型存在幻觉和缺漏等问题，难以与临床需求高度对齐。

Method: 提出了一个集成评估与强化学习的框架，用Group Relative Policy Optimization（GRPO）方法结合DocLens（基于对话的确定性声称级评估器），直接优化事实准确性和完整性，无需单独奖励模型或人工参考；通过简单奖励门控策略提升成本效率。

Result: 该方法显著提升了临床文本的事实性和完整性，并降低了训练成本；GPT-5独立评估显示GRPO生成结果在事实性、完整性和简洁性上表现优异，遗漏和幻觉更少。

Conclusion: 本框架在已有模型基础上依然带来可观的、较为保守的提升，具备现实可扩展性且能适配多种定制目标。

Abstract: Automating clinical documentation with large language models requires precise
alignment with priorities such as completeness and factual grounding. We
present an evaluation-integrated reinforcement learning framework for long-form
clinical text generation that couples Group Relative Policy Optimization (GRPO)
with DocLens, a claim-level evaluator that provides deterministic,
dialogue-grounded rewards. Our method directly optimizes factual grounding and
completeness without training a separate reward model or relying on
human-authored references. Empirically, the approach improves clinical note
quality and reduces training cost via a simple reward-gating strategy. An
independent GPT-5 qualitative evaluation further supports these gains, showing
higher preference for GRPO outputs in factuality, completeness, and brevity,
with fewer omissions and hallucinations. Because the benchmarks are relatively
clean and the base model already well aligned, these improvements likely
represent a conservative lower bound. The framework is scalable to real-world
settings and can incorporate custom objectives such as guideline adherence or
billing preferences.

</details>


### [33] [Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models](https://arxiv.org/abs/2510.02339)
*Kevin Zhou,Adam Dejl,Gabriel Freedman,Lihu Chen,Antonio Rago,Francesca Toni*

Main category: cs.CL

TL;DR: 论文提出将不确定性量化方法结合到辩论型大模型用于决策，实验证明简单的直接提示方式在量化不确定性时效果突出，且该评测方式本身具创新性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在不确定性量化（UQ）研究变得越来越重要，旨在提升其在决策制定上的可靠性，尤其是在需要解释与推理的场景下。该论文关注于将UQ方法整合进解释性强、用于决策的辩论型大模型（ArgLLMs），以确保AI推理的可信度。

Method: 论文在基于计算论证的ArgLLMs上，应用和比较了不同的大语言模型UQ方法，通过实验证明在主张验证任务（claim verification）中的效果，从而间接评估了各UQ方法优劣。实验过程本身提出了一种新的UQ方法评估方式，特别适用于复杂、有争议的语句。

Result: 实验结果显示，即便是最简单的直接提示（direct prompting）方法，在ArgLLMs上的UQ任务中也相当有效，并超越了一些更为复杂的UQ方案。

Conclusion: 直接提示法作为一种不确定性量化方法，在辩论型大语言模型中的表现优异，简单有效，对提升决策AI的可靠性有重要意义。利用ArgLLMs及其任务，也能新颖、有效地评估UQ方法。

Abstract: Research in uncertainty quantification (UQ) for large language models (LLMs)
is increasingly important towards guaranteeing the reliability of this
groundbreaking technology. We explore the integration of LLM UQ methods in
argumentative LLMs (ArgLLMs), an explainable LLM framework for decision-making
based on computational argumentation in which UQ plays a critical role. We
conduct experiments to evaluate ArgLLMs' performance on claim verification
tasks when using different LLM UQ methods, inherently performing an assessment
of the UQ methods' effectiveness. Moreover, the experimental procedure itself
is a novel way of evaluating the effectiveness of UQ methods, especially when
intricate and potentially contentious statements are present. Our results
demonstrate that, despite its simplicity, direct prompting is an effective UQ
strategy in ArgLLMs, outperforming considerably more complex approaches.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [34] [Optimized Degree Realization: Minimum Dominating Set & Maximum Matching](https://arxiv.org/abs/2510.03176)
*Amotz Bar-Noy,Igor Kalinichev,David Peleg,Dror Rawitz*

Main category: cs.DM

TL;DR: 该文提出了两个此前未解的度数序列优化实现问题的高效算法（分别针对最小支配集和最大匹配），并给出了支配集规模的度数序列判定的标准，对图论优化问题的实际求解具有推动意义。


<details>
  <summary>Details</summary>
Motivation: 给定一个度数序列，找到对应图的构造问题在图论中非常经典，但当该序列对应多个不同的图时，某些特定性质（如最大团、最大独立集、最小点覆盖等）的‘优化实现’问题更具挑战性。对于最小支配集和最大匹配两个性质，目前还没有高效算法，因此本研究旨在填补这两个空白。

Method: 研究专注于开发两类优化实现的多项式时间算法：一是最小支配集优化实现（在所有可能对应的图中，支配集最小），二是最大匹配优化实现（在所有可能的图中，最大匹配最大）。同时，对所有支配集最小值达到给定规模的度数序列进行了刻画分析。

Result: 论文提出了两个多项式时间算法，分别用于最小支配集优化实现及最大匹配优化实现。这有效解决了此前这两类度数序列优化实现问题的开放性问题。同时，给出了支配集最小值为给定大小时的度数序列判定的简洁刻画。

Conclusion: 本文为两个度数序列优化实现的公开问题（最小支配集、最大匹配）提供了高效算法，并进一步对最小支配集规模的度数序列进行了细致刻画，对相关领域的优化算法与理论分析有重要推动作用。

Abstract: The Degree Realization problem requires, given a sequence $d$ of $n$ positive
integers, to decide whether there exists a graph whose degrees correspond to
$d$, and to construct such a graph if it exists. A more challenging variant of
the problem arises when $d$ has many different realizations, and some of them
may be more desirable than others. We study \emph{optimized realization}
problems in which the goal is to compute a realization that optimizes some
quality measure. Efficient algorithms are known for the problems of finding a
realization with the maximum clique, the maximum independent set, or the
minimum vertex cover. In this paper, we focus on two problems for which such
algorithms were not known. The first is the Degree Realization with Minimum
Dominating Set problem, where the goal is to find a realization whose minimum
dominating set is minimized among all the realizations of the given sequence
$d$. The second is the Degree Realization with Maximum Matching problem, where
the goal is to find a realization with the largest matching among all the
realizations of $d$. We present polynomial time realization algorithms for
these two open problems.
  A related problem of interest and importance is \emph{characterizing} the
sequences with a given value of the optimized function. This leads to an
efficient computation of the optimized value without providing the realization
that achieves that value. For the Maximum Matching problem, a succinct
characterization of degree sequences with a maximum matching of a given size
was known. This paper provides a succinct characterization of sequences with
minimum dominating set of a given size.

</details>
