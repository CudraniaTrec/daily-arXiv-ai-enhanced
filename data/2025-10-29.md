<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 10]
- [cs.LO](#cs.LO) [Total: 7]
- [cs.CL](#cs.CL) [Total: 10]
- [cs.DM](#cs.DM) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [VisCoder2: Building Multi-Language Visualization Coding Agents](https://arxiv.org/abs/2510.23642)
*Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: 本文针对代码可视化LLM的局限，提出了覆盖多语言、支持多轮修正的大规模数据集与基准，并推出性能优越的多语言模型VisCoder2，极大提升了代码生成和自我修正能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在可视化代码生成过程中存在语言支持有限、执行不可靠、缺乏迭代修正等问题，且目前数据集与基准测试多为单轮生成和单一语言任务，难以覆盖实际工作流需求。

Method: 作者提出三个创新资源：1）VisCode-Multi-679K，一个包含67.9万条、覆盖12种编程语言、带有多轮修正对话且可执行的大规模监督数据集；2）VisPlotBench，一个系统化的评测基准，涵盖可执行任务、可渲染结果及支持初始生成和多轮自我调试流程的评测协议；3）VisCoder2系列可视化多语言模型，在VisCode-Multi-679K数据集上训练。

Result: 实验结果表明，VisCoder2在各项任务中显著优于现有开源模型，并接近GPT-4.1等专有模型的表现。通过多轮自我调试，32B规模下整体代码执行通过率达到82.4%，在符号或依赖编译器的语言中表现尤为突出。

Conclusion: 作者提出的数据集、基准和模型推进了多语言可视化代码生成领域，可广泛促进LLM驱动的编程与数据可视化应用。

Abstract: Large language models (LLMs) have recently enabled coding agents capable of
generating, executing, and revising visualization code. However, existing
models often fail in practical workflows due to limited language coverage,
unreliable execution, and lack of iterative correction mechanisms. Progress has
been constrained by narrow datasets and benchmarks that emphasize single-round
generation and single-language tasks. To address these challenges, we introduce
three complementary resources for advancing visualization coding agents.
VisCode-Multi-679K is a large-scale, supervised dataset containing 679K
validated and executable visualization samples with multi-turn correction
dialogues across 12 programming languages. VisPlotBench is a benchmark for
systematic evaluation, featuring executable tasks, rendered outputs, and
protocols for both initial generation and multi-round self-debug. Finally, we
present VisCoder2, a family of multi-language visualization models trained on
VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms
strong open-source baselines and approaches the performance of proprietary
models like GPT-4.1, with further gains from iterative self-debug, reaching
82.4% overall execution pass rate at the 32B scale, particularly in symbolic or
compiler-dependent languages.

</details>


### [2] [AI-Driven Development of a Publishing Imprint: Xynapse Traces](https://arxiv.org/abs/2510.23627)
*Fred Zimmerman*

Main category: cs.SE

TL;DR: Xynapse Traces利用人机协作，通过AI驱动的全面自动化极大提升出版速度与效率，并确保高质量，实现出版能力的民主化。


<details>
  <summary>Details</summary>
Motivation: 传统出版流程耗时长、成本高、创新难和市场受限。该方案旨在利用AI技术解决传统出版的效率、成本、质量和市场进入障碍，实现出版流程变革。

Method: 采用配置驱动的多模型AI框架，实现创意生成、筛选、出版和分发的全流程自动化，辅以人工监督和验证机制，保持质量标准。

Result: Xynapse Traces 通过结合人类与算法方法，采用配置驱动架构和多模型AI集成框架，实验性地创建出版品牌。系统在缩短上市时间（6-12个月降至2-4周）和降低成本（节约80%）的同时，保持高质量标准：第1年出版52本书，引用准确率99%，经过初步修正后验证成功率100%。其中关键技术创新包括：持续创意生成并用锦标赛式评估筛选、原创译经冥想手册的编码仪式、全面自动化（涵盖创意至分发）、以及定义并引导品牌使命的出版社人格设定。同时，将自动化验证和人工监督结合，兼顾速度与出版标准。该系统推动出版领域人机协作新范式，有助于提升出版能力普及度并开发小众市场。

Conclusion: 本系统表明，结合AI和人类专家能极大提高出版效率和降低成本，同时通过创新机制保障质量，还能支持更多细分领域的发展，对出版社和行业具有重要启示。

Abstract: Xynapse Traces is an experimental publishing imprint created via a fusion of
human and algorithmic methods using a configuration-driven architecture and a
multi-model AI integration framework. The system achieved a remarkable 90%
reduction in time-to-market (from a typical 6-12 months to just 2-4 weeks),
with 80% cost reduction compared to traditional imprint development, while
publishing 52 books in its first year and maintaining exceptional quality
metrics, including 99% citation accuracy and 100% validation success after
initial corrections. Key technical innovations include a continuous ideation
pipeline with tournament-style evaluation, a novel codex design for
transcriptive meditation practice, comprehensive automation spanning from
ideation through production and distribution, and publisher personas that
define and guide the imprint's mission. The system also integrates automated
verification with human oversight, ensuring that gains in speed do not
compromise publishing standards. This effort has significant implications for
the future of book publishing, suggesting new paradigms for human-AI
collaboration that democratize access to sophisticated publishing capabilities
and make previously unviable niche markets accessible.

</details>


### [3] [Agentsway -- Software Development Methodology for AI Agents-based Teams](https://arxiv.org/abs/2510.23664)
*Eranga Bandara,Ross Gore,Xueping Liang,Sachini Rajapakse,Isurunima Kularathne,Pramoda Karunarathna,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Amin Hass,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.SE

TL;DR: 本文提出了Agentsway框架，解决AI agent主导的软件开发中传统方法不适用的问题，实现了智能协作、隐私保护和责任透明，开启了AI原生软件工程的方法论创新。


<details>
  <summary>Details</summary>
Motivation: 随着Agentic AI的兴起，传统以人为核心的软件开发方法（如Agile、Kanban等）已无法适应AI自主参与的团队协作，亟需为AI agent作为主要协作者设计新的开发方法论。

Method: 提出了“Agentsway”框架，为AI agent主导的软件开发生态系统设计结构化生命周期，明确分工规划、编码、测试、微调等专责agent，并融合精调LLM支持隐私保护和人类主导的协作。

Result: Agentsway框架实现了AI agent之间的高效、隐私保护协作，通过持续反馈和精调提升决策解释性和领域推理能力，并嵌入了可衡量的生产力与信任指标，促进责任、透明和可控的软件开发流程。

Conclusion: Agentsway是首个专为AI agent团队设计的软件开发方法，推动软件工程朝向AI原生、自我改进的新一代开发范式迈进。

Abstract: The emergence of Agentic AI is fundamentally transforming how software is
designed, developed, and maintained. Traditional software development
methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for
human-centric teams and are increasingly inadequate in environments where
autonomous AI agents contribute to planning, coding, testing, and continuous
learning. To address this methodological gap, we present "Agentsway" a novel
software development framework designed for ecosystems where AI agents operate
as first-class collaborators. Agentsway introduces a structured lifecycle
centered on human orchestration, and privacy-preserving collaboration among
specialized AI agents. The framework defines distinct roles for planning,
prompting, coding, testing, and fine-tuning agents, each contributing to
iterative improvement and adaptive learning throughout the development process.
By integrating fine-tuned LLMs that leverage outputs and feedback from
different agents throughout the development cycle as part of a retrospective
learning process, Agentsway enhances domain-specific reasoning, and explainable
decision-making across the entire software development lifecycle. Responsible
AI principles are further embedded across the agents through the coordinated
use of multiple fine-tuned LLMs and advanced reasoning models, ensuring
balanced, transparent, and accountable decision-making. This work advances
software engineering by formalizing agent-centric collaboration, integrating
privacy-by-design principles, and defining measurable metrics for productivity
and trust. Agentsway represents a foundational step toward the next generation
of AI-native, self-improving software development methodologies. To the best of
our knowledge, this is the first research effort to introduce a dedicated
methodology explicitly designed for AI agent-based software engineering teams.

</details>


### [4] [RefleXGen:The unexamined code is not worth using](https://arxiv.org/abs/2510.23674)
*Bin Wang,Hui Li,AoFan Liu,BoTao Yang,Ao Yang,YiLu Zhong,Weixiang Huang,Yanping Zhang,Runhuai Huang,Weimin Zeng*

Main category: cs.SE

TL;DR: RefleXGen是一种结合RAG和自我反思机制的新方法，无需资源密集操作即可持续提升LLM生成代码的安全性，在多类模型中效果显著，证明自我反思对代码安全至关重要。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型(LLM)生成代码时，代码安全性是一个核心挑战。传统提升代码安全性的方式如微调模型或构建专门安全数据集，通常非常耗费资源。因此，亟需不依赖大量资源的新方法来提升生成代码的安全性。

Method: 提出了RefleXGen方法，将检索增强生成（RAG）技术与LLM原有的自我反思机制结合起来。RefleXGen无需微调或大量专用数据集，而是通过模型自身的持续自我评估和反思，以迭代优化代码生成过程并不断丰富知识库，逐步提升生成代码的安全性。

Result: RefleXGen在多个主流模型上提升了代码安全性：GPT-3.5 Turbo提升13.6%，GPT-4o提升6.7%，CodeQwen提升4.5%，Gemini提升5.8%。

Conclusion: 通过改善模型的自我反思质量，是提升AI生成代码安全性的有效且实用的策略。RefleXGen无需昂贵资源，就能持续优化模型和生成结果，显著增强代码安全。

Abstract: Security in code generation remains a pivotal challenge when applying large
language models (LLMs). This paper introduces RefleXGen, an innovative method
that significantly enhances code security by integrating Retrieval-Augmented
Generation (RAG) techniques with guided self-reflection mechanisms inherent in
LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing
specialized secure code datasets - processes that can be resource-intensive -
RefleXGen iteratively optimizes the code generation process through
self-assessment and reflection without the need for extensive resources. Within
this framework, the model continuously accumulates and refines its knowledge
base, thereby progressively improving the security of the generated code.
Experimental results demonstrate that RefleXGen substantially enhances code
security across multiple models, achieving a 13.6% improvement with GPT-3.5
Turbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a
5.8% improvement with Gemini. Our findings highlight that improving the quality
of model self-reflection constitutes an effective and practical strategy for
strengthening the security of AI-generated code.

</details>


### [5] [TDFlow: Agentic Workflows for Test Driven Software Engineering](https://arxiv.org/abs/2510.23761)
*Kevin Han,Siddharth Maddikayala,Tim Knappe,Om Patel,Austen Liao,Amir Barati Farimani*

Main category: cs.SE

TL;DR: TDFlow提出了分工明确、测试驱动的多子代理大模型软件修复流程，显著提升了代码补丁通过率，接近人类水平，实现仓库级自动修复的关键难题转向高质量测试用例生成。


<details>
  <summary>Details</summary>
Motivation: 当前的软件工程任务（如代码修复）对大模型推理能力和流程分解提出了更高要求，传统方法难以高效解决人类编写的测试。为此，论文设计了TDFlow，一种将代码修复流程以测试为驱动，利用多个子代理分工协作的新范式，力求提升大模型在仓库级别自动化代码修复的能力。

Method: TDFlow框架将仓库级软件工程的测试解决过程分解为：补丁建议、调试、补丁修订、可选的测试用例生成4个组件，每个子代理专注于对应子任务。这一流程设计显著降低了单一子代理处理超长上下文的难度，强化了任务聚焦和专项性能。整个流程面向人类编写的测试，通过精细设计的子代理和工具进行迭代修复。

Result: 在SWE-Bench Lite数据集上取得88.8%的测试通过率，比现有最佳系统提升27.8%；SWE-Bench Verified上通过率为94.3%。手动检查800个运行案例，仅发现7例作弊（test hacking），已排除。此外，发现阻碍人类级表现的主要障碍在于成功复现测试的编写。

Conclusion: 通过设计工程化的测试驱动、多子代理分工模式，LLM已可在标准测试集上获得接近人类的软件工程水平，唯一瓶颈在于高质量测试的生成。未来可通过人类编写测试+大模型自动修复融合，推动自动化软件工程发展。

Abstract: We introduce TDFlow, a novel test-driven agentic workflow that frames
repository-scale software engineering as a test-resolution task, specifically
designed to solve human-written tests. Given a set of tests, TDFlow repeatedly
proposes, revises, and debugs repository-scale patches using precisely
engineered sub-agents and tightly constrained tools. The workflow decomposes
software engineering program repair into four components governed by respective
sub-agents. This simple, forced decoupling of patch proposing, debugging, patch
revision, and optional test generation (1) reduces long-context burden on any
individual sub-agent, (2) focuses each sub-agent on specific, pre-defined
sub-tasks, and (3) allows for specialized performance improvement on specific
sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on
SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and
94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within
SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which
were subsequently counted as failures. Furthermore, we show that the primary
obstacle to human-level software engineering performance lies within writing
successful reproduction tests. We envision a human-LLM interactive system
powered by TDFlow where human developers write tests solved by LLM systems.
Together, these results indicate that modern LLMs, when embedded in a narrowly
engineered, test-driven workflow, already achieve human-level test resolution
-- with the final frontier for fully autonomous repository repair being the
accurate generation of valid reproduction tests.

</details>


### [6] [Evaluating the effectiveness of LLM-based interoperability](https://arxiv.org/abs/2510.23893)
*Rodrigo Falcão,Stefan Schweitzer,Julien Siebert,Emily Calvet,Frank Elberzhager*

Main category: cs.SE

TL;DR: 本研究用13个开源大语言模型测试农业互操作任务，发现qwen2.5-coder:32b在多个数据集版本下表现优异，部分LLM可实现无需人工介入的自主系统互操作，仍需跨领域和可靠性进一步研究。


<details>
  <summary>Details</summary>
Motivation: 随着系统集成的复杂性提升，系统间异构性和动态性增强，互操作性问题愈发突出。传统的互操作性方案耗时耗力，急需探索能够减少人力干预、提升开发效率的新方法，尤其是经济上可持续的技术途径。

Method: 作者选择了13个开源大语言模型（LLM），针对农业领域的互操作性任务，设计了4个不同版本的数据集。每个模型在每个数据集版本上使用两种策略（DIRECT和CODEGEN）各运行三轮，并统计模型效果及其结果的一致性。

Result: 在DIRECT策略下，qwen2.5-coder:32b模型的平均通过率（pass@1）在三个版本中达到0.99以上；在CODEGEN策略下同一模型平均通过率达到0.89以上。在包含单位转换的第四个数据集版本中，所有模型的DIRECT策略均失败，而qwen2.5-coder:32b在CODEGEN策略下仍有平均通过率0.75。

Conclusion: 部分大语言模型能够实现系统间自主互操作，无需人工干预。但建议在更多领域进一步验证，同时还需深入研究结果可靠性提升的策略。

Abstract: Background: Systems of systems are becoming increasingly dynamic and
heterogeneous, and this adds pressure on the long-standing challenge of
interoperability. Besides its technical aspect, interoperability has also an
economic side, as development time efforts are required to build the
interoperability artifacts. Objectives: With the recent advances in the field
of large language models (LLMs), we aim at analyzing the effectiveness of
LLM-based strategies to make systems interoperate autonomously, at runtime,
without human intervention. Method: We selected 13 open source LLMs and curated
four versions of a dataset in the agricultural interoperability use case. We
performed three runs of each model with each version of the dataset, using two
different strategies. Then we compared the effectiveness of the models and the
consistency of their results across multiple runs. Results: qwen2.5-coder:32b
was the most effective model using both strategies DIRECT (average pass@1 >=
0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset
versions. In the fourth dataset version, which included an unit conversion, all
models using the strategy DIRECT failed, whereas using CODEGEN
qwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some
LLMs can make systems interoperate autonomously. Further evaluation in
different domains is recommended, and further research on reliability
strategies should be conducted.

</details>


### [7] [Validating Alerts in Cloud-Native Observability](https://arxiv.org/abs/2510.23970)
*Maria C. Borges,Julian Legler,Lucca Di Benedetto*

Main category: cs.SE

TL;DR: 论文针对报警设计难题，提出并实现了 OXN 的报警扩展，让开发者能在设计阶段系统性实验和验证报警策略，有效提升报警代码质量和运维可靠性。


<details>
  <summary>Details</summary>
Motivation: 报警机制在可靠性工程中至关重要，但有效设计报警十分困难，存在误报与漏报等问题。此外，报警代码针对罕见故障，缺乏系统性测试与验证的工具。

Method: 研究通过开发并整合报警扩展到现有的 OXN 可观测性实验工具，让工程师在设计阶段实验和优化报警规则，并定期验证其触发行为。

Result: 引入的报警扩展使工程师能够在开发早期优化和验证报警规则，从设计上减少运行时问题。

Conclusion: 该论文提出了一种新的报警扩展工具，用于在开发早期系统性地设计和验证报警规则，提高报警代码的可靠性。

Abstract: Observability and alerting form the backbone of modern reliability
engineering. Alerts help teams catch faults early before they turn into
production outages and serve as first clues for troubleshooting. However,
designing effective alerts is challenging. They need to strike a fine balance
between catching issues early and minimizing false alarms. On top of this,
alerts often cover uncommon faults, so the code is rarely executed and
therefore rarely checked. To address these challenges, several industry
practitioners advocate for testing alerting code with the same rigor as
application code. Still, there's a lack of tools that support such systematic
design and validation of alerts.
  This paper introduces a new alerting extension for the observability
experimentation tool OXN. It lets engineers experiment with alerts early during
development. With OXN, engineers can now tune rules at design time and
routinely validate the firing behavior of their alerts, avoiding future
problems at runtime.

</details>


### [8] [Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs](https://arxiv.org/abs/2510.24019)
*Xing Xing,Wei Wang,Lipeng Ma,Weidong Yang,Junjie Zheng*

Main category: cs.SE

TL;DR: 本文提出将需求分析、状态机建模和伪代码等中间产物纳入大语言模型代码生成流程，实验显示多阶段推理和微调能大幅提升代码生成质量和鲁棒性，尤其是状态机建模贡献最大。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型（LLMs）在自动代码生成上取得了显著进展，但现有方法通常依赖于从问题描述到代码的一步式直接转换，忽略了结构化的软件工程实践。该研究旨在将标准软件开发流程中的中间产物系统性地融入代码生成过程，提高代码生成的结构化和正确性。

Method: 提出了一个生命周期感知的框架，在训练和推理过程中引入需求分析、状态机建模、伪代码等中间产物，使代码生成与软件开发标准流程对齐，并实现更结构化的推理。实验比较了多步推理与一步生成的性能，并进行了消融实验评估各产物贡献。

Result: 多步推理显著优于一步生成。经过生命周期级微调，代码正确率最高提升75％，且各中间阶段的性能增益可叠加。在DeepSeek-Coder-1.3B上的CodeBLEU得分，分别较ChatGPT-3.5、ChatGPT-4o-mini、DeepSeek-R1和LLaMA-8B提升34.3%、20.0%、11.2%和22.3%。该方法在训练数据缩减80％时仍具备强泛化能力。消融实验显示，状态机建模对最终代码质量提升作用最大。

Conclusion: 生命周期感知的代码生成框架能系统提升代码生成质量，实现对标准软件开发流程的结构化迁移。多步、包含中间产物的方式显著提高了代码正确性和泛化能力，对低资源场景同样有效。各中间产物对结果均有独特价值，其中状态机建模贡献最大。

Abstract: Recent progress in large language models (LLMs) has advanced automatic code
generation, yet most approaches rely on direct, single-step translation from
problem descriptions to code, disregarding structured software engineering
practices. We introduce a lifecycle-aware framework that systematically
incorporates intermediate artifacts such as requirements analysis, state
machine modeling, and pseudocode into both the training and inference stages.
This design aligns code generation with standard software development phases
and enables more structured reasoning. Experiments show that lifecycle-level
fine-tuning improves code correctness by up to 75% over the same model before
fine-tuning, with performance gains compounding across intermediate stages.
Multi-step inference consistently surpasses single-step generation,
demonstrating the effectiveness of intermediate scaffolding. Notably,
open-source LLMs, once fine-tuned under our framework, match or slightly
outperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our
framework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and
22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,
respectively. Our pipeline also proves robust with up to 80\% less training
data, confirming its resilience. Ablation studies further reveal that each
intermediate artifact contributes distinctly to final code quality, with state
machine modeling yielding the most substantial impact. Our source code and
detailed experimental data are available at
https://anonymous.4open.science/r/Lifecycle-Aware-3CCB.

</details>


### [9] [Monitoring and Observability of Machine Learning Systems: Current Practices and Gaps](https://arxiv.org/abs/2510.24142)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 该文通过实证研究梳理了生产级ML系统中可观测信息的实际记录与应用现状，发现了当前实践中的空白，并为后续工具设计和研究提出建议。


<details>
  <summary>Details</summary>
Motivation: 生产环境中的机器学习系统在做出错误决策时通常不会崩溃，而是“静默”失败，因此对可观测性的需求变得非常迫切。然而，目前缺乏关于实际操作中从业人员具体记录哪些可观测信息的实证证据。

Method: 通过在多个领域开展七场焦点小组讨论，收集和分析了机器学习从业者在实际操作中有关可观测性的信息捕获与利用方式。

Result: 梳理总结了从业者在ML系统及其环境中系统性记录的信息类型，并绘制了他们在模型验证、故障检测与诊断、以及性能下降解释中的具体用法。同时，发现了当前可观测性实践中的若干空白和不足。

Conclusion: 本文揭示了现有ML可观测性实践中记录行为和关键空白，提出了对工具设计和后续研究的启发，以进一步建立有效的ML可观测性实践。

Abstract: Production machine learning (ML) systems fail silently -- not with crashes,
but through wrong decisions. While observability is recognized as critical for
ML operations, there is a lack empirical evidence of what practitioners
actually capture. This study presents empirical results on ML observability in
practice through seven focus group sessions in several domains. We catalog the
information practitioners systematically capture across ML systems and their
environment and map how they use it to validate models, detect and diagnose
faults, and explain observed degradations. Finally, we identify gaps in current
practice and outline implications for tooling design and research to establish
ML observability practices.

</details>


### [10] [Investigating Software Aging in LLM-Generated Software Systems](https://arxiv.org/abs/2510.24188)
*César Santos,Ermeson Andrade,Roberto Natella*

Main category: cs.SE

TL;DR: 本研究发现由LLM生成的软件在长期运行下普遍存在性能和资源消耗恶化的老化现象，提示相关软件开发需重视长期可靠性并探索缓解方案。


<details>
  <summary>Details</summary>
Motivation: 自动生成代码日益被用于加速开发并减少人工工作，但关于这些系统长期可靠性尚缺乏深入研究，尤其是软件在持续运行中的老化问题。

Method: 实验研究，通过Bolt平台和标准化Baxbench提示生成四个服务型应用，并进行50小时压力测试，持续监测资源使用、响应时间和吞吐率，以观察软件老化现象。

Result: 所有测试应用均出现显著的软件老化迹象，统计分析证实了资源消耗增加和性能下降，并且不同类型应用老化程度有所差异。

Conclusion: 自动生成的软件（尤其是由大型语言模型生成的代码）存在明显的软件老化现象，包括逐步加重的内存消耗、响应时间延长以及性能不稳定。

Abstract: Automatically generated software, especially code produced by Large Language
Models (LLMs), is increasingly adopted to accelerate development and reduce
manual effort. However, little is known about the long-term reliability of such
systems under sustained execution. In this paper, we experimentally investigate
the phenomenon of software aging in applications generated by LLM-based tools.
Using the Bolt platform and standardized prompts from Baxbench, we generated
four service-oriented applications and subjected them to 50-hour load tests.
Resource usage, response time, and throughput were continuously monitored to
detect degradation patterns. The results reveal significant evidence of
software aging, including progressive memory growth, increased response time,
and performance instability across all applications. Statistical analyzes
confirm these trends and highlight variability in the severity of aging
according to the type of application. Our findings show the need to consider
aging in automatically generated software and provide a foundation for future
studies on mitigation strategies and long-term reliability evaluation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [11] [Formalizing Schwartz functions and tempered distributions](https://arxiv.org/abs/2510.24060)
*Moritz Doll*

Main category: cs.LO

TL;DR: 本文首次在Lean定理证明助手中形式化了温和分布理论，实现了傅里叶变换在L^2空间上的等距扩展，并基于此定义了Sobolev空间，为自动化数学证明做出了重要贡献。


<details>
  <summary>Details</summary>
Motivation: 分布理论在偏微分方程理论中至关重要，但该理论此前尚未在任何定理证明助手中被形式化，因此动机是推动温和分布理论在自动化证明系统上的实现。

Method: 利用交互式定理证明助手Lean对温和分布（tempered distributions）理论进行了形式化，并通过该工具证明和定义相关数学结果。

Result: 首次在任何定理证明助手中形式化了温和分布理论，证明了傅里叶变换在L^2上的等距性，并基于温和分布定义了Sobolev空间。

Conclusion: 本文证明了傅里叶变换可以扩展为L^2空间上的线性等距映射，并利用此定义了Sobolev空间。

Abstract: Distribution theory is a cornerstone of the theory of partial differential
equations. We report on the progress of formalizing the theory of tempered
distributions in the interactive proof assistant Lean, which is the first
formalization in any proof assistant. We give an overview of the mathematical
theory and highlight key aspects of the formalization that differ from the
classical presentation. As an application, we prove that the Fourier transform
extends to a linear isometry on $L^2$ and we define Sobolev spaces via the
Fourier transform on tempered distributions.

</details>


### [12] [Dynamic Hypersequents for Public Announcement Logic](https://arxiv.org/abs/2510.24165)
*Clara Lerouvillois,Francesca Poggiolesi*

Main category: cs.LO

TL;DR: 本文针对公共公告逻辑（PAL）的证明理论表达动态性不足问题，提出了动态超序列演算体系，完善了PAL的语法表达能力，并证明该系统具有优秀的结构和逻辑性质。


<details>
  <summary>Details</summary>
Motivation: 目前关于Public Announcement Logic(PAL)的语义研究较多，但现有的证明理论未能在纯语法层面上表达其动态性。本文旨在弥补这一不足。

Method: 本文从S5模态逻辑的超序列演算出发，提出并扩展了“动态超序列”机制，用以表达PAL中的知识状态变更。

Result: 构建了一套适用于PAL的动态超序列演算系统，并证明该系统具备结构规则（包括收缩规则）的可允许性、逻辑规则的可逆性及语法上的割消除性。

Conclusion: 提出的动态超序列演算为PAL提供了更强的语法表达力，不仅能捕捉语义上的动态变化，还确保了演算系统的优良证明性质。

Abstract: Dynamic Epistemic Logic extends classical epistemic logic by modeling not
only static knowledge but also its evolution through information updates. Among
its various systems, Public Announcement Logic (PAL) provides one of the
simplest and most studied frameworks for representing epistemic change. While
the semantics of PAL is well understood as transformation of Kripke models, the
proof theory so far developed fails to represent this dynamism in purely
syntactical terms. The aim of this paper is to repair this lack. In particular,
building on a hypersequent calculus for S5, we extend it with a mechanism that
models the transition between epistemic models induced by public announcements.
We call these structures dynamic hypersequents. Using dynamic hypersequents, we
construct a calculus for PAL and we show that it enjoys several desirable
properties: admissibility of all structural rules (including contraction),
invertibility of logical rules, as well as syntactic cut-elimination.

</details>


### [13] [Fault-Tolerant Multiparty Session Types with Global Escape Loops](https://arxiv.org/abs/2510.24203)
*Lukas Bartl,Julian Linne,Kirstin Peters*

Main category: cs.LO

TL;DR: 本文提出了一种新型容错多方会话类型结构，使其在需要容错的分布式算法终止性验证中更加高效，相关机制通过典型的分布式算法案例得以验证。


<details>
  <summary>Details</summary>
Motivation: 多方会话类型能够用于验证通信协议中的行为属性，其中一个重要属性是进展性（即无死锁）。而分布式算法经常与多方通信协议类似，然而对分布式算法尤其是终止性的证明（终止性和进展性密切相关）通常非常复杂。因为分布式算法常常需要具备容错能力，所以将会话类型应用于分布式算法的验证，首先需要与容错机制结合。

Method: 该论文扩展了FTMPST（一种支持系统失效模型的容错多方会话类型），提出了一种新的容错循环结构，具有全局跳出（global escapes）功能且不需要全局协调。每个进程运行自己本地的循环版本，一旦某个进程找到问题的解法，就发出退出消息（exit-messages）通知其他进程立即终止。该退出消息为非阻塞模式，因此其他进程可在收到退出消息前继续运行。

Result: 该方法提升了验证分布式算法（尤其容错型算法）时的效率和适用性，并通过分析著名的Chandra和Toueg的轮转协调算法的变体进行说明。

Conclusion: 作者通过创新的容错循环结构和全局跳出机制，将多方会话类型更好地应用到需要容错性的分布式算法验证中，为分布式协议提供了高效且理论支持的终止性验证手段。

Abstract: Multiparty session types are designed to abstractly capture the structure of
communication protocols and verify behavioural properties. One important such
property is progress, i.e., the absence of deadlock. Distributed algorithms
often resemble multiparty communication protocols. But proving their
properties, in particular termination that is closely related to progress, can
be elaborate. Since distributed algorithms are often designed to cope with
faults, a first step towards using session types to verify distributed
algorithms is to integrate fault-tolerance.
  We extend FTMPST (a version of fault-tolerant multiparty session types with
failure patterns to represent system requirements for system failures such as
unreliable communication and process crashes) by a novel, fault-tolerant loop
construct with global escapes that does not require global coordination. Each
process runs its own local version of the loop. If a process finds a solution
to the considered problem, it does not only terminate its own loop but also
informs the other participants via exit-messages. Upon receiving an
exit-message, a process immediately terminates its algorithm. To increase
efficiency and model standard fault-tolerant algorithms, these messages are
non-blocking, i.e., a process may continue until a possibly delayed
exit-message is received. To illustrate our approach, we analyse a variant of
the well-known rotating coordinator algorithm by Chandra and Toueg.

</details>


### [14] [An Adequacy Theorem Between Mixed Powerdomains and Probabilistic Concurrency](https://arxiv.org/abs/2510.24204)
*Renato Neves*

Main category: cs.LO

TL;DR: 本文提出适用于概率GCL并发扩展的充分性定理，通过混合幂域语义和拓扑方法，证明了概率并发程序某些性质的半可判定性，为相关可观测属性的分析和验证提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 并发概率程序中融合了非确定性与概率行为，传统语义难以全面描述其可观测属性，本文旨在为此类系统建立完善的充分性语义基础，并探讨可判定性问题。

Method: 采用混合幂域的形式化语义，结合M. Smyth提出的将可观测属性视为拓扑空间的开集，通过对König引理的拓扑泛化证明主定理。

Result: 得到了一条适用于概率GCL并发扩展的充分性定理，证明了概率程序满足某些可观测属性具有半可判定性，部分回应了Escardo有关概率测试可判定性的猜想。

Conclusion: 本文提出的充分性定理能够判断并发概率程序是否满足某些可观测属性，且实现了对这些属性的半可判定性。

Abstract: We present an adequacy theorem for a concurrent extension of probabilistic
GCL. The underlying denotational semantics is based on the so-called mixed
powerdomains, which combine non-determinism with probabilistic behaviour. The
theorem itself is formulated via M. Smyth's idea of treating observable
properties as open sets of a topological space. The proof hinges on a
'topological generalisation' of K\"onig's lemma in the setting of probabilistic
programming (a result that is proved in the paper as well). One application of
the theorem is that it entails semi-decidability w.r.t. whether a concurrent
program satisfies an observable property (written in a certain form). This is
related to M. Escardo's conjecture about semi-decidability w.r.t. may and must
probabilistic testing.

</details>


### [15] [Unique Solutions of Guarded Recursive Equations](https://arxiv.org/abs/2510.24206)
*Rob van Glabbeek*

Main category: cs.LO

TL;DR: 本文证明了只要满足某些语法与语义条件（就绪模拟格式），递归方程具有唯一解，并且为强互模拟等价给出了通用且基础完备的公理系统。


<details>
  <summary>Details</summary>
Motivation: 递归定义在进程代数和系统建模中广泛存在，理解和保证其唯一解对于语义分析和等价判定具有重要意义。此前对于唯一解和公理化的普适条件尚不充分，本文意在弥补这一理论空白。

Method: 作者采用形式系统的方法，利用就绪模拟格式的结构操作语义，对递归方程系统及其解的（强）互模拟、模拟等价等性质进行了理论化分析和证明，并提出可用于任意有限GSOS语言的公理化系统。

Result: 受保护递归方程系统在就绪模拟格式下具有唯一（强互模拟等价的）解；相应等价关系与序是完全（预）合同；强互模拟的公理化在GSOS语言下是可靠且基础完备的。

Conclusion: 本文证明了受保护的递归方程系统在就绪模拟格式的结构操作语义下，关于强互模拟具有唯一解。这一结果同样适用于模拟等价、就绪模拟等价及（就绪）模拟序。由此，这些等价关系和序对于受保护递归都是完全（预）合同的。此外，唯一解结果为任何有限GSOS语言上的强互模拟给出了可靠且基础完备的公理化方法。

Abstract: This paper shows that guarded systems of recursive equations have unique
solutions up to strong bisimilarity for any process algebra with a structural
operation semantics in the ready simulation format. A similar result holds for
simulation equivalence, for ready simulation equivalence and for the (ready)
simulation preorder. As a consequence, these equivalences and preorders are
full (pre)congruences for guarded recursion. Moreover, the unique-solutions
result yields a sound and ground-complete axiomatisation of strong bisimilarity
for any finitary GSOS language.

</details>


### [16] [Traces via Strategies in Two-Player Games](https://arxiv.org/abs/2510.24252)
*Benjamin Plummer,Corina Cirstea*

Main category: cs.LO

TL;DR: 本文扩展了余代数轨迹语义框架到控制者-环境游戏，统一了对非确定性及概率性环境建模，轨迹映射可对应控制者策略下可强制行为路径，参数化结果由弱分配律刻画。


<details>
  <summary>Details</summary>
Motivation: 为了在各种系统类型中研究进程状态之间的语义等价性，特别是在涉及控制者与环境游戏的场景下，现有的轨迹语义框架需要扩展以涵盖非确定性和概率性环境。

Method: 实例化Hasuo等人的有限轨迹语义的余代数框架，并结合适当的单子理论以适用于控制者-环境游戏；利用弱分配律刻画控制者在单步内能强制实现的结果。

Result: 在扩展后的框架下，轨迹映射的每个元素对应控制者可强制实现的一组（子集或分布）行为路径，每个元素等价于一个控制者策略的结果。所得结果由弱分配律参数化，用于计算控制者在一步中可以强制的可能性。

Conclusion: 该方法将余代数轨迹语义扩展到控制者与环境的博弈场景，实现了对非确定性与概率性环境的统一建模，并能有效地对应和恢复熟悉的博弈论概念。

Abstract: Traces form a coarse notion of semantic equivalence between states of a
process, and have been studied coalgebraically for various types of system. We
instantiate the finitary coalgebraic trace semantics framework of Hasuo et al.
for controller-versus-environment games, encompassing both nondeterministic and
probabilistic environments. Although our choice of monads is guided by the
constraints of this abstract framework, they enable us to recover familiar
game-theoretic concepts. Concretely, we show that in these games, each element
in the trace map corresponds to a collection (a subset or distribution) of
plays the controller can force. Furthermore, each element can be seen as the
outcome of following a controller strategy. Our results are parametrised by a
weak distributive law, which computes what the controller can force in a single
step.

</details>


### [17] [Graded Monads in the Semantics of Nominal Automata](https://arxiv.org/abs/2510.24353)
*Hannes Schulze,Lutz Schröder,Üsame Cengiz*

Main category: cs.LO

TL;DR: 本文扩展了分级单子的代数理论到名义自动机领域，提出了新的分级名义代数框架，有效刻画了RNNAs的局部新鲜语义，在提升表达能力的同时保持了计算可行性。


<details>
  <summary>Details</summary>
Motivation: 名义自动机模型作为数据语言的形式主义，与经典的寄存器模型密切相关。由于寄存器模型在计算复杂度上的困难，名义自动机通过分配名称，力求在表达能力与计算可行性之间取得平衡。

Method: 将分级单子的语义框架扩展到名义设置，并在此基础上构建分级名义代数理论，提出描述RNNAs局部新鲜语义的代数理论。

Result: 提出了分级名义代数的理论，能够捕捉RNNAs的局部新鲜语义，为名义自动机模型提供了统一的代数处理方法，并促进了其行为等价性的刻画。

Conclusion: 通过将分级代数理论扩展到名义自动机，建立了新的理论框架，有效结合了表达能力与计算可行性，为数据语言的形式建模和行为分析提供了新的工具。

Abstract: Nominal automata models serve as a formalism for data languages, and in fact
often relate closely to classical register models. The paradigm of name
allocation in nominal automata helps alleviate the pervasive computational
hardness of register models in a tradeoff between expressiveness and
computational tractability. For instance, regular nondeterministic nominal
automata (RNNAs) correspond, under their local freshness semantics, to a form
of lossy register automata, and unlike the full register automaton model allow
for inclusion checking in elementary complexity. The semantic framework of
graded monads provides a unified algebraic treatment of spectra of behavioural
equivalences in the setting of universal coalgebra. In the present work, we
extend the associated notion of graded algebraic theory to the nominal setting.
In the arising framework of graded nominal algebra, we give an algebraic theory
capturing the local freshness semantics of RNNAs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [Evaluating Long-Term Memory for Long-Context Question Answering](https://arxiv.org/abs/2510.23730)
*Alessandra Terranova,Björn Ross,Alexandra Birch*

Main category: cs.CL

TL;DR: 对多种记忆增强方法进行了系统性测试，结果表明可大幅减少token用量且准确率不受影响。不同比例模型需选用适配的记忆架构，情节记忆尤其有助于模型自我认知能力提升。


<details>
  <summary>Details</summary>
Motivation: 推动大型语言模型实现真正的对话连续性并从经验中学习，需要为模型赋予记忆能力，但目前尚不清楚哪种记忆方式最适合长上下文的对话任务。

Method: 系统性评估了多种记忆增强方法，包括全上下文提示、基于检索增强生成的语义记忆、智能体记忆、通过上下文学习的情节记忆，以及通过提示优化的程序性记忆。使用合成长上下文对话基准LoCoMo进行测评。

Result: 记忆增强方法可以在保持准确率的同时，将token使用量减少超过90%。不同记忆架构要根据模型能力进行选择：小型基础模型受益于检索增强生成，大型、推理能力强的模型则适合更复杂的情节记忆和智能体语义记忆结构。

Conclusion: 记忆结构的复杂性应随模型能力扩展，小模型选用RAG，大模型选用反思驱动的情节记忆和复杂语义记忆。此外，情节记忆还可帮助大模型识别自身知识的边界。

Abstract: In order for large language models to achieve true conversational continuity
and benefit from experiential learning, they need memory. While research has
focused on the development of complex memory systems, it remains unclear which
types of memory are most effective for long-context conversational tasks. We
present a systematic evaluation of memory-augmented methods using LoCoMo, a
benchmark of synthetic long-context dialogues annotated for question-answering
tasks that require diverse reasoning strategies. We analyse full-context
prompting, semantic memory through retrieval-augmented generation and agentic
memory, episodic memory through in-context learning, and procedural memory
through prompt optimization. Our findings show that memory-augmented approaches
reduce token usage by over 90% while maintaining competitive accuracy. Memory
architecture complexity should scale with model capability, with small
foundation models benefitting most from RAG, and strong instruction-tuned
reasoning model gaining from episodic learning through reflections and more
complex agentic semantic memory. In particular, episodic memory can help LLMs
recognise the limits of their own knowledge.

</details>


### [19] [BitSkip: An Empirical Analysis of Quantization and Early Exit Composition](https://arxiv.org/abs/2510.23766)
*Ramshankar Bhuvaneswaran,Handan Liu*

Main category: cs.CL

TL;DR: 本文通过BitSkip框架系统分析量化与相关技术的组合对LLM效率与性能的影响，发现简单8位量化模型胜过更复杂设计，Hadamard变换部分组合效果极差，强调设计应兼顾简洁性与实用稳定性。


<details>
  <summary>Details</summary>
Motivation: 近年来，大语言模型（LLMs）的高效化趋势促使研究者提出了诸如极端量化和动态路由等越来越复杂的技术。虽然这些方法的单独优势已有较多研究，但它们相互组合时的影响尚不明确。

Method: 本文提出了一种混合架构框架BitSkip，用于系统性地探索极端量化与动态路由等方法的组合效应。作者通过实证对比不同量化位宽、是否应用Hadamard变换等模型设计，对其性能表现进行详细分析。

Result: 实验显示，简单的8-bit量化模型（BitSkip-V1）在未加Hadamard变换时的效果，不仅优于更低比特（4-bit）或含Hadamard变换的复杂模型，且在质量上接近全精度模型（困惑度1.13对1.19）。引入Hadamard变换反而导致性能灾难性下降（性能降低超37000%），源于训练稳定性受损。BitSkip-V1还具备更优的early-exit特性，第18层可以实现32.5%的速度提升，且只损失4%的质量。

Conclusion: 量化和复杂技术不一定组合就更优。简单的8-bit量化模型（无Hadamard）可以兼顾精度和速度，复杂方法反而可能引发训练不稳定和性能下降。BitSkip-V1为高效LLM提供了有价值的设计建议。

Abstract: The pursuit of efficient Large Language Models (LLMs) has led to increasingly
complex techniques like extreme quantization and dynamic routing. While
individual benefits of these methods are well-documented, their compositional
effects remain poorly understood. This paper introduces BitSkip, a hybrid
architectural framework for systematically exploring these interactions.
Counter-intuitively, our findings reveal that a simple 8-bit quantized model
without Hadamard transform (BitSkip-V1) not only outperforms its more complex
4-bit and Hadamard-enhanced counterparts but also competes the full-precision
baseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard
transforms, even at 8-bit precision, catastrophically degraded performance by
over 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe
demonstrates superior early-exit characteristics, with layer 18 providing
optimal 32.5% speed gain for minimal 4% quality loss.

</details>


### [20] [Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language](https://arxiv.org/abs/2510.23828)
*Mena Attia,Aashiq Muhamed,Mai Alkhamissi,Thamar Solorio,Mona Diab*

Main category: cs.CL

TL;DR: 论文系统评估了大语言模型在处理带有文化色彩的比喻表达方面的能力，发现理解尚可，但在实际运用和内涵把握上存在明显短板，并提出Kinayat数据集以支持相关研究。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在处理包含地方知识和文化细节的语言（例如习语、谚语等）时的表现尚不明确，作者希望通过分析模型对比喻性表达的理解与使用能力，评估其文化推理能力。

Method: 设计了多项评测任务，涵盖语境理解、实际使用和内涵解释，针对阿拉伯语（埃及阿拉伯语及多方言谚语）和英语的比喻性表达进行测试，总共对22个开源和闭源的大语言模型进行评估。

Result: 模型对不同文化和方言的比喻性表达理解存在较大差异，阿拉伯语谚语的平均准确率比英语谚语低4.29%，埃及阿拉伯语习语比阿拉伯语谚语低10.28%；在实际使用任务中，准确率比理解下降14.07%，但提供情境句子可提升10.66%；在内涵理解上，模型的表现最多与人工标注员有85.58%的一致性。

Conclusion: 比喻性语言是评估大语言模型文化推理能力的一种有效指标。尽管模型在理解比喻意义上表现不错，但在实际使用和文化内涵把握方面仍有较大挑战。此外，作者发布了Kinayat，这是首个用于埃及阿拉伯语习语理解和实际使用评估的数据集。

Abstract: We present a comprehensive evaluation of the ability of large language models
(LLMs) to process culturally grounded language, specifically to understand and
pragmatically use figurative expressions that encode local knowledge and
cultural nuance. Using figurative language as a proxy for cultural nuance and
local knowledge, we design evaluation tasks for contextual understanding,
pragmatic use, and connotation interpretation in Arabic and English. We
evaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,
multidialectal Arabic proverbs, and English proverbs. Our results show a
consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower
than for English proverbs, and performance for Egyptian idioms is 10.28% lower
than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%
relative to understanding, though providing contextual idiomatic sentences
improves accuracy by 10.66%. Models also struggle with connotative meaning,
reaching at most 85.58% agreement with human annotators on idioms with 100%
inter-annotator agreement. These findings demonstrate that figurative language
serves as an effective diagnostic for cultural reasoning: while LLMs can often
interpret figurative meaning, they face challenges in using it appropriately.
To support future research, we release Kinayat, the first dataset of Egyptian
Arabic idioms designed for both figurative understanding and pragmatic use
evaluation.

</details>


### [21] [How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse](https://arxiv.org/abs/2510.23842)
*Saki Imai,Lee Kezar,Laurel Aichler,Mert Inan,Erin Walker,Alicia Wooten,Lorna Quandt,Malihe Alikhani*

Main category: cs.CL

TL;DR: 主流手语模型忽略自然对话中的语境变化。本文采集并分析了美国手语STEM对话动作捕捉数据，发现对话中手语表达更简化。研究还测评了手语嵌入模型对术语识别和协同程度刻画的能力，为手语技术更贴合真实交流提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有的手语模型主要基于翻译或孤立的词汇数据，忽视了自然对话中的变化性，而人类交流在不同语境和对象下有动态的时空和表达方式变化。该问题在教育环境中尤为突出，比如教师和学生使用新词汇。

Method: 收集了美国手语（ASL）STEM对话的动作捕捉数据集，可以量化比较双人互动、独自讲解和口译文章三种情境。采用连续的运动学特征，区分对话中特有的协同动作和个人的努力降低，并分析STEM术语重复出现时的时空变化。还评估了手语嵌入模型对STEM词识别和参与者协同变化的刻画能力。

Result: 发现对话情境下的手语平均持续时间比孤立词语短24.6%-44.6%，而且在独白环境下没有显著缩短。手语嵌入模型可以一定程度上识别STEM词并衡量参与者协同水平的变化。

Conclusion: 该研究连接了语言学分析和计算建模，揭示了语用学如何影响手语表达及其技术表示方式，为提升手语技术的表达能力和理解自然交流提供了数据和方法基础。

Abstract: Most state-of-the-art sign language models are trained on interpreter or
isolated vocabulary data, which overlooks the variability that characterizes
natural dialogue. However, human communication dynamically adapts to contexts
and interlocutors through spatiotemporal changes and articulation style. This
specifically manifests itself in educational settings, where novel vocabularies
are used by teachers, and students. To address this gap, we collect a motion
capture dataset of American Sign Language (ASL) STEM (Science, Technology,
Engineering, and Mathematics) dialogue that enables quantitative comparison
between dyadic interactive signing, solo signed lecture, and interpreted
articles. Using continuous kinematic features, we disentangle dialogue-specific
entrainment from individual effort reduction and show spatiotemporal changes
across repeated mentions of STEM terms. On average, dialogue signs are
24.6%-44.6% shorter in duration than the isolated signs, and show significant
reductions absent in monologue contexts. Finally, we evaluate sign embedding
models on their ability to recognize STEM signs and approximate how entrained
the participants become over time. Our study bridges linguistic analysis and
computational modeling to understand how pragmatics shape sign articulation and
its representation in sign language technologies.

</details>


### [22] [CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection](https://arxiv.org/abs/2510.23845)
*Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi*

Main category: cs.CL

TL;DR: 针对语言模型中的心理健康危机检测这一挑战，作者提出了CRADLE BENCH基准，覆盖七种危机类型及时序标签，并利用多模型投票提升训练标注质量，为危机自动检测提供了更科学完整的基础。


<details>
  <summary>Details</summary>
Motivation: 在语言模型逐渐应用于广泛人机交互的背景下，心理健康危机（如自杀意念、强奸、家庭暴力、虐童和性骚扰等）检测变得格外重要。误判或漏判此类危机会导致严重后果，现有方法覆盖面有限，难以应对实际多样化场景，临床标准和时序信息也鲜有结合。

Method: 作者提出了CRADLE BENCH基准，涵盖七种临床标准下的危机类型，并首次引入了时序标签。该数据集包括600个临床专家标注的评测样本、420个开发样本，以及约4,000个由多语言模型多数投票自动标注的训练样本。基于多数和全体一致性标准，还微调了六种危机检测模型，分别在不同子集上训练。

Result: 多模型多数投票自动标注显著优于单模型标注，为训练集提供了更高质量数据；通过微调不同一致性参数下的模型，得到了互补的危机检测系统，提高了多类型和多阶段危机识别能力。

Conclusion: CRADLE BENCH是首个临床标准覆盖且包含时序标签的危机检测基准，通过集成多模型标注与专家评测，推动了心理健康危机自动检测方法的多维进展，为提升人机交互安全性奠定了基础。

Abstract: Detecting mental health crisis situations such as suicide ideation, rape,
domestic violence, child abuse, and sexual harassment is a critical yet
underexplored challenge for language models. When such situations arise during
user--model interactions, models must reliably flag them, as failure to do so
can have serious consequences. In this work, we introduce CRADLE BENCH, a
benchmark for multi-faceted crisis detection. Unlike previous efforts that
focus on a limited set of crisis types, our benchmark covers seven types
defined in line with clinical standards and is the first to incorporate
temporal labels. Our benchmark provides 600 clinician-annotated evaluation
examples and 420 development examples, together with a training corpus of
around 4K examples automatically labeled using a majority-vote ensemble of
multiple language models, which significantly outperforms single-model
annotation. We further fine-tune six crisis detection models on subsets defined
by consensus and unanimous ensemble agreement, providing complementary models
trained under different agreement criteria.

</details>


### [23] [Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception](https://arxiv.org/abs/2510.23853)
*Yize Cheng,Arshia Soltani Moakhar,Chenrui Fan,Kazem Faghih,Parsa Hosseini,Wenxiao Wang,Soheil Feizi*

Main category: cs.CL

TL;DR: 本文发现大模型在多轮对话中的时间感知严重不足，即便补充时间戳也仅收获有限优化，模型在“是否需要工具调用”上的决策与人类偏好存在明显差距，表明未来需专门强化大模型的‘时间敏感’推理能力。


<details>
  <summary>Details</summary>
Motivation: 随着大模型代理被广泛用于多轮对话及动态任务场景，其对“真实时间流逝”缺乏感知，影响工具决策的合理性。当前模型忽略时间信息，决策容易失误，迫切需要研究大模型的时间感知能力及其与现实需求的匹配度。

Method: 作者提出了TicToc-v1测试集，通过在多轮人机对话场景中人为设置不同时间敏感性问题，并为每条对话注入明确的时间戳，然后收集人类对于“是否需要工具调用”的偏好，分为prefer-noTool和prefer-Tool两类。最后评估现有LLM在有时间戳和无时间戳条件下的工具调用决策与人类偏好的对齐程度。

Result: 无时间信息时，各主流模型的工具调用决策与人类偏好对齐率仅略高于随机，最好者约60%；加入时间戳后顶尖模型提升至约65%，但进步有限。简单使用时间信息的prompt方法效果很有限，无法达到人类水平。论文强调需要针对时间感知展开专门的后训练。

Conclusion: 当前大语言模型在多轮对话中存在“时间盲区”问题，即难以准确利用对话间隔时间以做出合理工具调用决策。即使加入时间戳，也仅有小幅提升，仍未与人类感知对齐。需要专门的后训练方法以提升模型在多轮任务中的时间感知与决策能力。

Abstract: Large language model agents are increasingly used in multi-turn
conversational settings to interact with and execute tasks in dynamic
environments. However, a key limitation is their temporal blindness: they, by
default, operate with a stationary context, failing to account for the
real-world time elapsed between messages. This becomes a critical liability
when an agent must decide whether to invoke a tool based on how much time has
passed since the last observation. Without temporal awareness, agents often
either over-rely on previous context (skipping necessary tool calls), or
under-rely on it (unnecessarily repeating tool calls). To study this challenge,
we introduce TicToc-v1, a test set of multi-turn user-agent trajectories across
34 scenarios with varying time sensitivity. Each trajectory ends with a user
question, where the need for a tool call depends on the amount of time elapsed
since the last message. To give LLMs temporal context, we augment dialogue
messages with explicit timestamps, bridging the gap between static dialogue and
evolving environments. We then collected human preferences for these samples,
creating two subsets: one where humans preferred relying on the previous
observation (prefer-noTool), and another where they preferred a new tool call
(prefer-Tool). We evaluated how well LLM tool-calling decisions align with
human preferences under varying time intervals on TicToc-v1. Our analysis show
that without time information, most models perform only slightly better than
random, with the top alignment rate being just over 60%. While adding
timestamps leads to a slight improvement, particularly for larger models, the
improvement is modest, peaking at around 65%. We also show that naive,
prompt-based alignment have limited effectiveness. Our findings highlight the
need for specific post-training alignment to align multi-turn LLM tool use with
human temporal perception.

</details>


### [24] [Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs](https://arxiv.org/abs/2510.23854)
*Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: 作者提出了一种新型NLR评估方法Combo-Eval，提高了评估效果和效率，并发布了全新数据集NLR-BIRD。人类评测验证该方法效果优越。


<details>
  <summary>Details</summary>
Motivation: 当前，表格数据库结果转换为自然语言表达主要依赖大语言模型，但信息丢失或错误问题缺乏系统性评估方法。为解决该难题，作者希望提升NLR评估的多样性与效率。

Method: 提出了Combo-Eval，一种结合多种已有评估方法的新型评估策略，用于评价大语言模型（LLM）生成的自然语言结果（NLR），并配套发布了NLR-BIRD数据集。

Result: Combo-Eval在评估真实性提高的同时，减少了约25-61%的LLM调用次数。同时，推出了NLR-BIRD，这是第一个专用于NLR基准测试的数据集。人类评测结果显示Combo-Eval与人工判断高度一致。

Conclusion: Combo-Eval能更好地评判LLM生成的NLR质量，具有较高的通用性和节省算力优势，为表格结果自然语言化任务提供了可靠评测工具。

Abstract: In modern industry systems like multi-turn chat agents, Text-to-SQL
technology bridges natural language (NL) questions and database (DB) querying.
The conversion of tabular DB results into NL representations (NLRs) enables the
chat-based interaction. Currently, NLR generation is typically handled by large
language models (LLMs), but information loss or errors in presenting tabular
results in NL remains largely unexplored. This paper introduces a novel
evaluation method - Combo-Eval - for judgment of LLM-generated NLRs that
combines the benefits of multiple existing methods, optimizing evaluation
fidelity and achieving a significant reduction in LLM calls by 25-61%.
Accompanying our method is NLR-BIRD, the first dedicated dataset for NLR
benchmarking. Through human evaluations, we demonstrate the superior alignment
of Combo-Eval with human judgments, applicable across scenarios with and
without ground truth references.

</details>


### [25] [OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning](https://arxiv.org/abs/2510.23870)
*Marianne Menglin Liu,Sai Ashish Somayajula,Syed Fahad Allam Shah,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: OraPlan-SQL 提出以单一主控规划 agent 为核心，有效整合反馈引导和实体链接的新体系，大幅提升英中文 NL2SQL 复杂推理的准确性和可靠性，在权威赛事中夺冠。


<details>
  <summary>Details</summary>
Motivation: 当前复杂 NL2SQL 任务需要强大的推理能力和多语言适应性，现有方法往往增加多个子 agent 带来的调度开销且泛化能力有限。为有效提升准确性与效率，同时解决中英文和实体相关的难题，作者设计了全新单一 Planner agent 优化框架。

Method: 提出了一个包含 Planner agent 和 SQL agent 的 agentic 框架。采用反馈引导的元提示（meta-prompting）来持续改进主控规划器，同时引入实体链接机制解决多语言下的实体错配和转写问题。通过多方案生成和多数表决选择最终输出。

Result: 在 Archer NL2SQL Challenge 2025 英文和中文数据集上分别实现了 55.0% 和 56.7% 的执行准确率，SQL 有效率高达 99% 以上，显著领先其他系统。

Conclusion: OraPlan-SQL 系统在 Archer NL2SQL Evaluation Challenge 2025 中排名第一，超越第二名 6% 以上，显著提升了英中双语的执行准确率与 SQL 合法性。创新的反馈引导元提示和实体链接指南增强了模型泛化与多语言适应能力，最终结合多方案多选机制进一步提升了系统可靠性。

Abstract: We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge
2025, a bilingual benchmark requiring complex reasoning such as arithmetic,
commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding
the second-best system by more than 6% in execution accuracy (EX), with 55.0%
in English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).
Our system follows an agentic framework with two components: Planner agent that
generates stepwise natural language plans, and SQL agent that converts these
plans into executable SQL. Since SQL agent reliably adheres to the plan, our
refinements focus on the planner. Unlike prior methods that rely on multiple
sub-agents for planning and suffer from orchestration overhead, we introduce a
feedback-guided meta-prompting strategy to refine a single planner. Failure
cases from a held-out set are clustered with human input, and an LLM distills
them into corrective guidelines that are integrated into the planner's system
prompt, improving generalization without added complexity. For the multilingual
scenario, to address transliteration and entity mismatch issues, we incorporate
entity-linking guidelines that generate alternative surface forms for entities
and explicitly include them in the plan. Finally, we enhance reliability
through plan diversification: multiple candidate plans are generated for each
query, with the SQL agent producing a query for each plan, and final output
selected via majority voting over their executions.

</details>


### [26] [Language Models for Longitudinal Clinical Prediction](https://arxiv.org/abs/2510.23884)
*Tananun Songdechakraiwut,Michael Lutz*

Main category: cs.CL

TL;DR: 提出了一种无需微调的大型语言模型轻量框架，通过整合患者历史与语境，实现对神经心理评估的高准确性预测，尤其适合阿尔茨海默症早期检测，且对训练数据依赖极低。


<details>
  <summary>Details</summary>
Motivation: 目前纵向临床数据分析对模型适应性和数据量需求高，本研究旨在探索如何高效利用预训练语言模型以降低成本和数据门槛。

Method: 采用一个轻量级框架，将患者历史和语境整合到语言模型空间中，无需对预训练的大型语言模型进行微调。

Result: 即使在训练数据极少的情况下，模型也能获得准确且可靠的预测性能，特别适用于阿尔茨海默症早期监测。

Conclusion: 该论文提出的方法能够在不需要微调大型语言模型的前提下，准确地分析神经心理评估数据，用于阿尔茨海默症早期监测。

Abstract: We explore a lightweight framework that adapts frozen large language models
to analyze longitudinal clinical data. The approach integrates patient history
and context within the language model space to generate accurate forecasts
without model fine-tuning. Applied to neuropsychological assessments, it
achieves accurate and reliable performance even with minimal training data,
showing promise for early-stage Alzheimer's monitoring.

</details>


### [27] [AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages](https://arxiv.org/abs/2510.23896)
*Kosei Uemura,Miaoran Zhang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 作者针对MMTEB在非洲语言上的覆盖不足，提出了AfriMTEB基准和AfriE5模型，显著提升了非洲多语种文本嵌入评测和模型表现，填补了相关任务和数据集的空白。


<details>
  <summary>Details</summary>
Motivation: 当前NLP任务严重依赖文本嵌入，尤其在防止大型语言模型（LLMs）产生幻觉上意义重大。然而，非洲语言在最新多语言基准（如MMTEB）中显著缺乏代表性，相关任务多源自翻译基准，缺少原生语义任务。作者希望填补非洲语言在这些基准中的空白。

Method: 提出了AfriMTEB——针对非洲地区的MMTEB扩展，涵盖59种语言、14个任务和38个数据集，并新增六个数据集，加入了仇恨言论检测、意图检测、情感分类等此前未涵盖的新任务。同时，开发了AfriE5模型，通过跨语种对比蒸馏将指令调优的mE5模型适配非洲语言。

Result: AfriMTEB极大扩展了非洲语言的覆盖范围，新任务和新数据集显著提升了多语言评测的全面性。AfriE5模型在评测中表现优异，超越了当前的强基线模型（如Gemini-Embeddings和mE5）。

Conclusion: 通过AfriMTEB和AfriE5，极大增强了非洲语言在文本嵌入领域的资源和模型性能，为相关NLP任务提供了更广泛和有效的支持。

Abstract: Text embeddings are an essential building component of several NLP tasks such
as retrieval-augmented generation which is crucial for preventing
hallucinations in LLMs. Despite the recent release of massively multilingual
MTEB (MMTEB), African languages remain underrepresented, with existing tasks
often repurposed from translation benchmarks such as FLORES clustering or
SIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB
covering 59 languages, 14 tasks, and 38 datasets, including six newly added
datasets. Unlike many MMTEB datasets that include fewer than five languages,
the new additions span 14 to 56 African languages and introduce entirely new
tasks, such as hate speech detection, intent detection, and emotion
classification, which were not previously covered. Complementing this, we
present AfriE5, an adaptation of the instruction-tuned mE5 model to African
languages through cross-lingual contrastive distillation. Our evaluation shows
that AfriE5 achieves state-of-the-art performance, outperforming strong
baselines such as Gemini-Embeddings and mE5.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [28] [How to see the forest for the trees](https://arxiv.org/abs/2510.23614)
*Erika Bérczi-Kovács,András Frank*

Main category: cs.DM

TL;DR: 本文系统回顾了Nash-Williams与Tutte定理及其推广在图论和离散优化中的发展与应用，总结了大量文献和新成果，旨在让该领域的理论和贡献为更广泛的读者理解。


<details>
  <summary>Details</summary>
Motivation: Nash-Williams与Tutte定理在离散优化中具有核心地位，激发了大量研究。作者希望系统综述该领域的发展，让非专家也能领会其理论美妙，同时专家也可发现新颖内容。

Method: 通过文献综述及理论梳理，总结该定理的推广与应用，包括最新研究进展，并探讨其与其它领域的联系。

Result: 该综述展示了定理的深远影响、诸多推广及其在其他领域的应用，总结了上千篇相关文献及最新成果，为读者提供了全面视角。

Conclusion: 本论文综述了Nash-Williams与Tutte定理对图中k个不相交生成树及k个覆盖所有边的森林的存在性研究，概括了该领域的广泛发展与应用，并希望为专家与非专家都带来新的见解。

Abstract: One of the major starting points of discrete optimization is the theorem of
Nash-Williams and Tutte on the existence of $k$ disjoint spanning trees of a
graph along with its counterpart on the existence of $k$ forests covering all
edges of the graph. These elegant results triggered a comprehensive research
that gave rise to far-reaching generalizations and found applications at
seemingly far-fetched areas. There are well over a thousand papers in the
literature, including quite a few brand-new ones. Our first goal is to
enlighten some aspects and links of these developments with the hope that the
melody finds its way to non-experts. But we hope that experts will also find
some novelties in our orchestration.

</details>


### [29] [Robust Extensible Bin Packing and Revisiting the Convex Knapsack Problem](https://arxiv.org/abs/2510.23765)
*Noam Goldberg,Michael Poss,Yariv Marmor*

Main category: cs.DM

TL;DR: 本文针对带预算不确定性的鲁棒装箱问题，提出了情景生成算法与高效分离问题求解方法，理论证明和实验均表明新方法在复杂性和实践效果上具有显著优势，且在手术排程等实际案例中展示了优良表现。


<details>
  <summary>Details</summary>
Motivation: 该论文关注鲁棒可扩展装箱问题，在实际应用中物品大小通常存在不确定性，特别是在预算不确定性模型下。研究此问题可为如手术排程等实际场景提供更好的决策支持。

Method: 作者提出了一个情景生成算法，通过交替求解有有限不确定集合的主鲁棒装箱问题和分离问题来进行。论文对分离问题的复杂性进行了理论分析，并针对特殊情形设计了动态规划和近似方案（FPTAS），同时进行了大量数值实验与实际案例分析。

Result: （1）分离问题（连续情形）是强NP难的。（2）在主问题为整数优化时，分离问题可归约为连续凸背包问题（弱NP难）。（3）当目标函数为两段分段线性时，仍为NP难。针对该特殊情况，给出了伪多项式DP和FPTAS算法，数值实验显示DP算法性能优于主流MIP求解器和SOS约束。现实数据案例也验证了模型的优越性。

Conclusion: 针对具有预算不确定性的鲁棒可扩展装箱问题，作者提出的算法和理论成果具有较高实用性和有效性。特别是所开发的DP和FPTAS方法，在效率和效果上显著优于通用求解算法，对实际应用有重要指导价值。

Abstract: We study a robust extensible bin packing problem with budgeted uncertainty,
under a budgeted uncertainty model where item sizes are defined to lie in the
intersection of a box with a one-norm ball. We propose a scenario generation
algorithm for this problem, which alternates between solving a master robust
bin-packing problem with a finite uncertainty set and solving a separation
problem. We first show that the separation is strongly NP-hard given solutions
to the continuous relaxation of the master problem. Then, focusing on the
separation problem for the integer master problem, we show that this problem
becomes a special case of the continuous convex knapsack problem, which is
known to be weakly NP-hard. Next, we prove that our special case when each of
the functions is piecewise linear, having only two pieces, remains NP-hard. We
develop a pseudo-polynomial dynamic program (DP) and a fully polynomial-time
approximation scheme (FPTAS) for our special case whose running times match
those of a binary knapsack FPTAS. Finally, our computational study shows that
the DP can be significantly more efficient in practice compared with solving
the problem with specially ordered set (SOS) constraints using advanced
mixed-integer (MIP) solvers. Our experiments also demonstrate the application
of our separation problem method to solving the robust extensible bin packing
problem, including the evaluation of deferring the exact solution of the master
problem, separating based on approximate master solutions in intermediate
iterations. Finally, a case-study, based on real elective surgery data,
demonstrates the potential advantage of our model compared with the actual
schedule and optimal nominal schedules.

</details>


### [30] [Pinwheel Scheduling with Real Periods](https://arxiv.org/abs/2510.24068)
*Hiroshi Fujiwara,Kota Miyagi,Katsuhisa Ouchi*

Main category: cs.DM

TL;DR: 本文讨论了pinwheel调度问题，证明了当任务周期为三个不同的实数且密度不超过5/6时总能找到有效调度，并猜测更一般的情况（实数周期、密度不超过5/6）也成立。


<details>
  <summary>Details</summary>
Motivation: Chan和Chin在1993年提出了一个猜想：对于一系列具有正整数周期的任务，如果其密度（即各周期倒数之和）不超过5/6，则总存在一个有效调度。有效调度的定义是每天执行一个任务，且每个任务在其周期内必须执行至少一次。近期，Kawamura证实了这一猜想。而现在，文中进一步讨论当周期为实数时的更广泛情况，即每个任务在任意连续的天数区间内，按照特殊约束也能被有效调度。

Method: 论文采用针对扩展pinwheel调度问题的新定义（周期为实数），并证明当所有任务的周期取三个不同实数值且密度不超过5/6时，能够有效调度。这个结果是通过理论分析和严密的证明得到的。

Result: 作者证明了对于所有周期只取三个不同实数值的任务序列，只要其密度不超过5/6，就始终可以构造出有效调度。并由此提出猜想：Chan和Chin的原始猜想（对整数周期任务有效）也可以扩展适用于实数周期任务。

Conclusion: 本文推广了已证实的pinwheel调度猜想到任务周期为实数的情况，并证明了三个周期取值的特殊情形下该猜想成立。作者进一步猜测该结论在更一般的实数周期下也成立，为后续研究指明方向。

Abstract: For a sequence of tasks, each with a positive integer period, the pinwheel
scheduling problem involves finding a valid schedule in the sense that the
schedule performs one task per day and each task is performed at least once
every consecutive days of its period. It had been conjectured by Chan and Chin
in 1993 that there exists a valid schedule for any sequence of tasks with
density, the sum of the reciprocals of each period, at most $\frac{5}{6}$.
Recently, Kawamura settled this conjecture affirmatively. In this paper we
consider an extended version with real periods proposed by Kawamura, in which a
valid schedule must perform each task $i$ having a real period~$a_{i}$ at least
$l$ times in any consecutive $\lceil l a_{i} \rceil$ days for all positive
integer $l$. We show that any sequence of tasks such that the periods take
three distinct real values and the density is at most $\frac{5}{6}$ admits a
valid schedule. We hereby conjecture that the conjecture of Chan and Chin is
true also for real periods.

</details>
