<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [SafeTree: Expressive Tree Policies for Microservices](https://arxiv.org/abs/2508.16746)
*Karuna Grewal,P. Brighten Godfrey,Justin Hsu*

Main category: cs.PL

TL;DR: 本论文提出了一种无需改动服务代码、可表达服务调用树结构的安全策略语言，并基于服务网格和可见下推自动机制，设计了高效的动态监控器，能在线强制复杂安全策略，且性能损耗极小。


<details>
  <summary>Details</summary>
Motivation: 在微服务架构中，多个服务之间的通信需严格管控，以确保系统安全。现有微服务部署工具对跨服务通信的支持有限，往往仅能配置简单的一跳策略，导致通信权限过于宽泛，无法充分利用微服务调用的层级结构，实现安全和管理上的细粒度控制。

Method: 设计了一种表达能力强的策略语言，可以精确描述服务调用树结构，并开发了一种基于可见下推自动机（visibly pushdown automata）的动态策略强制机制。整个方法为无侵入式，无需更改服务实现或访问服务代码。具体实现是在主流服务网格Istio之上搭建运行时监控器，利用其可编程网络流量过滤功能实现分布式在线监控。

Result: 构建的监控器可在不修改现有微服务代码的情况下，在线动态、分布式地强制复杂的通信安全策略。实验结果表明，该方法可以准确地施加安全策略，并只引入毫秒级的很小延迟。

Conclusion: 提出了一种新颖的服务树结构策略语言，并结合可见下推自动机和服务网格实现了动态安全策略的强制执行，有效提升了微服务通信的管理和安全性。

Abstract: A microservice-based application is composed of multiple self-contained
components called microservices, and controlling inter-service communication is
important for enforcing safety properties. Presently, inter-service
communication is configured using microservice deployment tools. However, such
tools only support a limited class of single-hop policies, which can be overly
permissive because they ignore the rich service tree structure of microservice
calls. Policies that can express the service tree structure can offer
development and security teams more fine-grained control over communication
patterns.
  To this end, we design an expressive policy language to specify service tree
structures, and we develop a visibly pushdown automata-based dynamic
enforcement mechanism to enforce service tree policies. Our technique is
non-invasive: it does not require any changes to service implementations, and
does not require access to microservice code. To realize our method, we build a
runtime monitor on top of a service mesh, an emerging network infrastructure
layer that can control inter-service communication during deployment. In
particular, we employ the programmable network traffic filtering capabilities
of Istio, a popular service mesh implementation, to implement an online and
distributed monitor. Our experiments show that our monitor can enforce rich
safety properties while adding minimal latency overhead on the order of
milliseconds.

</details>


### [2] [Syntactic Completions with Material Obligations](https://arxiv.org/abs/2508.16848)
*David Moon,Andrew Blinn,Thomas J. Porter,Cyrus Omar*

Main category: cs.PL

TL;DR: 该论文提出了tylr，一个能智能修复任意语法错误并将修复点可视化的编辑器生成器，通过新方法大幅提升编辑器在代码非结构化状态下的辅助能力，并得到实验支持其可用性和实用性。


<details>
  <summary>Details</summary>
Motivation: 目前代码编辑器在遇到语法错误时，辅助功能常常失效。而现有的语法错误修复方法要么粗暴地删除大量代码，要么产生过多的修复选项，难以有效提升开发体验。

Method: 提出了一种新的解析器和编辑器生成器——tylr，通过在代码中插入义务（obligations）来补全任意格式错误的代码，这种义务泛化了“洞”，可以覆盖缺失的操作数、操作符、混合关键字及类型转换。该方法基于新颖的瓷砖式解析理论，并引入“grammar walks”和“grammar zippers”体系实现更精细的语法解析和修复。

Result: tylr不仅提升了错误修正能力，还支持编辑器将这些义务以可视化形式呈现给用户，实现文本编辑器与结构编辑器的混合。实验表明，这种义务可视化的编辑器在可用性和实用性方面都有积极结果，并提出了未来新的研究方向。

Conclusion: tylr实现了对语法错误更细致、更智能的修复，能够以可视化方式增强代码编辑体验，为人机交互和编程工具领域带来新的可能性。

Abstract: Code editors provide essential services that help developers understand,
navigate, and modify programs. However, these services often fail in the
presence of syntax errors. Existing syntax error recovery techniques, like
panic mode and multi-option repairs, are either too coarse, e.g. in deleting
large swathes of code, or lead to a proliferation of possible completions. This
paper introduces $\texttt{tylr}$, a parser and editor generator that completes
arbitrarily malformed code by inserting obligations, which generalize holes to
cover missing operands, operators, mixfix keywords, and sort transitions.
$\texttt{tylr}$ is backed by a novel theory of tile-based parsing, which
extends operator-precedence parsing in two ways. First, traditional token
precedence comparisons are replaced by a notion of grammar walks, which form
the basis for generating obligations. Second, a distinct "molding" system based
on grammar zippers expand grammar expressivity by allowing the system to
disambiguate between possible parses and completions based on an obligation
minimization criterion. In addition to serving as a novel approach to error
correction, $\texttt{tylr}$'s design enables the development of an editor that
visually materializes obligations to the human user, serving as a novel hybrid
between a text editor and a structure editor. We introduce $\texttt{tylr}$ by
example, then formalize its key ideas. Finally, we conduct a human subjects
study to evaluate the extent to which an editor like $\texttt{tylr}$ that
materializes syntactic obligations might be usable and useful, finding both
points of positivity and interesting new avenues for future work.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Reflective Paper-to-Code Reproduction Enabled by Fine-Grained Verification](https://arxiv.org/abs/2508.16671)
*Mingyang Zhou,Quanming Yao,Lun Du,Lanning Wei,Da Zheng*

Main category: cs.SE

TL;DR: 作者提出了RePro，一个自动提取论文关键实现细节并实现反思修正的论文复现框架，在公开基准上超越现有方法，能更好对齐论文实现的复杂细节，大幅提升复现效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习论文复现方法，无论人工还是自动代理，都很难完全、准确地再现实现细节（如数学公式和算法逻辑）。先前研究发现，通过反思并结合明确反馈，代理的表现会提升，但现有方法并未有效采用该策略，主要原因是论文结构多样，方法复杂，配置各异。作者受到人类使用系统化清单高效调试代码的启发，提出新方法。

Method: 提出RePro，一个反思式论文到代码再现框架。首先自动提取论文的“指纹”（准确且原子化的标准），用作高质量监督信号。框架先生成代码，再利用指纹在迭代验证和修正循环中系统识别与原论文实现细节的偏差，提出有针对性修正，确保复现结果和论文实现细节一致。

Result: 在PaperBench Code-Dev基准上进行大量实验，RePro的性能比现有基线高出13.0%，在反思过程中能够正确修正复杂的逻辑和数学标准，显示出方法的有效性。

Conclusion: RePro通过自动指纹提取和反思式验证修正，有效提升机器学习论文代码复现的准确性，尤其在处理复杂逻辑和数学实现细节时表现优越。

Abstract: Reproducing machine learning papers is essential for scientific progress but
remains challenging for both humans and automated agents. Existing agent-based
methods often struggle to fully and accurately reproduce implementation details
such as mathematical formulas and algorithmic logic. Previous studies show that
reflection with explicit feedback improves agent performance. However, current
paper reproduction methods fail to effectively adopt this strategy. This gap
mainly arises from the diverse paper patterns, complex method modules, and
varied configurations encountered in research papers. Motivated by how humans
use systematic checklists to efficiently debug complex code, we propose
\textbf{RePro}, a \textbf{Re}flective Paper-to-Code \textbf{Repro}duction
framework that automatically extracts a paper's fingerprint, referring to a
comprehensive set of accurate and atomic criteria serving as high-quality
supervisory signals. The framework first generates code based on the extracted
information, and then leverages the fingerprint within iterative verification
and refinement loop. This approach systematically detects discrepancies and
produces targeted revisions to align generated code with the paper's
implementation details. Extensive experiments on the PaperBench Code-Dev
benchmark have been conducted, RePro achieves 13.0\% performance gap over
baselines, and it correctly revises complex logical and mathematical criteria
in reflecting, on which the effectiveness is obvious.

</details>


### [4] [Cognitive Agents Powered by Large Language Models for Agile Software Project Management](https://arxiv.org/abs/2508.16678)
*Konrad Cinkusz,Jarosław A. Chudziak,Ewa Niewiadomska-Szynkiewicz*

Main category: cs.SE

TL;DR: 本研究表明，将大型语言模型驱动的认知智能体集成到敏捷项目管理框架中，可提升项目执行效率、交付质量和团队协作能力，为软件工程实践带来变革。


<details>
  <summary>Details</summary>
Motivation: 在敏捷开发和软件项目管理日益复杂的背景下，团队难以高效沟通、协作与决策。本文旨在探索将大型语言模型（LLM）驱动的认知智能体集成到Scaled Agile Framework（SAFe）中，以提升项目管理效率和项目成果。

Method: 该研究在CogniSim模拟平台中，通过部署虚拟认知智能体，模拟现实软件工程场景，反复进行迭代仿真实验，分析智能体在任务分配、沟通和项目管理过程中表现。智能体使用自然语言处理模拟人类团队成员角色，实现高效交流与自动化决策。

Result: 实验结果显示，LLM驱动的认知智能体可提升任务完成速度、交付物质量及沟通一致性。智能体具有良好的可扩展性和适应性，能够胜任复杂多变的项目管理环境。

Conclusion: LLM认知智能体集成到敏捷项目管理，可优化管理流程、提升工程实践，并促进团队协作和应对新挑战，具备推动软件开发范式转变的潜力。

Abstract: This paper investigates the integration of cognitive agents powered by Large
Language Models (LLMs) within the Scaled Agile Framework (SAFe) to reinforce
software project management. By deploying virtual agents in simulated software
environments, this study explores their potential to fulfill fundamental roles
in IT project development, thereby optimizing project outcomes through
intelligent automation. Particular emphasis is placed on the adaptability of
these agents to Agile methodologies and their transformative impact on
decision-making, problem-solving, and collaboration dynamics. The research
leverages the CogniSim ecosystem, a platform designed to simulate real-world
software engineering challenges, such as aligning technical capabilities with
business objectives, managing interdependencies, and maintaining project
agility. Through iterative simulations, cognitive agents demonstrate advanced
capabilities in task delegation, inter-agent communication, and project
lifecycle management. By employing natural language processing to facilitate
meaningful dialogues, these agents emulate human roles and improve the
efficiency and precision of Agile practices. Key findings from this
investigation highlight the ability of LLM-powered cognitive agents to deliver
measurable improvements in various metrics, including task completion times,
quality of deliverables, and communication coherence. These agents exhibit
scalability and adaptability, ensuring their applicability across diverse and
complex project environments. This study underscores the potential of
integrating LLM-powered agents into Agile project management frameworks as a
means of advancing software engineering practices. This integration not only
refines the execution of project management tasks but also sets the stage for a
paradigm shift in how teams collaborate and address emerging challenges.

</details>


### [5] [Democratizing AI Development: Local LLM Deployment for India's Developer Ecosystem in the Era of Tokenized APIs](https://arxiv.org/abs/2508.16684)
*Vikranth Udandarao,Nipun Misra*

Main category: cs.SE

TL;DR: 印度开发者通过使用Ollama本地部署LLM，不仅节省了约三分之一成本，还显著提高了实验次数和深度。本地部署为资源有限环境下的AI学习和创新提供了重要支持。


<details>
  <summary>Details</summary>
Motivation: 印度开发者因经济和基础设施限制，难以持续实验和学习商用LLM。研究动机是寻求更经济、可行的替代方案，推动更多开发者参与AI实验。

Method: 通过混合方法分析，研究了180名印度开发者、学生和AI爱好者使用Ollama进行本地LLM部署。对比了本地与商业云服务的成本和开发体验。

Result: 本地部署能将成本降低约33%，实验迭代次数提升一倍以上，参与者对AI架构的理解也更深入。

Conclusion: 本研究发现本地部署LLM对印度开发者社区来说是更包容和可访问的解决方案，能有效提升学习成果和创新能力。

Abstract: India's developer community faces significant barriers to sustained
experimentation and learning with commercial Large Language Model (LLM) APIs,
primarily due to economic and infrastructural constraints. This study
empirically evaluates local LLM deployment using Ollama as an alternative to
commercial cloud-based services for developer-focused applications. Through a
mixed-methods analysis involving 180 Indian developers, students, and AI
enthusiasts, we find that local deployment enables substantially greater
hands-on development and experimentation, while reducing costs by 33% compared
to commercial solutions. Developers using local LLMs completed over twice as
many experimental iterations and reported deeper understanding of advanced AI
architectures. Our results highlight local deployment as a critical enabler for
inclusive and accessible AI development, demonstrating how technological
accessibility can enhance learning outcomes and innovation capacity in
resource-constrained environments.

</details>


### [6] [Cybernaut: Towards Reliable Web Automation](https://arxiv.org/abs/2508.16688)
*Ankur Tomar,Hengyue Liang,Indranil Bhattacharya,Natalia Larios,Francesco Carbone*

Main category: cs.SE

TL;DR: 本文针对AI驱动网页自动化在实际企业场景下的四大挑战，提出了Cybernaut框架，通过SOP生成、高精度HTML元素识别以及一致性度量，系统显著提升了任务执行成功率和可靠性。


<details>
  <summary>Details</summary>
Motivation: AI驱动的网页自动化通过大语言模型为数字工作流程优化带来了巨大潜力，但在实际工业环境中面临四大核心挑战：执行一致性、HTML元素识别、类人准确率需求以及缺乏内部网页基准数据。现有方案多针对结构良好的对外网站，不适用于复杂、设计不佳的内部网页。

Method: 提出了Cybernaut框架，主要包括三个组件：（1）将用户演示转成可靠自动化操作流程的SOP生成器；（2）高精度、针对复杂网页DOM的HTML元素识别系统；（3）定量评估执行一致性的指标。并在自有基准集上进行实验。

Result: Cybernaut在任务执行成功率上提升了23.2%（从72%提升到88.68%）；能以84.7%的准确率识别出一致执行模式，实现更可靠的置信评估和自适应指导。

Conclusion: Cybernaut有效提升了企业级网页自动化的可靠性和执行一致性，为未来网页自动化研究打下基础。

Abstract: The emergence of AI-driven web automation through Large Language Models
(LLMs) offers unprecedented opportunities for optimizing digital workflows.
However, deploying such systems within industry's real-world environments
presents four core challenges: (1) ensuring consistent execution, (2)
accurately identifying critical HTML elements, (3) meeting human-like accuracy
in order to automate operations at scale and (4) the lack of comprehensive
benchmarking data on internal web applications. Existing solutions are
primarily tailored for well-designed, consumer-facing websites (e.g.,
Amazon.com, Apple.com) and fall short in addressing the complexity of
poorly-designed internal web interfaces. To address these limitations, we
present Cybernaut, a novel framework to ensure high execution consistency in
web automation agents designed for robust enterprise use. Our contributions are
threefold: (1) a Standard Operating Procedure (SOP) generator that converts
user demonstrations into reliable automation instructions for linear browsing
tasks, (2) a high-precision HTML DOM element recognition system tailored for
the challenge of complex web interfaces, and (3) a quantitative metric to
assess execution consistency. The empirical evaluation on our internal
benchmark demonstrates that using our framework enables a 23.2% improvement
(from 72% to 88.68%) in task execution success rate over the browser_use.
Cybernaut identifies consistent execution patterns with 84.7% accuracy,
enabling reliable confidence assessment and adaptive guidance during task
execution in real-world systems. These results highlight Cybernaut's
effectiveness in enterprise-scale web automation and lay a foundation for
future advancements in web automation.

</details>


### [7] [A Scalable Framework for the Management of STPA Requirements: a Case Study on eVTOL Operations](https://arxiv.org/abs/2508.16708)
*Shufeng Chen,Halima El Badaoui,Mariat James Elizebeth,Takuya Nakashima,Siddartha Khastgir,Paul Jennings*

Main category: cs.SE

TL;DR: 该论文提出了一套面向STPA安全需求优先级排序的自动化管理框架，综合考虑多因素并用蒙特卡罗模拟减少主观性，在真实eVTOL案例中验证有效，提升了复杂系统安全开发的决策效率。


<details>
  <summary>Details</summary>
Motivation: STPA（系统理论过程分析）在识别复杂系统安全需求方面优于传统方法，但产生大量安全需求后，缺乏有效的管理和优先级排序方法。这对快速开发环境构成挑战，迫切需要一种结构化框架来高效管理与优先处理这些需求。

Method: 提出一种可扩展的框架整合了STPA各阶段输出，并基于实施时间、成本、需求类型和法规覆盖四大因素引入专家评估。为减少主观性，采用蒙特卡罗模拟计算与稳定排序，并开发自动化工具链以支持动态映射及可视化管理优先级需求。该方法通过真实案例验证并应用于电动垂直起降（eVTOL）场景。

Result: 在与英国民航管理局合作的实际eVTOL运营案例中，框架有效帮助决策者识别并高效管理高影响力的安全需求。成果直接促进了CAP3141等民航官方发布文件的风险识别和安全缓解对策制定。

Conclusion: 文中提出的STPA需求优先级排序框架及其工具链，实用性强，可贯穿系统开发各阶段，显著提升了新兴技术领域安全开发过程的管理效率。该方法有效解决了STPA输出的需求管理难题，为安全关键领域提供了有力支持。

Abstract: System-Theoretic Process Analysis (STPA) is a recommended method for
analysing complex systems, capable of identifying thousands of safety
requirements often missed by traditional techniques such as Failure Mode and
Effects Analysis (FMEA) and Fault Tree Analysis (FTA). However, the absence of
a structured framework for managing and prioritising these requirements
presents challenges, particularly in fast-paced development environments. This
paper introduces a scalable framework for prioritising STPA-derived
requirements. The framework integrates outputs from each STPA step and
incorporates expert evaluations based on four key factors: implementation time,
cost, requirement type, and regulatory coverage. To reduce subjectivity,
Monte-Carlo Simulation (MCS) is employed to calculate and stabilise requirement
rankings. An automation toolchain supports the framework, enabling dynamic
mapping of prioritised requirements in a scaling matrix. This visualisation
aids decision-making and ensures traceability across development phases. The
framework is applicable from early conceptualisation to more advanced stages,
enhancing its utility in iterative system development. The framework was
validated through a real-world case study focused on Electric Vertical Take-off
and Landing (eVTOL) operations, conducted in collaboration with the UK Civil
Aviation Authority. The findings contributed directly to CAP3141, a Civil
Aviation Publication that identifies systemic operational risks and safety
mitigations for regulators, operators, and vertiports. The prioritisation
process supported decision-making by helping stakeholders identify and manage
high-impact requirements efficiently. This work contributes a practical
solution for managing STPA outputs, bridging gaps in requirement prioritisation
and supporting safety-critical development in emerging technologies.

</details>


### [8] [CelloAI: Leveraging Large Language Models for HPC Software Development in High Energy Physics](https://arxiv.org/abs/2508.16713)
*Mohammad Atif,Kriti Chopra,Ozgur Kilic,Tianle Wang,Zhihua Dong,Charles Leggett,Meifeng Lin,Paolo Calafiura,Salman Habib*

Main category: cs.SE

TL;DR: 该论文提出并实现了一款本地AI编码助手CelloAI，通过大模型与检索增强生成技术，解决高能物理领域软件文档稀缺和代码维护难题，在真实实验下有效提升了代码理解和生成能力，保障数据安全和科学透明性。


<details>
  <summary>Details</summary>
Motivation: 下一代高能物理（HEP）实验将产生前所未有的大量数据，必须结合高性能计算（HPC）。但传统HEP软件很难迁移到异构架构，并且文档极为稀缺，因此需要新的技术手段来辅助软件文档和优化。

Method: 提出了一款本地部署的AI编码助手CelloAI，结合大语言模型（LLM）与检索增强生成（RAG）。CelloAI专注于代码文档自动生成、代码生成与交互式理解，支持Doxygen风格注释生成、文件级摘要、代码查询聊天机器人，采用语法感知分块提升检索准确性，并结合调用图知识保障代码依赖修改的准确性。

Result: 在ATLAS、CMS和DUNE等HEP真实应用中评估了CelloAI，比较了不同嵌入模型的检索效果。结果表明CelloAI显著提升了代码理解、文档补全和生成能力，兼顾科学计算环境的透明性和安全需求。

Conclusion: CelloAI有效地推动了HEP复杂遗留代码的软件文档自动化与智能代码生成，有助于促进HPC在HEP领域的广泛应用，满足科研团队的数据隐私和高性能要求。

Abstract: Next-generation High Energy Physics (HEP) experiments will generate
unprecedented data volumes, necessitating High Performance Computing (HPC)
integration alongside traditional high-throughput computing. However, HPC
adoption in HEP is hindered by the challenge of porting legacy software to
heterogeneous architectures and the sparse documentation of these complex
scientific codebases. We present CelloAI, a locally hosted coding assistant
that leverages Large Language Models (LLMs) with retrieval-augmented generation
(RAG) to support HEP code documentation and generation. This local deployment
ensures data privacy, eliminates recurring costs and provides access to large
context windows without external dependencies. CelloAI addresses two primary
use cases, code documentation and code generation, through specialized
components. For code documentation, the assistant provides: (a) Doxygen style
comment generation for all functions and classes by retrieving relevant
information from RAG sources (papers, posters, presentations), (b) file-level
summary generation, and (c) an interactive chatbot for code comprehension
queries. For code generation, CelloAI employs syntax-aware chunking strategies
that preserve syntactic boundaries during embedding, improving retrieval
accuracy in large codebases. The system integrates callgraph knowledge to
maintain dependency awareness during code modifications and provides
AI-generated suggestions for performance optimization and accurate refactoring.
We evaluate CelloAI using real-world HEP applications from ATLAS, CMS, and DUNE
experiments, comparing different embedding models for code retrieval
effectiveness. Our results demonstrate the AI assistant's capability to enhance
code understanding and support reliable code generation while maintaining the
transparency and safety requirements essential for scientific computing
environments.

</details>


### [9] [Who Wins the Race? (R Vs Python) - An Exploratory Study on Energy Consumption of Machine Learning Algorithms](https://arxiv.org/abs/2508.17344)
*Rajrupa Chattaraj,Sridhar Chimalakonda,Vibhu Saujanya Sharma,Vikrant Kaulgud*

Main category: cs.SE

TL;DR: 本研究量化对比了Python与R在ML任务中的能耗差异，发现语言选择可带来极大能效提升，对推动绿色计算具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习广泛应用于软件系统，但其高能耗带来的环境影响，尤其是碳排放问题，鲜有研究关注。编程语言在ML任务中的能耗比较存在研究空白。

Method: 通过实证研究，分别用Python和R实现五个回归与五个分类任务，测量并对比两种语言在训练和推理过程中的能耗与运行性能。

Result: 95%的测试用例中，两种语言的能耗和性能差异具有统计显著性。语言选择对能效影响极大，训练阶段最高可达99.16%，推理阶段最高达99.8%。

Conclusion: 编程语言的选择在机器学习任务中，对能耗和碳排放有极大影响，需引起关注和权衡。

Abstract: The utilization of Machine Learning (ML) in contemporary software systems is
extensive and continually expanding. However, its usage is energy-intensive,
contributing to increased carbon emissions and demanding significant resources.
While numerous studies examine the performance and accuracy of ML, only a
limited few focus on its environmental aspects, particularly energy
consumption. In addition, despite emerging efforts to compare energy
consumption across various programming languages for specific algorithms and
tasks, there remains a gap specifically in comparing these languages for
ML-based tasks. This paper aims to raise awareness of the energy costs
associated with employing different programming languages for ML model training
and inference. Through this empirical study, we measure and compare the energy
consumption along with run-time performance of five regression and five
classification tasks implemented in Python and R, the two most popular
programming languages in this context. Our study results reveal a statistically
significant difference in costs between the two languages in 95% of the cases
examined. Furthermore, our analysis demonstrates that the choice of programming
language can influence energy efficiency significantly, up to 99.16% during
model training and up to 99.8% during inferences, for a given ML task.

</details>


### [10] [EyeMulator: Improving Code Language Models by Mimicking Human Visual Attention](https://arxiv.org/abs/2508.16771)
*Yifan Zhang,Chen Huang,Yueke Zhang,Jiahao Zhang,Toby Jia-Jun Li,Collin McMillan,Kevin Leach,Yu Huang*

Main category: cs.SE

TL;DR: 本文提出EyeMulator方法，将人类视觉关注（通过眼动追踪获得）数据引入CodeLLM训练，显著增强模型在代码相关任务上的表现。该方法只需在人类数据集上训练一次，无需在推理阶段附加眼动数据，证实了模仿人类注意力分布的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的代码语言模型（CodeLLMs）仅依赖输入token对输出token的重要性进行训练，而没有考虑人类开发者对代码的视觉关注差异，人类通常会关注更有意义的代码部分。这种差异可能导致模型表现不及人类直觉。本文试图通过人类视觉注视数据改进CodeLLM，使其更接近人类实际处理方式。

Method: 提出了一种称为EyeMulator的新方法，在CodeLLM微调过程中引入基于人类视觉关注（眼动追踪实验数据）的token权重到损失函数中。这些权重反映了人类在软件开发任务中实际关注的代码部分，以此指导模型学习更接近人类的注意力分布。在推理过程中，模型不再需要眼动数据。

Result: 实验表明，使用EyeMulator技术的CodeLLM在代码翻译、代码补全和代码摘要等任务上优于现有主流LLM基线模型。消融实验也证明了性能提升来源于模型成功模仿了人类视觉注意力。

Conclusion: 将人类视觉关注信息纳入CodeLLM训练显著提升了模型在多项代码相关自动化任务上的效果，且无需在推理阶段持续依赖额外的人机交互数据。该方法有助于使自动化软件开发工具更加智能和人性化。

Abstract: Code language models (so-called CodeLLMs) are now commonplace in software
development. As a general rule, CodeLLMs are trained by dividing training
examples into input tokens and then learn importance of those tokens in a
process called machine attention. Machine attention is based solely on input
token salience to output token examples during training. Human software
developers are different, as humans intuitively know that some tokens are more
salient than others. While intuition itself is ineffable and a subject of
philosophy, clues about salience are present in human visual attention, since
people tend to look at more salient words more often. In this paper, we present
EyeMulator, a technique for training CodeLLMs to mimic human visual attention
while training for various software development tasks. We add special weights
for each token in each input example to the loss function used during LLM
fine-tuning. We draw these weights from observations of human visual attention
derived from a previously-collected publicly-available dataset of eye-tracking
experiments in software engineering tasks. These new weights ultimately induce
changes in the attention of the subject LLM during training, resulting in a
model that does not need eye-tracking data during inference. Our evaluation
shows that EyeMulator outperforms strong LLM baselines on several tasks such as
code translation, completion and summarization. We further show an ablation
study that demonstrates the improvement is due to subject models learning to
mimic human attention.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [11] [On systematic construction of correct logic programs](https://arxiv.org/abs/2508.16782)
*Włodzimierz Drabent*

Main category: cs.LO

TL;DR: 本文提出一种系统性构建正确及半完备逻辑程序的方法，在三值和well-founded语义下，操作简单且适用于实际开发场景。


<details>
  <summary>Details</summary>
Motivation: 逻辑程序的部分正确性（correctness和completeness）是编程的重要问题，现有方法面临如何系统地构建既正确又完备的程序的挑战。作者希望找到一种简单且具有实用价值的方法，指导逻辑程序的开发。

Method: 该文提出系统性构建逻辑程序的方法，在给定规范下，能保证程序的正确性和半完备性。研究对象为正常逻辑程序，并在Kunen的三值完备语义（消极失败）和well-founded语义（可能无限失败）下进行分析。方法偏向宣告式，抽象掉操作语义中的细节，如选定字面量的具体形式。

Result: 得到了一种简单且可实际应用的方法，可以保证逻辑程序的正确性和半完备性，易于被开发者在日常编程中使用。其理论基础成立于两种主流逻辑语义下。

Conclusion: 该方法能够指导开发者系统化地编写正确、半完备的逻辑程序，而且实用性强，可支持实际编程需求。

Abstract: Partial correctness of imperative or functional programming divides in logic
programming into two notions. Correctness means that all answers of the program
are compatible with the specification. Completeness means that the program
produces all the answers required by the specifications. We also consider
semi-completeness -- completeness for those queries for which the program does
not diverge. This paper presents an approach to systematically construct
provably correct and semi-complete logic programs, for a given specification.
Normal programs are considered, under Kunen's 3-valued completion semantics (of
negation as finite failure) and the well-founded semantics (of negation as
possibly infinite failure). The approach is declarative, it abstracts from
details of operational semantics, like e.g.\ the form of the selected literals
(``procedure calls'') during the computation. The proposed method is simple,
and can be used (maybe informally) in actual everyday programming.

</details>


### [12] [Paraconsistent Constructive Modal Logic](https://arxiv.org/abs/2508.17758)
*Han Gao,Daniil Kozhemiachenko,Nicola Olivetti*

Main category: cs.LO

TL;DR: 本文提出了基于模态逻辑CK的悖容推理新体系，以双赋值Kripke语义结合Nelson强否定进行形式化，给出对应的公理化和序列演算，并证明系统可判定。


<details>
  <summary>Details</summary>
Motivation: 传统模态逻辑CK不足以处理存在矛盾但不致平凡化的推理需求，比如信念或义务可能自相矛盾仍值得推理，因此需要引入协调矛盾和模态逻辑的形式系统。

Method: 定义了基于直觉主义Kripke框架、两种赋值（分别支持真和假）、强否定操作的语义体系。探讨了不同可及关系下的系统，并分别给出了Hilbert公理化及割自由序列演算，用以证明可判定性。

Result: 得到了模态逻辑CK家族的悖容对应逻辑，建立了Kripke语义、对应公理系统和可判定的割自由序列演算体系，丰富了对非平凡矛盾态度的形式化工具。

Conclusion: 本文提出的家族逻辑系统通过两种独立支持真和假的赋值，能形式化处理矛盾但不平凡的命题态度（如信念、义务），并且给出了系统的语义、Hilbert风格公理化及模块化割自由序列演算，证明了可判定性。

Abstract: We present a family of paraconsistent counterparts of the constructive modal
logic CK. These logics aim to formalise reasoning about contradictory but
non-trivial propositional attitudes like beliefs or obligations. We define
their Kripke-style semantics based on intuitionistic frames with two valuations
which provide independent support for truth and falsity; they are connected by
strong negation as defined in Nelson's logic. A family of systems is obtained
depending on whether both modal operators are defined using the same or by
different accessibility relations for their positive and negative support. We
propose Hilbert-style axiomatisations for all logics determined by this
semantic framework. We also propose a~family of modular cut-free sequent
calculi that we use to establish decidability.

</details>


### [13] [Certificates and Witnesses for Multi-objective ω-regular Queries in Markov Decision Processes](https://arxiv.org/abs/2508.17859)
*Christel Baier,Calvin Chau,Volodymyr Drobitko,Simon Jantsch,Sascha Klüppelholz*

Main category: cs.LO

TL;DR: 本文提出了增强概率模型检查可信性的新技术，包括独立证书和见证，并在马尔可夫决策过程及链上实现高效验证，实验证明了其有效性，且显著降低了空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 多目标概率模型检查能够验证随机系统对多个可能冲突的属性的满足情况。为了提高模型检查工具的可信度和可解释性，本文旨在为多目标ω-正则查询提供可独立检验的证书和见证。

Method: 扩展并改进了现有的关于最大端分量分解和可达性属性的证书；提出了利用混合整数线性规划（MILP）寻找最小见证子系统的方法。对于马尔可夫链和LTL属性的特例，采用无二义性Büchi自动机寻找见证，使算法空间复杂度降低到单指数级（相比基于确定性自动机的现有方法的双指数空间复杂度）。最后，考虑证书和见证的实际计算，并实现了相关技术，并进行了实验评估。

Result: 开发了一套可独立检验的证书与见证，显著降低了复杂度（尤其在马尔可夫链和LTL场景下），并通过实验验证了所提出技术的有效性。

Conclusion: 提出的新方法能增强概率模型检查的可信性和可解释性，在多目标ω-正则查询场景中表现优良，可实际计算并有效支持相关系统的验证。

Abstract: Multi-objective probabilistic model checking is a powerful technique for
verifying stochastic systems against multiple (potentially conflicting)
properties. To enhance the trustworthiness and explainability of model checking
tools, we present independently checkable certificates and witnesses for
multi-objective {\omega}-regular queries in Markov decision processes. For the
certification, we extend and improve existing certificates for the
decomposition of maximal end components and reachability properties. We then
derive mixed-integer linear programs (MILPs) for finding minimal witnessing
subsystems. For the special case of Markov chains and LTL properties, we use
unambiguous B\"uchi automata to find witnesses, resulting in an algorithm that
requires single-exponential space. Existing approaches based on deterministic
automata require doubly-exponential space in the worst case. Finally, we
consider the practical computation of our certificates and witnesses and
provide an implementation of the developed techniques, along with an
experimental evaluation, demonstrating the efficacy of our techniques.

</details>


### [14] [Model-Based Testing of an Intermediate Verifier Using Executable Operational Semantics](https://arxiv.org/abs/2508.17895)
*Lidia Losavio,Marco Paganoni,Carlo A. Furia*

Main category: cs.LO

TL;DR: 本文提出基于PLT Redex框架的Boogie验证器模型随机测试方法BCC。实验发现BCC能检测到Boogie 2%的完整性缺陷，表明轻量级随机测试对形式验证工具有重要补充价值。


<details>
  <summary>Details</summary>
Motivation: 轻量级验证技术（如随机测试）可以作为完整形式化验证的实际替代方案，不需极大努力即可发现潜在问题。即使是对已经形式化验证的工具，这类方法也能覆盖形式化模型难以触及的复杂系统部分。

Method: 提出BCC：一种针对Boogie中间验证器的基于模型的测试技术。BCC通过PLT Redex框架随机生成Boogie程序并基于形式操作语义执行，再用Boogie验证器对同一程序进行验证，将两种执行结果进行比对，从中发现实现中的潜在bug。

Result: 使用BCC生成了三百万个Boogie程序实验，发现2%案例呈现Boogie工具链的完整性失败（错误的验证失败）。该结果表明，轻量级分析工具（如基于模型的随机测试）对形式化验证工具（如Boogie）有实际测试和验证价值。

Conclusion: BCC能够有效发现Boogie验证器的实际缺陷，说明轻量级随机测试技术能辅助和完善正式验证工具的可靠性。

Abstract: Lightweight validation technique, such as those based on random testing, are
sometimes practical alternatives to full formal verification -- providing
valuable benefits, such as finding bugs, without requiring a disproportionate
effort. In fact, they can be useful even for fully formally verified tools, by
exercising the parts of a complex system that go beyond the reach of formal
models.
  In this context, this paper introduces BCC: a model-based testing technique
for the Boogie intermediate verifier. BCC combines the formalization of a
small, deterministic subset of the Boogie language with the generative
capabilities of the PLT Redex language engineering framework. Basically, BCC
uses PLT Redex to generate random Boogie programs, and to execute them
according to a formal operational semantics; then, it runs the same programs
through the Boogie verifier. Any inconsistency between the two executions (in
PLT Redex and with Boogie) may indicate a potential bug in Boogie's
implementation.
  To understand whether BCC can be useful in practice, we used it to generate
three million Boogie programs. These experiments found 2% of cases indicative
of completeness failures (i.e., spurious verification failures) in Boogie's
toolchain. These results indicate that lightweight analysis tools, such as
those for model-based random testing, are also useful to test and validate
formal verification tools such as Boogie.

</details>


### [15] [Compositional Verification in Concurrent Separation Logic with Permissions Regions](https://arxiv.org/abs/2508.18115)
*Quang Loc Le*

Main category: cs.LO

TL;DR: 本文提出了一种提升CSLPerm自动化和组合性的新方法，通过自动推理内存堆残余、支持复杂并发验证，并用原型工具在多个高难度案例上取得优异效果。


<details>
  <summary>Details</summary>
Motivation: CSLPerm具备简洁严密的推理能力，但在自动化和组合性支持上存在不足。因此迫切需要提升其对复杂并发程序的验证自动化和可组合性。

Method: 提出了一种支持并发程序组合推理的验证系统，基于对CSL-Perm片段的逻辑原则和蕴涵判定过程，能够自动推导内存堆的残余部分，并实现对算术约束下堆不相交性的自动推理。实现了原型工具CoSl。

Result: 该方法能够自动处理并发线程与函数调用下的组合推理，原型工具CoSl可验证10个极具挑战性的并发程序，并在部分案例上超越当前技术水平。

Conclusion: 本文提出的新的组合式验证系统有效提升了对并发程序的分析与验证能力，并已通过原型工具CoSl和若干具有挑战性的程序测试证明其实用性和有效性。

Abstract: Concurrent separation logic with fractional permissions (CSLPerm) provides a
promising reasoning system to verify most complex sequential and concurrent
fine-grained programs. The logic with strong and weak separating conjunctions
offers a solid foundation for producing concise and precise proofs. However, it
lacks automation and compositionality support. This paper addresses this
limitation by introducing a compositional verification system for concurrent
programs that manipulate regions of shared memory. The centre of our system is
novel logical principles and an entailment procedure that can infer the
residual heaps in the frame rule for a fragment of CSL-Perm with explicit
arithmetical constraints for memory heaps' disjointness. This procedure enables
the compositional reasoning for concurrent threads and function calls. We have
implemented the proposal in a prototype tool called CoSl, tested it with 10
challenging concurrent programs, including those beyond the state-of-the-art,
and confirmed the advantage of our approach.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting](https://arxiv.org/abs/2508.16603)
*Zheng Dong,Luming Shang,Gabriela Olinto*

Main category: cs.CL

TL;DR: 本文提出了一种名为GreenTEA的多智能体自动提示优化方法，通过分析错误和遗传算法协同优化提示，在多个任务上优于以往方法，实现了高效、自动化的提示优化。


<details>
  <summary>Details</summary>
Motivation: 高质量的提示（prompt）对于大语言模型（LLM）的高效表现至关重要，但手工设计有效提示十分耗时且依赖专业领域知识，难以大规模应用。现有的自动提示优化方法要么消耗大量计算资源进行低效搜索，要么过度依赖已有提示，导致优化效果不理想。

Method: 提出GreenTEA：一种自动提示优化的agent工作流。其流程包括：1）由多智能体团队协作，基于模型错误样本进行提示优化；2）分析代理通过主题建模识别当前提示导致的常见错误；3）生成代理根据这些错误对提示进行针对性修改；4）整个过程嵌入在遗传算法框架中，通过交叉、变异等操作进化提示，不断优化性能。

Result: 在公开基准数据集上的大量实验表明，GreenTEA在逻辑与定量推理、常识以及伦理决策等任务上优于人工设计和当前最优的自动提示优化方法。

Conclusion: GreenTEA能高效、自动地优化提示，兼顾探索与利用，显著提升了大语言模型的多项任务表现，在实际应用中具有优越性和广阔前景。

Abstract: High-quality prompts are crucial for Large Language Models (LLMs) to achieve
exceptional performance. However, manually crafting effective prompts is
labor-intensive and demands significant domain expertise, limiting its
scalability. Existing automatic prompt optimization methods either extensively
explore new prompt candidates, incurring high computational costs due to
inefficient searches within a large solution space, or overly exploit feedback
on existing prompts, risking suboptimal optimization because of the complex
prompt landscape. To address these challenges, we introduce GreenTEA, an
agentic LLM workflow for automatic prompt optimization that balances candidate
exploration and knowledge exploitation. It leverages a collaborative team of
agents to iteratively refine prompts based on feedback from error samples. An
analyzing agent identifies common error patterns resulting from the current
prompt via topic modeling, and a generation agent revises the prompt to
directly address these key deficiencies. This refinement process is guided by a
genetic algorithm framework, which simulates natural selection by evolving
candidate prompts through operations such as crossover and mutation to
progressively optimize model performance. Extensive numerical experiments
conducted on public benchmark datasets suggest the superior performance of
GreenTEA against human-engineered prompts and existing state-of-the-arts for
automatic prompt optimization, covering logical and quantitative reasoning,
commonsense, and ethical decision-making.

</details>


### [17] [Cognitive Decision Routing in Large Language Models: When to Think Fast, When to Think Slow](https://arxiv.org/abs/2508.16636)
*Y. Du,C. Guo,W. Wang,G. Tang*

Main category: cs.CL

TL;DR: 该论文提出了认知决策路由（CDR）框架，让LLM可根据问题复杂性智能选择推理策略，实验显示不但性能提升，还降低了计算成本，特别适用于专业判断任务，为LLM自适应推理开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在面对不同类型问题时，往往对所有查询采用统一的推理深度或高成本的计算方法，缺乏根据问题复杂性动态调整推理策略的能力，这限制了模型的高效性和适应性。作者受双系统思维理论及人类认知偏差启发，旨在提升LLM的灵活推理与决策能力。

Method: 提出了认知决策路由（CDR）框架，在LLM推理前通过元认知层分析查询的复杂性，评估信息与结论的相关性、领域跨越、参与主体多样性和不确定性等多维度特征，动态决定采用快速直觉还是深度慢速推理策略。

Result: 通过多种推理任务的实验，CDR框架在降低34%的计算成本的同时，显著提升了模型表现，尤其在专业判断任务中一致性提高23%，专家级评价准确率提升18%。

Conclusion: 本论文提出的CDR框架有效结合认知科学原理与AI系统设计，实现了LLM的自适应推理，为大模型在不同复杂场景下的高效决策提供了有力方案。

Abstract: Large Language Models (LLMs) face a fundamental challenge in deciding when to
rely on rapid, intuitive responses versus engaging in slower, more deliberate
reasoning. Inspired by Daniel Kahneman's dual-process theory and his insights
on human cognitive biases, we propose a novel Cognitive Decision Routing (CDR)
framework that dynamically determines the appropriate reasoning strategy based
on query characteristics. Our approach addresses the current limitations where
models either apply uniform reasoning depth or rely on computationally
expensive methods for all queries. We introduce a meta-cognitive layer that
analyzes query complexity through multiple dimensions: correlation strength
between given information and required conclusions, domain boundary crossings,
stakeholder multiplicity, and uncertainty levels. Through extensive experiments
on diverse reasoning tasks, we demonstrate that CDR achieves superior
performance while reducing computational costs by 34\% compared to uniform deep
reasoning approaches. Our framework shows particular strength in professional
judgment tasks, achieving 23\% improvement in consistency and 18\% better
accuracy on expert-level evaluations. This work bridges cognitive science
principles with practical AI system design, offering a principled approach to
adaptive reasoning in LLMs.

</details>


### [18] [Trust but Verify! A Survey on Verification Design for Test-time Scaling](https://arxiv.org/abs/2508.16665)
*V Venktesh,Mandeep rathee,Avishek Anand*

Main category: cs.CL

TL;DR: 本文对大语言模型测试时扩展（TTS）技术——特别是验证器的使用与训练方法进行了系统综述，填补了领域内缺乏统一视角的空白。


<details>
  <summary>Details</summary>
Motivation: 尽管验证器被广泛采用于TTS，但目前缺乏对各类验证方法及其训练机制的全面收集与分类，因此有必要进行系统性梳理和总结。

Method: 对现有使用验证器进行TTS的方法进行文献回顾和分类，系统讨论了验证器的训练方式、类型及其在TTS中的应用。

Result: 整理并展示了验证器在TTS中的类型、训练方法和实际用途，构建了相关文献的统一体系，并开源了相关资源库以供学界参考。

Conclusion: 本文总结了大语言模型在推理过程中使用验证器进行测试时扩展（TTS）的多种方法，并提出统一视角进行归纳和分类。

Abstract: Test-time scaling (TTS) has emerged as a new frontier for scaling the
performance of Large Language Models. In test-time scaling, by using more
computational resources during inference, LLMs can improve their reasoning
process and task performance. Several approaches have emerged for TTS such as
distilling reasoning traces from another model or exploring the vast decoding
search space by employing a verifier. The verifiers serve as reward models that
help score the candidate outputs from the decoding process to diligently
explore the vast solution space and select the best outcome. This paradigm
commonly termed has emerged as a superior approach owing to parameter free
scaling at inference time and high performance gains. The verifiers could be
prompt-based, fine-tuned as a discriminative or generative model to verify
process paths, outcomes or both. Despite their widespread adoption, there is no
detailed collection, clear categorization and discussion of diverse
verification approaches and their training mechanisms. In this survey, we cover
the diverse approaches in the literature and present a unified view of verifier
training, types and their utility in test-time scaling. Our repository can be
found at
https://github.com/elixir-research-group/Verifierstesttimescaling.github.io.

</details>


### [19] [Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?](https://arxiv.org/abs/2508.16695)
*Siddhant Bhambri,Upasana Biswas,Subbarao Kambhampati*

Main category: cs.CL

TL;DR: 对LLMs进行链式思维微调时，最强性能不一定来自最可解释的推理轨迹。性能提升与可解释性可并行独立发展，无需强行结合。


<details>
  <summary>Details</summary>
Motivation: 近年来，链式思维（CoT）推理已成为提升大语言模型（LLM）推理能力的重要方法，CoT轨迹不仅用于推理，还作为训练小模型的监督信号。主流观点认为，这些推理轨迹应对用户具有可解释性，但这一假设尚待验证。本文提出核心问题：CoT轨迹是否必须可解释，才能提升LLM任务表现？

Method: 在开放式问答任务中，作者对LLaMA与Qwen两种模型进行有监督微调，分别用四种不同类型的推理轨迹：(1) DeepSeek R1轨迹，(2) LLM自动生成的R1轨迹摘要，(3) LLM自动生成的R1后解释，(4) 算法生成且可验证正确的轨迹。同时，设计了包含100人的用户调研，收集他们对不同类型轨迹可解释性的主观评分，以量化可解释性与任务表现的权衡。

Result: 微调实验显示，使用R1轨迹训练的模型性能最高，但用户主观感受R1轨迹的可解释性最低。即，可解释性与模型性能存在明显脱钩。

Conclusion: CoT轨迹无需强制追求用户可解释性，也能大幅提升LLM的推理能力。建议在设计中间推理过程时，可以将“对模型有效”与“对用户可解释”分离考虑。

Abstract: Recent progress in reasoning-oriented Large Language Models (LLMs) has been
driven by introducing Chain-of-Thought (CoT) traces, where models generate
intermediate reasoning traces before producing an answer. These traces, as in
DeepSeek R1, are not only used to guide inference but also serve as supervision
signals for distillation into smaller models. A common but often implicit
assumption is that CoT traces should be semantically meaningful and
interpretable to the end user. While recent research questions the need for
semantic nature of these traces, in this paper, we ask: ``\textit{Must CoT
reasoning traces be interpretable to enhance LLM task performance?}" We
investigate this question in the Open Book Question-Answering domain by
supervised fine-tuning LLaMA and Qwen models on four types of reasoning traces:
(1) DeepSeek R1 traces, (2) LLM-generated summaries of R1 traces, (3)
LLM-generated post-hoc explanations of R1 traces, and (4) algorithmically
generated verifiably correct traces. To quantify the trade-off between
interpretability and performance, we further conduct a human-subject study with
100 participants rating the interpretability of each trace type. Our results
reveal a striking mismatch: while fine-tuning on R1 traces yields the strongest
performance, participants judged these traces to be the least interpretable.
These findings suggest that it is useful to decouple intermediate tokens from
end user interpretability.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [20] [On The Space Complexity of Partial Derivatives of Regular Expressions with Shuffle](https://arxiv.org/abs/2508.17451)
*Davide Ancona,Angelo Ferrando*

Main category: cs.FL

TL;DR: 本文提出了一种结合正则表达式部分导数和shuffle操作符的运行时验证新方法。只需每步存储一个导数，有效控制空间复杂度，最大部分导数高度增加有限，表达式大小为二次级别，并证明对shuffle也成立。该方法改善了事件可穿插场景下的规范表达和验证效率。


<details>
  <summary>Details</summary>
Motivation: 现有的正则表达式通过部分导数方法，可以生成等价的NFA，但在运行时验证（RV）中，当事件可互相穿插时，生成的NFA状态数可能会变得难以处理。为了更高效监控，规范需要更紧凑易读并能支持事件穿插。

Method: 使用扩展正则表达式（加入shuffle操作符），利用部分导数进行改写式运行时验证。该方法每步只存储一个导数，避免构造巨大不可处理的自动机。此外，研究了最大部分导数表达式的空间复杂度（高度和大小两个指标）。

Result: 证明了最大部分导数的高度至多增加一，表达式大小则为原正则表达式大小的二次函数。这一结论在引入shuffle运算符后仍然成立。

Conclusion: 这种基于部分导数的运行时验证方法能避免生成不可处理的巨大自动机，通过对空间复杂度的界定，为实际RV提供了理论保证。引入shuffle扩展运算符也不会增加复杂性指标。

Abstract: Partial derivatives of regular expressions, introduced by Antimirov, define
an elegant algorithm for generating equivalent non-deterministic finite
automata (NFA) with a limited number of states.
  Here we focus on runtime verification (RV) of simple properties expressible
with regular expressions. In this case, words are finite traces of monitorable
events forming the language's alphabet, and the generated NFA may have an
intractable number of states.
  This typically occurs when sub-traces of mutually independent events are
allowed to interleave.
  To address this issue, regular expressions used for RV are extended with the
shuffle operator to make specifications more compact and easier to read.
  Exploiting partial derivatives enables a rewriting-based approach to RV,
where only one derivative is stored at each step, avoiding the construction of
an intractably large automaton.
  This raises the question of the space complexity of the largest generated
partial derivative. While the total number of generated partial derivatives is
known to be linear in the size of the initial regular expression, no results
can be found in the literature regarding the size of the largest partial
derivative.
  We study this problem w.r.t. two metrics (height and size of regular
expressions), and show that the former increases by at most one, while the
latter is quadratic in the size of the regular expression. Surprisingly, these
results also hold with shuffle.

</details>


### [21] [Weighing Obese Timed Languages](https://arxiv.org/abs/2508.18133)
*Eugene Asarin,Aldric Degorre,Catalin Dima,Bernardo Jacobo Inclán*

Main category: cs.FL

TL;DR: 本文提出了计算timed automata带宽的通用方法，通过建立加权时序图并用辅助自动机的熵作为权重，将带宽计算问题转化为奖励与时间比率的优化。最终给出了其带宽的近似公式α/ε。


<details>
  <summary>Details</summary>
Motivation: timed automata的事件频率无界，信息产生速率最大化，亟需精确评估其单位时间内能表达的信息量（带宽），以量化其信息能力。

Method: 将timed automata的问题转化为求加权时序图中的最佳奖励与时间比，并利用辅助有限自动机的熵来给予权重，从而进行计算。

Result: 得到timed automata的带宽约为α/ε，其中α由图的最佳奖励与时间比率计算。提供了一种通用计算方法。

Conclusion: 本文得出可通过计算加权时序图中最佳奖励与时间比率来获取timed automata的带宽，该图由原timed automata生成并以有限自动机熵为权重。

Abstract: The bandwidth of a timed language characterizes the quantity of information
per time unit (with a finite observation precision $\varepsilon$). Obese timed
automata have an unbounded frequency of events and produce information at the
maximal possible rate. In this article, we compute the bandwidth of any such
automaton in the form $\approx\alpha/\varepsilon$. Our approach reduces the
problem to computing the best reward-to-time ratio in a weighted timed graph
constructed from the given timed automaton, with weights corresponding to the
entropy of auxiliary finite automata.

</details>
