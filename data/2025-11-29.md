<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 11]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 34]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Optimism in Equality Saturation](https://arxiv.org/abs/2511.20782)
*Russel Arbore,Alvin Cheung,Max Willsey*

Main category: cs.PL

TL;DR: 本文提出了一种结合抽象解释与等价饱和的新算法，能更精确地分析带循环的 SSA 程序，在简单案例上优于现有主流编译器，提升了程序优化的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 e-class 分析方法由于过于悲观，无法有效分析如 SSA 这类带有循环的程序，亟需一种新的分析方法提升优化能力和准确性。

Method: 作者采用抽象解释的方法，并结合等价饱和技术，对 SSA 形式的程序进行统一且乐观的分析。提出了一种新颖的 SSA 语义，从而能够更好地处理程序中的循环。

Result: 该方法能够比主流编译器（clang 和 gcc）更精确地分析一些简单的 SSA 程序范例，证明了其有效性和改进空间。

Conclusion: 通过提出一种新的抽象解释算法，作者实现了在等价饱和过程中对循环结构的精确分析，提升了分析的乐观性和统一性。原型系统在分析某些简单 SSA 程序时优于 clang 和 gcc。

Abstract: Equality saturation is a technique for program optimization based on non-destructive rewriting and a form of program analysis called e-class analysis. The current form of e-class analysis is pessimistic and therefore ineffective at analyzing cyclic programs, such as those in SSA form. We propose an abstract interpretation algorithm that can precisely analyze cycles during equality saturation. This results in a unified algorithm for optimistic analysis and non-destructive rewriting. We instantiate this approach on a prototype abstract interpreter for SSA programs using a new semantics of SSA. Our prototype can analyze simple example programs more precisely than clang and gcc.

</details>


### [2] [Towards Computational UIP in Cubical Agda](https://arxiv.org/abs/2511.21209)
*Yee-Jian Tan,Andreas Nuyts,Dominique Devriese*

Main category: cs.PL

TL;DR: 本文致力于在 Cubical Agda 中实现仅支持 h-Set 的 Cubical Type Theory，通过移除 Glue Types 和分析UIP公理，保留了 QITs 和函数外延性等关键特性，并给出解决方案与实现，为后续自动化与理论发展提供支持。


<details>
  <summary>Details</summary>
Motivation: Cubical Type Theory 拥有高阶归纳类型和函数外延性等优点，但其无限层级的等同性在形式化过程中变得难以处理。作者希望在保留这些优点的前提下，实现只包含 h-Set 层级的理论，即假设唯一性身份证明（UIP），使其更易于实践和自动化。

Method: 分析和对比 Cubical Agda 中去除 Glue Types 的实现方式，并系统梳理和实现了支持 UIP 的理论与工具。同时对不同 UIP 表述及其计算规则进行了详尽研究与评估。

Result: 提出并实现了一个无 Glue 版本的 Cubical Agda，并分析了不同 UIP 实现方案，为 Cubical Agda 未来原生支持 UIP 提供了理论和技术基础。

Conclusion: 作者提出了在 Cubical Agda 中实现 h-Set Cubical Type Theory 的方法，分析了不同版本的 UIP 公理，并实现了一个兼容 UIP 的 Cubical Agda 变体，为未来更完善的实现奠定基础。

Abstract: Some advantages of Cubical Type Theory, as implemented by Cubical Agda, over intensional Martin-Löf Type Theory include Quotient Inductive Types (QITs), which exist as instances of Higher Inductive Types, and functional extensionality, which is provable in Cubical Type Theory. However, HoTT features an infinite hierarchy of equalities that may become unwieldy in formalisations. Fortunately, QITs and functional extensionality are both preserved even if the equality levels of Cubical Type Theory are truncated to only homotopical Sets (h-Sets). In other words, removing the univalence axiom from Cubical Type Theory and instead postulating a conflicting axiom: the Uniqueness of Identity Proofs (UIP) postulate. Since univalence is proved in Cubical Type Theory from the so-called Glue Types, therefore, it is known that one can first remove the Glue Types (thus removing univalence) and then set-truncate all equalities (essentially assuming UIP), à la XTT. The result is a "h-Set Cubical Type Theory" that retains features such as functional extensionality and QITs.
  However, in Cubical Agda, there are currently only two unsatisfying ways to achieve h-Set Cubical Type Theory. The first is to give up on the canonicity of the theory and simply postulate the UIP axiom, while the second way is to use a standard result stating "type formers preserve h-levels" to manually prove UIP for every defined type. The latter is, however, laborious work best suited for an automatic implementation by the proof assistant. In this project, we analyse formulations of UIP and detail their computation rules for Cubical Agda, and evaluate their suitability for implementation. We also implement a variant of Cubical Agda without Glue, which is already compatible with postulated UIP, in anticipation of a future implementation of UIP in Cubical Agda.

</details>


### [3] [SV-LIB 1.0: A Standard Exchange Format for Software-Verification Tasks](https://arxiv.org/abs/2511.21509)
*Dirk Beyer,Gidon Ernst,Martin Jonáš,Marian Lingsch-Rosenfeld*

Main category: cs.PL

TL;DR: 本文提出了SV-LIB，一种针对软件验证任务的通用交换格式和中间语言，解决了现有验证工具多语言兼容难题，已实现首版并展望未来扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数软件验证工具都是为特定编程语言（如C、C++、Java）开发的，尽管许多验证方法本质上是语言无关的。如果能实现验证技术在不同语言之间的迁移，将极大提升工具的复用与适用范围。

Method: 提出了一种新的交换格式和中间语言SV-LIB，用于软件验证任务，涵盖程序、规格说明和验证见证。SV-LIB借鉴了命令式编程语言的通用概念，并采用SMT-LIB格式表示程序中的表达式和类型，便于解析并集成到已有的验证工具基础设施中。SV-LIB还定义了正确和错误程序的见证文件格式及验证任务规范。

Result: SV-LIB 1.0版本已实现，包含其设计目标、语法及非正式语义，并能便捷地用于验证工具及证据验证。同时，未来将继续完善形式语义和扩展对并发的支持。

Conclusion: SV-LIB为软件验证提供了统一的交换格式和中间语言，促进了不同语言间验证技术的复用，并简化了验证见证的交换与验证流程。该格式易于集成到现有工具链，是推进软件验证通用化的重要一步。

Abstract: In the past two decades, significant research and development effort went into the development of verification tools for individual languages, such asC, C++, and Java. Many of the used verification approaches are in fact language-agnostic and it would be beneficial for the technology transfer to allow for using the implementations also for other programming and modeling languages. To address the problem, we propose SV-LIB, an exchange format and intermediate language for software-verification tasks, including programs, specifications, and verification witnesses. SV-LIBis based on well-known concepts from imperative programming languages and uses SMT-LIB to represent expressions and sorts used in the program. This makes it easy to parse and to build into existing infrastructure, since many verification tools are based on SMT solvers already. Furthermore, SV-LIBdefines a witness format for both correct and incorrect SV-LIB programs, together with means for specifying witness-validation tasks. This makes it possible both to implement independent witness validators and to reuse some verifiers also as validators for witnesses. This paper presents version 1.0 of the SV-LIBformat, including its design goals, the syntax, and informal semantics. Formal semantics and further extensions to concurrency are planned for future versions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [DUALGUAGE: Automated Joint Security-Functionality Benchmarking for Secure Code Generation](https://arxiv.org/abs/2511.20709)
*Abhijeet Pathak,Suvadra Barua,Dinesh Gudimetla,Rupam Patir,Jiawei Guo,Hongxin Hu,Haipeng Cai*

Main category: cs.SE

TL;DR: 针对LLM生成安全代码的评测难题，本文提出DUALGAUGE框架及配套数据集，实现了代码安全性与正确性的联合自动化评估，并揭示主流LLMs在安全、正确代码生成方面仍有明显短板。开源工具和数据集有望推动该领域评测标准化和性能提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）与自动化编码代理在软件生成中应用广泛，但保障生成代码的安全性同时不影响功能正确性仍是未解决的核心需求。现有的安全代码生成评测通常仅考察漏洞减少，忽略正确性，或在不同数据集上分别评估安全与功能性，无法实现同时联合评测。

Method: 提出并开发了DUALGAUGE，这是首个能够自动化、严格联合评估LLM生成代码安全性与正确性的基准测试框架。此外，构建了DUALGAUGE-BENCH数据集，包括经过手工验证安全性与功能性测试的多样化编码任务，以实现评测标准的全面覆盖。DUALGAUGE核心包括代理化程序执行器（在沙盒环境中运行代码测试）和基于LLM的评估器（同时评估代码正确性和安全性）。

Result: DUALGAUGE和DUALGAUGE-BENCH经过严格测试确保质量。利用DUALGAUGE在DUALGAUGE-BENCH上对十个主流LLMs进行评测，覆盖数千测试场景。结果显示这些LLMs在生成正确且安全的代码方面存在显著不足。

Conclusion: DUALGAUGE及其数据集支持可复现、可扩展和严格的安全代码生成评测，有助于加速LLM安全代码生成领域的进展。

Abstract: Large language models (LLMs) and autonomous coding agents are increasingly used to generate software across a wide range of domains. Yet a core requirement remains unmet: ensuring that generated code is secure without compromising its functional correctness. Existing benchmarks and evaluations for secure code generation fall short-many measure only vulnerability reduction, disregard correctness preservation, or evaluate security and functionality on separate datasets, violating the fundamental need for simultaneous joint evaluation. We present DUALGAUGE, the first fully automated benchmarking framework designed to rigorously evaluate the security and correctness of LLM-generated code in unison. Given the lack of datasets enabling joint evaluation of secure code generation, we also present DUALGAUGE-BENCH, a curated benchmark suite of diverse coding tasks, each paired with manually validated test suites for both security and functionality, designed for full coverage of specification requirements. At the core of DUALGAUGE is an agentic program executor, which runs a program against given tests in sandboxed environments, and an LLM-based evaluator, which assesses both correctness and vulnerability behavior against expected outcomes. We rigorously evaluated and ensured the quality of DUALGAUGE-BENCH and the accuracy of DUALGAUGE, and applied DUALGAUGE to benchmarking ten leading LLMs on DUALGAUGE-BENCH across thousands of test scenarios. Our results reveal critical gaps in correct and secure code generation by these LLMs, for which our open-source system and datasets help accelerate progress via reproducible, scalable, and rigorous evaluation.

</details>


### [5] [Data-Driven Methods and AI in Engineering Design: A Systematic Literature Review Focusing on Challenges and Opportunities](https://arxiv.org/abs/2511.20730)
*Nehal Afifi,Christoph Wittig,Lukas Paehler,Andreas Lindenmann,Kai Wolter,Felix Leitenberger,Melih Dogru,Patric Grauberger,Tobias Düser,Albert Albers,Sven Matthiesen*

Main category: cs.SE

TL;DR: 本论文系统性梳理了2014-2024年数据驱动方法在工程设计各阶段的应用情况，发现机器学习和统计方法为主流，深度学习应用逐渐增多，但存在解释性、跨阶段追踪和真实验证不足等问题，为后续建立设计阶段指导方案和模型应用标准提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着数据可用性和计算智能的发展，数据驱动方法在产品开发中被广泛采用，但实际集成过程仍高度碎片化，主要原因是对不同DDM使用时机和类型缺乏明晰认识，亟需梳理其应用现状以为标准化与指导方案奠定基础。

Method: 采用PRISMA系统性文献回顾方法，使用V模型对产品开发流程进行简化分阶段评审，通过在Scopus、Web of Science和IEEE Xplore数据库检索2014-2024年间的相关论文，并筛选分析114篇全文文献，梳理数据驱动方法（DDMs）在产品开发各阶段的应用情况。

Result: 目前产品开发中以机器学习及统计学方法为主，深度学习虽应用较少但呈上升趋势。监督学习、聚类、回归分析、替代建模多用于设计、实施和集成阶段，但在验证阶段贡献有限。主要挑战包括模型可解释性不足、跨阶段追踪性差以及真实环境下验证不充分。

Conclusion: 目前数据驱动方法在产品开发流程中的应用尚不成熟，主要集中于设计和实施等前期阶段。缺乏模型可解释性、跨阶段追踪和现实条件验证是限制其深入集成的核心问题。未来应关注开发可解释的混合模型，并将计算机科学算法与工程设计活动有机结合，为行业标准化和最佳实践提供理论基础。

Abstract: The increasing availability of data and advancements in computational intelligence have accelerated the adoption of data-driven methods (DDMs) in product development. However, their integration into product development remains fragmented. This fragmentation stems from uncertainty, particularly the lack of clarity on what types of DDMs to use and when to employ them across the product development lifecycle. To address this, a necessary first step is to investigate the usage of DDM in engineering design by identifying which methods are being used, at which development stages, and for what application. This paper presents a PRISMA systematic literature review. The V-model as a product development framework was adopted and simplified into four stages: system design, system implementation, system integration, and validation. A structured search across Scopus, Web of Science, and IEEE Xplore (2014--2024) retrieved 1{,}689 records. After screening, 114 publications underwent full-text analysis. Findings show that machine learning (ML) and statistical methods dominate current practice, whereas deep learning (DL), though still less common, exhibits a clear upward trend in adoption. Additionally, supervised learning, clustering, regression analysis, and surrogate modeling are prevalent in design, implementation, and integration system stages but contributions to validation remain limited. Key challenges in existing applications include limited model interpretability, poor cross-stage traceability, and insufficient validation under real-world conditions. Additionally, it highlights key limitations and opportunities such as the need for interpretable hybrid models. This review is a first step toward design-stage guidelines; a follow-up synthesis should map computer science algorithms to engineering design problems and activities.

</details>


### [6] [Train While You Fight -- Technical Requirements for Advanced Distributed Learning Platforms](https://arxiv.org/abs/2511.20813)
*Simon Hacks*

Main category: cs.SE

TL;DR: 论文探讨ADL平台支持作战期间持续学习需解决的技术难题，基于文献归纳挑战，并用德国军队案例验证软件工程设计模式的有效性。


<details>
  <summary>Details</summary>
Motivation: 推动“边训练边作战”（TWYF）理念的实现，提升作战过程中的连续学习能力。明确ADL平台在协助TWYF中需满足哪些技术要求。

Method: 采用Design Science Research方法：（1）从PfPC/NATO文档和近期实践中归纳挑战，（2）定义解决目标，（3）系统映射挑战与软件工程成熟模式之间的关系。

Result: 识别了七大技术挑战：互操作性、弹性、多语言支持、数据安全与隐私、可扩展性、平台无关性和模块化，并通过德国军队的国家级案例进行了模式说明。

Conclusion: 为实现TWYF，ADL平台需要在七个关键技术领域采用合适的软件工程模式以应对挑战，理论与案例分析为类似场景提供参考。

Abstract: "Train While You Fight" (TWYF) advocates for continuous learning that occurs during operations, not just before or after. This paper examines the technical requirements that advanced distributed learning (ADL) platforms must meet to support TWYF, and how existing software engineering patterns can fulfill these requirements. Using a Design Science Research approach, we (i) derive challenges from PfPC/NATO documentation and recent practice, (ii) define solution objectives, and (iii) conduct a systematic mapping from challenges to proven patterns. We identify seven technical challenges: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. We illustrate the patterns with a national use case from the German armed forces.

</details>


### [7] [Application of machine learning for infrastructure reconstruction programs management](https://arxiv.org/abs/2511.20916)
*Illia Khudiakov,Vladyslav Pliuhin,Sergiy Plankovskyy,Yevgen Tsegelnyk*

Main category: cs.SE

TL;DR: 本文提出了一种结合机器学习和神经网络的自适应决策支持模型，用于提升工程基础设施重建项目管理效率。模型能够根据项目类型智能调整决策过程，已在云平台部署并评估。该方法适用于各类基础设施工程，显著增强管理决策的自动化与智能化。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提升工程基础设施重建项目管理效率，尤其针对方案架构及工作分解结构（WBS）开发，解决传统管理方法在复杂工程项目中的适应性和效率不足问题。

Method: 通过分析现有的自适应项目管理工具，并结合基础设施系统建模工具，提出一种融合机器学习与人工神经网络的新型自适应决策支持模型。模型主要组件包括决策者偏好、决策任务、输入数据集与软件模块，通过系统建模和基于历史数据的机器学习预测目标函数的值。

Result: 模型能够根据不同的项目类型动态调整决策参数，提高项目管理的精确性和灵活性。该方法已在Microsoft Azure Machine Learning Studio实现，对神经网络的参数进行了评估，并展示了应用效果。

Conclusion: 所开发的自适应模型适用于热力、燃气、电力、水务及排水等基础设施系统的重建项目管理，可有效提升决策效率和项目管理的适应性及智能化水平。

Abstract: The purpose of this article is to describe an adaptive decision-making support model aimed at improving the efficiency of engineering infrastructure reconstruction program management in the context of developing the architecture and work breakdown structure of programs. As part of the study, the existing adaptive program management tools are analyzed, the use of infrastructure systems modelling tools is justified for program architecture and WBS creation. Existing models and modelling methods are viewed, and machine learning and artificial neural networks are selected for the model. The main components of the model are defined, which include a set of decision-maker preferences, decision-making tasks, sets of input data, and applied software components of the model. To support decision-making, the adaptive model applies the method of system modeling and predicting the value of the objective function at a given system configuration. Prediction is done using machine learning methods based on a dataset consisting of historical data related to existing engineering systems. The work describes the components of the redistribution of varied model parameters, which modify the model dataset based on the selected object type, which allows adapting the decision-making process to the existing program implementation goals. The functional composition done in Microsoft Azure Machine Learning Studio is described. The neural network parameters and evaluation results are given. The application of the developed adaptive model is possible in the management of programs for the reconstruction of such engineering systems as systems of heat, gas, electricity supply, water supply, and drainage, etc.

</details>


### [8] [Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code](https://arxiv.org/abs/2511.20933)
*Mootez Saad,Boqi Chen,José Antonio Hernández López,Dániel Varró,Tushar Sharma*

Main category: cs.SE

TL;DR: 本文系统测试了大语言模型对软件设计内聚与耦合的理解，发现模型基础认知好，但对耦合推理脆弱，噪声环境下性能大降，内聚鲁棒但无指导时也会失效。这表明模型在真实场景自主理解能力不足，需要改进其程序理解能力。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在软件工程核心设计概念（内聚与耦合）上的理解能力及其鲁棒性，鉴于其广泛应用但相关认知能力尚不明晰。

Method: 通过程序化生成差设计代码，并引入干扰因素，测试不同规模DeepSeek-R1模型在各种任务指导下对内聚和耦合的理解能力，并分析推理轨迹。

Result: 模型在理想条件下表现良好，但实际应用脆弱且对耦合推理尤为不稳定，噪声环境下F1分数下降超过50%。内聚分析则对噪声更为鲁棒，但无指导时同样表现下降。推理分析发现模型在耦合判别时易用认知捷径，内聚则分析更为细致但仍不稳定。

Conclusion: LLMs能识别设计缺陷，但在噪声和开放场景下自主推理能力有限，需要提升其可扩展性和健壮性。

Abstract: Large language models (LLMs) are being increasingly adopted in the software engineering domain, yet the robustness of their grasp on core software design concepts remains unclear. We conduct an empirical study to systematically evaluate their understanding of cohesion (intra-module) and coupling (inter-module). We programmatically generate poorly designed code fragments and test the DeepSeek-R1 model family ($14$B, $32$B, $70$B) under varying levels of guidance, from simple \textit{Verification} to \textit{Guided} and \textit{Open-ended Generation}, while varying contextual noise by injecting distractor elements. While models exhibit a solid baseline understanding of both concepts in ideal conditions, their practical knowledge is fragile and highly asymmetrical. Reasoning about coupling proves brittle; performance collapses in noisy, open-ended scenarios, with F1 scores dropping by over $50\%$. In contrast, the models' analysis of cohesion is remarkably robust to internal noise in guided tasks, showing little performance degradation. However, this resilience also fails when all guidance is removed. Reasoning-trace analysis confirms these failure modes, revealing \textit{cognitive shortcutting} for coupling versus a more exhaustive (yet still failing) analysis for cohesion. To summarize, while LLMs can provide reliable assistance for recognizing design flaws, their ability to reason autonomously in noisy, realistic contexts is limited, highlighting the critical need for more scalable and robust program understanding capabilities.

</details>


### [9] [SpaceX: Exploring metrics with the SPACE model for developer productivity](https://arxiv.org/abs/2511.20955)
*Sanchit Kaul,Kevin Nhu,Jason Eissayou,Ivan Eser,Victor Borup*

Main category: cs.SE

TL;DR: 论文发现用情感、协作网络结构等多维指标衡量开发者生产力，比传统单一指标更科学可靠，并推出综合评价分值CPS。


<details>
  <summary>Details</summary>
Motivation: 以往关于开发者生产力的衡量标准过于简单，通常用单一、确定性的度量方法，无法全面刻画开发者多维度的生产力特性。本文旨在通过系统分析开发者行为，提出更全面、有效的生产力评价方法。

Method: 本研究基于大量开源代码库数据，通过GLMM广义线性混合模型分析、RoBERTa情感分类等统计方法，结合SPACE框架，构建综合生产力衡量体系。同时分析贡献者之间的互动拓扑结构以反映协作动态。

Result: 结果显示，开发者消极情绪与提交频次呈显著正相关，表明负面情绪促进了“修正-再犯-修正”式循环。同时，贡献者互动拓扑结构分析比传统以数量为主的指标更能准确反映协作态势。

Conclusion: 传统的一维生产力衡量方法存在显著局限，建议采用CPS（复合生产力评分）来涵盖开发者产出的多样性和复杂性。

Abstract: This empirical investigation elucidates the limitations of deterministic, unidimensional productivity heuristics by operationalizing the SPACE framework through extensive repository mining. Utilizing a dataset derived from open-source repositories, the study employs rigorous statistical methodologies including Generalized Linear Mixed Models (GLMM) and RoBERTa-based sentiment classification to synthesize a holistic, multi-faceted productivity metric. Analytical results reveal a statistically significant positive correlation between negative affective states and commit frequency, implying a cycle of iterative remediation driven by frustration. Furthermore, the investigation has demonstrated that analyzing the topology of contributor interactions yields superior fidelity in mapping collaborative dynamics compared to traditional volume-based metrics. Ultimately, this research posits a Composite Productivity Score (CPS) to address the heterogeneity of developer efficacy.

</details>


### [10] [Lightweight Model Editing for LLMs to Correct Deprecated API Recommendations](https://arxiv.org/abs/2511.21022)
*Guancheng Lin,Xiao Yu,Jacky Keung,Xing Hu,Xin Xia,Alex X. Liu*

Main category: cs.SE

TL;DR: 本文专注解决LLM生成弃用API的问题，评估10种模型编辑技术后，提出AdaLoRA-L方法，在提升更新准确性的同时显著改善了特异性，是维护代码模型实用新方案。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在代码补全上表现出色，但其知识易受训练数据滞后影响，常生成已弃用（deprecated）的API，危及代码质量。重新训练模型成本极高，现有轻量模型编辑能否用于更新这类知识尚不明确。

Method: 本文系统性评估了10种最先进模型编辑技术，应用于三款主流代码LLM（Qwen2.5-Coder、StarCoder2、DeepSeek-Coder），并自建包含8个流行Python库、70+弃用API的基准（EDAPIBench）。提出了新方法AdaLoRA-L，仅编辑特定API相关层，避免泛化层受到影响。

Result: AdaLoRA方法提升了API知识的更新，但在特异性上表现不佳。改进的AdaLoRA-L法通过区分“通用API层”和“特定API层”进行限制编辑，显著提升了特异性，同时其它指标保持竞争力。

Conclusion: AdaLoRA-L能高效、精准地更新LLM中的弃用API知识，为代码模型及时性维护提供了新途径。

Abstract: Pre-trained or fine-tuned on large code corpora, Large Language Models (LLMs) have demonstrated strong performance in code completion tasks. However, their embedded knowledge is constrained by the timeliness of training data, which often includes code using deprecated APIs. Consequently, LLMs frequently generate deprecated APIs that will no longer be supported in future versions of third-party libraries. While retraining LLMs on updated codebases could refresh their API knowledge, this approach is computationally expensive. Recently, lightweight model editing methods have emerged to efficiently correct specific knowledge in LLMs. However, it remains unclear whether these methods can effectively update deprecated API knowledge and enable edited models to generate up-to-date APIs. To address this gap, we conduct the first systematic study applying 10 state-of-the-art model editing techniques to update deprecated API knowledge in three LLMs: Qwen2.5-Coder, StarCoder2, and DeepSeek-Coder. We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances. Our results show that the parameter-efficient fine-tuning method AdaLoRA achieves the best performance in enabling edited models to generate correct, up-to-date APIs, but falls short in Specificity (i.e., the editing influences untargeted knowledge). To resolve this, we propose AdaLoRA-L, which defines "Common API Layers" (layers within the LLMs with high importance across all APIs, storing general knowledge and excluded from editing) and restricts edits exclusively to "Specific API Layers" (layers with high importance only for the target API, storing the API-specific knowledge). Experimental results demonstrate that AdaLoRA-L significantly improves Specificity while maintaining comparable performance across other evaluation metrics.

</details>


### [11] [Exploring Hidden Geographic Disparities in Android Apps](https://arxiv.org/abs/2511.21151)
*M. Alecci,P. Jiménez,J. Samhi,T. Bissyandé,J. Klein*

Main category: cs.SE

TL;DR: 本文大型实证研究揭示：安卓应用因地区不同，虽外观一致但行为却有差异，包括权限、库和隐私，带来安全与透明度的新挑战。


<details>
  <summary>Details</summary>
Motivation: 当前对移动应用程序在不同地区表现的差异性研究较少，尤其是地理位置对应用安全性和公平性的影响尚未被充分探讨。

Method: 构建了遍布多个地区的分布式应用收集管道，分析了数千款应用，并公开了包含81,963对GeoTwins的数据集。主要比较同一品牌但分布于不同地区的应用在权限请求、第三方库和隐私披露等方面的差异。

Result: 发现同一品牌的应用（GeoTwins）在不同国家/地区存在权限、库、隐私披露等诸多差异，甚至Android的base.apk也有区域差异。这不仅影响恶意软件检测的结论一致性，还造成了地区性偏差，对安全性、隐私和透明度构成挑战。

Conclusion: 地理位置显著影响移动应用的行为与特性，并对安全、隐私和公平性研究提出新的挑战。研究者、开发者和平台方需关注地区性差异，以提升透明度和一致性。

Abstract: While mobile app evolution has been widely studied, geographical variation in app behavior remains largely unexplored. This paper presents a large-scale study of location-based Android app differentiation, uncovering two important and underexamined phenomena with security and fairness implications. First, we introduce GeoTwins: apps that are functionally similar and share branding but are released under different package names across countries. Despite their similarity, GeoTwins often diverge in requested permissions, third-party libraries, and privacy disclosures. Second, we examine the Android App Bundle ecosystem and reveal unexpected regional differences in supposedly consistent base.apk files. Contrary to common assumptions, even base.apk files vary by region, exposing hidden customizations that may affect app behavior or security.
  These discrepancies have concrete consequences. Geographically distinct variants can lead the same app to be labeled benign in one malware study but suspicious in another, depending on the region of download. Such hidden variation undermines reproducibility and introduces geographic bias into assessments of security, privacy, and functionality. It also raises ethical concerns about transparency and consent: visually identical Google Play listings may mask subtle but important differences.
  To study these issues, we built a distributed app collection pipeline spanning multiple regions and analyzed thousands of apps. We also release a dataset of 81,963 GeoTwins to support future work. Our findings reveal systemic regional disparities in mobile software, with implications for researchers, developers, platform architects, and policymakers.

</details>


### [12] [Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools](https://arxiv.org/abs/2511.21197)
*Paolo Buono,Mary Cerullo,Stefano Cirillo,Giuseppe Desolda,Francesco Greco,Emanuela Guglielmi,Grazia Margarella,Giuseppe Polese,Simone Scalabrino,Cesare Tucci*

Main category: cs.SE

TL;DR: 研究发现开发者对AI检测和可读性工具有不同心理预期，信任和采纳取决于工具的透明度、解释和控制性，提出了IDE中以人为本AI设计原则以改善体验。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助工具在技术方面不断进步，但关于开发者如何建立对这些工具的心理模型，以及这些心理模型不匹配如何影响信任、控制和采纳，仍然知之甚少。

Method: 通过六场共同设计研讨会，邀请了58名开发者参与，旨在收集他们对于AI辅助的bug检测和代码可读性评估工具的心理模型。

Result: 开发者将bug检测工具看作“bug侦探”，期望其仅在有严重问题时发出警告，并能保证透明度、可行动反馈与信心提示。可读性评估工具则被视为“质量教练”，应能提供情境化、个性化且渐进的指导。对于两种任务，信任建立依赖于解释的清晰度、反馈时机和用户控制度。论文还总结了在IDE中实现以人为中心的AI的设计原则，强调在扰动与支持、简明与深度、自动化与人为主导之间的平衡。

Conclusion: 理解和匹配开发者的心理模型对于提升AI辅助工具在IDE中的信任、控制和采纳至关重要，需在设计中加入以人为中心的原则。

Abstract: AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.

</details>


### [13] [Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions](https://arxiv.org/abs/2511.21380)
*Jingyi Chen,Xiaoyan Guo,Songqiang Chen,Shing-Chi Cheung,Jiasi Shen*

Main category: cs.SE

TL;DR: 本文首次实证分析了最先进的LLM多智能体系统在软件工程数据集适配中的表现，发现其可部分完成任务，但依赖有效反馈才能取得显著提升，提示未来需关注智能体的自纠错与反馈机制。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程中的研究成果需要在不同的数据集上迁移才能实现可扩展性和可复现性，但自动化完成这一过程仍然鲜有研究。随着基于大语言模型（LLM）的多智能体系统崛起，如GitHub Copilot的agent模式，有望自动化复杂的数据集适配任务，因此亟需对其进行实证评估。

Method: 论文对当前最先进的多智能体系统（以GPT-4.1和Claude Sonnet 4为后端的Copilot）在适配ROCODE和LogHub2.0等基准库中的软件工程研究工件时的表现进行实证分析。评估流程分为五个阶段：文件理解、代码编辑、命令生成、验证和最终执行。同时，研究通过干预提示（如提供错误信息和参考代码）来增强系统性能。

Result: 多智能体系统能够识别关键文件并生成部分有效的适配代码，但很少能完全生成功能性正确的实现。当引入执行错误信息和参考代码作为提示时，适配结果与真实实现的结构相似率由7.25%提升至67.14%。

Conclusion: 当前基于LLM的多智能体系统在数据集适配任务中展现出一定潜力，依赖于上下文和反馈驱动的引导能显著提升表现，但仍存在无法完全自动生成功能正确实现的局限性。为实现更可靠、具备自纠错能力的智能体，未来需在提示和反馈机制上进一步优化。

Abstract: Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.

</details>


### [14] [Large Language Models for Unit Test Generation: Achievements, Challenges, and the Road Ahead](https://arxiv.org/abs/2511.21382)
*Bei Chu,Yang Feng,Kui Liu,Zifan Nan,Zhaoqiang Guo,Baowen Xu*

Main category: cs.SE

TL;DR: 本综述系统总结了近年来LLM用于单元测试生成的方法与挑战，发现提示工程和迭代修复是核心趋势，但错误检测能力和评测标准不足。未来建议结合传统工具，发展自动化与智能化测试方案。


<details>
  <summary>Details</summary>
Motivation: 单元测试是验证软件和减少回归风险的重要手段，但自动化测试生成工具往往缺少语义信息，难以生成真实的输入和断言。大语言模型因其对代码语义和编程模式的理解，为提升自动化单元测试带来新机遇。

Method: 本文通过系统性文献综述，梳理了2021年5月至2025年8月期间115篇相关研究。提出了基于测试生成生命周期的新分类法，将LLM视为概率生成器，并从生成策略、上下文强化到质量保障等方面对文献进行分析。

Result: 研究发现，提示工程成为主流方法，占比89%；通过迭代验证和修复循环，提升了测试用例的编译和执行通过率。但自动生成测试的错误检测能力薄弱，缺乏统一评测基准，仍是主要挑战。

Conclusion: LLM在单元测试生成领域展现巨大潜力，但仍需解决错误检测和评估标准等关键问题。文末提出以自主测试智能体和与传统技术结合为核心的未来研究方向。

Abstract: Unit testing is an essential yet laborious technique for verifying software and mitigating regression risks. Although classic automated methods effectively explore program structures, they often lack the semantic information required to produce realistic inputs and assertions. Large Language Models (LLMs) address this limitation by utilizing by leveraging their data-driven knowledge of code semantics and programming patterns. To analyze the state of the art in this domain, we conducted a systematic literature review of 115 publications published between May 2021 and August 2025. We propose a unified taxonomy based on the unit test generation lifecycle that treats LLMs as stochastic generators requiring systematic engineering constraints. This framework analyzes the literature regarding core generative strategies and a set of enhancement techniques ranging from pre-generation context enrichment to post-generation quality assurance. Our analysis reveals that prompt engineering has emerged as the dominant utilization strategy and accounts for 89% of the studies due to its flexibility. We find that iterative validation and repair loops have become the standard mechanism to ensure robust usability and lead to significant improvements in compilation and execution pass rates. However, critical challenges remain regarding the weak fault detection capabilities of generated tests and the lack of standardized evaluation benchmarks. We conclude with a roadmap for future research that emphasizes the progression towards autonomous testing agents and hybrid systems combining LLMs with traditional software engineering tools. This survey provides researchers and practitioners with a comprehensive perspective on converting the potential of LLMs into industrial-grade testing solutions.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [Coco: Corecursion with Compositional Heterogeneous Productivity](https://arxiv.org/abs/2511.21093)
*Jaewoo Kim,Yeonwoo Nam,Chung-Kil Hur*

Main category: cs.LO

TL;DR: 本文提出了CHP理论框架和Coco共递归库，有效扩大并自动化了对共递归函数的支持，弥补了以往方法覆盖与自动化的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有证明助手对递归定义施加了严格的语法限制，因而会拒绝许多本质上是合法的共递归定义。如何在保证自动化程度的同时，扩大对递归定义的覆盖范围是一个难题，现有方法往往在这两者之间做权衡。

Method: 提出了一套称为Compositional Heterogeneous Productivity（CHP）的理论框架，该框架将高度自动化与广泛的递归定义覆盖结合起来。CHP允许异构生产力，适用于各种不同类型域与值域的函数，包括非余归纳类型。其核心创新是复合性，即可以通过组件系统地推导复合函数的生产力，实现对复杂共递归模式的模块化推理。基于CHP开发了Coco，一个为Rocq提供的共递归库，用于自动化计算生产力和生成不动点。

Result: CHP框架实现了自动化与覆盖范围的统一，可对复杂和多样的共递归函数实现模块化、自动化的生产力分析。Coco库进一步为Rocq系统提供自动化工具，简化用户的递归定义和相关证明工作。

Conclusion: CHP框架及Coco库有效突破了现有证明助手的限制，显著提升了递归定义的灵活性和自动化水平，并为共递归理论和工具的发展提供了有力支持。

Abstract: Contemporary proof assistants impose restrictive syntactic guardedness conditions that reject many valid corecursive definitions. Existing approaches to overcome these restrictions present a fundamental trade-off between coverage and automation.
  We present Compositional Heterogeneous Productivity (CHP), a theoretical framework that unifies high automation with extensive coverage for corecursive definitions. CHP introduces heterogeneous productivity applicable to functions with diverse domain and codomain types, including non-coinductive types. Its key innovation is compositionality: the productivity of composite functions is systematically computed from their components, enabling modular reasoning about complex corecursive patterns.
  Building on CHP, we develop Coco, a corecursion library for Rocq that provides extensive automation for productivity computation and fixed-point generation.

</details>


### [16] [Common Knowledge, Sailboats, and Publicity](https://arxiv.org/abs/2511.21261)
*Sena Bozdag,Olivier Roy*

Main category: cs.LO

TL;DR: 本文重新审视共同知识中的“帆船案”，提出Lewisian共同知识理论更能解释某些事件为何直观上是“公共”的，补足了经典定义的不足，并提供了哲学和形式化论证支撑。


<details>
  <summary>Details</summary>
Motivation: 面对“帆船”案例，传统迭代式共同知识理论与直观认为的“公共事实”有矛盾：某些事实被视为公共，却不符合经典共同知识定义。作者动机在于寻求理论基础，解释这种直观公共性。

Method: 首先通过非形式化方式澄清主张的哲学立场，然后在认知-似然模型中给出形式化刻画。

Result: 哲学与形式化分析均表明Lewisian共同知识理论能够统一解释作为“公共”事件的条件，其合理性得到进一步证据支持。

Conclusion: Lewisian common knowledge能够提供对'公共性'事件的合理描述，并能解决“帆船”案例中关于事实何为“公共”的争议。

Abstract: We revisit a recent puzzle about common knowledge, the ``sailboat" case (Lederman, 2018), and argue that Lewisian common knowledge allows us to reconcile the pre-theoretical intuition that certain facts are ``public" in such situations, while these facts cannot be common knowledge in the classical, iterative sense. The crux of the argument is to understand Lewisian common knowledge as an account of what it means for an event to be public. We first formulate this argument informally to clarify its philosophical commitment and then propose one way to capture it formally in epistemic-plausibility models. Taken together, we take the philosophical and the formal arguments as providing evidence that Lewisian common knowledge is a plausible account of what it means for an event to be public.

</details>


### [17] [Bifurcation Logic: Separation Through Ordering](https://arxiv.org/abs/2511.21263)
*Didier Galmiche,Timo Lang,Daniel Méry,David Pym*

Main category: cs.LO

TL;DR: BL逻辑结合了模态特性与分支结构分离合取，部分条件下可判定，适用于多智能体访问控制建模等应用领域。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在提出并研究一种新的逻辑系统Bifurcation Logic（BL），通过结合模态逻辑与分离合取（separating conjunction），以更精准地刻画某些分支结构下的命题关系，特别适用于描述不同分支间无交集的情形。

Method: 作者提出了BL逻辑，在定义其语义的基础上，给出了标记化表格演算方法，并证明了其相对于关系语义的可靠性（正确性）与完备性。同时，对其有限模型属性进行分析，并在有限制时（无乘法蕴涵时）证明了等价有限表达及判定性。最后，通过多智能体访问控制的例子展示其应用潜力。

Result: 论文表明，BL逻辑在引入*操作时，每个模型都存在等价的有限表示，从而保证了判定性。作者还证明了带有乘法蕴涵时标准有限模型性质不成立。此外，其提出的标记表格演算是可靠且完备的。

Conclusion: BL逻辑成功融合了经典模态逻辑与分支结构的分离合取，并具备较强的表达能力。虽然有限模型属性并非总是成立，但部分情境下判定性得以保持，可应用于多智能体访问控制等场景。

Abstract: We introduce Bifurcation Logic, BL, which combines a basic classical modality with separating conjunction * together with its naturally associated multiplicative implication, that is defined using the modal ordering. Specifically, a formula A*B is true at a world w if and only if each of A,B holds at worlds that are each above w, on separate branches of the order, and have no common upper bound. We provide a labelled tableaux calculus for BL and establish soundness and completeness relative to its relational semantics. The standard finite model property fails for BL. However, we show that, in the absence of multiplicative implication, but in the presence of *, every model has an equivalent finite representation and that this is sufficient to obtain decidability. We illustrate the use of BL through an example of modelling multi-agent access control that is quite generic in its form, suggesting many applications.

</details>


### [18] [Two behavioural pseudometrics for continuous-time Markov processes](https://arxiv.org/abs/2511.21621)
*Linan Chen,Florence Clerc,Prakash Panangaden*

Main category: cs.LO

TL;DR: 本研究扩展了离散到连续时间马尔科夫过程的行为伪度量理论，提出了两种度量方法，并比较了它们的特点，为分析扩散类系统状态间的行为相似性提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 研究状态在不同类型跃迁系统中的行为等价性，并解决连续时间马尔科夫过程中行为度量难题。此前的研究在离散时间系统上取得进展，但在连续时间系统（如扩散过程和跳跃扩散）上缺乏有效的度量方法。

Method: 论文通过两种方法构造行为伪度量：1）基于函数型迭代法，2）基于实值逻辑法。两种方法在连续时间马尔科夫过程中应用，并证明了两者得到的伪度量是一致的。此外，本文在前人工作的基础上进一步提出基于轨迹的新型伪度量，并同样用上述两种方法进行分析和比较。

Result: 构造了两种适用于连续时间马尔科夫过程（如扩散过程）的行为伪度量，并证明了它们从函数型和逻辑型视角得到的一致性。此外，提出了基于轨迹的新伪度量，并与之前的度量进行比较，丰富了连续时间行为等价分析的工具。

Conclusion: 本文扩展了行为等价与度量理论到连续时间马尔科夫过程，提出了两种有效的行为伪度量（其中一个基于轨迹），为连续时间系统的行为比较和分析提供了理论支持，并揭示了不同度量间的联系与差异。

Abstract: Bisimulation is a concept that captures behavioural equivalence of states in a variety of types of transition systems. It has been widely studied in discrete-time settings where a key notion is the bisimulation metric which quantifies "how similar two states are". In [ 11], we generalized the concept of bisimulation metric in order to metrize the behaviour of continuous-time Markov processes. Similarly to the discrete-time case, we constructed a pseudometric following two iterative approaches - through a functional and through a real-valued logic, and showed that the outcomes coincide: the pseudometric obtained from the logic is a specific fixpoint of the functional which yields our first pseudometric. However, different from the discrete-time setting, in which the process has a step-by-step dynamics, the behavioural pseudometric we constructed applies to Markov processes that evolve continuously through time, such as diffusions and jump diffusions. While our treatment of the pseudometric in [11] relied on the time-indexed Markov kernels, in [ 8 , 9, 10 ], we showed the importance of trajectories in the consideration of behavioural equivalences for true continuous-time Markov processes. In this paper, we take the work from [11 ] further and propose a second behavioural pseudometric for diffusions based on trajectories. We conduct a similar study of this pseudometric from both the perspective of a functional and the viewpoint of a real-valued logic. We also compare this pseudometric with the first pseudometric obtained in [11].

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Democratizing LLM Efficiency: From Hyperscale Optimizations to Universal Deployability](https://arxiv.org/abs/2511.20662)
*Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 本文批评当前高效LLM技术对资源弱势群体不友好，主张以简单、健壮、可负担的高效方法实现技术普及，提出新的研究路线和评估标准以实现公平与可持续发展。


<details>
  <summary>Details</summary>
Motivation: 现有高效方法对大多数资源有限的组织（如医院、学校等）不适用，导致技术壁垒、碳排浪费和社会不公平。作者希望通过更简单高效的方法推翻这一局限。

Method: 提出新的研究方向，包括无须再训练的模型架构改造、轻量级微调策略、高效推理、无需复杂RAG的数据管理，以及将“可承受开销”纳入效率标准。

Result: 呼吁构建可支持更广泛实际部署（低资源和低专业要求）的高效LLM方法，并重塑效率评价体系，使其兼顾应用成本、可持续性与公平性，推动LLM技术普惠化。

Conclusion: 高效的大型语言模型（LLMs）方法（如MoE、speculative decoding和复杂RAG）主要造福于大型科技公司，却因需要庞大资源和专业团队，在普通组织内反受制约。作者提倡将效率目标转向健壮且简单的技术，以便更广泛的实际部署和公平性。

Abstract: Large language models (LLMs) have become indispensable, but the most celebrated efficiency methods -- mixture-of-experts (MoE), speculative decoding, and complex retrieval-augmented generation (RAG) -- were built for hyperscale providers with vast infrastructure and elite teams. Outside that context, their benefits collapse into overhead, fragility, and wasted carbon. The result is that a handful of Big Tech companies benefit, while thousands of hospitals, schools, governments, and enterprises are left without viable options. We argue that the next frontier is not greater sophistication at scale, but robust simplicity: efficiency that thrives under modest resources and minimal expertise. We propose a new research agenda: retrofitting pretrained models with more efficient architectures without retraining, inventing lightweight fine-tuning that preserves alignment, making reasoning economical despite long chains of thought, enabling dynamic knowledge management without heavy RAG pipelines, and adopting Overhead-Aware Efficiency (OAE) as a standard benchmark. By redefining efficiency to include adoption cost, sustainability, and fairness, we can democratize LLM deployment -- ensuring that optimization reduces inequality and carbon waste rather than amplifying them.

</details>


### [20] [Harmonic Token Projection (HTP): A Vocabulary-Free, Training-Free, Deterministic, and Reversible Embedding Methodology](https://arxiv.org/abs/2511.20665)
*Tcharlies Schmitz*

Main category: cs.CL

TL;DR: 提出无需训练、可逆且高效的Harmonic Token Projection文本嵌入方法，性能稳定且具良好语义能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流文本嵌入方法依赖统计、数据训练和大规模参数，效率较低且缺乏可解释性。因此，设计一种无需训练、可逆、确定性的文本嵌入方法具有重要意义。

Method: 提出Harmonic Token Projection (HTP)：用每个token的Unicode整数分析获得谐波轨迹，实现了符号与连续向量空间的可逆、解释性映射，无需词表、训练或随机参数。

Result: HTP在STS-B及其多语种扩展集上测试，英文Spearman相关系数达0.68，各语种表现稳定，计算代价极小，句对处理延迟亚毫秒。

Conclusion: HTP表明，语义关系可由确定性几何结构涌现，为数据驱动嵌入（如神经网络）提供透明高效的替代方法。

Abstract: This paper introduces the Harmonic Token Projection (HTP), a reversible and deterministic framework for generating text embeddings without training, vocabularies, or stochastic parameters. Unlike neural embeddings that rely on statistical co-occurrence or optimization, HTP encodes each token analytically as a harmonic trajectory derived from its Unicode integer representation, establishing a bijective and interpretable mapping between discrete symbols and continuous vector space. The harmonic formulation provides phase-coherent projections that preserve both structure and reversibility, enabling semantic similarity estimation from purely geometric alignment. Experimental evaluation on the Semantic Textual Similarity Benchmark (STS-B) and its multilingual extension shows that HTP achieves a Spearman correlation of \r{ho} = 0.68 in English, maintaining stable performance across ten languages with negligible computational cost and sub-millisecond latency per sentence pair. This demonstrates that meaningful semantic relations can emerge from deterministic geometry, offering a transparent and efficient alternative to data-driven embeddings. Keywords: Harmonic Token Projection, reversible embedding, deterministic encoding, semantic similarity, multilingual representation.

</details>


### [21] [A centroid based framework for text classification in itsm environments](https://arxiv.org/abs/2511.20667)
*Hossein Mohanna,Ali Ait-Bachir*

Main category: cs.CL

TL;DR: 提出一种用于IT工单分类的高效且可解释的双重嵌入质心分类方法，在分层F1分数上与传统方法相当但训练和更新速度远快于传统方法，非常适用于实际生产系统。


<details>
  <summary>Details</summary>
Motivation: 在IT服务管理（ITSM）系统中，分类支持工单时，需要处理基于树状层级结构的分类体系，现有方法在解释性和效率方面存在不足。

Method: 提出一种基于双重嵌入的质心分类框架，分别为每个类别维护语义和词汇的质心表示，并在推断时通过互惠排序融合两者。

Result: 该方法在8,968条工单、123个类别的数据集上进行评估，分层F1分数为0.731（与支持向量机的0.727相当），训练速度快5.9倍，增量更新速度快152倍，批量（100-1000样本）排除嵌入计算后有8.6-8.8倍加速。

Conclusion: 该方法兼具性能、解释性和高效率，非常适合优先考虑可解释性与运营效率的ITSM生产环境。

Abstract: Text classification with hierarchical taxonomies is a fundamental requirement in IT Service Management (ITSM) systems, where support tickets must be categorized into tree-structured taxonomies. We present a dual-embedding centroid-based classification framework that maintains separate semantic and lexical centroid representations per category, combining them through reciprocal rank fusion at inference time. The framework achieves performance competitive with Support Vector Machines (hierarchical F1: 0.731 vs 0.727) while providing interpretability through centroid representations. Evaluated on 8,968 ITSM tickets across 123 categories, this method achieves 5.9 times faster training and up to 152 times faster incremental updates. With 8.6-8.8 times speedup across batch sizes (100-1000 samples) when excluding embedding computation. These results make the method suitable for production ITSM environments prioritizing interpretability and operational efficiency.

</details>


### [22] [PIRA: Preference-Oriented Instruction-Tuned Reward Models with Dual Aggregation](https://arxiv.org/abs/2511.20668)
*Yongfu Xue*

Main category: cs.CL

TL;DR: 传统奖励模型面临数据利用率低、奖励过优化两大难题。PIRA通过偏好指令、任务聚合和输出均值策略，有效提升了奖励模型性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 奖励模型在对齐大型语言模型与人类偏好时，存在数据效率低和易受奖励过优化影响的问题。

Method: 提出了PIRA训练范式，包括三点：将问答对改写为偏好指令、聚合多样化偏好任务的奖励、对不同dropout率下的value-head输出取均值。

Result: 通过大量实验，PIRA在奖励模型的有效性和稳健性方面表现突出。

Conclusion: PIRA可有效提升奖励模型的数据效率和稳健性，从而更好地对齐LLM与人类偏好。

Abstract: Reward models are crucial for aligning Large Language Models (LLMs) with human preferences but face two representative challenges. First, traditional discriminative reward models usually concatenate questions and responses directly as input, resulting in low data efficiency. Second, reward models are vulnerable to reward overoptimization. We propose PIRA, a training paradigm addressing these issues through three strategies: (1) Reformulating question-answer pairs into preference-based instructions for clearer and more explicit task specification, (2) aggregating rewards from diverse preference tasks to reduce bias and improve robustness, and (3) averaging value-head outputs under varying dropout rates to stabilize rewards. Extensive experiments have demonstrated the effectiveness of PIRA.

</details>


### [23] [Structured Definitions and Segmentations for Legal Reasoning in LLMs: A Study on Indian Legal Data](https://arxiv.org/abs/2511.20669)
*Mann Khatri,Mirza Yusuf,Rajiv Ratn Shah,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: 通过结构化法律文本和术语说明，即使在零样本设定下，也可显著增强大语言模型在法律判决预测任务中的表现，最高可提升F1分数4.36%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型因缺乏法律领域特定预训练，在处理法律相关任务时表现欠佳，特别是面对冗长且复杂的法律文件时，现有模型很难高效处理完整文本及进行准确判断。该领域亟需探索提升模型专业能力的新方法。

Method: 作者通过三个实验：（1）重组法律文件以突出修辞结构，分析结构化信息对模型理解长文本的影响；（2）定义并向模型介绍法律修辞角色，提升其对法律术语的理解；（3）模拟法庭对修辞角色的推理过程，增强模型的推理能力。这些实验均在零样本设置下，于印度三个法律判决数据集上进行。

Result: 数据组织或解释关键法律术语均能显著提升模型表现，F1分数相比基线最低提升1.5%，最高提升4.36%。

Conclusion: 采用结构化信息和术语解释的方法，可以有效提升大语言模型应用于法律判决预测等专业场景的能力，即便在无领域特定预训练的情况下亦能获得明显性能提升。

Abstract: Large Language Models (LLMs), trained on extensive datasets from the web, exhibit remarkable general reasoning skills. Despite this, they often struggle in specialized areas like law, mainly because they lack domain-specific pretraining. The legal field presents unique challenges, as legal documents are generally long and intricate, making it hard for models to process the full text efficiently. Previous studies have examined in-context approaches to address the knowledge gap, boosting model performance in new domains without full domain alignment. In our paper, we analyze model behavior on legal tasks by conducting experiments in three areas: (i) reorganizing documents based on rhetorical roles to assess how structured information affects long context processing and model decisions, (ii) defining rhetorical roles to familiarize the model with legal terminology, and (iii) emulating the step-by-step reasoning of courts regarding rhetorical roles to enhance model reasoning. These experiments are conducted in a zero-shot setting across three Indian legal judgment prediction datasets. Our results reveal that organizing data or explaining key legal terms significantly boosts model performance, with a minimum increase of ~1.5% and a maximum improvement of 4.36% in F1 score compared to the baseline.

</details>


### [24] [MindSET: Advancing Mental Health Benchmarking through Large-Scale Social Media Data](https://arxiv.org/abs/2511.20672)
*Saad Mankarious,Ayah Zirikly,Daniel Wiechmann,Elma Kerz,Edward Kempa,Yu Qiao*

Main category: cs.CL

TL;DR: 本论文构建了大规模、经过严格清洗的心理健康社交媒体数据集MindSET，并验证了其在多个任务上的优越性，将有力支持心理健康与社交媒体领域的深入研究。


<details>
  <summary>Details</summary>
Motivation: 现有的心理健康社交媒体数据集由于数据有限、清洗不足以及内容多样（如多语言、有害内容等），已经不能很好地满足当前研究需求。

Method: 作者构建了新的基准数据集MindSET，从Reddit上收集带有自述诊断的帖子，经过严格的预处理（如语言过滤、去除NSFW和重复内容），并使用LIWC工具分析心理学术语频率。随后，利用该数据集进行了诊断检测的二元分类实验，采用的是微调的语言模型和词袋（BoW）特征。

Result: 与以往数据集相比，基于MindSET训练的模型表现更优，在不同心理健康状态检测任务上有明显提升，比如自闭症检测的F1分最高提升了18个百分点。

Conclusion: MindSET大大丰富了心理健康社交媒体数据，为风险早期检测及心理趋势分析提供了坚实基础。

Abstract: Social media data has become a vital resource for studying mental health, offering real-time insights into thoughts, emotions, and behaviors that traditional methods often miss. Progress in this area has been facilitated by benchmark datasets for mental health analysis; however, most existing benchmarks have become outdated due to limited data availability, inadequate cleaning, and the inherently diverse nature of social media content (e.g., multilingual and harmful material). We present a new benchmark dataset, \textbf{MindSET}, curated from Reddit using self-reported diagnoses to address these limitations. The annotated dataset contains over \textbf{13M} annotated posts across seven mental health conditions, more than twice the size of previous benchmarks. To ensure data quality, we applied rigorous preprocessing steps, including language filtering, and removal of Not Safe for Work (NSFW) and duplicate content. We further performed a linguistic analysis using LIWC to examine psychological term frequencies across the eight groups represented in the dataset. To demonstrate the dataset utility, we conducted binary classification experiments for diagnosis detection using both fine-tuned language models and Bag-of-Words (BoW) features. Models trained on MindSET consistently outperformed those trained on previous benchmarks, achieving up to an \textbf{18-point} improvement in F1 for Autism detection. Overall, MindSET provides a robust foundation for researchers exploring the intersection of social media and mental health, supporting both early risk detection and deeper analysis of emerging psychological trends.

</details>


### [25] [Semantics Meet Signals: Dual Codebook Representationl Learning for Generative Recommendation](https://arxiv.org/abs/2511.20673)
*Zheng Hui,Xiaokai Wei,Reza Shirkavand,Chen Wang,Weizhi Zhang,Alejandro Peláez,Michelle Gong*

Main category: cs.CL

TL;DR: 本文提出FlexCode：一种兼顾商品流行度的token分配方法，有效提升生成式推荐系统的准确性与长尾商品的推荐能力。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐系统通常采用统一的编码方式处理所有商品，没有考虑热门商品与长尾商品在协同信号和语义理解上的差异，导致表示效率受限、泛化能力不足。

Method: 提出了FlexCode框架，根据商品的受欢迎程度，在协同过滤（CF）码本和语义码本之间动态分配有限的token预算，并通过轻量级MoE结构动态平衡CF精度与语义泛化，同时引入对齐和平滑目标确保不同受欢迎度商品的表示一致性。

Result: 在公开和工业级数据集上的实验表明，FlexCode在推荐准确率和长尾商品鲁棒性方面均优于强基线方法。

Conclusion: FlexCode为生成式推荐系统中的token表达提供了新的机制，在增强准确性的同时提升了长尾鲁棒性，并为记忆-泛化平衡问题提供了新视角。

Abstract: Generative recommendation has recently emerged as a powerful paradigm that unifies retrieval and generation, representing items as discrete semantic tokens and enabling flexible sequence modeling with autoregressive models. Despite its success, existing approaches rely on a single, uniform codebook to encode all items, overlooking the inherent imbalance between popular items rich in collaborative signals and long-tail items that depend on semantic understanding. We argue that this uniform treatment limits representational efficiency and hinders generalization. To address this, we introduce FlexCode, a popularity-aware framework that adaptively allocates a fixed token budget between a collaborative filtering (CF) codebook and a semantic codebook. A lightweight MoE dynamically balances CF-specific precision and semantic generalization, while an alignment and smoothness objective maintains coherence across the popularity spectrum. We perform experiments on both public and industrial-scale datasets, showing that FlexCode consistently outperform strong baselines. FlexCode provides a new mechanism for token representation in generative recommenders, achieving stronger accuracy and tail robustness, and offering a new perspective on balancing memorization and generalization in token-based recommendation models.

</details>


### [26] [Prompt Engineering Techniques for Context-dependent Text-to-SQL in Arabic](https://arxiv.org/abs/2511.20677)
*Saleh Almohaimeed,May Alsofyani,Saad Almohaimeed,Mansour Al Ghanim,Liqiang Wang*

Main category: cs.CL

TL;DR: 该论文填补了阿拉伯语text-to-SQL的研究空白，构建了大规模阿拉伯语数据集Ar-SParC。使用大语言模型及多种提示工程技术并提出GAT corrector方法，显著提升任务准确率，为阿拉伯语及多语言text-to-SQL研究提供了坚实基础。


<details>
  <summary>Details</summary>
Motivation: 目前大部分跨领域、上下文相关的text-to-SQL研究及数据集集中于英语，少部分涉及中文，但尚无阿拉伯语相关工作。该研究旨在填补阿拉伯语text-to-SQL领域的空白，推动该领域多语言发展。

Method: 作者构建了首个阿拉伯语跨领域、上下文相关text-to-SQL数据集Ar-SParC，包含3450组问题序列，总计10225个问答及SQL。实验采用GPT-3.5-turbo和GPT-4.5-turbo模型，结合10种提示工程技术（包括4种问题表达法和6种上下文学习技巧），并提出新方法GAT corrector进行提升。最后通过消融实验分析GAT corrector的有效性。

Result: GAT corrector方法在40组实验中均提升了模型性能，在Zero-shot下执行和交互准确率各提升约1.9%；在in-context学习下分别提升1.72%（执行）和0.92%（交互）。消融实验表明GAT corrector在阿拉伯语表现优于旧版GAT verifier。

Conclusion: 该研究首次构建了阿拉伯语跨领域、上下文相关text-to-SQL标准数据集；验证了GAT corrector方法对提升阿拉伯语text-to-SQL任务模型性能的有效性，展示了通过多种提示工程技术和创新方法可实现准确率的提升。

Abstract: In recent years, the task of cross-domain, context-dependent text-to-SQL has received significant attention. Enables users with no prior knowledge of SQL to have a conversation with databases using natural language. However, most of the available datasets and research have been conducted in English, along with some work in Chinese. To this date, no effort has been made to address this task in the Arabic language. In this paper, we introduce Ar-SParC, the first Arabic cross-domain, context-dependent text-to-SQL dataset. The dataset consists of 3,450 sequences of interrelated questions, each sequence containing an average of approximately three questions, which results in a total of 10225 questions along with their corresponding SQL queries. We conducted 40 experiments on the Ar-SParC dataset using two large language models, GPT-3.5-turbo and GPT-4.5-turbo, applying 10 different prompt engineering techniques, including four question representation methods and six in-context learning techniques. Furthermore, we developed a novel approach named GAT corrector, which enhanced the performance across all 40 experiments, yielding an average improvement of 1.9% in execution accuracy (EX) and 1.9% in interaction accuracy (IX) under zero-shot settings, and an average increase of 1.72% EX and 0.92% IX under in-context learning settings. Finally, we conducted an ablation study with two more experiments to explain why the GAT corrector outperformed the previous GAT verifier technique, particularly for the Arabic language.

</details>


### [27] [Cognitive bias in LLM reasoning compromises interpretation of clinical oncology notes](https://arxiv.org/abs/2511.20680)
*Matthew W. Kenaston,Umair Ayub,Mihir Parmar,Muhammad Umair Anjum,Syed Arsalan Ahmed Naqvi,Priya Kumar,Samarth Rawal,Aadel A. Chaudhuri,Yousef Zakharia,Elizabeth I. Heath,Tanios S. Bekaii-Saab,Cui Tao,Eliezer M. Van Allen,Ben Zhou,YooJung Choi,Chitta Baral,Irbaz Bin Riaz*

Main category: cs.CL

TL;DR: 本研究建立了适用于大型语言模型的推理错误分类体系，通过真实肿瘤学临床笔记检验其有效性，发现约23%的模型推理存在认知偏见等错误，并可导致临床危险推荐。自动化工具虽能检测错误存在，但难以细致识别类型，强化了临床应用前加强推理质量评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在临床基准测试中表现优异，但它们可能通过错误的推理过程得出正确结论，仅依靠准确率评估难以发现这些推理缺陷。尤其在肿瘤学决策支持中，这种失效模式可能导致安全隐患。研究动机在于揭示和处理大模型推理错误的临床相关性，提高其部署的安全性。

Method: 本研究为回顾性两队列设计：首先利用CORAL数据集中的乳腺癌和胰腺癌临床记录，对GPT-4链式推理结果进行600条注释，开发三级推理错误分类体系（将计算失误映射至认知偏见框架）。随后将该分类体系应用于822条前列腺癌临床记录的模型推理结果，评估其在模拟信息提取、分析及推荐任务中的表现，并分析推理错误类型与临床指导一致性的关系。还测试了自动化评估器发现推理错误的能力。

Result: 推理错误在模型解释中发生率为23%，且占总错误数的主要部分，主要表现为确认偏见和锚定偏见。在疾病进展阶段，推理失败与不符临床指南甚至有潜在危害性的推荐显著相关。自动化评估器可检测错误存在，但难以区分具体错误类型。

Conclusion: 大型语言模型即使表达流畅，推理过程可能存在严重临床安全隐患。建立的推理错误分类体系为未来模型推理质量评估和改进提供了通用方法，对临床部署前的安全保障具有重要意义。

Abstract: Despite high performance on clinical benchmarks, large language models may reach correct conclusions through faulty reasoning, a failure mode with safety implications for oncology decision support that is not captured by accuracy-based evaluation. In this two-cohort retrospective study, we developed a hierarchical taxonomy of reasoning errors from GPT-4 chain-of-thought responses to real oncology notes and tested its clinical relevance. Using breast and pancreatic cancer notes from the CORAL dataset, we annotated 600 reasoning traces to define a three-tier taxonomy mapping computational failures to cognitive bias frameworks. We validated the taxonomy on 822 responses from prostate cancer consult notes spanning localized through metastatic disease, simulating extraction, analysis, and clinical recommendation tasks. Reasoning errors occurred in 23 percent of interpretations and dominated overall errors, with confirmation bias and anchoring bias most common. Reasoning failures were associated with guideline-discordant and potentially harmful recommendations, particularly in advanced disease management. Automated evaluators using state-of-the-art language models detected error presence but could not reliably classify subtypes. These findings show that large language models may provide fluent but clinically unsafe recommendations when reasoning is flawed. The taxonomy provides a generalizable framework for evaluating and improving reasoning fidelity before clinical deployment.

</details>


### [28] [Dynamic Template Selection for Output Token Generation Optimization: MLP-Based and Transformer Approaches](https://arxiv.org/abs/2511.20683)
*Bharadwaj Yadavalli*

Main category: cs.CL

TL;DR: 现有大型语言模型统一回复策略造成大量token浪费，输出token成本极高。作者提出动态模板选择方法，根据问题复杂度选用合适回复模板，并实验对比了MLP与RoBERTa两种路由策略。MLP不仅准确率高于RoBERTa，且参数更少，节约token成本达33%左右，且在三大主流LLM平台均验证有效。这种方法显著优化了模型调用经济性。


<details>
  <summary>Details</summary>
Motivation: 当前，大型语言模型在实际部署时常采用统一的提示策略，无论面对复杂分析任务还是简单事实问题，都使用冗长的回应模式。这种“一刀切”方法导致生成回复时的token效率低下，尤其是在输出token成本远高于输入token（高达4-8倍）的大型模型服务商里产生了巨大开销。因此，亟需一种能够依据查询复杂度智能调整回复模板的方法，实现成本优化。

Method: 提出了动态模板选择(DTS)方法。DTS能够根据查询复杂度自适应选择不同回复模板。为此，作者设计了两种路由策略：一种是基于预计算embedding的简易MLP模型，另一种是参数更大的微调版RoBERTa变换器。通过在大规模多样化数据集（如MMLU）上进行评估比较。

Result: 在1000个MMLU问题的测试中，MLP路由器在未见测试数据上的路由准确率达90.5%，略高于RoBERTa（89.5%），且参数少1.25亿。模板路由决策能够很好地在OpenAI GPT-4、Google Gemini、Anthropic Claude三大主流服务商间迁移泛化（支持9000次实际API调用验证）。不同平台上的token节约率在32.6%到33.9%之间。

Conclusion: 动态响应模板选择不仅不影响回答质量，还显著降低了token消耗和成本，且算法具备高效路由准确率及跨平台泛化能力。论文进一步给出了机器学习理论分析、四种算法及复杂度分析，并在真实生产环境下充分验证。

Abstract: Contemporary large language model deployments typically employ uniform prompting strategies across diverse query types, applying verbose response patterns to both complex analytical tasks and straightforward factual questions. This one-size-fits-all methodology leads to substantial token inefficiency, a concern amplified by the significant cost differential between input and output tokens--the latter commanding 4-8x higher prices across major providers. We present Dynamic Template Selection (DTS), which adaptively matches response templates to query complexity, achieving significant cost reductions without compromising response quality.
  We compared two routing approaches: a simple MLP that uses pre-computed embeddings and a more complex fine-tuned RoBERTa transformer. Through comprehensive evaluation on 1,000 MMLU questions, we find that the MLP router achieves 90.5% routing accuracy on held-out test data, marginally exceeding RoBERTa's performance (89.5%) despite utilizing 125M fewer parameters. Notably, our empirical analysis reveals provider-agnostic behavior in template selection--routing decisions generalize effectively across 3 major LLM providers (OpenAI GPT-4, Google Gemini, and Anthropic Claude), as validated through 9,000 production API calls. While routing accuracy remains consistent at 90.5% across providers, observed token reductions vary from 32.6% to 33.9%, reflecting provider-specific generation characteristics.
  This work contributes several key elements: formal problem formulation with theoretical grounding in machine learning, four algorithms with corresponding complexity analyses, and extensive empirical validation across production systems.

</details>


### [29] [LLMs-Powered Accurate Extraction, Querying and Intelligent Management of Literature derived 2D Materials Data](https://arxiv.org/abs/2511.20691)
*Lijun Shang,Yadong Yu,Wenqiang Kang,Jian Zhou,Dongyue Gao,Pan Xiang,Zhe Liu,Mengyan Dai,Zhonglu Guo,Zhimei Sun*

Main category: cs.CL

TL;DR: 本文分析众多文献中二维材料的性质与制备信息，系统整合分散的数据，为能源相关研究提供了有用的知识平台。


<details>
  <summary>Details</summary>
Motivation: 二维材料因其独特的物理化学和电子特性，在储能和能量转换领域展现出广泛应用。许多关于此类材料的关键信息（如性质、制备方法）分散在众多已发表论文中，导致信息难以系统整理和快速检索。本文试图解决相关信息分散的问题。

Method: 收集、整理并系统化已发表论文中有关二维材料的性质和制备方法等关键信息，或可能涉及知识图谱或数据库的构建。

Result: 通过对大量文献的整合，构建或完善了一个关于二维材料的系统性数据库（或知识图谱），便于学者对材料的各项属性和制备方法进行查询和分析。

Conclusion: 本研究有助于加速二维材料在能源领域的基础研究与应用开发，为后续相关研究提供了高效、系统的信息资源。

Abstract: Two-dimensional (2D) materials have showed widespread applications in energy storage and conversion owning to their unique physicochemical, and electronic properties. Most of the valuable information for the materials, such as their properties and preparation methods, is included in the published research papers. However, due to the dispersion of synthe

</details>


### [30] [Memories Retrieved from Many Paths: A Multi-Prefix Framework for Robust Detection of Training Data Leakage in Large Language Models](https://arxiv.org/abs/2511.20799)
*Trung Cuong Dang,David Mohaisen*

Main category: cs.CL

TL;DR: 论文提出多前缀记忆的新框架，通过定义和实验，证明该方法能更准确、可靠地区分大型语言模型中的记忆内容，有助于检测和管理数据泄漏风险。


<details>
  <summary>Details</summary>
Motivation: 现有记忆定义无法全面捕捉大型语言模型的数据记忆现象，尤其在对齐模型中尤为明显。因此，亟需新的更健壮和实用的记忆定义方法以应对隐私和版权风险。

Method: 提出了多前缀记忆（multi-prefix memorization）的新框架，通过实验在开源和对齐聊天模型中验证了该定义的有效性。具体方法是利用外部攻击性搜索，找到足够多能召回目标序列的不同前缀，以判断是否为记忆内容。

Result: 多前缀记忆定义不仅更好地区分了模型的记忆内容，还为审核模型数据泄漏提供了可操作性强的新工具。

Conclusion: 多前缀记忆框架可以有效区分大型语言模型中已记忆和未记忆的数据，成为审核数据泄漏的实用工具。

Abstract: Large language models, trained on massive corpora, are prone to verbatim memorization of training data, creating significant privacy and copyright risks. While previous works have proposed various definitions for memorization, many exhibit shortcomings in comprehensively capturing this phenomenon, especially in aligned models. To address this, we introduce a novel framework: multi-prefix memorization. Our core insight is that memorized sequences are deeply encoded and thus retrievable via a significantly larger number of distinct prefixes than non-memorized content. We formalize this by defining a sequence as memorized if an external adversarial search can identify a target count of distinct prefixes that elicit it. This framework shifts the focus from single-path extraction to quantifying the robustness of a memory, measured by the diversity of its retrieval paths. Through experiments on open-source and aligned chat models, we demonstrate that our multi-prefix definition reliably distinguishes memorized from non-memorized data, providing a robust and practical tool for auditing data leakage in LLMs.

</details>


### [31] [SAGE: An Agentic Explainer Framework for Interpreting SAE Features in Language Models](https://arxiv.org/abs/2511.20820)
*Jiaojiao Han,Wujiang Xu,Mingyu Jin,Mengnan Du*

Main category: cs.CL

TL;DR: 提出了一种新颖的SAE特征解释框架SAGE，能更准确地解释和验证大语言模型中的特征，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）虽然取得了显著进展，但其内部机制不透明，影响了安全与可靠部署。稀疏自编码器（SAEs）可提升LLM的可解释性，但解释SAEs捕获到的特征仍然困难。

Method: 提出SAGE（SAE AGentic Explainer）——一种基于智能体的解释框架，将特征解释从被动、单次生成任务转变为主动、以解释为驱动的流程。具体做法包括为每个特征系统性地生成多种解释、设计针对性的实验进行验证，并根据激活反馈迭代优化解释。

Result: 在多个语言模型中的SAE特征实验证明，SAGE在生成性和预测性解释任务上明显优于当前最先进的基线方法。

Conclusion: SAGE通过系统性和迭代优化提升了SAE特征的解释能力，有助于提高LLM内部机制的透明度和可解释性。

Abstract: Large language models (LLMs) have achieved remarkable progress, yet their internal mechanisms remain largely opaque, posing a significant challenge to their safe and reliable deployment. Sparse autoencoders (SAEs) have emerged as a promising tool for decomposing LLM representations into more interpretable features, but explaining the features captured by SAEs remains a challenging task. In this work, we propose SAGE (SAE AGentic Explainer), an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanation-driven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanationdriven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.

</details>


### [32] [Structured Prompting Enables More Robust, Holistic Evaluation of Language Models](https://arxiv.org/abs/2511.20836)
*Asad Aali,Muhammad Ahmed Mohsin,Vasiliki Bikia,Arnav Singhvi,Richard Gaus,Suhana Bedi,Hejie Cui,Miguel Fuentes,Alyssa Unell,Yifan Mai,Jordan Cahoon,Michael Pfeffer,Roxana Daneshjou,Sanmi Koyejo,Emily Alsentzer,Percy Liang,Christopher Potts,Nigam H. Shah,Akshay S. Chaudhari*

Main category: cs.CL

TL;DR: 本文提出并验证了一种结合DSPy结构化提示和HELM评测框架的方法，显著提升了对语言模型评测的准确性和泛化性，纠正了现有评测低估和排名误判问题，为模型部署和选择提供更可靠依据。相关工具已开源。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型广泛应用各领域，然而现有的评测框架如HELM依赖固定提示词，导致对模型性能估计不准确，容易低估模型潜力。需要一种能更全面反映不同模型真实能力的评测方法。

Method: 提出DSPy+HELM框架，结合结构化提示词（包括四种方法），针对不同任务自动优化提示词，用于更科学评估四个主流语言模型在七个基准任务（涵盖通用与医学领域）上的表现。并将其与现有HELM基线得分进行对比分析。

Result: 采用结构化提示词后：1）发现HELM低估了语言模型性能，平均低4%。2）在不同基准任务间的表现差异更小（标准差降低2%）。3）部分任务的排行榜排名发生颠倒。4）引入理由链（chain-of-thought）提示后，模型对提示设计的敏感度变小。

Conclusion: 结构化、可优化的提示词能显著提升语言模型评测的准确性和公平性，有助于更科学地判断模型上限和实际应用价值。DSPy+HELM框架为大规模高质量评测提供了有力工具并已开源相关资源。

Abstract: As language models (LMs) are increasingly adopted across domains, high-quality benchmarking frameworks that accurately estimate performance are essential for guiding deployment decisions. While frameworks such as Holistic Evaluation of Language Models (HELM) enable broad evaluation across tasks, they often rely on fixed prompts that fail to generalize across LMs, yielding unrepresentative performance estimates. Unless we estimate each LM's ceiling (maximum achievable via changes to the prompt), we risk underestimating performance. Declarative prompting frameworks, such as DSPy, offer a scalable alternative to manual prompt engineering by crafting structured prompts that can be optimized per task. However, such frameworks have not been systematically evaluated across established benchmarks. We present a reproducible DSPy+HELM framework that introduces structured prompting methods which elicit reasoning, enabling more accurate LM benchmarking. Using four prompting methods, we evaluate four frontier LMs across seven benchmarks (general/medical domain) against existing HELM baseline scores. We find that without structured prompting: (i) HELM underestimates LM performance (by 4% average), (ii) performance estimates vary more across benchmarks (+2% standard deviation), (iii) performance gaps are misrepresented (leaderboard rankings flip on 3/7 benchmarks), and (iv) introducing reasoning (chain-of-thought) reduces LM sensitivity to prompt design (smaller Δ across prompts). To our knowledge, this is the first large-scale benchmarking study to empirically characterize LM behavior across benchmarks and prompting methods, showing that scalable performance ceiling estimation enables more decision-useful benchmarks. We open-source (i) DSPy+HELM Integration (https://github.com/stanford-crfm/helm/pull/3893) and (ii) Prompt Optimization Pipeline (https://github.com/StanfordMIMI/dspy-helm).

</details>


### [33] [Length-MAX Tokenizer for Language Models](https://arxiv.org/abs/2511.20849)
*Dong Dong,Weijie Su*

Main category: cs.CL

TL;DR: 本文提出Length-MAX分词器，以最小化平均每字符token数量为目标，通过图分割和贪心算法优化词表。实验证明相比BPE分词器，可显著减少token、加速训练与推理，提升下游任务表现，同时兼容生产系统并节省内存，是更高效的分词工具。


<details>
  <summary>Details</summary>
Motivation: 当前主流的分词方法（如BPE）主要优化词频，未能有效减少平均每字符的分词数量，导致训练和推理时文本表征冗余，效率不高。作者希望找到更高效的分词策略，减少tokens数量，以提升训练和推理效率。

Method: 本文提出了一种新型分词器Length-MAX，通过将长度加权目标最大化问题转化为图分割问题，并设计了一个贪心近似算法来构造词表。该分词器专注于最小化平均每字符tokens数量，实现更高效的文本表示。

Result: 在FineWeb和多个领域测试下，Length-MAX分词器比BPE分词器减少了14-18%的token数量（词表大小10K-50K），64K词表下减少13.0%。训练GPT-2模型时达到目标验证损失所需步数分别减少18.5%、17.2%、18.5%；推理延迟降低约13%，吞吐率提升16%。在下游任务上也有显著提升（如LAMBADA perplexity下降11.7%，HellaSwag准确率提升4.3%）。词表覆盖率高达99.62%，测试集OOV率低至0.12%。推理时嵌入与KV-cache内存需求降低18%。

Conclusion: 通过优化平均token长度而非仅优化频率，可以实现更高效的语言建模，不仅提升训练与推理效率，还改善下游任务效果，且和生产系统兼容。Length-MAX分词器在多个方面优于传统BPE分词器，是更有效的分词解决方案。

Abstract: We introduce a new tokenizer for language models that minimizes the average tokens per character, thereby reducing the number of tokens needed to represent text during training and to generate text during inference. Our method, which we refer to as the Length-MAX tokenizer, obtains its vocabulary by casting a length-weighted objective maximization as a graph partitioning problem and developing a greedy approximation algorithm. On FineWeb and diverse domains, it yields 14--18\% fewer tokens than Byte Pair Encoding (BPE) across vocabulary sizes from 10K to 50K, and the reduction is 13.0\% when the size is 64K. Training GPT-2 models at 124M, 355M, and 1.3B parameters from scratch with five runs each shows 18.5\%, 17.2\%, and 18.5\% fewer steps, respectively, to reach a fixed validation loss, and 13.7\%, 12.7\%, and 13.7\% lower inference latency, together with a 16\% throughput gain at 124M, while consistently improving on downstream tasks including reducing LAMBADA perplexity by 11.7\% and enhancing HellaSwag accuracy by 4.3\%. Moreover, the Length-MAX tokenizer achieves 99.62\% vocabulary coverage and the out-of-vocabulary rate remains low at 0.12\% on test sets. These results demonstrate that optimizing for average token length, rather than frequency alone, offers an effective approach to more efficient language modeling without sacrificing -- and often improving -- downstream performance. The tokenizer is compatible with production systems and reduces embedding and KV-cache memory by 18\% at inference.

</details>


### [34] [Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory](https://arxiv.org/abs/2511.20857)
*Tianxin Wei,Noveen Sachdeva,Benjamin Coleman,Zhankui He,Yuanchen Bei,Xuying Ning,Mengting Ai,Yunzhe Li,Jingrui He,Ed H. Chi,Chi Wang,Shuo Chen,Fernando Pereira,Wang-Cheng Kang,Derek Zhiyuan Cheng*

Main category: cs.CL

TL;DR: 本文提出Evo-Memory基准，评价LLM在连续任务中的自进化记忆能力，并验证了流式记忆更新机制的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在实际应用中需要进行长期规划和跨任务流的复杂问题求解，因此状态保持和记忆管理极为重要。但目前的研究多局限于静态对话场景，对动态记忆的积累和重用能力关注不足，导致模型难以通过不断交互实现持续优化。

Method: 作者提出了Evo-Memory，这是一套用于评估LLM自主进化记忆能力的流式基准和框架。Evo-Memory将数据集组织为序列化的任务流，要求LLM在每次交互后检索、适应并进化记忆。框架包含十余种具有代表性的记忆模块，并在10个多轮对话和单轮推理/问答任务中统一评测。此外，作者提供了基线方法ExpRAG用于体验的检索与利用，并进一步提出了融合推理、行动与记忆更新的ReMem流程。

Result: Evo-Memory在多个任务和记忆机制下系统性地测试了LLM记忆自主进化能力。提出的ReMem流程在记忆检索、更新与利用中表现出可持续改进，优于传统的静态记忆与检索方法，验证了方法在长期推理、经验复用等场景下的有效性。

Conclusion: Evo-Memory为评估和推动LLM记忆进化能力提供了系统工具，支持模型在不断变化任务流中持续学习和优化，有望助力真实世界长期任务中的LLM自主进化和持续表现改进。

Abstract: Statefulness is essential for large language model (LLM) agents to perform long-term planning and problem-solving. This makes memory a critical component, yet its management and evolution remain largely underexplored. Existing evaluations mostly focus on static conversational settings, where memory is passively retrieved from dialogue to answer queries, overlooking the dynamic ability to accumulate and reuse experience across evolving task streams. In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. To bridge this gap, we introduce Evo-Memory, a comprehensive streaming benchmark and framework for evaluating self-evolving memory in LLM agents. Evo-Memory structures datasets into sequential task streams, requiring LLMs to search, adapt, and evolve memory after each interaction. We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. To better benchmark experience reuse, we provide a baseline method, ExpRAG, for retrieving and utilizing prior experience, and further propose ReMem, an action-think-memory refine pipeline that tightly integrates reasoning, task actions, and memory updates to achieve continual improvement.

</details>


### [35] [Winning with Less for Low Resource Languages: Advantage of Cross-Lingual English_Persian Argument Mining Model over LLM Augmentation](https://arxiv.org/abs/2511.20872)
*Ali Jahan,Masood Ghayoomi,Annette Hautli-Janisz*

Main category: cs.CL

TL;DR: 本文提出并实证分析了三种跨语言训练策略，发现英语与手动翻译波斯语数据的混合训练对低资源语言论证挖掘效果最佳，明显超过LLM数据增强和直接迁移方法。


<details>
  <summary>Details</summary>
Motivation: 论证挖掘作为自然语言处理的一个分支，能够揭示文本中的逻辑结构，但面对低资源语言时数据稀缺，阻碍了该领域在这些语言中的应用。因此，研究如何更好地支持低资源语言的论证挖掘具有重要价值。

Method: 本文设计了三种训练场景进行跨语言论证挖掘：(1) 零样本迁移，用仅基于英语数据训练的模型直接评估波斯语；(2) 用大型语言模型（LLMs）合成的样本增强英语训练；(3) 跨语言训练，将英语数据与手动翻译的波斯语句子结合训练。所有模型在英文Microtext语料及其波斯语对齐翻译上进行了评估。

Result: 零样本迁移模型英、波两语的F1分别为50.2%和50.7%；基于LLM增强后，英、波F1分别提升至59.2%和69.3%；跨语言混合模型在波斯语测试集上F1达到74.8%，优于资源消耗更高的增强方法。

Conclusion: 轻量级的跨语言混合训练方案能显著提升低资源语言的论证挖掘性能，优于依赖大规模增强数据的方法，为该领域在数据稀缺场景下的应用提供了有效解决途径。

Abstract: Argument mining is a subfield of natural language processing to identify and extract the argument components, like premises and conclusions, within a text and to recognize the relations between them. It reveals the logical structure of texts to be used in tasks like knowledge extraction. This paper aims at utilizing a cross-lingual approach to argument mining for low-resource languages, by constructing three training scenarios. We examine the models on English, as a high-resource language, and Persian, as a low-resource language. To this end, we evaluate the models based on the English Microtext corpus \citep{PeldszusStede2015}, and its parallel Persian translation. The learning scenarios are as follow: (i) zero-shot transfer, where the model is trained solely with the English data, (ii) English-only training enhanced by synthetic examples generated by Large Language Models (LLMs), and (iii) a cross-lingual model that combines the original English data with manually translated Persian sentences. The zero-shot transfer model attains F1 scores of 50.2\% on the English test set and 50.7\% on the Persian test set. LLM-based augmentation model improves the performance up to 59.2\% on English and 69.3\% on Persian. The cross-lingual model, trained on both languages but evaluated solely on the Persian test set, surpasses the LLM-based variant, by achieving a F1 of 74.8\%. Results indicate that a lightweight cross-lingual blend can outperform considerably the more resource-intensive augmentation pipelines, and it offers a practical pathway for the argument mining task to overcome data resource shortage on low-resource languages.

</details>


### [36] [Emergence and Localisation of Semantic Role Circuits in LLMs](https://arxiv.org/abs/2511.20910)
*Nura Aljaafari,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 本文提出新方法分析LLM内部语义结构，发现其回路高度集中并呈现逐步优化趋势，这些机制在不同模型间能部分迁移，揭示了LLM抽象语义实现的新机制。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在语义能力上表现出色，但它们内部是如何实现抽象语义结构的机制还没有被充分解读。

Method: 提出一种结合角色交叉最小对比实验、时间性涌现分析、跨模型对比的方法研究LLMs实现语义角色的方法。

Result: （i）发现高度集中的回路（89-94%的归因集中在28个节点内）；（ii）结构是逐步细化而非阶段性突变，且更大的模型有时会绕过局部回路；（iii）存在中等程度的跨模型保守性（24-59%的组件重叠），以及高频谱相似性。

Conclusion: LLMs会形成紧凑、因果上隔离的机制对抽象语义结构，同时这些机制在尺度和架构之间表现出部分转移能力。

Abstract: Despite displaying semantic competence, large language models' internal mechanisms that ground abstract semantic structure remain insufficiently characterised. We propose a method integrating role-cross minimal pairs, temporal emergence analysis, and cross-model comparison to study how LLMs implement semantic roles. Our analysis uncovers: (i) highly concentrated circuits (89-94% attribution within 28 nodes); (ii) gradual structural refinement rather than phase transitions, with larger models sometimes bypassing localised circuits; and (iii) moderate cross-scale conservation (24-59% component overlap) alongside high spectral similarity. These findings suggest that LLMs form compact, causally isolated mechanisms for abstract semantic structure, and these mechanisms exhibit partial transfer across scales and architectures.

</details>


### [37] [Chatty-KG: A Multi-Agent AI System for On-Demand Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2511.20940)
*Reham Omar,Abdelghny Orogat,Ibrahim Abdelaziz,Omij Mangukiya,Panos Kalnis,Essam Mansour*

Main category: cs.CL

TL;DR: 本论文提出一种结合结构化知识图谱和大语言模型对话能力的多智能体系统Chatty-KG。在各类知识图谱和模型上表现优异，兼具准确性和扩展性，为多轮对话式知识图谱问答提供了新的技术路径。


<details>
  <summary>Details</summary>
Motivation: 知识图谱问答（KGQA）难以实现与用户自然对话的多轮交互，传统KGQA结构化能力强但仅支持单轮问答，缺乏上下文追踪，延迟高且难以应对实际应用中的动态知识图谱。大模型虽对话能力强但不能直接利用私有/动态KG知识。检索增强生成（RAG）虽能部分结合二者优势，但结构保持有限且效率较低。亟需一种方案结合KG结构化与大模型对话能力，适用于多轮对话和动态场景。

Method: 提出Chatty-KG：一种模块化多智能体系统，结合RAG检索方式和结构化执行，通过专门的LLM代理自动协作，完成语境理解、对话追踪、实体和关系链接、高效查询规划，并将自然语言问题翻译为SPARQL查询。系统可灵活对接多类型大模型，无需额外微调或预处理，兼容商业及开源LLM。

Result: 在多个大型、多样化知识图谱实验证明，Chatty-KG在单轮与多轮问答均显著优于现有最先进方法（F1和P@1分数更高），能够保持对话连贯性并适应动态变化的KG结构。商用和开源大模型测试均展现出强兼容性与稳定性。

Conclusion: Chatty-KG方法有效统一了对话灵活性和知识图谱的结构化可靠性，是面向多轮KGQA的可扩展、高效和可靠方案，具备广泛实际应用潜力。

Abstract: Conversational Question Answering over Knowledge Graphs (KGs) combines the factual grounding of KG-based QA with the interactive nature of dialogue systems. KGs are widely used in enterprise and domain applications to provide structured, evolving, and reliable knowledge. Large language models (LLMs) enable natural and context-aware conversations, but lack direct access to private and dynamic KGs. Retrieval-augmented generation (RAG) systems can retrieve graph content but often serialize structure, struggle with multi-turn context, and require heavy indexing. Traditional KGQA systems preserve structure but typically support only single-turn QA, incur high latency, and struggle with coreference and context tracking. To address these limitations, we propose Chatty-KG, a modular multi-agent system for conversational QA over KGs. Chatty-KG combines RAG-style retrieval with structured execution by generating SPARQL queries through task-specialized LLM agents. These agents collaborate for contextual interpretation, dialogue tracking, entity and relation linking, and efficient query planning, enabling accurate and low-latency translation of natural questions into executable queries. Experiments on large and diverse KGs show that Chatty-KG significantly outperforms state-of-the-art baselines in both single-turn and multi-turn settings, achieving higher F1 and P@1 scores. Its modular design preserves dialogue coherence and supports evolving KGs without fine-tuning or pre-processing. Evaluations with commercial (e.g., GPT-4o, Gemini-2.0) and open-weight (e.g., Phi-4, Gemma 3) LLMs confirm broad compatibility and stable performance. Overall, Chatty-KG unifies conversational flexibility with structured KG grounding, offering a scalable and extensible approach for reliable multi-turn KGQA.

</details>


### [38] [TrackList: Tracing Back Query Linguistic Diversity for Head and Tail Knowledge in Open Large Language Models](https://arxiv.org/abs/2511.21006)
*Ioana Buhnila,Aman Sinha,Mathieu Constant*

Main category: cs.CL

TL;DR: 该研究结合新分析管道和医学数据集，发现大语言模型仅在定义类问题表现突出，例证和解释类则表现较差，且知识点频率影响其释义能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在不同类型查询下表现不一致，尤其定义类问题表现优异，而其他类型如例证、释义等变差。本研究旨在探究LLMs为何在多样化语言任务下性能下降，以及预训练数据的影响。

Method: 提出TrackList分析管道，结合细粒度语言与统计分析；引入RefoMed-EN数据集（包含6170个人工标注医学词条及其定义、例证、解释、释义等）；利用句法和语义相似度指标、统计相关性及嵌入等评估LLM回答质量；分析高频/低频概念对结果影响。

Result: LLMs在定义类问题表现最佳，在例证类问题表现最差。在定义类问题上，模型对常见知识更倾向于进行释义，而对冷门或技术性知识则释义较少，尤其在专业文本中。

Conclusion: LLMs擅长定义类问题但难以处理例证等其他语言任务，且预训练数据频率影响其在不同类型问题上的表现，专业或低频知识更难被释义。

Abstract: Large Language Models (LLMs) have proven efficient in giving definition-type answers to user input queries. While for humans giving various types of answers, such as examples and paraphrases, is an easy task, LLMs struggle to provide correct answers for other than definition-type queries. In this study, we evaluated this drop in performance using TrackList, a fine-grained linguistic and statistical analysis pipeline to investigate the impact of the pre-training data on LLMs answers to diverse linguistic queries. We also introduce RefoMed-EN, an English dataset consisting of 6170 human-annotated medical terms alongside their corresponding definitions, denominations, exemplifications, explanations, or paraphrases. We studied whether the high frequency of a concept (head) or low frequency (tail) impacts the language model's performance. We evaluated the quality of the LLM's output using syntactic and semantic similarity metrics, statistical correlations and embeddings. Results showed that the LLM's task performance for definition type questions is the highest, while for the exemplification type it is the lowest. Additionally, we showed that for definition-type questions, large language models are prone to paraphrase more on popular and frequent knowledge and less on tail and technical knowledge, especially in the expert texts.

</details>


### [39] [Semantic Anchors in In-Context Learning: Why Small LLMs Cannot Flip Their Labels](https://arxiv.org/abs/2511.21038)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CL

TL;DR: 上下文学习只能微调、不能颠覆预训练的大模型语义标签理解，要完全改变标签含义需其它方式。


<details>
  <summary>Details</summary>
Motivation: 社区对ICL作用机制存在疑问，亟需明确ICL是在灵活改变标签语义，还是只能调整预训练基础上的输出，关系到prompt设计和模型能力理解。

Method: 作者将大模型视为prompt驱动的分类器，设置自然与反转两种标签演示，设计三种对齐指标（真值、先验、prompt），并提出语义覆盖率这一新衡量指标，系统测试了多任务、多模型的表现。

Result: 本文研究了上下文学习（ICL）是否能改变或仅仅微调大模型预训练期间形成的标签语义。作者通过大量实验，比较了模型在“自然”（正确标签）与“反转”（标签含义翻转）两种演示下的行为。结果显示，在八个分类任务和八个LLM（1-12B参数）上，一致发现ICL不能完全覆盖和颠覆原有语义锚点（semantic anchor），只是在原有预训练语义基础上进行调整。特别是在标签意义被反转时，模型不能学会反语义的分类器，语义覆盖率为零。

Conclusion: ICL主要是微调输入在预训练语义空间中的投影，难以覆盖或颠覆已有语义锚点，在1-12B参数规模下通过ICL无法实现对标签语义的完全替换，需其他方法干预。

Abstract: Can in-context learning (ICL) override pre-trained label semantics, or does it merely refine an existing semantic backbone? We address this question by treating LLMs as prompt-induced classifiers and contrasting their behavior under \emph{natural} demonstrations (with correct labels) and \emph{inverted} demonstrations (systematically flipping label meanings). We decompose ICL behavior into three alignment metrics (truth, prior, and prompt alignment) and introduce a semantic override rate, defined as correctness under flipped semantics. Across eight classification tasks and eight open-source LLMs (1--12B parameters), we find consistent evidence for a semantic anchor view. With natural demonstrations, ICL improves accuracy while maintaining strong prior alignment; most correct predictions coincide with zero-shot behavior, even when the prior is weak. With inverted demonstrations, models cannot learn coherent anti-semantic classifiers: prompt alignment increases only by sacrificing accuracy, and semantic override rates remain exactly zero in our few-shot 1--12B setting. Rather than flexibly remapping label meanings, ICL primarily adjusts how inputs project onto stable semantic directions learned during pre-training, clarifying fundamental limits of few-shot prompting and suggesting that overriding label semantics at these scales requires interventions beyond ICL. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/semantic-anchors-icl.

</details>


### [40] [Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection](https://arxiv.org/abs/2511.21066)
*Michael Iskandardinata,William Christian,Derwin Suhartono*

Main category: cs.CL

TL;DR: 为了提升大型语言模型在讽刺检测任务中的表现，本文提出结合网络检索和模型内部知识补充背景信息的方案，并在多数据集上取得显著性能提升，强调上下文尤其是文化相关内容对于讽刺识别的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管神经网络和预训练语言模型在讽刺检测领域取得进展，但由于讽刺语言的复杂性及不同社群的语言和文化差异，这些模型仍面临挑战，特别是在处理需要更多外部知识的词语时准确性不足。因而亟需利用更多上下文信息提升模型性能。

Method: 在现有Pragmatic Metacognitive Prompting（PMP）基础上，提出了检索增强方法，包括两种策略：一是利用网络检索为目标文本补充非参数化知识，二是激发模型自身的内部知识以实现“自我知识检索”。通过三组讽刺文本数据集进行实验并评估。

Result: 在Twitter Indonesia Sarcastic数据集上，非参数化检索使macro-F1提升9.87%；在SemEval-2018 Task 3和MUStARD数据集上，自我知识检索分别提升macro-F1 3.29%和4.08%。结果证明适当补充上下文能大幅提升LLMs讽刺检测表现。

Conclusion: 引入检索相关背景知识可以显著提升大型语言模型（LLMs）对讽刺文本的识别能力，尤其是在涉及文化特定俚语、参考和未知词汇情境下。

Abstract: Detecting sarcasm remains a challenging task in the areas of Natural Language Processing (NLP) despite recent advances in neural network approaches. Currently, Pre-trained Language Models (PLMs) and Large Language Models (LLMs) are the preferred approach for sarcasm detection. However, the complexity of sarcastic text, combined with linguistic diversity and cultural variation across communities, has made the task more difficult even for PLMs and LLMs. Beyond that, those models also exhibit unreliable detection of words or tokens that require extra grounding for analysis. Building on a state-of-the-art prompting method in LLMs for sarcasm detection called Pragmatic Metacognitive Prompting (PMP), we introduce a retrieval-aware approach that incorporates retrieved contextual information for each target text. Our pipeline explores two complementary ways to provide context: adding non-parametric knowledge using web-based retrieval when the model lacks necessary background, and eliciting the model's own internal knowledge for a self-knowledge awareness strategy. We evaluated our approach with three datasets, such as Twitter Indonesia Sarcastic, SemEval-2018 Task 3, and MUStARD. Non-parametric retrieval resulted in a significant 9.87% macro-F1 improvement on Twitter Indonesia Sarcastic compared to the original PMP method. Self-knowledge retrieval improves macro-F1 by 3.29% on Semeval and by 4.08% on MUStARD. These findings highlight the importance of context in enhancing LLMs performance in sarcasm detection task, particularly the involvement of culturally specific slang, references, or unknown terms to the LLMs. Future work will focus on optimizing the retrieval of relevant contextual information and examining how retrieval quality affects performance. The experiment code is available at: https://github.com/wllchrst/sarcasm-detection_pmp_knowledge-base.

</details>


### [41] [Enhancing Burmese News Classification with Kolmogorov-Arnold Network Head Fine-tuning](https://arxiv.org/abs/2511.21081)
*Thura Aung,Eaint Kay Khaing Kyaw,Ye Kyaw Thu,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: 本研究发现，在缅甸语等低资源语言的分类任务中，KAN分类头能够在表达能力和效率上优于传统MLP，为该类任务提供了新型替代方案。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言（如缅甸语）的分类任务中，通常只微调最后的分类层，保持预训练编码器权重不变。常用的多层感知机（MLP）受限于固定的非线性，表达能力有限且计算开销较大。因此，需要寻找更高效且具有更强表达能力的替代方法。

Method: 本研究探索了Kolmogorov-Arnold Networks (KANs) 作为替代的分类头，并评估了基于傅里叶变换的FourierKAN、基于样条的EfficientKAN以及基于网格的FasterKAN，它们被应用于多种嵌入方法（TF-IDF、fastText、多语种transformer如mBERT和Distil-mBERT）。

Result: 实验结果显示，KAN分类头与MLPs在效果上有竞争力或更优。EfficientKAN结合fastText达到了最高的F1分数（0.928），FasterKAN在速度和精度之间取得了最佳平衡。在transformer嵌入下，EfficientKAN与mBERT结合下的表现与MLP持平或略优（F1=0.917）。

Conclusion: KANs可以作为低资源语言分类任务中MLPs的高效、富有表现力的替代方案。

Abstract: In low-resource languages like Burmese, classification tasks often fine-tune only the final classification layer, keeping pre-trained encoder weights frozen. While Multi-Layer Perceptrons (MLPs) are commonly used, their fixed non-linearity can limit expressiveness and increase computational cost. This work explores Kolmogorov-Arnold Networks (KANs) as alternative classification heads, evaluating Fourier-based FourierKAN, Spline-based EfficientKAN, and Grid-based FasterKAN-across diverse embeddings including TF-IDF, fastText, and multilingual transformers (mBERT, Distil-mBERT). Experimental results show that KAN-based heads are competitive with or superior to MLPs. EfficientKAN with fastText achieved the highest F1-score (0.928), while FasterKAN offered the best trade-off between speed and accuracy. On transformer embeddings, EfficientKAN matched or slightly outperformed MLPs with mBERT (0.917 F1). These findings highlight KANs as expressive, efficient alternatives to MLPs for low-resource language classification.

</details>


### [42] [Orthographic Constraint Satisfaction and Human Difficulty Alignment in Large Language Models](https://arxiv.org/abs/2511.21086)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.CL

TL;DR: 三大主流语言模型在字符级约束任务中架构比参数规模影响更大，现有模型在不寻常拼写上表现不佳，未来需针对约束性生成改进模型架构与训练目标。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在受控文本生成时需满足硬正字约束，然而各模型架构间系统性评估有限，需揭示架构与参数扩充对字符约束满足的影响。

Method: 评价了三大模型家族（Qwen3、Claude Haiku-4.5、GPT-5-mini）共28种配置，在58个字符约束单词谜题上的表现，并结合1万名人类解答者的难度标注进行对比分析。

Result: 架构差异导致性能差距远大于同族参数规模提升（F1提升2.0-2.2倍），高容量模型“思考预算”敏感度高但中型模型提升有限。不常见拼写导致系统性失败，模型普遍依赖分布式合理性，难以满足特殊字形约束。

Conclusion: 约束性文本生成需要大型语言模型超越简单参数规模扩增，需通过架构或训练目标创新来满足更难的字符级约束。

Abstract: Large language models must satisfy hard orthographic constraints during controlled text generation, yet systematic cross-architecture evaluation remains limited. We evaluate 28 configurations spanning three model families (Qwen3, Claude Haiku-4.5, GPT-5-mini) on 58 word puzzles requiring character-level constraint satisfaction. Architectural differences produce substantially larger performance gaps (2.0-2.2x, F1=0.761 vs. 0.343) than parameter scaling within families (83% gain from eightfold scaling), suggesting that constraint satisfaction may require specialized architectural features or training objectives beyond standard language model scaling. Thinking budget sensitivity proves heterogeneous: high-capacity models show strong returns (+0.102 to +0.136 F1), while mid-sized variants saturate or degrade. These patterns are inconsistent with uniform compute benefits. Using difficulty ratings from 10,000 human solvers per puzzle, we establish modest but consistent calibration (r=0.24-0.38) across all families, yet identify systematic failures on common words with unusual orthography ("data", "poop", "loll": 86-95% human success, 89-96% model miss rate). These failures reveal over-reliance on distributional plausibility that penalizes orthographically atypical but constraint-valid patterns, suggesting architectural innovations may be required beyond simply scaling parameters or computational budgets.

</details>


### [43] [ASR Error Correction in Low-Resource Burmese with Alignment-Enhanced Transformers using Phonetic Features](https://arxiv.org/abs/2511.21088)
*Ye Bhone Lin,Thura Aung,Ye Kyaw Thu,Thazin Myint Oo*

Main category: cs.CL

TL;DR: 针对低资源缅甸语，采用Transformer模型进行自动语音识别错误纠正，有效集成IPA和对齐特征后，各指标显著优于基线，显示该方法在低资源环境下具有强鲁棒性和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 缅甸语属于低资源语种，自动语音识别（ASR）容易出现错误，且现有研究极其有限，因此该论文首次专门针对缅甸语的ASR错误纠正问题进行研究。

Method: 研究采用序列到序列的Transformer架构作为ASR错误纠正模型，探索了多种特征集成策略，包括IPA（国际音标）和对齐信息，并评估了五种不同的ASR主模型。

Result: 结合IPA和对齐特征的AEC模型，在不使用数据增强时能将平均词错误率（WER）从51.56降至39.82，使用数据增强时从51.56降至43.59，chrF++指标从0.5864提升至0.627，相较于基础ASR系统有显著提升。

Conclusion: 所提出的ASR错误纠正方法对低资源缅甸语的识别有稳定且显著的改善，突出了特征设计的重要性，以及在低资源场景下ASR改进的可行性。

Abstract: This paper investigates sequence-to-sequence Transformer models for automatic speech recognition (ASR) error correction in low-resource Burmese, focusing on different feature integration strategies including IPA and alignment information. To our knowledge, this is the first study addressing ASR error correction specifically for Burmese. We evaluate five ASR backbones and show that our ASR Error Correction (AEC) approaches consistently improve word- and character-level accuracy over baseline outputs. The proposed AEC model, combining IPA and alignment features, reduced the average WER of ASR models from 51.56 to 39.82 before augmentation (and 51.56 to 43.59 after augmentation) and improving chrF++ scores from 0.5864 to 0.627, demonstrating consistent gains over the baseline ASR outputs without AEC. Our results highlight the robustness of AEC and the importance of feature design for improving ASR outputs in low-resource settings.

</details>


### [44] [MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing](https://arxiv.org/abs/2511.21101)
*Manish Jain,Satheesh Kumar Ponnambalam,Salman Faroz,Chandrakanth Lns,Vinay Sharma*

Main category: cs.CL

TL;DR: 本文提出抵押贷款领域专用大语言模型MortgageLLM，采用双专家架构和指令残差技术，解决了结构任务与对话任务间性能折中问题，并在实际任务上显著优于主流通用模型。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在专业领域（如抵押贷款金融）能力受限，需要增强领域知识的同时保持强指令遵循性，而单一多任务训练存在性能折中。

Method: 以LLaMA-3.1-8B为基础，采用双专家（对话问答和结构化任务）并结合指令残差（instruction residual）技术和智能任务分流机制，分别优化模型的专业能力与指令遵循性，并在专业领域基准上验证其效果。

Result: 在抵押贷款领域的基准测试中，MLM v2模型在摘要、问答和分类得分上均明显优于基础模型，LLM-as-a-Judge摘要得分提升至4.58（基础为3.99）、问答4.09（基础4.0）、分类2.6（基础1.2）；BERTScore指标也显著上升，展示其在领域定制和指令遵循两方面均有提升。

Conclusion: 提出了MortgageLLM，一个面向抵押贷款金融领域的专用大语言模型，采用双专家架构并应用指令残差技术，有效提升了结构化任务与对话任务的性能且超越了基础模型。

Abstract: Large Language Models (LLMs) demonstrate exceptional capabilities across general domains, yet their application to specialized sectors such as mortgage finance requires domain-specific knowledge augmentation while preserving instruction-following fidelity. We present MortgageLLM, a novel domain-specific large language model that addresses this dual challenge. It is developed using a dual-track specialization framework from a single base model (LLaMA-3.1-8B). We opted for this dual-expert approach as a single multi-task model suffers from performance trade-offs, where optimizing for structured tasks (via SFT) degrades conversational fidelity (via DPO). Our dual-track method solves this by creating two specialists, allowing each to be optimally trained for its distinct capability. Our approach applies the instruction residual technique to restore instruction-following capabilities post-domain adaptation without supervised fine-tuning. We contribute: (1) application of this residual technique to the highly specialized mortgage finance domain; (2) a dual-expert architecture combining a conversational Q&A model and a structured task model for classification and summarization; and (3) an intelligent task routing mechanism using few-shot classification performed by one of the expert models itself. We validate our approach on domain-specific benchmarks, where our final model (MLM v2) significantly outperforms the base LLaMA-3.1-8B-Instruct, achieving an LLM-as-a-Judge summarization score of 4.58 (vs. 3.99), a Q&A score of 4.09 (vs. 4.0), and a classification score of 2.6 (vs. 1.2). On semantic similarity, our model achieved a BERTScore of 0.77 for summarization (vs. 0.74), 0.68 for Q&A (vs. 0.58), and 0.75 for classification (vs. 0.73), substantially outperforming baseline approaches.

</details>


### [45] [Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines](https://arxiv.org/abs/2511.21214)
*Yuhang Wang,Yanxu Zhu,Dongyuan Lu,Jitao Sang*

Main category: cs.CL

TL;DR: 提出了一种自适应安全对齐框架SGASA，通过预合成数据和模型微调嵌入安全指引，有效提升了模型对有害提示的防护能力且提升鲁棒性，实验结果显著。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型易被隐蔽的、欺骗性的对抗性提示规避安全机制并生成有害内容，因此亟需自适应安全对齐方法提升模型防御能力。

Method: 提出SGASA框架，包括数据预合成阶段（生成安全指南及增强提示）和对齐微调阶段（采用SFT和DPO将安全指南内化到模型中）。

Result: 在多个数据集上的大量实验表明SGASA在模型安全性提升方面具有显著优势，并具备自适应和可扩展的效果。

Conclusion: SGASA能够有效增强模型在面对有害对抗性提示时的安全性和鲁棒性，同时减少对正常请求的误拒。

Abstract: Reasoning models have demonstrated remarkable capabilities in complex reasoning tasks. However, ensuring their safety against adversarial jailbreak prompts remains a critical challenge. Due to the covert and deceptive nature of such prompts, they can often evade built-in safety mechanisms and lead to the generation of harmful content. This underscores the need for an adaptive safety alignment approach that enables models to autonomously reinforce their defenses in response to adversarial inputs. This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework, which internalizes model-generated safety guidelines to strengthen models' ability to enhance robustness against harmful adversarial prompts while minimizing unnecessary refusals of benign requests. SGASA consists of two key stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which leverages Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed these guidelines into the model. Extensive experiments across multiple datasets demonstrate that SGASA significantly improves model safety, validating its adaptive and scalable effectiveness.

</details>


### [46] [Can Finetuing LLMs on Small Human Samples Increase Heterogeneity, Alignment, and Belief-Action Coherence?](https://arxiv.org/abs/2511.21218)
*Steven Wang,Kyle Hunt,Shaojie Tang,Kenneth Joseph*

Main category: cs.CL

TL;DR: 小样本微调能改善LLM模拟人类行为的某些不足，但LLM尚不能作为正式科研中人类参与者的完全替代。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型（LLM）能否作为调查与实验研究中人类参与者的替代，并检验微调LLM能否改善其与真实人类行为的差异。

Method: 以信息披露的行为实验为例，将经过少量人类调查数据微调的LLM与人类参与者进行对比，包括分布多样性、子群体一致性、信念与行为一致性、以及回归系数的还原等方面。

Result: 微调后，LLM在异质性、一致性和信念-行为匹配性上均有提升，但即便是表现最佳的模型也无法还原出原始研究中的回归系数。

Conclusion: 使用小样本人类数据微调能缓解部分问题，但LLM生成数据目前还不能取代人类参与者用于正式推断分析。

Abstract: There is ongoing debate about whether large language models (LLMs) can serve as substitutes for human participants in survey and experimental research. While recent work in fields such as marketing and psychology has explored the potential of LLM-based simulation, a growing body of evidence cautions against this practice: LLMs often fail to align with real human behavior, exhibiting limited diversity, systematic misalignment for minority subgroups, insufficient within-group variance, and discrepancies between stated beliefs and actions. This study examines an important and distinct question in this domain: whether fine-tuning on a small subset of human survey data, such as that obtainable from a pilot study, can mitigate these issues and yield realistic simulated outcomes. Using a behavioral experiment on information disclosure, we compare human and LLM-generated responses across multiple dimensions, including distributional divergence, subgroup alignment, belief-action coherence, and the recovery of regression coefficients. We find that fine-tuning on small human samples substantially improves heterogeneity, alignment, and belief-action coherence relative to the base model. However, even the best-performing fine-tuned models fail to reproduce the regression coefficients of the original study, suggesting that LLM-generated data remain unsuitable for replacing human participants in formal inferential analyses.

</details>


### [47] [Developing an Open Conversational Speech Corpus for the Isan Language](https://arxiv.org/abs/2511.21229)
*Adisai Na-Thalang,Chanakan Wittayasakpan,Kritsadha Phatcharoen,Supakit Buakaw*

Main category: cs.CL

TL;DR: 该论文推出依然语首个真实对话语音数据集，并制定标准化转写规则，为AI与语言学领域研究提供重要基础和资源。


<details>
  <summary>Details</summary>
Motivation: 目前依然语缺乏自然对话语音数据集，影响AI算法应用与边缘语言研究；同时因无标准正字法，语音数据转写难度高。作者为促进AI多元化、助力依然语及相似语言研究，提出此数据集及转写策略。

Method: 通过收集自然对话语音，分析依然语与泰语代码转换、口语特性及口误等现象，并设计务实的语音转写流程以解决无统一正字法导致的记录难题。

Result: 构建了含自然口语、代码转换等真实语言现象的依然语对话语音数据集，制定了可行的转写规范，公开资源支持AI与语言研究领域相关任务。

Conclusion: 论文成功推出了首个开放式依然语对话语音数据集，并制定了兼顾真实性与计算处理需求的转写规范。此举为推动包容性AI、边缘语言研究及语音模型发展奠定了基础。

Abstract: This paper introduces the development of the first open conversational speech dataset for the Isan language, the most widely spoken regional dialect in Thailand. Unlike existing speech corpora that are primarily based on read or scripted speech, this dataset consists of natural speech, thereby capturing authentic linguistic phenomena such as colloquials, spontaneous prosody, disfluencies, and frequent code-switching with central Thai. A key challenge in building this resource lies in the lack of a standardized orthography for Isan. Current writing practices vary considerably, due to the different lexical tones between Thai and Isan. This variability complicates the design of transcription guidelines and poses questions regarding consistency, usability, and linguistic authenticity. To address these issues, we establish practical transcription protocols that balance the need for representational accuracy with the requirements of computational processing. By releasing this dataset as an open resource, we aim to contribute to inclusive AI development, support research on underrepresented languages, and provide a basis for addressing the linguistic and technical challenges inherent in modeling conversational speech.

</details>


### [48] [PEFT-Bench: A Parameter-Efficient Fine-Tuning Methods Benchmark](https://arxiv.org/abs/2511.21285)
*Robert Belanec,Branislav Pecher,Ivan Srba,Maria Bielikova*

Main category: cs.CL

TL;DR: 本文提出了PEFT-Bench，一个用于系统评估PEFT方法的基准，并引入了综合性能指标PSCP，提升了对PEFT方法的可比性和实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在许多任务中表现优异，但由于模型规模庞大，计算和环境成本高，限制了其可用性。参数高效微调（PEFT）方法能够减少可训练参数的数量，同时保持较强的下游性能。

Method: 通过在27个NLP数据集和6种PEFT方法上实验，展示PEFT-Bench的适用性。设计PSCP指标综合考虑可训练参数、推理速度和训练内存等关键因素。

Result: 本文提出了PEFT-Bench，这是一个统一的端到端基准，用于在自回归LLM上评估多样的PEFT方法。通过27个NLP数据集和6种PEFT方法展示了其实用性。本文还提出了PEFT Soft Score Penalties（PSCP）指标，将可训练参数、推理速度和训练内存同时纳入考量。

Conclusion: PEFT-Bench为PEFT方法的评价和比较提供了标准化平台和工具，包括多维度综合性能指标，有助于推动PEFT方法的研究与应用。

Abstract: Despite the state-of-the-art performance of Large Language Models (LLMs) achieved on many tasks, their massive scale often leads to high computational and environmental costs, limiting their accessibility. Parameter-efficient fine-tuning (PEFT) methods address this challenge by reducing the number of trainable parameters while maintaining strong downstream performance. Despite the increased development in PEFT methods, current evaluations remain limited (in terms of evaluated models and datasets) and difficult to reproduce. To bridge this gap, we introduce PEFT-Bench, a unified end-to-end benchmark for evaluating diverse PEFT methods on autoregressive LLMs. We demonstrate its usage across 27 NLP datasets and 6 PEFT methods. To account for different PEFT training and inference factors, we also introduce the PEFT Soft Score Penalties (PSCP) metric, which takes trainable parameters, inference speed, and training memory usage into account.

</details>


### [49] [Emergent Lexical Semantics in Neural Language Models: Testing Martin's Law on LLM-Generated Text](https://arxiv.org/abs/2511.21334)
*Kai Kugler*

Main category: cs.CL

TL;DR: 该文系统研究了神经语言模型在训练生成文本时的Martin定律，发现规律遵循度并非随训练持续提升，而是有峰值后降低。小模型易语义崩溃，大模型表现平稳，并建立了新的评估语言结构的方法。


<details>
  <summary>Details</summary>
Motivation: 该论文关注由神经语言模型生成文本中的Martin定律（词频与多义性的经验关系），填补了该领域系统性研究的空白。其动机是探究神经语言模型在训练过程中如何遵循或偏离这一语言学规律。

Method: 作者采用DBSCAN聚类分析语境化嵌入，以此作为词义的操作定义。研究对象为四种规模的Pythia模型（70M到1B参数），并在30个训练检查点进行分析。

Result: 研究发现，Martin定律的相关性在训练早期并不明显，但在100号检查点左右出现，并在104号检查点达到峰值（r > 0.6），之后逐渐衰减。小模型在训练后期会出现语义崩溃，大模型则表现为渐进退化。词频与多义性之间的权衡关系在各模型之间保持稳定（r约为-0.3）。

Conclusion: 神经语言模型在训练过程中对语言学规律的遵循不是单调增加的，而是呈现出平衡的发展轨迹，存在一个最佳的语义窗口，并首次提出用于评估神经语言模型语言结构涌现的方法论。

Abstract: We present the first systematic investigation of Martin's Law - the empirical relationship between word frequency and polysemy - in text generated by neural language models during training. Using DBSCAN clustering of contextualized embeddings as an operationalization of word senses, we analyze four Pythia models (70M-1B parameters) across 30 training checkpoints. Our results reveal a non-monotonic developmental trajectory: Martin's Law emerges around checkpoint 100, reaches peak correlation (r > 0.6) at checkpoint 104, then degrades by checkpoint 105. Smaller models (70M, 160M) experience catastrophic semantic collapse at late checkpoints, while larger models (410M, 1B) show graceful degradation. The frequency-specificity trade-off remains stable (r $\approx$ -0.3) across all models. These findings suggest that compliance with linguistic regularities in LLM-generated text is not monotonically increasing with training, but instead follows a balanced trajectory with an optimal semantic window. This work establishes a novel methodology for evaluating emergent linguistic structure in neural language models.

</details>


### [50] [Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model](https://arxiv.org/abs/2511.21399)
*Joshua Fonseca Rivera*

Main category: cs.CL

TL;DR: 论文通过微调让大语言模型学会可靠检测自身被注入的“思想”内容，显著提升检测能力，部分实现AI可解释与透明，为自省能力的可训练性和模型间一致性提供实证。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型自省能力的可训练性，以及是否能提高模型检测自身状态信息的可靠性，回应Lindsey提出的能否通过训练消除模型间的自省行为差异这一开放问题。

Method: 对7B参数语言模型进行微调，使其识别单token注入的激活模式，并在后续生成中报告语义内容。

Result: 微调后模型准确率由0.4%提升至85%（假阳性率为0%），实现对新概念的泛化（仅有7.5个百分点差距），满足准确率、扎根性和内在性三项标准，证明部分自省能力可直接诱导。

Conclusion: 通过针对注入激活模式进行微调，可以直接训练模型内部自省能力，使其可靠检测和报告“思想”注入内容，部分实现AI透明化。

Abstract: Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected "thoughts" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model from near-complete failure (0.4% accuracy, 6.7% false positive rate) to reliable detection (85% accuracy on held-out concepts at α=40, 0% false positives). Our model detects fleeting "thoughts" injected at a single token position, retains that information, and reports the semantic content across subsequent generation steps. On this task, our trained model satisfies three of Lindsey's criteria: accuracy (correct identification), grounding (0/60 false positives), and internality (detection precedes verbalization). Generalization to unseen concept vectors (7.5pp gap) demonstrates the model learns a transferable skill rather than memorizing specific vectors, though this does not establish metacognitive representation in Lindsey's sense. These results address an open question raised by Lindsey: whether "training for introspection would help eliminate cross-model differences." We show that at least one component of introspective behavior can be directly induced, offering a pathway to built-in AI transparency.

</details>


### [51] [Can LLMs extract human-like fine-grained evidence for evidence-based fact-checking?](https://arxiv.org/abs/2511.21401)
*Antonín Jarolím,Martin Fajčík,Lucia Makaiová*

Main category: cs.CL

TL;DR: 该论文为捷克语和斯洛伐克语主张构建了人工标注的细粒度证据数据集，分析多种LLM在证据提取上的表现，发现小模型（如llama3.1:8b）能取得高正确率，而模型参数多不代表效果好，部分中等规模模型更平衡。


<details>
  <summary>Details</summary>
Motivation: 在线新闻评论区虚假信息泛滥，需要精准检测评论中的事实错误并提供支持或反驳证据。

Method: 建立一个包含捷克语和斯洛伐克语主张的细粒度证据新数据集，由人工双向标注，利用多种大型语言模型在此数据集上评估其提取证据能力及与人工标注的一致性。

Result: llama3.1:8b模型表现出较高正确率，尽管体积小；gpt-oss-120b模型参数多但效果较差；qwen3:14b、deepseek-r1:32b、gpt-oss:20b在模型规模与人工标注一致性之间表现较好。

Conclusion: 现有LLM在细粒度证据提取任务上容易不能精准复现原文证据，但较小模型也能取得高正确率；模型规模与表现并非线性相关。

Abstract: Misinformation frequently spreads in user comments under online news articles, highlighting the need for effective methods to detect factually incorrect information. To strongly support or refute claims extracted from such comments, it is necessary to identify relevant documents and pinpoint the exact text spans that justify or contradict each claim. This paper focuses on the latter task -- fine-grained evidence extraction for Czech and Slovak claims. We create new dataset, containing two-way annotated fine-grained evidence created by paid annotators. We evaluate large language models (LLMs) on this dataset to assess their alignment with human annotations. The results reveal that LLMs often fail to copy evidence verbatim from the source text, leading to invalid outputs. Error-rate analysis shows that the {llama3.1:8b model achieves a high proportion of correct outputs despite its relatively small size, while the gpt-oss-120b model underperforms despite having many more parameters. Furthermore, the models qwen3:14b, deepseek-r1:32b, and gpt-oss:20b demonstrate an effective balance between model size and alignment with human annotations.

</details>


### [52] [Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](https://arxiv.org/abs/2511.21402)
*Zhifeng Hao,Qibin Song,Ruichu Cai,Boyan Xu*

Main category: cs.CL

TL;DR: DSR-SQL是一种针对企业级复杂数据库的Text-to-SQL新方法，通过上下文与生成状态的交互，提升了语言模型推理的语义准确性和执行能力，在主流测试集上取得了领先表现，无需再训练或额外示例。


<details>
  <summary>Details</summary>
Motivation: 当前基于Chain-of-Thought（CoT）的分治推理方法显著提升了大型语言模型（LLM）的Text-to-SQL能力，但在复杂企业级数据库上，因上下文容量受限、模式链接不可靠以及数据库语义基础薄弱，导致推理不连贯，影响性能。因此，迫切需要一种新的方法以更好地解决这些瓶颈。

Method: 提出DSR-SQL（Dual-State Reasoning）框架，将Text-to-SQL任务建模为自适应上下文状态与递进生成状态的交互。自适应上下文状态通过精简和筛选大规模数据库模式，构建语义精准的上下文环境；递进生成状态将SQL生成过程形式化为反馈驱动的状态转换，允许模型自我修正以更好地契合用户意图。方法不依赖额外训练或上下文样例。

Result: 在无需后训练和上下文样例的前提下，DSR-SQL在Spider 2.0-Snow数据集上获得35.28%执行准确率，在BIRD开发集上达到68.32%，表现具有竞争力。

Conclusion: DSR-SQL有效缓解了复杂数据库下Text-to-SQL任务中的上下文限制与语义对齐难题，并在主流基准上取得了优异表现；该方法将开源，促进相关研究发展。

Abstract: Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise databases, such methods struggle to maintain coherent reasoning due to limited context capacity, unreliable schema linking, and weak grounding in database semantics. To overcome these issues, we introduce DSR-SQL, a \textbf{D}ual-\textbf{S}tate \textbf{R}easoning framework that models Text-to-SQL as an interaction between an adaptive context state and a progressive generation state. The first constructs a compact, semantically faithful environment by refining large schemas and selecting relevant structures, while the second formalizes SQL synthesis as feedback-guided state transitions, enabling the model to self-correct and align with user intent. Without any post-training or in-context examples, DSR-SQL achieves competitive performance, reaching 35.28\% execution accuracy on Spider 2.0-Snow and 68.32\% on BIRD development set. Our implementation will be open-sourced at: https://github.com/DMIRLAB-Group/DSR-SQL.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [53] [Local generation of languages](https://arxiv.org/abs/2511.21226)
*Mathieu Hoyrup*

Main category: cs.DM

TL;DR: 该文用单纯复形（一种拓扑结构）量化字符串位置间的通信需求，系统分析了产生特定语言所需的最小通信网络结构，并进行了理论应用。


<details>
  <summary>Details</summary>
Motivation: 探讨语言生成过程中，各位置间通信需求的问题，希望通过新颖的数学结构（单纯复形）来量化和分析通信机制。

Method: 将每个字符串位置视为独立实体，每个实体有自己的局部规则，并允许它们之间根据特定通信结构（用单纯复形建模）相互交流，从而生成语言元素。

Result: 发展了一套理论，能够根据语言的具体特性，确定所需的通信结构（即可用的单纯复形），并已在多种语言上进行了应用。

Conclusion: 本文提出了通过局部规制作语言元素的方法，并用单纯复形建模通信结构，以此理论刻画了可生成某类语言的通信网络结构。

Abstract: Given a language, which in this article is a set of strings of some fixed length, we study the problem of producing its elements by a procedure in which each position has its own local rule. We introduce a way of measuring how much communication is needed between positions. The communication structure is captured by a simplicial complex whose vertices are the positions and the simplices are the communication channels between positions. The main problem is then to identify the simplicial complexes that can be used to generate a given language. We develop the theory and apply it to a number of languages.

</details>


### [54] [$k$-path graphs: experiments and conjectures about algebraic connectivity and $α$-index](https://arxiv.org/abs/2511.21524)
*Rafael L. de Paula,Claudia M. Justel,Carla S. Oliveira,Milena S. Carauba*

Main category: cs.DM

TL;DR: 该论文系统探索k路径图的特征值极值问题，通过算法生成全部小规模非同构路径图并进行穷举搜索，统计极值图结构，对其拓扑与特征值关系提出新猜想。


<details>
  <summary>Details</summary>
Motivation: 探讨k-路径图关联矩阵的特征值表现，尤其关注拉普拉斯矩阵的代数连通性和Aα矩阵的最大特征值，以及这些特征值在极值图中的结构特征。此领域有关极值图结构尚有诸多未知，论文通过系统方法挖掘其中规律与猜想。

Method: 借鉴Pereira等人的生成过程，系统生成所有非同构的2-路径、3-路径和4-路径图（在不同n范围下），利用这些图进行穷举搜索，确定在固定阶数下，相关特征值达到极值的图结构，并据此做统计分析与提出猜想。

Result: 成功生成指定范围内所有非同构的小k路径图，并全面搜索获得在拉普拉斯代数连通性和Aα矩阵最大特征值下的极值图。基于这些数据，归纳出关于极值图结构的若干猜想。

Conclusion: 论文提出了关于k路径图极值性质的结构性猜想，丰富了特征值极值问题的经验基础，为后续理论证明和更大规模图的研究提供了参考。

Abstract: This work presents conjectures about eigenvalues of matrices associated with $k$-path graphs, the algebraic connectivity, defined as the second smallest eigenvalue of the Laplacian matrix, and the $α$-index, as the largest eigenvalue of the $A_α$-matrix. For this purpose, a process based in Pereira et al., is presented to generate lists of $k$-path graphs containing all non-isomorphic 2-paths, 3-paths, and 4-paths of order $n$, for $6 \leq n \leq 26, 8 \leq n \leq 19$, and $10 \leq n \leq 18$, respectively. Using these lists, exhaustive searches for extremal graphs of fixed order for the mentioned eigenvalues were performed. Based on the empirical results, conjectures are suggested about the structure of extremal $k$-path graphs for these eigenvalues.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [55] [General Decidability Results for Systems with Continuous Counters](https://arxiv.org/abs/2511.21559)
*A. R. Balasubramanian,Matthew Hague,Rupak Majumdar,Ramanathan S. Thinniyam,Georg Zetzsche*

Main category: cs.FL

TL;DR: 提出用连续计数器高效逼近离散计数器，证明相关指令序列语言正则且可有效计算，保持了系统可判定性，但自动机规模可能非常大。


<details>
  <summary>Details</summary>
Motivation: 离散计数器用于模拟和验证软件系统中的自然数计数，尤其在并发程序中建模资源的动态创建和使用。然而，这类离散计数器会导致极高的复杂性。因此，提出将离散计数器放宽为连续计数器以提升分析效率。

Method: 将原始的自然数计数器放宽为非负有理数的连续计数器，并研究其行为的可判定性，重点分析计数器指令序列语言的正则性，并给出有效计算有限自动机的方法。同时，探讨过程中产生的有限自动机规模的下界。

Result: 连续计数器尽管是无限状态系统，其到达特定配置的计数器指令序列语言是正则的，且可有效构造相应有限自动机。此外，证明了该自动机的规模存在非元素级的下界。

Conclusion: 通过连续计数器放宽，可以在保证可判定性的前提下，将此方法应用于多种系统（如高阶递归方案、结构良好的转移系统及可判定的离散计数器扩展），从而提升可达性分析效率。

Abstract: Counters that hold natural numbers are ubiquitous in modeling and verifying software systems; for example, they model dynamic creation and use of resources in concurrent programs. Unfortunately, such discrete counters often lead to extremely high complexity. Continuous counters are an efficient over-approximation of discrete counters. They are obtained by relaxing the original counters to hold values over the non-negative rational numbers.
  This work shows that continuous counters are extraordinarily well-behaved in terms of decidability. Our main result is that, despite continuous counters being infinite-state, the language of sequences of counter instructions that can arrive in a given target configuration, is regular. Moreover, a finite automaton for this language can be computed effectively. This implies that a wide variety of transition systems can be equipped with continuous counters, while maintaining decidability of reachability properties. Examples include higher-order recursion schemes, well-structured transition systems, and decidable extensions of discrete counter systems.
  We also prove a non-elementary lower bound for the size of the resulting finite automaton.

</details>
