{"id": "2510.02890", "categories": ["cs.LO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.02890", "abs": "https://arxiv.org/abs/2510.02890", "authors": ["Philippe Balbiani", "Hans van Ditmarsch", "Clara Lerouvillois"], "title": "Axiomatisation for an asynchronous epistemic logic with sending and receiving messages", "comment": null, "summary": "We investigate a public announcement logic for asynchronous public\nannouncements wherein the sending of the announcements by the environment is\nseparated from the reception of the announcements by the individual agents.\nBoth come with different modalities. In the logical semantics, formulas are\ninterpreted in a world of a Kripke model but given a history of prior\nannouncements and receptions of announcements that already happened. An\naxiomatisation AA for such a logic has been given in prior work, for the\nformulas that are valid when interpreted in the Kripke model before any such\nannouncements have taken place. This axiomatisation is a reduction system\nwherein one can show that every formula is equivalent to a purely epistemic\nformula without dynamic modalities for announcements and receptions. We propose\na generalisation AA* of this axiomatisation, for the formulas that are valid\nwhen interpreted in the Kripke model given any history of prior announcements\nand receptions of announcements. It does not extend the axiomatisation AA, for\nexample it is no longer valid that nobody has received any announcement. Unlike\nAA, this axiomatisation AA* is infinitary and it is not a reduction system.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73af\u5883\u53d1\u9001\u516c\u544a\u4e0e\u4e2a\u4f53\u5f02\u6b65\u63a5\u6536\u516c\u544a\u7684\u60c5\u5f62\uff0c\u63d0\u51fa\u4e86\u66f4\u4e00\u822c\u5316\u7684\u5f02\u6b65\u516c\u544a\u903b\u8f91\u516c\u7406\u5316\u4f53\u7cfb\uff0c\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u4e2d\u77e5\u8bc6\u52a8\u6001\u53d8\u5316\u7684\u523b\u753b\u80fd\u529b\uff0c\u4f46\u5e26\u6765\u4e86\u4f53\u7cfb\u7684\u975e\u7ea6\u5316\u6027\u548c\u65e0\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u516c\u4f17\u516c\u544a\u903b\u8f91\u5047\u8bbe\u516c\u544a\u7684\u53d1\u9001\u548c\u63a5\u6536\u662f\u540c\u6b65\u7684\uff0c\u4f46\u5b9e\u9645\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u516c\u544a\u7684\u53d1\u9001\u548c\u5404\u4e2a\u4f53\u7684\u63a5\u6536\u5f80\u5f80\u662f\u5f02\u6b65\u53d1\u751f\u7684\u3002\u8be5\u6587\u5c1d\u8bd5\u523b\u753b\u5e76\u5b8c\u5584\u63cf\u8ff0\u5f02\u6b65\u516c\u544a\u4e0b\u7684\u77e5\u8bc6\u53d8\u5316\u53ca\u5176\u516c\u7406\u5316\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e24\u79cd\u4e0d\u540c\u7684\u6a21\u6001\uff0c\u7528\u4ee5\u533a\u5206\u516c\u544a\u7684\u53d1\u9001\u4e0e\u63a5\u6536\u52a8\u4f5c\uff0c\u5e76\u57fa\u4e8eKripke\u6a21\u578b\u63d0\u51fa\u4e86\u4e00\u79cd\u63cf\u8ff0\u5386\u53f2\u516c\u544a\u4e0e\u63a5\u6536\u8fc7\u7a0b\u7684\u903b\u8f91\u8bed\u4e49\u3002\u540c\u65f6\uff0c\u5728\u5df2\u6709AA\u516c\u7406\u4f53\u7cfb\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u52a0\u4e00\u822c\u5316\u7684AA*\u516c\u7406\u4f53\u7cfb\uff0c\u5141\u8bb8\u5728\u4efb\u610f\u5386\u53f2\u516c\u544a\u63a5\u6536\u60c5\u5883\u4e0b\u63a8\u7406\u3002", "result": "AA*\u516c\u7406\u4f53\u7cfb\u80fd\u591f\u5728\u5305\u542b\u5df2\u6709\u516c\u544a\u548c\u63a5\u6536\u5386\u53f2\u7684\u66f4\u4e00\u822c\u60c5\u5883\u4e0b\u6210\u7acb\uff0c\u4f46\u5b83\u4e0d\u518d\u5982AA\u90a3\u6837\u662f\u7ea6\u5316\u4f53\u7cfb\uff0c\u4e5f\u4e0d\u518d\u9002\u7528\u4e8e\u6240\u6709\u521d\u59cb\u5047\u8bbe\u6761\u4ef6\u5982\u201c\u6ca1\u4eba\u63a5\u6536\u8fc7\u516c\u544a\u201d\u3002AA*\u8fd8\u662f\u4e2a\u65e0\u9650\u516c\u7406\u4f53\u7cfb\uff0c\u5f62\u5f0f\u4e0a\u6bd4AA\u66f4\u4e3a\u590d\u6742\u3002", "conclusion": "\u6587\u7ae0\u6269\u5c55\u4e86\u5f02\u6b65\u516c\u544a\u903b\u8f91\u7684\u516c\u7406\u4f53\u7cfb\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u4efb\u610f\u5386\u53f2\u60c5\u5883\uff0c\u52a0\u5f3a\u4e86\u5bf9\u591a\u667a\u80fd\u4f53\u540c\u6b65\u4e0e\u5f02\u6b65\u77e5\u8bc6\u52a8\u6001\u53d8\u5316\u7684\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2510.03130", "categories": ["cs.LO", "D.3.1, F.3.2, F.4.3"], "pdf": "https://arxiv.org/pdf/2510.03130", "abs": "https://arxiv.org/abs/2510.03130", "authors": ["Robin Adams"], "title": "A Graded Modal Type Theory for Pulse Schedules", "comment": "12 pages, 1 figure", "summary": "We propose a language for representing the pulse schedules that a\nsuperconducting quantum computer accepts as input. The language is a graded\nmodal type theory named PSTT (Pulse Schedule Type Theory). Graded modals type\ntheories are type systems where each variable is annotated with a parameter or\ngrade. These can be used to represent, for example, resource usage, where the\ngrade denotes how many times a given resource may be used; or privacy levels,\nwhether a resource is private or public. In this system, we use the grades to\nrepresent timing information. We give categorical semantics to the system and\nprove soundness and completeness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u63cf\u8ff0\u8d85\u5bfc\u91cf\u5b50\u8ba1\u7b97\u673a\u8109\u51b2\u8c03\u5ea6\u7684\u7c7b\u578b\u7406\u8bba\u8bed\u8a00PSTT\uff0c\u901a\u8fc7\u5f15\u5165grade\u673a\u5236\u8868\u8fbe\u65f6\u5e8f\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u76ee\u524d\u5bf9\u8d85\u5bfc\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u8109\u51b2\u8c03\u5ea6\u7f3a\u4e4f\u7cfb\u7edf\u5316\u8bed\u8a00\u63cf\u8ff0\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7cbe\u786e\u8868\u8fbe\u8d44\u6e90\u65f6\u5e8f\u4e0e\u8c03\u5ea6\u9700\u6c42\u3002", "method": "\u5229\u7528\u5206\u7ea7\u6a21\u6001\u7c7b\u578b\u7406\u8bba\uff08graded modal type theory\uff09\uff0c\u4e3a\u6bcf\u4e2a\u53d8\u91cf\u8d4b\u4e88\u53c2\u6570\uff08grade\uff09\uff0c\u4ee5\u4ee3\u8868\u65f6\u5e8f\u4fe1\u606f\uff0c\u5e76\u7ed3\u5408\u8303\u7574\u8bed\u4e49\u8fdb\u884c\u7406\u8bba\u8bc1\u660e\u3002", "result": "PSTT\u8bed\u8a00\u6709\u6548\u5730\u63cf\u8ff0\u4e86\u8109\u51b2\u8c03\u5ea6\u95ee\u9898\uff0c\u5e76\u80fd\u901a\u8fc7grade\u53c2\u6570\u5b9e\u73b0\u65f6\u5e8f\u7684\u4fe1\u606f\u8868\u8fbe\uff0c\u7406\u8bba\u4e0a\u7684\u5145\u5206\u6027\u548c\u5b8c\u5907\u6027\u4e5f\u5df2\u5f97\u5230\u8bc1\u660e\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPSTT\uff08Pulse Schedule Type Theory\uff09\u7684\u65b0\u578b\u7c7b\u578b\u7406\u8bba\u8bed\u8a00\uff0c\u53ef\u4ee5\u7528\u4e8e\u63cf\u8ff0\u8d85\u5bfc\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u8109\u51b2\u8c03\u5ea6\u8f93\u5165\uff0c\u5176\u8bed\u4e49\u5728\u8303\u7574\u8bba\u4e0b\u5f97\u5230\u89e3\u91ca\uff0c\u5e76\u8bc1\u660e\u8be5\u7cfb\u7edf\u7684\u5145\u5206\u6027\u4e0e\u5b8c\u5907\u6027\u3002"}}
{"id": "2510.03176", "categories": ["cs.DM", "cs.DS", "05C07, 68R10", "G.2.2"], "pdf": "https://arxiv.org/pdf/2510.03176", "abs": "https://arxiv.org/abs/2510.03176", "authors": ["Amotz Bar-Noy", "Igor Kalinichev", "David Peleg", "Dror Rawitz"], "title": "Optimized Degree Realization: Minimum Dominating Set & Maximum Matching", "comment": null, "summary": "The Degree Realization problem requires, given a sequence $d$ of $n$ positive\nintegers, to decide whether there exists a graph whose degrees correspond to\n$d$, and to construct such a graph if it exists. A more challenging variant of\nthe problem arises when $d$ has many different realizations, and some of them\nmay be more desirable than others. We study \\emph{optimized realization}\nproblems in which the goal is to compute a realization that optimizes some\nquality measure. Efficient algorithms are known for the problems of finding a\nrealization with the maximum clique, the maximum independent set, or the\nminimum vertex cover. In this paper, we focus on two problems for which such\nalgorithms were not known. The first is the Degree Realization with Minimum\nDominating Set problem, where the goal is to find a realization whose minimum\ndominating set is minimized among all the realizations of the given sequence\n$d$. The second is the Degree Realization with Maximum Matching problem, where\nthe goal is to find a realization with the largest matching among all the\nrealizations of $d$. We present polynomial time realization algorithms for\nthese two open problems.\n  A related problem of interest and importance is \\emph{characterizing} the\nsequences with a given value of the optimized function. This leads to an\nefficient computation of the optimized value without providing the realization\nthat achieves that value. For the Maximum Matching problem, a succinct\ncharacterization of degree sequences with a maximum matching of a given size\nwas known. This paper provides a succinct characterization of sequences with\nminimum dominating set of a given size.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u4e24\u4e2a\u6b64\u524d\u672a\u89e3\u7684\u5ea6\u6570\u5e8f\u5217\u4f18\u5316\u5b9e\u73b0\u95ee\u9898\u7684\u9ad8\u6548\u7b97\u6cd5\uff08\u5206\u522b\u9488\u5bf9\u6700\u5c0f\u652f\u914d\u96c6\u548c\u6700\u5927\u5339\u914d\uff09\uff0c\u5e76\u7ed9\u51fa\u4e86\u652f\u914d\u96c6\u89c4\u6a21\u7684\u5ea6\u6570\u5e8f\u5217\u5224\u5b9a\u7684\u6807\u51c6\uff0c\u5bf9\u56fe\u8bba\u4f18\u5316\u95ee\u9898\u7684\u5b9e\u9645\u6c42\u89e3\u5177\u6709\u63a8\u52a8\u610f\u4e49\u3002", "motivation": "\u7ed9\u5b9a\u4e00\u4e2a\u5ea6\u6570\u5e8f\u5217\uff0c\u627e\u5230\u5bf9\u5e94\u56fe\u7684\u6784\u9020\u95ee\u9898\u5728\u56fe\u8bba\u4e2d\u975e\u5e38\u7ecf\u5178\uff0c\u4f46\u5f53\u8be5\u5e8f\u5217\u5bf9\u5e94\u591a\u4e2a\u4e0d\u540c\u7684\u56fe\u65f6\uff0c\u67d0\u4e9b\u7279\u5b9a\u6027\u8d28\uff08\u5982\u6700\u5927\u56e2\u3001\u6700\u5927\u72ec\u7acb\u96c6\u3001\u6700\u5c0f\u70b9\u8986\u76d6\u7b49\uff09\u7684\u2018\u4f18\u5316\u5b9e\u73b0\u2019\u95ee\u9898\u66f4\u5177\u6311\u6218\u6027\u3002\u5bf9\u4e8e\u6700\u5c0f\u652f\u914d\u96c6\u548c\u6700\u5927\u5339\u914d\u4e24\u4e2a\u6027\u8d28\uff0c\u76ee\u524d\u8fd8\u6ca1\u6709\u9ad8\u6548\u7b97\u6cd5\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e24\u4e2a\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u4e13\u6ce8\u4e8e\u5f00\u53d1\u4e24\u7c7b\u4f18\u5316\u5b9e\u73b0\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff1a\u4e00\u662f\u6700\u5c0f\u652f\u914d\u96c6\u4f18\u5316\u5b9e\u73b0\uff08\u5728\u6240\u6709\u53ef\u80fd\u5bf9\u5e94\u7684\u56fe\u4e2d\uff0c\u652f\u914d\u96c6\u6700\u5c0f\uff09\uff0c\u4e8c\u662f\u6700\u5927\u5339\u914d\u4f18\u5316\u5b9e\u73b0\uff08\u5728\u6240\u6709\u53ef\u80fd\u7684\u56fe\u4e2d\uff0c\u6700\u5927\u5339\u914d\u6700\u5927\uff09\u3002\u540c\u65f6\uff0c\u5bf9\u6240\u6709\u652f\u914d\u96c6\u6700\u5c0f\u503c\u8fbe\u5230\u7ed9\u5b9a\u89c4\u6a21\u7684\u5ea6\u6570\u5e8f\u5217\u8fdb\u884c\u4e86\u523b\u753b\u5206\u6790\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5206\u522b\u7528\u4e8e\u6700\u5c0f\u652f\u914d\u96c6\u4f18\u5316\u5b9e\u73b0\u53ca\u6700\u5927\u5339\u914d\u4f18\u5316\u5b9e\u73b0\u3002\u8fd9\u6709\u6548\u89e3\u51b3\u4e86\u6b64\u524d\u8fd9\u4e24\u7c7b\u5ea6\u6570\u5e8f\u5217\u4f18\u5316\u5b9e\u73b0\u95ee\u9898\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002\u540c\u65f6\uff0c\u7ed9\u51fa\u4e86\u652f\u914d\u96c6\u6700\u5c0f\u503c\u4e3a\u7ed9\u5b9a\u5927\u5c0f\u65f6\u7684\u5ea6\u6570\u5e8f\u5217\u5224\u5b9a\u7684\u7b80\u6d01\u523b\u753b\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e24\u4e2a\u5ea6\u6570\u5e8f\u5217\u4f18\u5316\u5b9e\u73b0\u7684\u516c\u5f00\u95ee\u9898\uff08\u6700\u5c0f\u652f\u914d\u96c6\u3001\u6700\u5927\u5339\u914d\uff09\u63d0\u4f9b\u4e86\u9ad8\u6548\u7b97\u6cd5\uff0c\u5e76\u8fdb\u4e00\u6b65\u5bf9\u6700\u5c0f\u652f\u914d\u96c6\u89c4\u6a21\u7684\u5ea6\u6570\u5e8f\u5217\u8fdb\u884c\u4e86\u7ec6\u81f4\u523b\u753b\uff0c\u5bf9\u76f8\u5173\u9886\u57df\u7684\u4f18\u5316\u7b97\u6cd5\u4e0e\u7406\u8bba\u5206\u6790\u6709\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2510.02579", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.02579", "abs": "https://arxiv.org/abs/2510.02579", "authors": ["Santiago Cu\u00e9llar", "Naomi Spargo", "Jonathan Daugherty", "David Darais"], "title": "Designing Walrus: Relational Programming with Rich Types, On-Demand Laziness, and Structured Traces", "comment": "20 pages, miniKanren 2025", "summary": "We present Walrus, a functional relational programming language embedded in\nHaskell that extends the miniKanren model with type-polymorphic unification,\non-demand laziness, and a range of usability features aimed at practical\ndevelopment. These include use of Haskell Generics for boilerplate reduction,\nstructured debugging traces, and ergonomic support for product types. We\ndescribe the design and implementation of Walrus through the lens of our\nexperience developing bidirectional compilers, and reflect on key design\ndecisions and recurring usability challenges encountered in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5d4c\u5165\u4e8eHaskell\u7684\u529f\u80fd\u5173\u7cfb\u7f16\u7a0b\u8bed\u8a00Walrus\uff0c\u76f8\u8f83\u4f20\u7edfminiKanren\u6a21\u578b\uff0c\u5728\u7c7b\u578b\u7edf\u4e00\u3001\u60f0\u6027\u8ba1\u7b97\u3001\u8c03\u8bd5\u8ffd\u8e2a\u3001\u4ee3\u7801\u7b80\u5316\u548c\u4ea7\u54c1\u7c7b\u578b\u652f\u6301\u7b49\u65b9\u9762\u5927\u5e45\u63d0\u5347\u4e86\u53ef\u7528\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u7f16\u8bd1\u5668\u5f00\u53d1\u5e94\u7528\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u548c\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684miniKanren\u6a21\u578b\u5728\u529f\u80fd\u5173\u7cfb\u7f16\u7a0b\u4e2d\u5b58\u5728\u7c7b\u578b\u4e0d\u7075\u6d3b\u3001\u4ee3\u7801\u6a21\u677f\u7e41\u7410\u548c\u8c03\u8bd5\u4e0d\u4fbf\u7b49\u5b9e\u9645\u5f00\u53d1\u5c40\u9650\u3002\u4f5c\u8005\u65e8\u5728\u6539\u8fdb\u7f16\u7a0b\u4f53\u9a8c\uff0c\u4f7f\u8be5\u8303\u5f0f\u5bf9\u5b9e\u9645\u5e94\u7528\u66f4\u5177\u53ef\u7528\u6027\u3002", "method": "\u5728Haskell\u4e2d\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86Walrus\u8bed\u8a00\uff0c\u901a\u8fc7\u5f15\u5165\u7c7b\u578b\u591a\u6001\u7edf\u4e00\uff08type-polymorphic unification\uff09\u3001\u6309\u9700\u60f0\u6027\uff08on-demand laziness\uff09\u4ee5\u53ca\u4e30\u5bcc\u7684\u53ef\u7528\u6027\u65b9\u6848\uff08\u5982Haskell Generics\u51cf\u5c11\u6837\u677f\u4ee3\u7801\u3001\u7ed3\u6784\u5316\u8c03\u8bd5\u3001\u4ea7\u7269\u7c7b\u578b\u7684\u53cb\u597d\u652f\u6301\uff09\uff0c\u5e76\u7ed3\u5408\u5b9e\u9645\u6784\u5efa\u53cc\u5411\u7f16\u8bd1\u5668\u7684\u7ecf\u9a8c\u9a8c\u8bc1\u5176\u8bbe\u8ba1\u548c\u5b9e\u7528\u6027\u3002", "result": "Walrus\u663e\u8457\u63d0\u5347\u4e86miniKanren\u6a21\u578b\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u6613\u7528\u6027\u3002\u5b9e\u9645\u5f00\u53d1\u53cc\u5411\u7f16\u8bd1\u5668\u8fc7\u7a0b\u4e2d\uff0c\u9a8c\u8bc1\u4e86\u5176\u7c7b\u578b\u7cfb\u7edf\u3001\u8c03\u8bd5\u80fd\u529b\u548c\u4ee3\u7801\u7b80\u5316\u7279\u6027\u7684\u6709\u6548\u6027\uff0c\u4f46\u4e5f\u603b\u7ed3\u4e86\u90e8\u5206\u8bbe\u8ba1\u548c\u53ef\u7528\u6027\u4e0a\u7684\u6311\u6218\u3002", "conclusion": "Walrus\u5728\u4fdd\u6709miniKanren\u8303\u5f0f\u5f3a\u5927\u8868\u8fbe\u529b\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u591a\u9879\u529f\u80fd\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9762\u5411\u5b9e\u9645\u529f\u80fd\u5173\u7cfb\u7a0b\u5e8f\u5f00\u53d1\u7684\u53ef\u7528\u6027\u548c\u4fbf\u5229\u6027\uff0c\u4e3a\u7c7b\u4f3c\u7cfb\u7edf\u8bbe\u8ba1\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2510.02324", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02324", "abs": "https://arxiv.org/abs/2510.02324", "authors": ["Wannan Yang", "Xinchi Qiu", "Lei Yu", "Yuchen Zhang", "Oliver Aobo Yang", "Narine Kokhlikyan", "Nicola Cancedda", "Diego Garcia-Olano"], "title": "Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning", "comment": null, "summary": "Large Language Models (LLMs) exhibit impressive capabilities but often\nhallucinate, confidently providing incorrect answers instead of admitting\nignorance. Prior work has shown that models encode linear representations of\ntheir own knowledge and that activation steering can reduce hallucinations.\nThese approaches, however, require real-time monitoring and intervention during\ninference. We introduce Contrastive Activation Steering for Amortized Learning\n(CASAL), an efficient algorithm that connects interpretability with amortized\noptimization. CASAL directly bakes the benefits of activation steering into\nmodel's weights. Once trained, LLMs answer questions they know while abstaining\nfrom answering those they do not. CASAL's light-weight design requires training\nonly a submodule of a single transformer layer and yet reduces hallucination by\n30%-40% across multiple short-form QA benchmarks. CASAL is 30x more\ncompute-efficient and 20x more data-efficient than strong LoRA-based baselines\nsuch as SFT and DPO, boosting its practical applicability in data scarce\ndomains. Importantly, CASAL also generalizes effectively to out-of-distribution\n(OOD) domains. We showcase CASAL's flexibility in mitigating hallucinations in\nboth text-only and vision-language models. To our knowledge, CASAL is the first\nsteering-based training method that has been shown to be effective for both\ndense and Mixture-of-Experts (MoE) models. CASAL represents a promising step\nforward for applying interpretability-inspired method for practical deployment\nin production systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CASAL\u7b97\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6fc0\u6d3b\u5f15\u5bfc\u8bad\u7ec3\uff0c\u80fd\u9ad8\u6548\u964d\u4f4eLLM\u5e7b\u89c9\uff0c\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u573a\u666f\u548c\u6a21\u578b\u7c7b\u578b\uff0c\u5177\u5907\u5f3a\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5728\u4e0d\u77e5\u9053\u7b54\u6848\u65f6\u4ecd\u7ecf\u5e38\u81ea\u4fe1\u5730\u7ed9\u51fa\u9519\u8bef\u56de\u7b54\uff08\u5e7b\u89c9\uff09\uff0c\u800c\u4e0d\u662f\u627f\u8ba4\u4e0d\u77e5\u9053\u3002\u4ee5\u5f80\u7684\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u51cf\u5c11\u5e7b\u89c9\uff0c\u4f46\u9700\u8981\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u76d1\u63a7\u548c\u5e72\u9884\uff0c\u5b9e\u9645\u5e94\u7528\u8f83\u4e3a\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u5bf9\u6bd4\u6fc0\u6d3b\u5f15\u5bfc\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7b97\u6cd5\uff08CASAL\uff09\uff0c\u5c06\u6fc0\u6d3b\u5f15\u5bfc\u7684\u4f18\u52bf\u76f4\u63a5\u6574\u5408\u8fdb\u6a21\u578b\u6743\u91cd\u3002\u8bad\u7ec3\u65f6\u4ec5\u9700\u5fae\u8c03\u5355\u4e2a transformer \u5c42\u7684\u4e00\u4e2a\u5b50\u6a21\u5757\u3002\u65e0\u9700\u5b9e\u65f6\u5e72\u9884\uff0c\u65b9\u6cd5\u8f7b\u91cf\u9ad8\u6548\u3002", "result": "CASAL\u53ef\u4f7f\u6a21\u578b\u5728\u77e5\u9053\u7b54\u6848\u65f6\u4f5c\u7b54\uff0c\u4e0d\u77e5\u9053\u65f6\u9009\u62e9\u56de\u907f\u3002\u76f8\u6bd4\u5f3aLORA\u57fa\u7ebf\u5982SFT\u548cDPO\uff0cCASAL\u5728\u77ed\u6587\u672cQA\u57fa\u51c6\u4e0a\u53ef\u5c06\u5e7b\u89c9\u7387\u964d\u4f4e30%-40%\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u534730\u500d\uff0c\u6570\u636e\u6548\u7387\u63d0\u534720\u500d\u3002\u5728\u6587\u672c\u548c\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4ee5\u53caOOD\u573a\u666f\u5747\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CASAL\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u91ca\u6027\u9a71\u52a8\u8bad\u7ec3\u65b9\u6cd5\uff0c\u65e2\u53ef\u51cf\u5c11LLM\u5e7b\u89c9\uff0c\u53c8\u5229\u4e8e\u5728\u5b9e\u9645\u751f\u4ea7\u7cfb\u7edf\u4e2d\u843d\u5730\u90e8\u7f72\uff0c\u5e76\u9996\u6b21\u5728\u7a20\u5bc6\u4e0e\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u6a21\u578b\u4e0a\u90fd\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.02387", "categories": ["cs.SE", "cs.AI", "cs.LG", "68T07", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.02387", "abs": "https://arxiv.org/abs/2510.02387", "authors": ["FAIR CodeGen team", "Quentin Carbonneaux", "Gal Cohen", "Jonas Gehring", "Jacob Kahn", "Jannik Kossen", "Felix Kreuk", "Emily McMilin", "Michel Meyer", "Yuxiang Wei", "David Zhang", "Kunhao Zheng", "Jordi Armengol-Estap\u00e9", "Pedram Bashiri", "Maximilian Beck", "Pierre Chambon", "Abhishek Charnalia", "Chris Cummins", "Juliette Decugis", "Zacharias V. Fisches", "Fran\u00e7ois Fleuret", "Fabian Gloeckle", "Alex Gu", "Michael Hassid", "Daniel Haziza", "Badr Youbi Idrissi", "Christian Keller", "Rahul Kindi", "Hugh Leather", "Gallil Maimon", "Aram Markosyan", "Francisco Massa", "Pierre-Emmanuel Mazar\u00e9", "Vegard Mella", "Naila Murray", "Keyur Muzumdar", "Peter O'Hearn", "Matteo Pagliardini", "Dmitrii Pedchenko", "Tal Remez", "Volker Seeker", "Marco Selvi", "Oren Sultan", "Sida Wang", "Luca Wehrstedt", "Ori Yoran", "Lingming Zhang", "Taco Cohen", "Yossi Adi", "Gabriel Synnaeve"], "title": "CWM: An Open-Weights LLM for Research on Code Generation with World Models", "comment": "58 pages", "summary": "We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,\nto advance research on code generation with world models. To improve code\nunderstanding beyond what can be learned from training on static code alone, we\nmid-train CWM on a large amount of observation-action trajectories from Python\ninterpreter and agentic Docker environments, and perform extensive multi-task\nreasoning RL in verifiable coding, math, and multi-turn software engineering\nenvironments. With CWM, we provide a strong testbed for researchers to explore\nthe opportunities world modeling affords for improving code generation with\nreasoning and planning in computational environments. We present first steps of\nhow world models can benefit agentic coding, enable step-by-step simulation of\nPython code execution, and show early results of how reasoning can benefit from\nthe latter. CWM is a dense, decoder-only LLM trained with a context size of up\nto 131k tokens. Independent of its world modeling capabilities, CWM offers\nstrong performance on general coding and math tasks: it reaches pass@1 scores\nof 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on\nLiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further\nresearch on code world modeling, we release model checkpoints after\nmid-training, SFT, and RL.", "AI": {"tldr": "CWM\u662f\u4e00\u4e2a\u89c4\u6a21\u5e9e\u5927\u7684\u5f00\u6e90\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u73af\u5883\u4e0b\u7684\u4e2d\u671f\u8bad\u7ec3\u548c\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u7f16\u7801\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u591a\u9879\u4ee3\u7801\u3001\u6570\u5b66\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\uff0c\u6a21\u578b\u6743\u91cd\u5f00\u653e\u52a9\u529b\u540e\u7eed\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u6a21\u578b\u4e3b\u8981\u4f9d\u9760\u9759\u6001\u4ee3\u7801\u8bad\u7ec3\uff0c\u7f3a\u4e4f\u5b9e\u9645\u73af\u5883\u4e0b\u7684\u4ea4\u4e92\u53ca\u63a8\u7406\u80fd\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u4e16\u754c\u6a21\u578b\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u7406\u89e3\u4e0e\u63a8\u7406\u8868\u73b0\uff0c\u8d4b\u80fd\u667a\u80fd\u4f53\u81ea\u4e3b\u7f16\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86Code World Model (CWM)\uff0c\u4e00\u4e2a\u62e5\u6709320\u4ebf\u53c2\u6570\u7684\u5f00\u653e\u6743\u91cd\u5927\u8bed\u8a00\u6a21\u578b\u3002\u901a\u8fc7\u5728Python\u89e3\u91ca\u5668\u548cDocker\u73af\u5883\u7684\u89c2\u5bdf-\u884c\u52a8\u8f68\u8ff9\u4e0a\u8fdb\u884c\u4e2d\u671f\u8bad\u7ec3\uff0c\u5e76\u91c7\u7528\u591a\u4efb\u52a1\u63a8\u7406\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff08\u6db5\u76d6\u53ef\u9a8c\u8bc1\u7f16\u7a0b\u3001\u6570\u5b66\u3001\u591a\u8f6e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff09\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u52a8\u6001\u6267\u884c\u73af\u5883\u7684\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\u3002\u6a21\u578b\u91c7\u7528\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u652f\u6301\u6700\u591a131k\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "result": "CWM\u5728\u4e00\u822c\u7f16\u7801\u548c\u6570\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff1aSWE-bench Verified\uff08pass@1\uff09\u5f97\u520665.8%\uff0cLiveCodeBench 68.6%\uff0cMath-500 96.6%\uff0cAIME 2024 76.0%\u3002\u6b64\u5916\uff0c\u5c55\u793a\u4e86\u5229\u7528\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u9010\u6b65\u4ee3\u7801\u6267\u884c\u6a21\u62df\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u521d\u6b65\u7ed3\u679c\uff0c\u76f8\u5173\u6a21\u578b\u6743\u91cd\u4e5f\u5f00\u653e\u53d1\u5e03\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e16\u754c\u6a21\u578b\u4e0e\u590d\u6742\u73af\u5883\u63a8\u7406\u8bad\u7ec3\uff0cCWM\u4e0d\u4ec5\u5728\u4f20\u7edf\u7f16\u7801\u53ca\u6570\u5b66\u4efb\u52a1\u4e0a\u53d6\u5f97\u9ad8\u5206\uff0c\u66f4\u4e3a\u667a\u80fd\u4f53\u81ea\u4e3b\u7f16\u7a0b\u53ca\u4ee3\u7801\u63a8\u7406\u63a2\u7d22\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6709\u671b\u63a8\u52a8\u76f8\u5173\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.03170", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.03170", "abs": "https://arxiv.org/abs/2510.03170", "authors": ["Rafaello Sanna", "William E. Byrd", "Nada Amin"], "title": "Beyond Cons: Purely Relational Data Structures", "comment": "17 pages, 6 figures, Source code available at\n  https://www.github.com/rvs314/faster-clpset-minikanren . To be published in\n  the 7th Workshop on miniKanren and Relational Programming (miniKanren'25)", "summary": "We present {Kanren} (read: set-Kanren), an extension to miniKanren with\nconstraints for reasoning about sets and association lists. {Kanren} includes\nfirst-class set objects, a functionally complete family of set-theoretic\nconstraints (including membership, union, and disjointedness), and new\nconstraints for reasoning about association lists with shadowing and scoped\nlookup. These additions allow programmers to describe collections declaratively\nand lazily, without relying on structural encodings and eager search over\nrepresentation spaces. The result is improved expressiveness and operational\nbehavior in programs that manipulate abstract data -- particularly interpreters\n-- by supporting set equality based on contents, enabling finite failure. We\ndescribe the design and implementation of {Kanren} in a constraint-enabled\nminiKanren system and illustrate its use in representative examples.", "AI": {"tldr": "{Kanren} \u6269\u5c55 miniKanren\uff0c\u52a0\u4e86\u96c6\u5408\u548c\u5173\u8054\u5217\u8868\u7684\u7ea6\u675f\uff0c\u80fd\u66f4\u9ad8\u6548\u8868\u8fbe\u548c\u64cd\u4f5c\u62bd\u8c61\u6570\u636e\u7ed3\u6784\uff0c\u63d0\u5347\u903b\u8f91\u7a0b\u5e8f\u7684\u8868\u8fbe\u529b\u548c\u6027\u80fd\uff0c\u5c24\u5176\u9002\u5408\u5904\u7406\u96c6\u5408\u5185\u5bb9\u76f8\u7b49\u7684\u573a\u666f\u3002", "motivation": "miniKanren \u5728\u5904\u7406\u96c6\u5408\u548c\u5173\u8054\u5217\u8868\u7b49\u62bd\u8c61\u6570\u636e\u65f6\uff0c\u539f\u6709\u673a\u5236\uff08\u5982\u7ed3\u6784\u7f16\u7801\u548c\u6025\u5207\u641c\u7d22\uff09\u8868\u73b0\u51fa\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u3001\u8868\u8fbe\u6027\u66f4\u5f3a\u7684\u65b9\u5f0f\u6765\u58f0\u660e\u548c\u64cd\u4f5c\u8fd9\u4e9b\u6570\u636e\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u540d\u4e3a {Kanren} \u7684\u65b0\u7cfb\u7edf\uff0c\u5411 miniKanren \u6269\u5c55\u4e86\u5bf9\u96c6\u5408\u4e0e\u5173\u8054\u5217\u8868\u7684\u7ea6\u675f\u652f\u6301\u3002\u65b0\u589e\u4e86\u4e00\u6574\u5957\u96c6\u5408\u7ea6\u675f\uff08\u5982\u6210\u5458\u3001\u5e76\u96c6\u3001\u4e0d\u76f8\u4ea4\uff09\u53ca\u5bf9\u5173\u8054\u5217\u8868\uff08\u652f\u6301\u5c4f\u853d\u4e0e\u4f5c\u7528\u57df\u67e5\u627e\uff09\u7684\u7ea6\u675f\uff0c\u76f8\u5173\u8bbe\u8ba1\u548c\u5b9e\u73b0\u5747\u57fa\u4e8e\u7ea6\u675f\u589e\u5f3a\u7248\u7684 miniKanren\u3002", "result": "{Kanren} \u5141\u8bb8\u7a0b\u5e8f\u5458\u4ee5\u58f0\u660e\u5f0f\u3001\u60f0\u6027\u65b9\u5f0f\u63cf\u8ff0\u96c6\u5408\u53ca\u5173\u8054\u5217\u8868\uff0c\u4e0d\u5fc5\u4f9d\u8d56\u7ed3\u6784\u7f16\u7801\u6216\u6025\u5207\u641c\u7d22\uff0c\u63d0\u5347\u4e86\u7a0b\u5e8f\u7684\u8868\u8fbe\u80fd\u529b\u548c\u8fd0\u884c\u6027\u80fd\uff0c\u5c24\u5176\u5728\u5b9e\u73b0\u89e3\u91ca\u5668\u7b49\u62bd\u8c61\u6570\u636e\u64cd\u4f5c\u4e2d\u6548\u679c\u660e\u663e\u3002\u5176\u96c6\u5408\u76f8\u7b49\u57fa\u4e8e\u5185\u5bb9\u5224\u5b9a\uff0c\u652f\u6301\u6709\u9650\u5931\u8d25\u673a\u5236\u3002\u901a\u8fc7\u5178\u578b\u4f8b\u5b50\u8bf4\u660e\u5176\u5b9e\u9645\u7528\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5411 miniKanren \u5f15\u5165\u96c6\u5408\u4e0e\u5173\u8054\u5217\u8868\u7ea6\u675f\uff0c{Kanren} \u663e\u8457\u63d0\u5347\u4e86\u58f0\u660e\u6027\u903b\u8f91\u7f16\u7a0b\u4e2d\u64cd\u4f5c\u62bd\u8c61\u6570\u636e\u7684\u80fd\u529b\u4e0e\u8fd0\u884c\u6548\u7387\uff0c\u7279\u522b\u9002\u5408\u5bf9\u96c6\u5408\u8bed\u4e49\u654f\u611f\u7684\u9886\u57df\uff0c\u5982\u89e3\u91ca\u5668\u5b9e\u73b0\u3002"}}
{"id": "2510.02326", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02326", "abs": "https://arxiv.org/abs/2510.02326", "authors": ["Vivek Bhavsar", "Joseph Ereifej", "Aravanan Gurusami"], "title": "Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval", "comment": "21 pages, 5 figures", "summary": "Large language models accelerate literature synthesis but can hallucinate and\nmis-cite, limiting their usefulness in expert workflows. We present RA-FSM\n(Research Assistant - Finite State Machine), a modular GPT-based research\nassistant that wraps generation in a finite-state control loop: Relevance ->\nConfidence -> Knowledge. The system is grounded in vector retrieval and a\ndeterministic citation pipeline. The controller filters out-of-scope queries,\nscores answerability, decomposes questions, and triggers retrieval only when\nneeded, and emits answers with confidence labels and in-corpus, de-duplicated\nreferences. A ranked-tier ingestion workflow constructs a domain knowledge base\nfrom journals, conferences, indices, preprints, and patents, writing both to a\ndense vector index and to a relational store of normalized metrics. We\nimplement the system for photonics and evaluate it on six task categories:\nanalytical reasoning, numerical analysis, methodological critique, comparative\nsynthesis, factual extraction, and application design. In blinded A/B reviews,\ndomain experts prefer RA-FSM to both a strong Notebook LM (NLM) and a vanilla\nDefault GPT API call single-pass baseline, citing stronger boundary-condition\nhandling and more defensible evidence use. Coverage and novelty analyses\nindicate that RA-FSM explores beyond the NLM while incurring tunable latency\nand cost overheads. The design emphasizes transparent, well-cited answers for\nhigh-stakes technical work and is generalizable to other scientific domains.", "AI": {"tldr": "RA-FSM\u901a\u8fc7\u6709\u9650\u72b6\u6001\u63a7\u5236\u4e0e\u68c0\u7d22\u589e\u5f3a\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u79d1\u7814\u9886\u57df\u7684\u56de\u5e94\u53ef\u9760\u6027\u4e0e\u6587\u732e\u5f15\u7528\u51c6\u786e\u6027\uff0c\u88ab\u4e13\u5bb6\u8ba4\u4e3a\u4f18\u4e8e\u4f20\u7edfNotebook LM\u4e0e\u57fa\u7ebf\u6a21\u578b\uff0c\u5177\u5907\u5e7f\u6cdb\u63a8\u5e7f\u4ef7\u503c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u52a0\u901f\u6587\u732e\u7efc\u8ff0\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u548c\u9519\u8bef\u5f15\u7528\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e13\u5bb6\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u3002\u8be5\u7814\u7a76\u8bd5\u56fe\u63d0\u5347LLM\u5728\u79d1\u5b66\u7814\u7a76\u9886\u57df\u7684\u53ef\u9760\u6027\u548c\u5f15\u8bc1\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684GPT\u578b\u7814\u7a76\u52a9\u624b\uff08RA-FSM\uff09\uff0c\u5c06\u751f\u6210\u8fc7\u7a0b\u5305\u88f9\u5728\u6709\u9650\u72b6\u6001\u63a7\u5236\u73af\u8def\u4e2d\uff08\u76f8\u5173\u6027-> \u7f6e\u4fe1\u5ea6-> \u77e5\u8bc6\uff09\u3002\u7cfb\u7edf\u7ed3\u5408\u5411\u91cf\u68c0\u7d22\u4e0e\u786e\u5b9a\u6027\u5f15\u7528\u6d41\u7a0b\uff0c\u901a\u8fc7\u6709\u9650\u72b6\u6001\u673a\u63a7\u5236\u67e5\u8be2\u8fc7\u6ee4\u3001\u95ee\u9898\u5206\u89e3\u3001\u68c0\u7d22\u89e6\u53d1\u7b49\uff0c\u540c\u65f6\u751f\u6210\u5e26\u6709\u7f6e\u4fe1\u5ea6\u6807\u7b7e\u5e76\u53bb\u91cd\u7684\u6587\u732e\u5f15\u7528\u3002\u77e5\u8bc6\u5e93\u4ee5\u591a\u6e90\u6e20\u9053\u6784\u5efa\uff0c\u5305\u62ec\u671f\u520a\u3001\u4f1a\u8bae\u3001\u4e13\u5229\u7b49\uff0c\u5e76\u5199\u5165\u5411\u91cf\u7d22\u5f15\u548c\u7ed3\u6784\u5316\u6570\u636e\u5e93\u3002\u7cfb\u7edf\u9488\u5bf9\u5149\u5b50\u5b66\u9886\u57df\uff0c\u5728\u516d\u7c7b\u4efb\u52a1\u4e2d\u4e0eNotebook LM\u53caGPT\u57fa\u7ebf\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u6d4b\u3002", "result": "\u5728\u76f2\u6d4bA/B\u6d4b\u8bd5\u4e2d\uff0c\u9886\u57df\u4e13\u5bb6\u66f4\u559c\u6b22RA-FSM\u7cfb\u7edf\uff0c\u8ba4\u4e3a\u5176\u8fb9\u754c\u6761\u4ef6\u5904\u7406\u66f4\u4f18\u4e14\u5f15\u7528\u53ef\u9760\u6027\u66f4\u9ad8\u3002\u7cfb\u7edf\u80fd\u591f\u5728\u4fdd\u8bc1\u5ef6\u8fdf\u548c\u6210\u672c\u53ef\u8c03\u63a7\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u4f20\u7edfNotebook LM\u5177\u5907\u66f4\u5f3a\u7684\u63a2\u7d22\u4e0e\u53d1\u73b0\u80fd\u529b\u3002", "conclusion": "RA-FSM \u80fd\u591f\u4e3a\u9ad8\u8981\u6c42\u7684\u6280\u672f\u9886\u57df\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u6eaf\u6e90\u7684\u7b54\u6848\uff0c\u4e14\u7cfb\u7edf\u8bbe\u8ba1\u5177\u5907\u5411\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u6cdb\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.02389", "categories": ["cs.SE", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02389", "abs": "https://arxiv.org/abs/2510.02389", "authors": ["Haoran Xi", "Minghao Shao", "Brendan Dolan-Gavitt", "Muhammad Shafique", "Ramesh Karri"], "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization", "comment": null, "summary": "Large language models show promise for vulnerability discovery, yet\nprevailing methods inspect code in isolation, struggle with long contexts, and\nfocus on coarse function- or file-level detections - offering limited\nactionable guidance to engineers who need precise line-level localization and\ntargeted patches in real-world software development. We present T2L-Agent\n(Trace-to-Line Agent), a project-level, end-to-end framework that plans its own\nanalysis and progressively narrows scope from modules to exact vulnerable\nlines. T2L-Agent couples multi-round feedback with an Agentic Trace Analyzer\n(ATA) that fuses runtime evidence - crash points, stack traces, and coverage\ndeltas - with AST-based code chunking, enabling iterative refinement beyond\nsingle pass predictions and translating symptoms into actionable, line-level\ndiagnoses. To benchmark line-level vulnerability discovery, we introduce\nT2L-ARVO, a diverse, expert-verified 50-case benchmark spanning five crash\nfamilies and real-world projects. T2L-ARVO is specifically designed to support\nboth coarse-grained detection and fine-grained localization, enabling rigorous\nevaluation of systems that aim to move beyond file-level predictions. On\nT2L-ARVO, T2L-Agent achieves up to 58.0% detection and 54.8% line-level\nlocalization, substantially outperforming baselines. Together, the framework\nand benchmark push LLM-based vulnerability detection from coarse identification\ntoward deployable, robust, precision diagnostics that reduce noise and\naccelerate patching in open-source software workflows.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86T2L-Agent\uff0c\u4e00\u79cd\u53ef\u9488\u5bf9\u9879\u76ee\u5b9e\u73b0\u7aef\u5230\u7aef\u3001\u884c\u7ea7\u6f0f\u6d1e\u5b9a\u4f4d\u7684AI\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86T2L-ARVO\u57fa\u51c6\u8fdb\u884c\u8bc4\u6d4b\u3002\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u9886\u5148\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u7cbe\u51c6\u3001\u66f4\u9ad8\u6548\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u4fee\u590d\u3002", "motivation": "\u76ee\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u53d1\u73b0\u4ee3\u7801\u6f0f\u6d1e\u65b9\u9762\u5c55\u793a\u4e86\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u591a\u662f\u5bf9\u5b64\u7acb\u7684\u4ee3\u7801\u8fdb\u884c\u5206\u6790\uff0c\u96be\u4ee5\u5904\u7406\u957f\u4e0a\u4e0b\u6587\uff0c\u4e14\u591a\u805a\u7126\u4e8e\u51fd\u6570\u6216\u6587\u4ef6\u7ea7\u522b\u7684\u7c97\u7565\u68c0\u6d4b\uff0c\u96be\u4ee5\u4e3a\u5de5\u7a0b\u5e08\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u63d0\u4f9b\u7cbe\u786e\u884c\u7ea7\u5b9a\u4f4d\u548c\u9488\u5bf9\u6027\u4fee\u590d\u65b9\u6848\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u5b9e\u73b0\u7cbe\u7ec6\u7c92\u5ea6\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u5efa\u8bae\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86T2L-Agent\uff08Trace-to-Line Agent\uff09\u6846\u67b6\uff0c\u652f\u6301\u9879\u76ee\u7ea7\u3001\u7aef\u5230\u7aef\u7684\u6f0f\u6d1e\u53d1\u73b0\u5206\u6790\u3002\u5176\u901a\u8fc7\u81ea\u8eab\u89c4\u5212\u5206\u6790\u6d41\u7a0b\u3001\u9010\u6b65\u7f29\u5c0f\u8303\u56f4\uff0c\u4ece\u6a21\u5757\u7ea7\u5230\u5177\u4f53\u5b58\u5728\u6f0f\u6d1e\u7684\u4ee3\u7801\u884c\u3002T2L-Agent\u7ed3\u5408\u591a\u8f6e\u53cd\u9988\u673a\u5236\u53caAgentic Trace Analyzer\uff08ATA\uff09\uff0c\u5c06\u8fd0\u884c\u65f6\u8bc1\u636e\uff08\u5982\u5d29\u6e83\u70b9\u3001\u5806\u6808\u8ffd\u8e2a\u3001\u8986\u76d6\u7387\u53d8\u5316\u7b49\uff09\u4e0e\u57fa\u4e8eAST\u7684\u4ee3\u7801\u5206\u5757\u878d\u5408\uff0c\u5b9e\u73b0\u8fed\u4ee3\u4f18\u5316\uff0c\u80fd\u591f\u5c06\u51fa\u73b0\u7684\u5f02\u5e38\u75c7\u72b6\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u884c\u7ea7\u8bca\u65ad\u3002\u5e76\u5f15\u5165\u4e86\u65b0\u57fa\u51c6\u96c6T2L-ARVO\uff0c\u7528\u4e8e\u8bc4\u4f30\u6f0f\u6d1e\u68c0\u6d4b\u548c\u5b9a\u4f4d\u6027\u80fd\u3002", "result": "\u5728T2L-ARVO\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cT2L-Agent\u7684\u6f0f\u6d1e\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u5230\u4e8658.0%\uff0c\u884c\u7ea7\u5b9a\u4f4d\u51c6\u786e\u7387\u8fbe54.8%\uff0c\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "T2L-Agent\u53caT2L-ARVO\u57fa\u51c6\u63a8\u52a8\u4e86\u57fa\u4e8eLLM\u7684\u6f0f\u6d1e\u68c0\u6d4b\u4ece\u7c97\u7c92\u5ea6\u8bc6\u522b\u8fc8\u5411\u53ef\u843d\u5730\u3001\u9c81\u68d2\u4e14\u9ad8\u7cbe\u5ea6\u7684\u8bca\u65ad\uff0c\u663e\u8457\u51cf\u5c11\u566a\u58f0\u3001\u63d0\u9ad8\u4fee\u590d\u6548\u7387\uff0c\u5e76\u6709\u671b\u52a0\u901f\u5f00\u6e90\u8f6f\u4ef6\u7684\u6f0f\u6d1e\u4fee\u8865\u6d41\u7a0b\u3002"}}
{"id": "2510.02327", "categories": ["cs.CL", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.02327", "abs": "https://arxiv.org/abs/2510.02327", "authors": ["So Kuroki", "Yotaro Kubo", "Takuya Akiba", "Yujin Tang"], "title": "KAME: Tandem Architecture for Enhancing Knowledge in Real-Time Speech-to-Speech Conversational AI", "comment": null, "summary": "Real-time speech-to-speech (S2S) models excel at generating natural,\nlow-latency conversational responses but often lack deep knowledge and semantic\nunderstanding. Conversely, cascaded systems combining automatic speech\nrecognition, a text-based Large Language Model (LLM), and text-to-speech\nsynthesis offer superior knowledge representation at the cost of high latency,\nwhich disrupts the flow of natural interaction. This paper introduces a novel\nhybrid architecture that bridges the gap between these two paradigms. Our\nframework processes user speech through an S2S transformer for immediate\nresponsiveness while concurrently relaying the query to a powerful back-end\nLLM. The LLM's text-based response is then injected in real time to guide the\nS2S model's speech generation, effectively infusing its output with rich\nknowledge without the full latency penalty of a cascaded system. We evaluated\nour method using a speech-synthesized variant of the MT-Bench benchmark that\nconsists of multi-turn question-answering sessions. The results demonstrate\nthat our system substantially outperforms a baseline S2S model in response\ncorrectness, approaching that of a cascaded system, while maintaining a latency\non par with the baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u628a\u540e\u7aefLLM\u77e5\u8bc6\u5b9e\u65f6\u6ce8\u5165S2S\u6a21\u578b\u7684\u65b0\u6df7\u5408\u67b6\u6784\uff0c\u5728\u4fdd\u8bc1\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u8bed\u97f3\u4ea4\u4e92\u7cfb\u7edf\u7684\u77e5\u8bc6\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5b9e\u65f6\u8bed\u97f3\u5230\u8bed\u97f3\uff08S2S\uff09\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u81ea\u7136\u3001\u4f4e\u5ef6\u8fdf\u7684\u5bf9\u8bdd\u54cd\u5e94\uff0c\u4f46\u7f3a\u4e4f\u6df1\u5c42\u77e5\u8bc6\u4e0e\u8bed\u4e49\u7406\u89e3\u3002\u76f8\u53cd\uff0c\u57fa\u4e8e\u7ea7\u8054\u7cfb\u7edf\uff08\u5305\u62ec\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3001\u57fa\u4e8e\u6587\u672c\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ca\u6587\u672c\u8f6c\u8bed\u97f3\uff09\u7684\u89e3\u51b3\u65b9\u6848\u867d\u7136\u77e5\u8bc6\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u5ef6\u8fdf\u8f83\u9ad8\uff0c\u5f71\u54cd\u81ea\u7136\u4ea4\u4e92\u6d41\u7a0b\u3002\u4e9f\u9700\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\uff0c\u517c\u5177\u4f4e\u5ef6\u8fdf\u4e0e\u77e5\u8bc6\u6df1\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u67b6\u6784\uff1a\u7528\u6237\u8bed\u97f3\u8f93\u5165\u9996\u5148\u901a\u8fc7S2S Transformer\u8fdb\u884c\u5373\u65f6\u54cd\u5e94\uff0c\u540c\u65f6\u5c06\u67e5\u8be2\u53d1\u9001\u7ed9\u540e\u7aef\u5f3a\u5927\u7684LLM\u3002LLM\u8fd4\u56de\u6587\u672c\u540e\uff0c\u5b9e\u65f6\u6ce8\u5165\u5e76\u6307\u5bfcS2S\u6a21\u578b\u7684\u8bed\u97f3\u751f\u6210\uff0c\u4ece\u800c\u5728\u4e0d\u589e\u52a0\u7ea7\u8054\u7cfb\u7edf\u5168\u90e8\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u4e30\u5bcc\u7684\u77e5\u8bc6\u878d\u5165\u8f93\u51fa\u3002", "result": "\u5728\u57fa\u4e8e\u8bed\u97f3\u5408\u6210\u7684MT-Bench\u57fa\u51c6\uff08\u591a\u8f6e\u95ee\u7b54\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7cfb\u7edf\u5728\u56de\u7b54\u6b63\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u666e\u901aS2S\u57fa\u7ebf\uff0c\u63a5\u8fd1\u7ea7\u8054\u7cfb\u7edf\u6c34\u5e73\uff0c\u540c\u65f6\u5ef6\u8fdf\u4e0eS2S\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "\u521b\u65b0\u6df7\u5408\u67b6\u6784\u80fd\u591f\u6709\u6548\u7ed3\u5408S2S\u7684\u4f4e\u5ef6\u8fdf\u548cLLM\u7684\u77e5\u8bc6\u4f18\u52bf\uff0c\u5b9e\u73b0\u65e2\u9ad8\u6548\u53c8\u667a\u80fd\u7684\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u54cd\u5e94\u901f\u5ea6\u548c\u77e5\u8bc6\u6df1\u5ea6\u4e0a\u7684\u6743\u8861\u9650\u5236\u3002"}}
{"id": "2510.02393", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02393", "abs": "https://arxiv.org/abs/2510.02393", "authors": ["Jianqing Zhang", "Wei Xia", "Hande Dong", "Qiang Lin", "Jian Cao"], "title": "AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization", "comment": null, "summary": "LLMs' code generation capabilities have yielded substantial improvements in\nthe effectiveness of programming tasks. However, LLM-generated code still\nsuffers from compilation and runtime errors. Existing offline preference\noptimization methods primarily focus on enhancing LLMs' coding abilities using\npass/fail signals in the preference data, overlooking the deep-level error\ntypes in the failed codes. To address this, we propose Adaptively Progressive\nPreference Optimization (AP2O) for coding (i.e., AP2O-Coder), a method that\nguides LLMs adaptively and methodically to reduce code errors for code\ngeneration. Specifically, we construct an error notebook from failed codes and\nprogressively optimize the LLM to correct errors type by type. Furthermore, we\nadaptively replay error types to tailor to the LLM's changing weaknesses\nthroughout the training process. Through extensive experiments on both code and\ngeneral LLMs (Llama, Qwen, and DeepSeek series) with parameters ranging from\n0.5B to 34B, our AP2O-Coder improves code generation performance by up to 3% in\npass@k while using less preference data. Code: https://github.com/TsingZ0/AP2O", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u6ce8\u4e8e\u9519\u8bef\u7c7b\u578b\u7684\u81ea\u9002\u5e94\u9012\u8fdb\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff08AP2O-Coder\uff09\uff0c\u80fd\u663e\u8457\u63d0\u5347LLM\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u51cf\u5c11\u6240\u9700\u7684\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5176\u751f\u6210\u7684\u4ee3\u7801\u4ecd\u5b58\u5728\u7f16\u8bd1\u548c\u8fd0\u884c\u9519\u8bef\u3002\u73b0\u6709\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u591a\u53ea\u5173\u6ce8\u4ee3\u7801\u80fd\u5426\u901a\u8fc7\uff08pass/fail\u4fe1\u53f7\uff09\uff0c\u5ffd\u7565\u4e86\u4ee3\u7801\u5931\u8d25\u80cc\u540e\u7684\u5177\u4f53\u9519\u8bef\u7c7b\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u9012\u8fdb\u504f\u597d\u4f18\u5316\uff08AP2O\uff09\uff0c\u5177\u4f53\u4e3aAP2O-Coder\u3002\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u4ece\u5931\u8d25\u4ee3\u7801\u4e2d\u6784\u5efa\u9519\u8bef\u7b14\u8bb0\u672c\uff0c\u9010\u7c7b\u4f18\u5316LLM\u4ee5\u77eb\u6b63\u7279\u5b9a\u9519\u8bef\u7c7b\u578b\uff1b2\uff09\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6839\u636e\u6a21\u578b\u5f31\u70b9\u7684\u53d8\u5316\uff0c\u81ea\u9002\u5e94\u91cd\u590d\u67d0\u4e9b\u9519\u8bef\u7c7b\u578b\u7684\u4f18\u5316\uff0c\u4ee5\u63d0\u5347\u6539\u6b63\u6548\u679c\u3002", "result": "\u5728Llama\u3001Qwen\u3001DeepSeek\u7b49\u53c2\u6570\u8303\u56f4\u4ece0.5B\u523034B\u7684\u591a\u79cd\u6a21\u578b\u4e0a\u5e7f\u6cdb\u5b9e\u9a8c\uff0cAP2O-Coder\u80fd\u4ee5\u66f4\u5c11\u7684\u504f\u597d\u6570\u636e\u5c06\u4ee3\u7801\u751f\u6210\u6027\u80fd\uff08pass@k\u6307\u6807\uff09\u63d0\u5347\u6700\u591a3%\u3002", "conclusion": "AP2O-Coder\u80fd\u591f\u6709\u6548\u51cf\u5c11LLM\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u9519\u8bef\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u548c\u9012\u8fdb\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002"}}
{"id": "2510.02328", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.02328", "abs": "https://arxiv.org/abs/2510.02328", "authors": ["Ziqing Wang", "Chengsheng Mao", "Xiaole Wen", "Yuan Luo", "Kaize Ding"], "title": "AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering", "comment": "EMNLP Findings", "summary": "Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise\nin medical visual question answering (Med-VQA). However, when deployed in\nlow-resource settings where abundant labeled data are unavailable, existing\nMed-MLLMs commonly fail due to their medical reasoning capability bottlenecks:\n(i) the intrinsic reasoning bottleneck that ignores the details from the\nmedical image; (ii) the extrinsic reasoning bottleneck that fails to\nincorporate specialized medical knowledge. To address those limitations, we\npropose AMANDA, a training-free agentic framework that performs medical\nknowledge augmentation via LLM agents. Specifically, our intrinsic medical\nknowledge augmentation focuses on coarse-to-fine question decomposition for\ncomprehensive diagnosis, while extrinsic medical knowledge augmentation grounds\nthe reasoning process via biomedical knowledge graph retrieval. Extensive\nexperiments across eight Med-VQA benchmarks demonstrate substantial\nimprovements in both zero-shot and few-shot Med-VQA settings. The code is\navailable at https://github.com/REAL-Lab-NU/AMANDA.", "AI": {"tldr": "AMANDA\u80fd\u5728\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4e2d\u4e0d\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u901a\u8fc7\u95ee\u9898\u5206\u89e3\u4e0e\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u63d0\u5347\u533b\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u533b\u5b66\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08Med-MLLMs\uff09\u5728\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u6709\u826f\u597d\u8868\u73b0\uff0c\u4f46\u5728\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u7684\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u4f1a\u56e0\u533b\u5b66\u63a8\u7406\u80fd\u529b\u74f6\u9888\u800c\u5931\u6548\u3002\u5177\u4f53\u5305\u62ec\uff1a\u6a21\u578b\u672a\u80fd\u7ec6\u81f4\u7406\u89e3\u533b\u5b66\u56fe\u50cf\u4e0e\u672a\u80fd\u6574\u5408\u4e13\u4e1a\u533b\u5b66\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86AMANDA\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u5229\u7528LLM\u4ee3\u7406\u8fdb\u884c\u533b\u5b66\u77e5\u8bc6\u589e\u5f3a\u3002\u65b9\u6cd5\u5305\u62ec\uff1a\u901a\u8fc7\u95ee\u9898\u5206\u89e3\u8fdb\u884c\u5185\u5728\u533b\u5b66\u77e5\u8bc6\u589e\u5f3a\u3001\u901a\u8fc7\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u8fdb\u884c\u5916\u5728\u533b\u5b66\u77e5\u8bc6\u589e\u5f3a\u3002", "result": "\u5728\u516b\u4e2a\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0cAMANDA\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u4efb\u52a1\u4e2d\u90fd\u663e\u8457\u63d0\u5347\u4e86\u8868\u73b0\u3002", "conclusion": "AMANDA\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3Med-MLLMs\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u7684\u63a8\u7406\u74f6\u9888\uff0c\u63d0\u5347\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.02404", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02404", "abs": "https://arxiv.org/abs/2510.02404", "authors": ["Siddharth Agarwal", "Maria A. Rodriguez", "Rajkumar Buyya"], "title": "Dynamic Function Configuration and its Management in Serverless Computing: A Taxonomy and Future Directions", "comment": "34 pages, 2 figures, 2 tables, journal", "summary": "The serverless cloud computing model offers a framework where the service\nprovider abstracts the underlying infrastructure management from developers. In\nthis serverless model, FaaS provides an event-driven, function-oriented\ncomputing service characterised by fine-grained, usage-based pricing that\neliminates cost for idle resources. Platforms like AWS Lambda, Azure Functions,\nand Cloud Run Functions require developers to configure their function(s) with\nminimum operational resources for its successful execution. This resource\nallocation influences both the operational expense and the performance quality\nof these functions. However, a noticeable lack of platform transparency forces\ndevelopers to rely on expert knowledge or experience-based ad-hoc decisions to\nrequest desired function resources. This makes optimal resource configuration a\nnon-trivial task while adhering to performance constraints. Furthermore, while\ncommercial platforms often scale resources like CPU and network bandwidth\nproportional to memory, open-source frameworks permit independent configuration\nof function resources, introducing additional complexity for developers aiming\nto optimise their functions. These complexities have directed researchers to\nresolve developer challenges and advance towards an efficient server-less\nexecution model. In this article, we identify different aspects of resource\nconfiguration techniques in FaaS settings and propose a taxonomy of factors\nthat influence function design, configuration, run-time cost, and performance\nguarantees. We conduct an analysis of existing literature on resource\nconfiguration to present a comprehensive review of current studies on function\nconfiguration. We also identify existing research gaps and suggest future\nresearch directions to enhance function configuration and strengthen the\ncapabilities of serverless computing environments to drive its broader\nadoption.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u65e0\u670d\u52a1\u5668FaaS\u8d44\u6e90\u914d\u7f6e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5f71\u54cd\u56e0\u7d20\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5206\u6790\u4e86\u73b0\u6709\u7814\u7a76\u8fdb\u5c55\u4e0e\u4e0d\u8db3\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u63d0\u5347\u51fd\u6570\u6027\u80fd\u548c\u5e73\u53f0\u80fd\u529b\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5728\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u6a21\u578b\uff08\u5982FaaS\uff09\u4e0b\uff0c\u8d44\u6e90\u5206\u914d\u76f4\u63a5\u5f71\u54cd\u6027\u80fd\u4e0e\u6210\u672c\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5e73\u53f0\u900f\u660e\u5ea6\u4e0d\u8db3\uff0c\u5f00\u53d1\u8005\u901a\u5e38\u7f3a\u5c11\u51c6\u786e\u7684\u8d44\u6e90\u914d\u7f6e\u6307\u5bfc\uff0c\u5bfc\u81f4\u8d44\u6e90\u914d\u7f6e\u8fc7\u7a0b\u590d\u6742\u4e14\u96be\u4ee5\u4f18\u5316\u3002", "method": "\u672c\u6587\u68b3\u7406\u4e86FaaS\u8d44\u6e90\u914d\u7f6e\u76f8\u5173\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5f71\u54cd\u51fd\u6570\u8bbe\u8ba1\u3001\u914d\u7f6e\u3001\u8fd0\u884c\u6210\u672c\u548c\u6027\u80fd\u4fdd\u969c\u7684\u56e0\u7d20\u5206\u7c7b\u4f53\u7cfb\u3002\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u5bf9\u73b0\u6709\u51fd\u6570\u8d44\u6e90\u914d\u7f6e\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5206\u6790\u3002", "result": "\u6587\u7ae0\u603b\u7ed3\u4e86\u5f53\u524dFaaS\u8d44\u6e90\u914d\u7f6e\u9886\u57df\u7684\u7814\u7a76\u6210\u679c\uff0c\u660e\u786e\u4e86\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63d0\u5347\u51fd\u6570\u914d\u7f6e\u7684\u667a\u80fd\u5316\u6c34\u5e73\u548c\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u73af\u5883\u7684\u80fd\u529b\u3002", "conclusion": "\u4f5c\u8005\u5f3a\u8c03\uff0c\u63d0\u5347\u8d44\u6e90\u914d\u7f6e\u6548\u7387\u548c\u5e73\u53f0\u80fd\u529b\u662f\u63a8\u52a8\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5e7f\u6cdb\u5e94\u7528\u7684\u5173\u952e\u3002\u672c\u6587\u7684\u5206\u7c7b\u4f53\u7cfb\u548c\u7efc\u8ff0\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4e5f\u660e\u786e\u4e86\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2510.02329", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02329", "abs": "https://arxiv.org/abs/2510.02329", "authors": ["Kanghoon Yoon", "Minsub Kim", "Sungjae Lee", "Joonhyung Lee", "Sunghyeon Woo", "Yeonjun In", "Se Jung Kwon", "Chanyoung Park", "Dongsoo Lee"], "title": "SelfJudge: Faster Speculative Decoding via Self-Supervised Judge Verification", "comment": null, "summary": "Speculative decoding accelerates LLM inference by verifying candidate tokens\nfrom a draft model against a larger target model. Recent judge decoding boosts\nthis process by relaxing verification criteria by accepting draft tokens that\nmay exhibit minor discrepancies from target model output, but existing methods\nare restricted by their reliance on human annotations or tasks with verifiable\nground truths, limiting generalizability across diverse NLP tasks. We propose\nSelfJudge, which trains judge verifiers via self-supervision of the target\nmodel. Our method measures semantic preservation by assessing whether\ntoken-substituted responses preserve the meaning of original responses,\nenabling automatic verifier training across diverse NLP tasks. Our experiments\nshow SelfJudge achieves superior inference-accuracy trade-offs than judge\ndecoding baselines, offering a broadly applicable solution for faster LLM\ninference.", "AI": {"tldr": "SelfJudge\u5b9e\u73b0\u4e86\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u8bed\u4e49\u5224\u65ad\uff0c\u52a0\u5feb\u5927\u6a21\u578b\u63a8\u7406\u901f\u5ea6\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709judge decoding\u867d\u80fd\u52a0\u901f\u63a8\u7406\uff0c\u4f46\u9700\u4eba\u5de5\u6ce8\u91ca\u6216\u7279\u5b9a\u771f\u503c\uff0c\u96be\u4ee5\u63a8\u5e7f\u3002\u5e0c\u671b\u53d1\u660e\u81ea\u52a8\u5316\u3001\u6cdb\u5316\u6027\u597d\u3001\u65e0\u9700\u4eba\u5de5\u53c2\u4e0e\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u8ba9\u76ee\u6807\u5927\u6a21\u578b\u5bf9\u6bd4\u66ff\u6362token\u524d\u540e\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u81ea\u52a8\u83b7\u5f97\u8bad\u7ec3judge verifier\u7684\u6570\u636e\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u7279\u5b9a\u4efb\u52a1\u7684\u771f\u503c\u3002", "result": "\u5728\u591a\u79cdNLP\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cSelfJudge\u7684\u63a8\u7406\u901f\u5ea6\u548c\u51c6\u786e\u7387\u6743\u8861\u660e\u663e\u4f18\u4e8e\u73b0\u6709judge decoding\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SelfJudge\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u8bad\u7ec3\u5224\u65ad\u5668\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u52a0\u901f\u5927\u6a21\u578b\u63a8\u7406\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u660e\u786e\u7684\u4efb\u52a1\u771f\u503c\u3002\u5b9e\u9a8c\u8bc1\u660e\u5176\u63a8\u7406\u901f\u5ea6\u4e0e\u51c6\u786e\u7387\u6743\u8861\u4f18\u4e8e\u73b0\u6709baseline\u3002"}}
{"id": "2510.02504", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02504", "abs": "https://arxiv.org/abs/2510.02504", "authors": ["Mara Ulloa", "Jenna L. Butler", "Sankeerti Haniyur", "Courtney Miller", "Barrett Amos", "Advait Sarkar", "Margaret-Anne Storey"], "title": "Product Manager Practices for Delegating Work to Generative AI: \"Accountability must not be delegated to non-human actors\"", "comment": "12 pages, 4 figures, 1 table", "summary": "Generative AI (GenAI) is changing the nature of knowledge work, particularly\nfor Product Managers (PMs) in software development teams. While much software\nengineering research has focused on developers' interactions with GenAI, there\nis less understanding of how the work of PMs is evolving due to GenAI. To\naddress this gap, we conducted a mixed-methods study at Microsoft, a large,\nmultinational software company: surveying 885 PMs, analyzing telemetry data for\na subset of PMs (N=731), and interviewing a subset of 15 PMs. We contribute:\n(1) PMs' current GenAI adoption rates, uses cases, and perceived benefits and\nbarriers and; (2) a framework capturing how PMs assess which tasks to delegate\nto GenAI; (3) PMs adaptation practices for integrating GenAI into their roles\nand perceptions of how their role is evolving. We end by discussing\nimplications on the broader GenAI workflow adoption process and software\ndevelopment roles.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u7814\u5fae\u8f6fPM\u5173\u4e8e\u751f\u6210\u5f0fAI\u7684\u4f7f\u7528\u4e0e\u5f71\u54cd\uff0c\u603b\u7ed3\u5176\u91c7\u7eb3\u7387\u3001\u5e94\u7528\u573a\u666f\u3001\u5e26\u6765\u7684\u89d2\u8272\u53d8\u5316\u53ca\u672a\u6765\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u7684\u542f\u793a\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5f00\u53d1\u7684\u5f71\u54cd\uff0c\u4e3b\u8981\u805a\u7126\u4e8e\u5f00\u53d1\u8005\uff0c\u7f3a\u4e4f\u5bf9\u4ea7\u54c1\u7ecf\u7406\u5f71\u54cd\u7684\u7cfb\u7edf\u7814\u7a76\u3002\u4f5c\u8005\u5e0c\u671b\u586b\u8865\u8be5\u9886\u57df\u7684\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u4e86\u6df7\u5408\u65b9\u6cd5\uff1a\u5bf9885\u4f4dPM\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u5206\u6790\u5176\u4e2d731\u4f4dPM\u7684\u9065\u6d4b\u6570\u636e\uff0c\u5e76\u6df1\u5ea6\u8bbf\u8c08\u4e8615\u4f4dPM\u3002", "result": "\uff081\uff09\u7edf\u8ba1\u4e86GenAI\u5728PM\u4e2d\u7684\u91c7\u7eb3\u7387\u3001\u4f7f\u7528\u573a\u666f\u548c\u4ed6\u4eec\u611f\u77e5\u7684\u6536\u76ca\u4e0e\u969c\u788d\uff1b\uff082\uff09\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u63cf\u8ff0PM\u5982\u4f55\u8bc4\u4f30\u54ea\u4e9b\u4efb\u52a1\u9002\u5408\u8ba9GenAI\u627f\u62c5\uff1b\uff083\uff09\u603b\u7ed3\u4e86PM\u5728\u878d\u5408GenAI\u8fdb\u5de5\u4f5c\u4e2d\u7684\u9002\u5e94\u63aa\u65bd\u53ca\u5176\u5bf9\u804c\u4e1a\u89d2\u8272\u53d8\u5316\u7684\u770b\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5bf9\u6574\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u548c\u804c\u4e1a\u7684\u542f\u793a\u3002", "conclusion": "\u672c\u6587\u53d1\u73b0\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u6b63\u5728\u63a8\u52a8\u4ea7\u54c1\u7ecf\u7406\uff08PM\uff09\u89d2\u8272\u548c\u5de5\u4f5c\u5185\u5bb9\u7684\u8f6c\u53d8\uff0c\u5305\u62ec\u5de5\u4f5c\u4efb\u52a1\u7684\u91cd\u5206\u914d\u548c\u6280\u80fd\u8981\u6c42\u7684\u53d8\u5316\u3002GenAI\u7684\u666e\u53ca\u5f71\u54cd\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684PM\u804c\u8d23\u3002"}}
{"id": "2510.02330", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02330", "abs": "https://arxiv.org/abs/2510.02330", "authors": ["Junlong Jia", "Ziyang Chen", "Xing Wu", "Chaochen Gao", "Zijia Lin", "Debing Zhang", "Songlin Hu", "Binghui Guo"], "title": "EntropyLong: Effective Long-Context Training via Predictive Uncertainty", "comment": "work in progress; Correspondence to: Xing Wu <wuxing@iie.ac.cn>", "summary": "Training long-context language models to capture long-range dependencies\nrequires specialized data construction. Current approaches, such as generic\ntext concatenation or heuristic-based variants, frequently fail to guarantee\ngenuine long-range dependencies. We propose EntropyLong, a novel data\nconstruction method that leverages predictive uncertainty to verify dependency\nquality. Our approach identifies high-entropy positions in documents, retrieves\nsemantically relevant contexts from large corpora, and verifies their utility\nby assessing whether they reduce prediction entropy. This model-in-the-loop\nverification ensures each dependency represents measurable information gain\nrather than spurious correlation. We construct training samples with long-range\ndependencies by combining original documents with these verified contextual\nsupplements. Using FineWebEdu and Cosmopedia, we generate a dataset of\n128K-length sequences with verified dependencies. Models trained on this data\ndemonstrate significant improvements on RULER benchmarks, particularly in tasks\nrequiring distant information. Following instruction fine-tuning, our models\nalso achieve substantial gains on LongBenchv2, demonstrating enhanced\nlong-context understanding. Extensive ablation studies further validate the\nnecessity and effectiveness of entropybased verification for long-context\ntraining.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u71b5\u7528\u4e8e\u6709\u6548\u6784\u5efa\u771f\u5b9e\u957f\u8ddd\u79bb\u4f9d\u8d56\u6570\u636e\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u663e\u8457\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u957f\u6587\u672c\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u7b80\u5355\u62fc\u63a5\u6216\u542f\u53d1\u5f0f\u624b\u6bb5\u6784\u9020\u957f\u4f9d\u8d56\uff0c\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u751f\u6210\u7684\u4f9d\u8d56\u662f\u771f\u5b9e\u4e14\u6709\u76ca\u7684\u3002\u4f5c\u8005\u65e8\u5728\u63d0\u9ad8\u8bad\u7ec3\u6837\u672c\u4e2d\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u771f\u5b9e\u6027\u548c\u6709\u6548\u6027\uff0c\u8fdb\u800c\u63d0\u5347\u6a21\u578b\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51faEntropyLong\u65b9\u6cd5\uff1a\u9996\u5148\u68c0\u6d4b\u6587\u672c\u4e2d\u9ad8\u71b5\uff08\u5373\u6a21\u578b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u9ad8\uff09\u7684\u4f4d\u7f6e\uff0c\u4ece\u5927\u89c4\u6a21\u8bed\u6599\u4e2d\u68c0\u7d22\u8bed\u4e49\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u5faa\u73af\u9a8c\u8bc1\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u80fd\u5426\u964d\u4f4e\u9884\u6d4b\u71b5\uff0c\u786e\u4fdd\u52a0\u5165\u7684\u4f9d\u8d56\u6709\u5b9e\u9645\u4fe1\u606f\u589e\u76ca\u3002\u6784\u9020\u5305\u542b\u771f\u5b9e\u957f\u8ddd\u79bb\u4f9d\u8d56\u7684\u6570\u636e\uff0c\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "\u57fa\u4e8eEntropyLong\u751f\u6210\u7684\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728RULER\u3001LongBenchv2\u7b49\u957f\u4f9d\u8d56\u4efb\u52a1\u8bc4\u6d4b\u4e2d\u7684\u51c6\u786e\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u8fdc\u8ddd\u79bb\u4fe1\u606f\u5224\u522b\u7684\u6d4b\u9879\u4e2d\u6548\u679c\u7a81\u51fa\u3002\u6d88\u878d\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u71b5\u7684\u4f9d\u8d56\u9a8c\u8bc1\u673a\u5236\u7684\u6709\u6548\u6027\u548c\u5fc5\u8981\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u9884\u6d4b\u71b5\u7684\u4f9d\u8d56\u9a8c\u8bc1\u4e0e\u6570\u636e\u6784\u9020\u65b9\u6cd5\uff0c\u4f5c\u8005\u6210\u529f\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u5728\u957f\u8ddd\u79bb\u4f9d\u8d56\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u5176\u5bf9\u63d0\u5347\u6a21\u578b\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\u6709\u6548\u3002"}}
{"id": "2510.02534", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02534", "abs": "https://arxiv.org/abs/2510.02534", "authors": ["Mohsen Iranmanesh", "Sina Moradi Sabet", "Sina Marefat", "Ali Javidi Ghasr", "Allison Wilson", "Iman Sharafaldin", "Mohammad A. Tayebi"], "title": "ZeroFalse: Improving Precision in Static Analysis with LLMs", "comment": null, "summary": "Static Application Security Testing (SAST) tools are integral to modern\nsoftware development, yet their adoption is undermined by excessive false\npositives that weaken developer trust and demand costly manual triage. We\npresent ZeroFalse, a framework that integrates static analysis with large\nlanguage models (LLMs) to reduce false positives while preserving coverage.\nZeroFalse treats static analyzer outputs as structured contracts, enriching\nthem with flow-sensitive traces, contextual evidence, and CWE-specific\nknowledge before adjudication by an LLM. This design preserves the systematic\nreach of static analysis while leveraging the reasoning capabilities of LLMs.\nWe evaluate ZeroFalse across both benchmarks and real-world projects using ten\nstate-of-the-art LLMs. Our best-performing models achieve F1-scores of 0.912 on\nthe OWASP Java Benchmark and 0.955 on the OpenVuln dataset, maintaining recall\nand precision above 90%. Results further show that CWE-specialized prompting\nconsistently outperforms generic prompts, and reasoning-oriented LLMs provide\nthe most reliable precision-recall balance. These findings position ZeroFalse\nas a practical and scalable approach for enhancing the reliability of SAST and\nsupporting its integration into real-world CI/CD pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faZeroFalse\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u6709\u6548\u51cf\u5c11SAST\u5de5\u5177\u8bef\u62a5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u9ad8\u51c6\u786e\u6027\uff0c\u9002\u5408\u5b9e\u9645\u5de5\u7a0b\u4f7f\u7528\u3002", "motivation": "\u9759\u6001\u5e94\u7528\u5b89\u5168\u6d4b\u8bd5\uff08SAST\uff09\u5de5\u5177\u867d\u7136\u5728\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u56e0\u8bef\u62a5\u7387\u9ad8\uff0c\u964d\u4f4e\u4e86\u5f00\u53d1\u8005\u4fe1\u4efb\uff0c\u9700\u8981\u8017\u8d39\u5927\u91cf\u4eba\u529b\u7b5b\u67e5\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3SAST\u8bef\u62a5\u8fc7\u591a\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u5176\u5b9e\u7528\u6027\u548c\u4fe1\u4efb\u5ea6\u3002", "method": "\u63d0\u51faZeroFalse\u6846\u67b6\uff0c\u5c06\u9759\u6001\u5206\u6790\u7ed3\u679c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u3002\u6846\u67b6\u5c06\u9759\u6001\u5206\u6790\u4ea7\u51fa\u7ed3\u6784\u5316\uff0c\u8865\u5145\u6d41\u7a0b\u654f\u611f\u7684\u8ffd\u8e2a\u4fe1\u606f\u3001\u4e0a\u4e0b\u6587\u8bc1\u636e\u548cCWE\u76f8\u5173\u77e5\u8bc6\uff0c\u7136\u540e\u4ea4\u7531LLM\u5224\u65ad\uff0c\u5b9e\u73b0\u65e2\u4fdd\u7559\u9759\u6001\u5206\u6790\u5168\u8986\u76d6\u4f18\u52bf\uff0c\u53c8\u5229\u7528LLM\u63a8\u7406\u80fd\u529b\u964d\u4f4e\u8bef\u62a5\u3002", "result": "\u5728OWASP Java Benchmark\u4e0a\u83b7\u5f970.912\u7684F1-score\uff0c\u5728OpenVuln\u6570\u636e\u96c6\u4e0a\u83b7\u5f970.955\uff0c\u53ec\u56de\u7387\u548c\u7cbe\u5ea6\u5747\u8d85\u8fc790%\u3002CWE\u4e13\u7528\u63d0\u793a\u8bcd\u6bd4\u901a\u7528\u63d0\u793a\u6548\u679c\u66f4\u4f73\uff0c\u64c5\u957f\u63a8\u7406\u7684LLM\u80fd\u66f4\u597d\u5e73\u8861\u7cbe\u5ea6\u548c\u53ec\u56de\u3002", "conclusion": "ZeroFalse\u663e\u8457\u964d\u4f4eSAST\u8bef\u62a5\uff0c\u63d0\u5347\u7cbe\u5ea6\u548c\u53ec\u56de\uff0c\u9002\u5408\u5927\u89c4\u6a21\u96c6\u6210\u5230\u5b9e\u9645CI/CD\u6d41\u7a0b\u3002"}}
{"id": "2510.02331", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02331", "abs": "https://arxiv.org/abs/2510.02331", "authors": ["Moonkyung Ryu", "Chih-Wei Hsu", "Yinlam Chow", "Mohammad Ghavamzadeh", "Craig Boutilier"], "title": "Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)", "comment": null, "summary": "While language models (LMs) offer great potential for conversational\nrecommender systems (CRSs), the paucity of public CRS data makes fine-tuning\nLMs for CRSs challenging. In response, LMs as user simulators qua data\ngenerators can be used to train LM-based CRSs, but often lack behavioral\nconsistency, generating utterance sequences inconsistent with those of any real\nuser. To address this, we develop a methodology for generating natural\ndialogues that are consistent with a user's underlying state using behavior\nsimulators together with LM-prompting. We illustrate our approach by generating\na large, open-source CRS data set with both preference elicitation and example\ncritiquing. Rater evaluation on some of these dialogues shows them to exhibit\nconsiderable consistency, factuality and naturalness.", "AI": {"tldr": "\u9488\u5bf9\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u6570\u636e\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u7528\u884c\u4e3a\u6a21\u62df\u5668\u53ca\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u751f\u6210\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u6570\u636e\uff0c\u5e76\u516c\u5f00\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\u751f\u6210\u6570\u636e\u81ea\u7136\u3001\u4e00\u81f4\u4e14\u4e8b\u5b9e\u6027\u9ad8\u3002", "motivation": "\u73b0\u6709\u53ef\u516c\u5f00\u83b7\u53d6\u7684\u5bf9\u8bdd\u5f0f\u63a8\u8350\u7cfb\u7edf\u6570\u636e\u7a00\u7f3a\uff0c\u5bfc\u81f4\u96be\u4ee5\u7528\u8fd9\u4e9b\u6570\u636e\u5bf9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u8868\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408\u884c\u4e3a\u6a21\u62df\u5668\u548c\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u636e\u6b64\u751f\u6210\u4e0e\u7528\u6237\u72b6\u6001\u4e00\u81f4\u7684\u81ea\u7136\u5bf9\u8bdd\u6570\u636e\u3002", "result": "\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b\u7528\u6237\u504f\u597d\u83b7\u53d6\u548c\u4f8b\u5b50\u6279\u5224\u7684\u5927\u89c4\u6a21\u5f00\u6e90\u5bf9\u8bdd\u5f0f\u63a8\u8350\u7cfb\u7edf\u6570\u636e\u96c6\uff1b\u4eba\u5de5\u8bc4\u4ef7\u663e\u793a\u751f\u6210\u5bf9\u8bdd\u5728\u4e00\u81f4\u6027\u3001\u4e8b\u5b9e\u6027\u548c\u81ea\u7136\u6027\u7b49\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7ed3\u5408\u884c\u4e3a\u6a21\u62df\u4e0e\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u80fd\u591f\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u63a8\u8350\u5bf9\u8bdd\u6570\u636e\uff0c\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u96be\u9898\uff0c\u4e3a\u5bf9\u8bdd\u5f0f\u63a8\u8350\u7cfb\u7edf\u8bad\u7ec3\u63d0\u4f9b\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2510.02585", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02585", "abs": "https://arxiv.org/abs/2510.02585", "authors": ["Majid Dashtbani", "Ladan Tahvildari"], "title": "Key Considerations for Auto-Scaling: Lessons from Benchmark Microservices", "comment": null, "summary": "Microservices have become the dominant architectural paradigm for building\nscalable and modular cloud-native systems. However, achieving effective\nauto-scaling in such systems remains a non-trivial challenge, as it depends not\nonly on advanced scaling techniques but also on sound design, implementation,\nand deployment practices. Yet, these foundational aspects are often overlooked\nin existing benchmarks, making it difficult to evaluate autoscaling methods\nunder realistic conditions. In this paper, we identify a set of practical\nauto-scaling considerations by applying several state-of-the-art autoscaling\nmethods to widely used microservice benchmarks. To structure these findings, we\nclassify the issues based on when they arise during the software lifecycle:\nArchitecture, Implementation, and Deployment. The Architecture phase covers\nhigh-level decisions such as service decomposition and inter-service\ndependencies. The Implementation phase includes aspects like initialization\noverhead, metrics instrumentation, and error propagation. The Deployment phase\nfocuses on runtime configurations such as resource limits and health checks. We\nvalidate these considerations using the Sock-Shop benchmark and evaluate\ndiverse auto-scaling strategies, including threshold-based, control-theoretic,\nlearning-based, black-box optimization, and dependency-aware approaches. Our\nfindings show that overlooking key lifecycle concerns can degrade autoscaler\nperformance, while addressing them leads to more stable and efficient scaling.\nThese results underscore the importance of lifecycle-aware engineering for\nunlocking the full potential of auto-scaling in microservice-based systems.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\uff0c\u4e0d\u540c\u751f\u547d\u5468\u671f\u9636\u6bb5\uff08\u67b6\u6784\u3001\u5b9e\u73b0\u3001\u90e8\u7f72\uff09\u7684\u95ee\u9898\u4e25\u91cd\u5f71\u54cd\u5fae\u670d\u52a1\u81ea\u52a8\u4f38\u7f29\u7684\u6548\u679c\u3002\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\uff0c\u5f3a\u8c03\u751f\u547d\u5468\u671f\u6574\u4f53\u5de5\u7a0b\u8003\u8651\u5bf9\u4e8e\u9ad8\u6027\u80fd\u81ea\u52a8\u4f38\u7f29\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u4f38\u7f29\u65b9\u6cd5\u8bc4\u4f30\u591a\u5ffd\u7565\u4e86\u5fae\u670d\u52a1\u7cfb\u7edf\u5728\u751f\u547d\u5468\u671f\u5404\u9636\u6bb5\u7684\u73b0\u5b9e\u8003\u8651\uff0c\u5bfc\u81f4\u57fa\u51c6\u4e0e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u5b58\u5728\u8131\u8282\u3002\u8be5\u7814\u7a76\u65e8\u5728\u627e\u51fa\u5f71\u54cd\u81ea\u52a8\u4f38\u7f29\u6548\u679c\u7684\u5173\u952e\u751f\u547d\u5468\u671f\u56e0\u7d20\uff0c\u4ee5\u63d0\u5347\u8bc4\u4ef7\u548c\u5e94\u7528\u7684\u73b0\u5b9e\u6027\u3002", "method": "\u901a\u8fc7\u5bf9Sock-Shop\u57fa\u51c6\u5e94\u7528\u591a\u79cd\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u4f38\u7f29\u65b9\u6cd5\uff08\u5305\u62ec\u9608\u503c\u578b\u3001\u63a7\u5236\u7406\u8bba\u3001\u5b66\u4e60\u578b\u3001\u9ed1\u76d2\u4f18\u5316\u548c\u4f9d\u8d56\u611f\u77e5\u65b9\u6cd5\uff09\uff0c\u603b\u7ed3\u5e76\u5206\u7c7b\u5728\u67b6\u6784\u3001\u5b9e\u73b0\u548c\u90e8\u7f72\u9636\u6bb5\u6240\u9047\u5230\u7684\u95ee\u9898\uff0c\u5e76\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u5206\u6790\u3002", "result": "\u5ffd\u89c6\u751f\u547d\u5468\u671f\u76f8\u5173\u56e0\u7d20\uff08\u5982\u670d\u52a1\u62c6\u5206\u3001\u4f9d\u8d56\u3001\u521d\u59cb\u5316\u3001\u6307\u6807\u76d1\u63a7\u548c\u8fd0\u884c\u65f6\u914d\u7f6e\uff09\u4f1a\u964d\u4f4e\u81ea\u52a8\u4f38\u7f29\u6027\u80fd\u3002\u76f8\u53cd\uff0c\u7cfb\u7edf\u6027\u5730\u5173\u6ce8\u8fd9\u4e9b\u95ee\u9898\u53ef\u4ee5\u5e26\u6765\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u4f38\u7f29\u8868\u73b0\u3002", "conclusion": "\u8bba\u6587\u8868\u660e\u8bb8\u591a\u73b0\u6709\u5fae\u670d\u52a1\u81ea\u52a8\u5f39\u6027\u4f38\u7f29\u57fa\u51c6\u5ffd\u7565\u4e86\u67b6\u6784\u3001\u5b9e\u73b0\u548c\u90e8\u7f72\u7b49\u751f\u547d\u5468\u671f\u5173\u952e\u95ee\u9898\uff0c\u5bb9\u6613\u5bfc\u81f4\u4f38\u7f29\u5668\u6027\u80fd\u4e0b\u964d\u3002\u53ea\u6709\u5173\u6ce8\u6574\u4e2a\u751f\u547d\u5468\u671f\u7684\u5de5\u7a0b\u5b9e\u8df5\uff0c\u624d\u80fd\u771f\u6b63\u5b9e\u73b0\u9ad8\u6548\u3001\u7a33\u5b9a\u7684\u81ea\u52a8\u4f38\u7f29\u3002"}}
{"id": "2510.02332", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02332", "abs": "https://arxiv.org/abs/2510.02332", "authors": ["Yapei Feng", "Feng Jiang", "Shanhao Wu", "Hua Zhong"], "title": "A High-Capacity and Secure Disambiguation Algorithm for Neural Linguistic Steganography", "comment": "13 pages,7 figures", "summary": "Neural linguistic steganography aims to embed information\n  into natural text while preserving statistical undetectability. A fundamental\nchallenge in this ffeld stems from tokenization ambiguity in modern tokenizers,\nwhich can lead to catastrophic decoding failures. The recent method, SyncPool,\naddresses this ambiguity\n  by employing a coarse-grained synchronization mechanism over groups of\nambiguous candidates. However, SyncPool sacriffces embedding capacity, as it\nutilizes the entire Shannon entropy of an ambiguous group solely for\nsynchronization rather than for payload embedding. We propose a method named\nlook-ahead Sync, which overcomes the capacity limitation of SyncPool while\nretaining its provable security guarantees. Our approach performs minimal\nsynchronized sampling only on truly indistinguishable token sequences, while\nstrategically preserving all other discernible paths to maximize embedding\ncapacity. We provide theoretical proofs for the security of our method and\nanalyze the gap between its achievable embedding capacity and the theoretical\nupper bound. Experiments on English (using Llama 3) and Chinese (using Qwen\n2.5) benchmarks show that our method consistently approaches the theoretical\ncapacity upper bound and signiffcantly outperforms SyncPool. The improvement in\nembedding rate exceeds 160% in English and 25% in Chinese, particularly in\nsettings with larger candidate pools. This work represents a signiffcant step\ntoward practical high-capacity provably secure linguistic steganography.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u540c\u6b65\u673a\u5236\uff0c\u63d0\u9ad8\u4e86\u795e\u7ecf\u8bed\u8a00\u9690\u5199\u7684\u4fe1\u606f\u627f\u8f7d\u80fd\u529b\uff0c\u5e76\u786e\u4fdd\u5b89\u5168\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u795e\u7ecf\u8bed\u8a00\u9690\u5199\u672f\uff08Neural linguistic steganography\uff09\u9700\u8981\u5728\u81ea\u7136\u6587\u672c\u4e2d\u5d4c\u5165\u4fe1\u606f\u4f46\u53c8\u4fdd\u6301\u4e0d\u53ef\u88ab\u68c0\u6d4b\u6027\u3002\u73b0\u4ee3\u5206\u8bcd\u5668\u5b58\u5728\u5206\u8bcd\u6b67\u4e49\uff0c\u4f1a\u9020\u6210\u707e\u96be\u6027\u7684\u89e3\u7801\u5931\u8d25\uff0c\u8fd9\u6210\u4e3a\u8be5\u9886\u57df\u6838\u5fc3\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3alook-ahead Sync\u7684\u65b0\u65b9\u6cd5\uff0c\u4ec5\u5728\u771f\u6b63\u4e0d\u53ef\u533a\u5206\u7684token\u5e8f\u5217\u4e0a\u8fdb\u884c\u6700\u5c0f\u540c\u6b65\u91c7\u6837\uff0c\u5176\u4ed6\u53ef\u533a\u5206\u8def\u5f84\u4fdd\u7559\u4ee5\u6700\u5927\u5316\u5d4c\u5165\u5bb9\u91cf\uff1b\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u5b89\u5168\u6027\u8bc1\u660e\u548c\u5bb9\u91cf\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u82f1\u6587\uff08Llama 3\uff09\u548c\u4e2d\u6587\uff08Qwen 2.5\uff09\u57fa\u51c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5d4c\u5165\u5bb9\u91cf\u6bd4SyncPool\u5927\u5927\u63d0\u5347\u3002\u7279\u522b\u662f\u5728\u5019\u9009 token \u8f83\u591a\u65f6\uff0c\u82f1\u6587\u63d0\u5347\u8d85160%\uff0c\u4e2d\u6587\u63d0\u5347\u8d8525%\u3002", "conclusion": "look-ahead Sync\u65b9\u6cd5\u517c\u987e\u4e86\u4fe1\u606f\u5d4c\u5165\u5bb9\u91cf\u548c\u7406\u8bba\u5b89\u5168\u6027\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u795e\u7ecf\u8bed\u8a00\u9690\u5199\u7684\u5b9e\u9645\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.02609", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02609", "abs": "https://arxiv.org/abs/2510.02609", "authors": ["Chengquan Guo", "Chulin Xie", "Yu Yang", "Zhaorun Chen", "Zinan Lin", "Xander Davies", "Yarin Gal", "Dawn Song", "Bo Li"], "title": "RedCodeAgent: Automatic Red-teaming Agent against Diverse Code Agents", "comment": null, "summary": "Code agents have gained widespread adoption due to their strong code\ngeneration capabilities and integration with code interpreters, enabling\ndynamic execution, debugging, and interactive programming capabilities. While\nthese advancements have streamlined complex workflows, they have also\nintroduced critical safety and security risks. Current static safety benchmarks\nand red-teaming tools are inadequate for identifying emerging real-world risky\nscenarios, as they fail to cover certain boundary conditions, such as the\ncombined effects of different jailbreak tools. In this work, we propose\nRedCodeAgent, the first automated red-teaming agent designed to systematically\nuncover vulnerabilities in diverse code agents. With an adaptive memory module,\nRedCodeAgent can leverage existing jailbreak knowledge, dynamically select the\nmost effective red-teaming tools and tool combinations in a tailored toolbox\nfor a given input query, thus identifying vulnerabilities that might otherwise\nbe overlooked. For reliable evaluation, we develop simulated sandbox\nenvironments to additionally evaluate the execution results of code agents,\nmitigating potential biases of LLM-based judges that only rely on static code.\nThrough extensive evaluations across multiple state-of-the-art code agents,\ndiverse risky scenarios, and various programming languages, RedCodeAgent\nconsistently outperforms existing red-teaming methods, achieving higher attack\nsuccess rates and lower rejection rates with high efficiency. We further\nvalidate RedCodeAgent on real-world code assistants, e.g., Cursor and Codeium,\nexposing previously unidentified security risks. By automating and optimizing\nred-teaming processes, RedCodeAgent enables scalable, adaptive, and effective\nsafety assessments of code agents.", "AI": {"tldr": "RedCodeAgent\u662f\u4e00\u6b3e\u65b0\u578b\u81ea\u52a8\u5316\u7ea2\u961f\u4ee3\u7406\uff0c\u80fd\u667a\u80fd\u7ec4\u5408\u7ea2\u961f\u5de5\u5177\uff0c\u52a8\u6001\u6316\u6398\u4ee3\u7801\u667a\u80fd\u4f53\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5176\u5728\u591a\u7c7b\u4ee3\u7801\u52a9\u624b\u4e2d\u7684\u8868\u73b0\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\uff0c\u5e76\u53d1\u6398\u4e86\u591a\u9879\u672a\u88ab\u53d1\u73b0\u7684\u771f\u5b9e\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7528\u4e8e\u8bc4\u6d4b\u4ee3\u7801\u667a\u80fd\u4f53\u5b89\u5168\u6027\u7684\u57fa\u51c6\u4e0e\u7ea2\u961f\u5de5\u5177\u5f80\u5f80\u5c40\u9650\u4e8e\u9759\u6001\u68c0\u6d4b\uff0c\u4e14\u8986\u76d6\u9762\u4e0d\u591f\uff0c\u96be\u4ee5\u5e94\u5bf9\u771f\u5b9e\u590d\u6742\u573a\u666f\u4e0b\u7684\u8fb9\u754c\u5b89\u5168\u5a01\u80c1\uff0c\u5982\u591a\u79cd\u5de5\u5177\u8054\u5408\u7ed5\u8fc7\u578b\u7684\u653b\u51fb\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u667a\u80fd\u4e14\u52a8\u6001\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u7cfb\u7edf\uff0c\u5168\u9762\u6316\u6398\u548c\u9a8c\u8bc1\u4ee3\u7801\u667a\u80fd\u4f53\u4e2d\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u81ea\u9002\u5e94\u8bb0\u5fc6\u6a21\u5757\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u4ee3\u7406\u7cfb\u7edfRedCodeAgent\uff0c\u80fd\u591f\u52a8\u6001\u6574\u5408\u548c\u9009\u62e9\u591a\u79cd\u73b0\u6709\u7ea2\u961f\u5de5\u5177\u53ca\u5176\u7ec4\u5408\uff0c\u81ea\u52a8\u5316\u68c0\u51fa\u4ee3\u7801\u667a\u80fd\u4f53\u4e2d\u6f5c\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u4e86\u6a21\u62df\u6c99\u7bb1\u73af\u5883\u5bf9\u4ee3\u7801\u5b9e\u9645\u6267\u884c\u7ed3\u679c\u8fdb\u884c\u8bc4\u4f30\uff0c\u51cf\u8f7b\u9759\u6001\u5206\u6790\u53caLLM\u88c1\u51b3\u5e26\u6765\u7684\u504f\u5dee\u3002", "result": "RedCodeAgent\u5728\u591a\u79cd\u4e3b\u6d41\u4ee3\u7801\u667a\u80fd\u4f53\u3001\u98ce\u9669\u573a\u666f\u548c\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u8868\u73b0\u51fa\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u653b\u51fb\u6210\u529f\u7387\u3001\u66f4\u4f4e\u7684\u62e6\u622a\u62d2\u7edd\u7387\u53ca\u8f83\u597d\u7684\u9ad8\u6548\u6027\uff0c\u4e14\u5728\u771f\u5b9e\u4ea7\u54c1\uff08\u5982Cursor\u548cCodeium\uff09\u4e2d\u53d1\u73b0\u4e86\u6b64\u524d\u672a\u516c\u5f00\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5c55\u793a\u4e86\u5176\u5f3a\u5927\u7684\u6cdb\u5316\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "RedCodeAgent\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5bf9\u4ee3\u7801\u667a\u80fd\u4f53\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u6548\u7387\uff0c\u8fd8\u80fd\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u68c0\u6d4b\u5230\u7684\u65b0\u578b\u5b89\u5168\u9690\u60a3\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u4ee3\u7801\u667a\u80fd\u4f53\u548c\u7f16\u7a0b\u52a9\u624b\u4e0a\u7684\u5b9e\u9a8c\u8868\u73b0\u4f18\u8d8a\uff0c\u6709\u6548\u63a8\u52a8\u4e86\u4ee3\u7801\u667a\u80fd\u4f53\u7684\u5b89\u5168\u6027\u7814\u7a76\u3002"}}
{"id": "2510.02333", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.02333", "abs": "https://arxiv.org/abs/2510.02333", "authors": ["Chiara Pugliese", "Francesco Lettich", "Guido Rocchietti", "Chiara Renso", "Fabio Pinelli"], "title": "Human Mobility Datasets Enriched With Contextual and Social Dimensions", "comment": "5 pages, 3 figures, 1 table", "summary": "In this resource paper, we present two publicly available datasets of\nsemantically enriched human trajectories, together with the pipeline to build\nthem. The trajectories are publicly available GPS traces retrieved from\nOpenStreetMap. Each dataset includes contextual layers such as stops, moves,\npoints of interest (POIs), inferred transportation modes, and weather data. A\nnovel semantic feature is the inclusion of synthetic, realistic social media\nposts generated by Large Language Models (LLMs), enabling multimodal and\nsemantic mobility analysis. The datasets are available in both tabular and\nResource Description Framework (RDF) formats, supporting semantic reasoning and\nFAIR data practices. They cover two structurally distinct, large cities: Paris\nand New York. Our open source reproducible pipeline allows for dataset\ncustomization, while the datasets support research tasks such as behavior\nmodeling, mobility prediction, knowledge graph construction, and LLM-based\napplications. To our knowledge, our resource is the first to combine real-world\nmovement, structured semantic enrichment, LLM-generated text, and semantic web\ncompatibility in a reusable framework.", "AI": {"tldr": "\u672c\u6587\u53d1\u5e03\u4e86\u9996\u4e2a\u878d\u5408\u4e86\u591a\u91cd\u8bed\u4e49\u589e\u5f3a\u548cLLM\u751f\u6210\u793e\u4ea4\u6587\u672c\u7684\u4eba\u7c7b\u8f68\u8ff9\u5f00\u653e\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u5df4\u9ece\u548c\u7ebd\u7ea6\uff0c\u652f\u6301\u884c\u4e3a\u5efa\u6a21\u548c\u8bed\u4e49\u63a8\u7406\u7b49\u591a\u79cd\u7814\u7a76\u4efb\u52a1\uff0c\u5e76\u9644\u5f00\u6e90\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u7c7b\u8f68\u8ff9\u6570\u636e\u96c6\u5f80\u5f80\u7f3a\u4e4f\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u548c\u53ef\u6269\u5c55\u6027\uff0c\u96be\u4ee5\u652f\u6301\u8bed\u4e49\u63a8\u7406\u548c\u591a\u6a21\u6001\u5206\u6790\uff0c\u9650\u5236\u4e86\u884c\u4e3a\u5efa\u6a21\u3001\u77e5\u8bc6\u56fe\u8c31\u7b49\u9886\u57df\u7684\u6df1\u5165\u7814\u7a76\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u548c\u5de5\u5177\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u8be5\u5de5\u4f5c\u53d1\u5e03\u4e86\u4e24\u4e2a\u4eba\u7c7b\u8f68\u8ff9\u7684\u5f00\u653e\u6570\u636e\u96c6\uff08\u5df4\u9ece\u548c\u7ebd\u7ea6\uff09\uff0c\u6240\u6709\u8f68\u8ff9\u57fa\u4e8eOpenStreetMap\u7684GPS\u8f68\u8ff9\u3002\u5bf9\u6570\u636e\u8fdb\u884c\u4e86\u591a\u5c42\u6b21\u8bed\u4e49\u4e30\u5bcc\uff0c\u5305\u62ec\u505c\u7559\u70b9\u3001\u79fb\u52a8\u6bb5\u3001\u5174\u8da3\u70b9\uff08POIs\uff09\u3001\u4ea4\u901a\u65b9\u5f0f\u63a8\u65ad\u3001\u5929\u6c14\u6570\u636e\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u5408\u6210\u4e0e\u73b0\u5b9e\u76f8\u7b26\u7684\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u3002\u6570\u636e\u96c6\u4ee5\u8868\u683c\u5f0f\u548cRDF\u683c\u5f0f\u53d1\u5e03\uff0c\u9644\u5e26\u5f00\u6e90\u7684\u53ef\u590d\u73b0\u751f\u6210\u6d41\u7a0b\uff0c\u4fbf\u4e8e\u81ea\u5b9a\u4e49\u3002", "result": "\u63d0\u4f9b\u4e86\u5e26\u591a\u91cd\u8bed\u4e49\u6807\u7b7e\u7684\u771f\u5b9e\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\uff0c\u652f\u6301\u8bed\u4e49\u63a8\u7406\u548c\u591a\u6a21\u6001\u5206\u6790\uff0c\u8986\u76d6\u4e24\u5927\u5178\u578b\u57ce\u5e02\u3002\u6570\u636e\u53ef\u7075\u6d3b\u5e94\u7528\u4e8e\u884c\u4e3a\u5efa\u6a21\u3001\u51fa\u884c\u9884\u6d4b\u3001\u77e5\u8bc6\u56fe\u8c31\u548cLLM\u5e94\u7528\u7b49\u9886\u57df\u3002\u6570\u636e\u5f00\u653e\u4e14\u53ef\u590d\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u6574\u5408\u4e86\u771f\u5b9e\u4e16\u754c\u79fb\u52a8\u6570\u636e\u3001\u7ed3\u6784\u5316\u8bed\u4e49\u589e\u5f3a\u3001LLM\u751f\u6210\u6587\u672c\u53ca\u8bed\u4e49\u7f51\u517c\u5bb9\uff0c\u6784\u5efa\u4e86\u53ef\u590d\u7528\u3001\u53ef\u62d3\u5c55\u7684\u5f00\u6e90\u4eba\u7c7b\u8f68\u8ff9\u6570\u636e\u96c6\u8d44\u6e90\uff0c\u6709\u671b\u63a8\u52a8\u591a\u9886\u57df\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2510.02634", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02634", "abs": "https://arxiv.org/abs/2510.02634", "authors": ["Hanlong Wan", "Weili Xu", "Michael Rosenberg", "Jian Zhang", "Aysha Siddika"], "title": "Automatic Building Code Review: A Case Study", "comment": null, "summary": "Building officials, particularly those in resource-constrained or rural\njurisdictions, face labor-intensive, error-prone, and costly manual reviews of\ndesign documents as projects increase in size and complexity. The growing\nadoption of Building Information Modeling (BIM) and Large Language Models\n(LLMs) presents opportunities for automated code review (ACR) solutions. This\nstudy introduces a novel agent-driven framework that integrates BIM-based data\nextraction with automated verification using both retrieval-augmented\ngeneration (RAG) and Model Context Protocol (MCP) agent pipelines. The\nframework employs LLM-enabled agents to extract geometry, schedules, and system\nattributes from heterogeneous file types, which are then processed for building\ncode checking through two complementary mechanisms: (1) direct API calls to the\nUS Department of Energy COMcheck engine, providing deterministic and\naudit-ready outputs, and (2) RAG-based reasoning over rule provisions, enabling\nflexible interpretation where coverage is incomplete or ambiguous.\n  The framework was evaluated through case demonstrations, including automated\nextraction of geometric attributes (such as surface area, tilt, and insulation\nvalues), parsing of operational schedules, and validation of lighting\nallowances under ASHRAE Standard 90.1-2022. Comparative performance tests\nacross multiple LLMs showed that GPT-4o achieved the best balance of efficiency\nand stability, while smaller models exhibited inconsistencies or failures.\nResults confirm that MCP agent pipelines outperform RAG reasoning pipelines in\nrigor and reliability. This work advances ACR research by demonstrating a\nscalable, interoperable, and production-ready approach that bridges BIM with\nauthoritative code review tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408BIM\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6574\u5408API\u4e0e\u77e5\u8bc6\u63a8\u7406\u7684\u65b0\u578b\u81ea\u52a8\u5316\u5ba1\u6838\u6846\u67b6\u3002GPT-4o\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cMCP\u5ba1\u6838\u6d41\u7a0b\u66f4\u53ef\u9760\uff0c\u4e3a\u81ea\u52a8\u5efa\u7b51\u89c4\u8303\u5ba1\u6838\u63d0\u4f9b\u4e86\u751f\u4ea7\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5efa\u7b51\u5b98\u5458\u5728\u8d44\u6e90\u53d7\u9650\u6216\u519c\u6751\u5730\u533a\u7ecf\u5e38\u9762\u4e34\u968f\u7740\u9879\u76ee\u89c4\u6a21\u548c\u590d\u6742\u6027\u589e\u52a0\uff0c\u4eba\u5de5\u5ba1\u67e5\u8bbe\u8ba1\u6587\u6863\u65e2\u8d39\u65f6\u3001\u6613\u51fa\u9519\u4e14\u6210\u672c\u9ad8\u3002\u968f\u7740BIM\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u9010\u6b65\u5e94\u7528\uff0c\u5e26\u6765\u4e86\u81ea\u52a8\u5316\u89c4\u8303\u5ba1\u6838(ACR)\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u57fa\u4e8e\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u5c06BIM\u6570\u636e\u63d0\u53d6\u4e0e\u81ea\u52a8\u5316\u9a8c\u8bc1\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528RAG\u548cMCP\u4ee3\u7406\u7ba1\u9053\u3002\u901a\u8fc7LLM\u4ee3\u7406\u62bd\u53d6\u51e0\u4f55\u3001\u8ba1\u5212\u548c\u7cfb\u7edf\u5c5e\u6027\uff0c\u7ed3\u5408(1)\u901a\u8fc7API\u8c03\u7528COMcheck\u5f15\u64ce\u8fdb\u884c\u786e\u5b9a\u6027\u5ba1\u6838\uff0c(2)RAG\u65b9\u5f0f\u5bf9\u89c4\u8303\u6761\u6587\u8fdb\u884c\u7075\u6d3b\u89e3\u8bfb\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u6f14\u793a\uff0c\u5305\u62ec\u81ea\u52a8\u63d0\u53d6\u51e0\u4f55\u5c5e\u6027\u3001\u89e3\u6790\u64cd\u4f5c\u8ba1\u5212\u3001\u9a8c\u8bc1\u7167\u660e\u914d\u989d\u7b49\uff0c\u5e76\u4e0e\u591a\u4e2aLLM\u6a21\u578b\u5bf9\u6bd4\u6d4b\u8bd5\uff0c\u53d1\u73b0GPT-4o\u5728\u6548\u7387\u4e0e\u7a33\u5b9a\u6027\u4e0a\u8868\u73b0\u6700\u4f73\u3002MCP\u7ba1\u9053\u5728\u4e25\u8c28\u6027\u548c\u53ef\u9760\u6027\u4e0a\u4f18\u4e8eRAG\u7ba1\u9053\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u662f\u53ef\u62d3\u5c55\u3001\u4e92\u64cd\u4f5c\u4e14\u53ef\u751f\u4ea7\u90e8\u7f72\uff0c\u6280\u672f\u4e0a\u5b9e\u73b0\u4e86BIM\u6570\u636e\u4e0e\u6743\u5a01\u5ba1\u6838\u5de5\u5177\u7684\u9ad8\u6548\u96c6\u6210\uff0c\u63a8\u52a8\u4e86\u5efa\u7b51\u81ea\u52a8\u89c4\u8303\u5ba1\u6838\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.02334", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02334", "abs": "https://arxiv.org/abs/2510.02334", "authors": ["Zhe Li", "Wei Zhao", "Yige Li", "Jun Sun"], "title": "Where Did It Go Wrong? Attributing Undesirable LLM Behaviors via Representation Gradient Tracing", "comment": "16 pages, 4 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities, yet\ntheir deployment is frequently undermined by undesirable behaviors such as\ngenerating harmful content, factual inaccuracies, and societal biases.\nDiagnosing the root causes of these failures poses a critical challenge for AI\nsafety. Existing attribution methods, particularly those based on parameter\ngradients, often fall short due to prohibitive noisy signals and computational\ncomplexity. In this work, we introduce a novel and efficient framework that\ndiagnoses a range of undesirable LLM behaviors by analyzing representation and\nits gradients, which operates directly in the model's activation space to\nprovide a semantically meaningful signal linking outputs to their training\ndata. We systematically evaluate our method for tasks that include tracking\nharmful content, detecting backdoor poisoning, and identifying knowledge\ncontamination. The results demonstrate that our approach not only excels at\nsample-level attribution but also enables fine-grained token-level analysis,\nprecisely identifying the specific samples and phrases that causally influence\nmodel behavior. This work provides a powerful diagnostic tool to understand,\naudit, and ultimately mitigate the risks associated with LLMs. The code is\navailable at https://github.com/plumprc/RepT.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u6fc0\u6d3b\u7a7a\u95f4\u7684\u65b0\u65b9\u6cd5\uff0c\u9ad8\u6548\u8bca\u65ad\u5e76\u5f52\u56e0LLM\u4e0d\u826f\u884c\u4e3a\uff0c\u652f\u6301\u6837\u672c\u4e0etoken\u7ea7\u522b\u5206\u6790\uff0c\u53ef\u7528\u4e8e\u63d0\u5347\u5927\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u5b89\u5168\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b9e\u9645\u90e8\u7f72\u65f6\u5e38\u5e38\u51fa\u73b0\u6709\u5bb3\u5185\u5bb9\u751f\u6210\u3001\u4e8b\u5b9e\u9519\u8bef\u53ca\u793e\u4f1a\u504f\u89c1\u7b49\u4e0d\u826f\u884c\u4e3a\uff0c\u800c\u8fd9\u4e9b\u95ee\u9898\u7684\u6839\u672c\u6210\u56e0\u96be\u4ee5\u8bca\u65ad\uff0c\u4e25\u91cd\u5a01\u80c1AI\u5b89\u5168\u3002\u73b0\u6709\u53c2\u6570\u68af\u5ea6\u5f52\u56e0\u65b9\u6cd5\u4fe1\u53f7\u566a\u58f0\u5927\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u96be\u4ee5\u6709\u6548\u8ffd\u6eaf\u548c\u5206\u6790\u6a21\u578b\u4e0d\u826f\u884c\u4e3a\u7684\u6839\u6e90\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u610f\u4e49\u7684\u5f52\u56e0\u8bca\u65ad\u5de5\u5177\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u9ad8\u6548\u7684\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790LLM\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u8868\u5f81\u53ca\u5176\u68af\u5ea6\uff0c\u76f4\u63a5\u5728\u6fc0\u6d3b\u7a7a\u95f4\u5b9e\u73b0\u6837\u672c\u4e0e\u8f93\u51fa\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u8054\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4f9d\u8d56\u53c2\u6570\u68af\u5ea6\uff0c\u800c\u662f\u5229\u7528\u6a21\u578b\u7684\u6fc0\u6d3b\u8868\u793a\u548c\u68af\u5ea6\uff0c\u7cfb\u7edf\u6027\u5730\u5e94\u7528\u4e8e\u8ffd\u8e2a\u6709\u5bb3\u5185\u5bb9\u3001\u68c0\u6d4b\u540e\u95e8\u6295\u6bd2\u548c\u8bc6\u522b\u77e5\u8bc6\u6c61\u67d3\u7b49\u4efb\u52a1\uff0c\u5e76\u80fd\u5b9e\u73b0\u7cbe\u786e\u5230token\u7ea7\u522b\u7684\u5f52\u56e0\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u6837\u672c\u7ea7\u5f52\u56e0\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8fd8\u80fd\u8fdb\u884c\u7cbe\u7ec6\u7684token\u7ea7\u5206\u6790\uff0c\u51c6\u786e\u5b9a\u4f4d\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\u7684\u5177\u4f53\u6837\u672c\u548c\u77ed\u8bed\u3002\u8be5\u6846\u67b6\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\uff0c\u5e76\u4e14\u5de5\u5177\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u3001\u5ba1\u8ba1\u548c\u51cf\u7f13LLM\u76f8\u5173\u98ce\u9669\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u6a21\u578b\u5b89\u5168\u6027\u548c\u53ef\u63a7\u6027\u3002"}}
{"id": "2510.02718", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02718", "abs": "https://arxiv.org/abs/2510.02718", "authors": ["Ali Ghanbari", "Sasan Tavakkol"], "title": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing", "comment": "2025 40th IEEE/ACM International Conference on Automated Software\n  Engineering (ASE)", "summary": "Deep neural network (DNN) mutation analysis is a promising approach to\nevaluating test set adequacy. Due to the large number of generated mutants that\nmust be tested on large datasets, mutation analysis is costly. In this paper,\nwe present a technique, named DM#, for accelerating DNN mutation testing using\nFourier analysis. The key insight is that DNN outputs are real-valued functions\nsuitable for Fourier analysis that can be leveraged to quantify mutant behavior\nusing only a few data points. DM# uses the quantified mutant behavior to\ncluster the mutants so that the ones with similar behavior fall into the same\ngroup. A representative from each group is then selected for testing, and the\nresult of the test, e.g., whether the mutant is killed or survived, is reused\nfor all other mutants represented by the selected mutant, obviating the need\nfor testing other mutants. 14 DNN models of sizes ranging from thousands to\nmillions of parameters, trained on different datasets, are used to evaluate DM#\nand compare it to several baseline techniques. Our results provide empirical\nevidence on the effectiveness of DM# in accelerating mutation testing by\n28.38%, on average, at the average cost of only 0.72% error in mutation score.\nMoreover, on average, DM# incurs 11.78, 15.16, and 114.36 times less mutation\nscore error compared to random mutant selection, boundary sample selection, and\nrandom sample selection techniques, respectively, while generally offering\ncomparable speed-up.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5085\u91cc\u53f6\u5206\u6790\u7684DNN\u53d8\u5f02\u6d4b\u8bd5\u52a0\u901f\u65b9\u6cd5DM#\uff0c\u53ef\u6709\u6548\u51cf\u5c11\u6d4b\u8bd5\u6210\u672c\uff0c\u63d0\u5347\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u8bc1\u6d4b\u8bd5\u51c6\u786e\u6027\u3002", "motivation": "\u53d8\u5f02\u6d4b\u8bd5\u53ef\u4ee5\u8bc4\u4f30\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6d4b\u8bd5\u96c6\u7684\u5145\u5206\u6027\uff0c\u4f46\u9700\u8981\u5bf9\u5927\u91cf\u53d8\u5f02\u4f53\u548c\u6570\u636e\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8ba1\u7b97\u6210\u672c\u6781\u9ad8\uff0c\u56e0\u6b64\u4e9f\u9700\u9ad8\u6548\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\u964d\u6210\u672c\u3002", "method": "\u5229\u7528\u5085\u91cc\u53f6\u5206\u6790\u91cf\u5316\u53d8\u5f02\u4f53\u884c\u4e3a\uff0c\u5c06\u884c\u4e3a\u76f8\u4f3c\u7684\u53d8\u5f02\u4f53\u805a\u7c7b\uff0c\u6bcf\u7ec4\u53ea\u9009\u4e00\u4e2a\u4ee3\u8868\u8fdb\ufa08\u6d4b\u8bd5\uff0c\u5176\u4f59\u53d8\u5f02\u4f53\u590d\u7528\u4ee3\u8868\u7ed3\u679c\uff0c\u4ece\u800c\u51cf\u5c11\u6d4b\u8bd5\u91cf\u3002", "result": "DM#\u65b9\u6cd5\u572814\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u5b9e\u8bc1\uff0c\u5e73\u5747\u80fd\u52a0\u901f\u53d8\u5f02\u6d4b\u8bd528.38%\uff0c\u4ec5\u5e26\u67650.72%\u7684\u53d8\u5f02\u5206\u6570\u8bef\u5dee\uff1b\u5176\u8bef\u5dee\u8fdc\u4f4e\u4e8e\u968f\u673a\u3001\u8fb9\u754c\u3001\u968f\u673a\u6837\u672c\u9009\u53d6\u6cd5\uff0c\u4e14\u63d0\u901f\u7c7b\u4f3c\u3002", "conclusion": "\u6587\u4e2d\u63d0\u51fa\u7684DM#\u65b9\u6cd5\u80fd\u663e\u8457\u52a0\u901f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u5f02\u6d4b\u8bd5\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u8bc1\u6781\u4f4e\u7684\u53d8\u5f02\u5206\u6570\u8bef\u5dee\uff0c\u5e76\u4e14\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u6709\u66f4\u4f18\u5f02\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.02335", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02335", "abs": "https://arxiv.org/abs/2510.02335", "authors": ["Xiao-Wen Yang", "Zihao Zhang", "Jianuo Cao", "Zhi Zhou", "Zenan Li", "Lan-Zhe Guo", "Yuan Yao", "Taolue Chen", "Yu-Feng Li", "Xiaoxing Ma"], "title": "FormalML: A Benchmark for Evaluating Formal Subgoal Completion in Machine Learning Theory", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated remarkable progress\nin formal theorem proving. Yet their ability to serve as practical assistants\nfor mathematicians, filling in missing steps within complex proofs, remains\nunderexplored. We identify this challenge as the task of subgoal completion,\nwhere an LLM must discharge short but nontrivial proof obligations left\nunresolved in a human-provided sketch. To study this problem, we introduce\nFormalML, a Lean 4 benchmark built from foundational theories of machine\nlearning. Using a translation tactic that converts procedural proofs into\ndeclarative form, we extract 4937 problems spanning optimization and\nprobability inequalities, with varying levels of difficulty. FormalML is the\nfirst subgoal completion benchmark to combine premise retrieval and complex\nresearch-level contexts. Evaluation of state-of-the-art provers highlights\npersistent limitations in accuracy and efficiency, underscoring the need for\nmore capable LLM-based theorem provers for effective subgoal completion,", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6b63\u5f0f\u7684\u673a\u5668\u5b66\u4e60\u7406\u8bba\u5b50\u76ee\u6807\u8865\u5168\u96c6\u57fa\u51c6\u6570\u636e\u96c6FormalML\uff0c\u5e76\u5206\u6790\u5f53\u524d\u5b9a\u7406\u8bc1\u660e\u5668\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\uff0c\u8868\u660e\u672a\u6765\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5927\u6a21\u578b\u63a8\u52a8\u8be5\u9886\u57df\u8fdb\u6b65\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u590d\u6742\u8bc1\u660e\u4e2d\u5e2e\u52a9\u6570\u5b66\u5bb6\u8865\u5168\u7f3a\u5931\u6b65\u9aa4\uff08\u5b50\u76ee\u6807\u8865\u5168\uff09\u7684\u80fd\u529b\u5c1a\u672a\u6df1\u5165\u63a2\u7d22\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u8bc4\u6d4b\u57fa\u51c6\u6765\u523b\u753b\u8fd9\u4e00\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u57fa\u51c6FormalML\uff0c\u5305\u62ec\u5c06\u8fc7\u7a0b\u5316\u8bc1\u660e\u8f6c\u5316\u4e3a\u58f0\u660e\u5f0f\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u6db5\u76d6\u673a\u5668\u5b66\u4e60\u57fa\u7840\u7406\u8bba\u76844937\u4e2a\u5b50\u76ee\u6807\u8865\u5168\u96c6\u95ee\u9898\uff0c\u540c\u65f6\u7ed3\u5408\u524d\u63d0\u68c0\u7d22\u548c\u590d\u6742\u80cc\u666f\uff0c\u5bf9\u73b0\u6709\u8bc1\u660e\u5668\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "FormalML\u63d0\u51fa\u540e\uff0c\u8bc4\u6d4b\u4e86\u4e3b\u6d41\u8bc1\u660e\u5668\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u65b9\u9762\u5747\u5b58\u5728\u4e0d\u8db3\uff0c\u66b4\u9732\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u8bc1\u660e\u5668\u5728\u5b50\u76ee\u6807\u8865\u5168\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u4f9d\u7136\u6709\u9650\uff0c\u8868\u660e\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u5b9a\u7406\u8bc1\u660e\u5de5\u5177\u3002"}}
{"id": "2510.02773", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02773", "abs": "https://arxiv.org/abs/2510.02773", "authors": ["Tamjid Al Rahat", "Yanju Chen", "Yu Feng", "Yuan Tian"], "title": "Automated Repair of OpenID Connect Programs (Extended Version)", "comment": "This is an extended version. The original paper is accepted to ASE\n  2025", "summary": "OpenID Connect has revolutionized online authentication based on single\nsign-on (SSO) by providing a secure and convenient method for accessing\nmultiple services with a single set of credentials. Despite its widespread\nadoption, critical security bugs in OpenID Connect have resulted in significant\nfinancial losses and security breaches, highlighting the need for robust\nmitigation strategies. Automated program repair presents a promising solution\nfor generating candidate patches for OpenID implementations. However,\nchallenges such as domain-specific complexities and the necessity for precise\nfault localization and patch verification must be addressed. We propose\nAuthFix, a counterexample-guided repair engine leveraging LLMs for automated\nOpenID bug fixing. AuthFix integrates three key components: fault localization,\npatch synthesis, and patch verification. By employing a novel Petri-net-based\nmodel checker, AuthFix ensures the correctness of patches by effectively\nmodeling interactions. Our evaluation on a dataset of OpenID bugs demonstrates\nthat AuthFix successfully generated correct patches for 17 out of 23 bugs\n(74%), with a high proportion of patches semantically equivalent to\ndeveloper-written fixes.", "AI": {"tldr": "OpenID Connect\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u57fa\u4e8eLLM\u548cPetri\u7f51\u7684\u81ea\u52a8\u8865\u4e01\u751f\u6210\u7cfb\u7edfAuthFix\uff0c\u80fd\u51c6\u786e\u5b9a\u4f4d\u548c\u4fee\u590d\u5927\u90e8\u5206\u6f0f\u6d1e\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u6548\u679c\u63a5\u8fd1\u4eba\u5de5\u4fee\u590d\u3002", "motivation": "OpenID Connect\u5e7f\u6cdb\u7528\u4e8e\u5355\u70b9\u767b\u5f55\uff08SSO\uff09\uff0c\u6781\u5927\u5730\u65b9\u4fbf\u4e86\u591a\u670d\u52a1\u8bbf\u95ee\uff0c\u4f46\u5176\u5b89\u5168\u6f0f\u6d1e\u5bfc\u81f4\u4e86\u8d22\u4ea7\u635f\u5931\u548c\u4fe1\u606f\u6cc4\u9732\uff0c\u4e9f\u9700\u66f4\u52a0\u81ea\u52a8\u5316\u548c\u7a33\u5065\u7684\u4fee\u590d\u65b9\u6848\u3002", "method": "\u63d0\u51faAuthFix\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u8fdb\u884c\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff0c\u96c6\u6210\u4e86\u6545\u969c\u5b9a\u4f4d\u3001\u8865\u4e01\u5408\u6210\u548c\u8865\u4e01\u9a8c\u8bc1\u4e09\u5927\u6a21\u5757\u3002\u901a\u8fc7\u521b\u65b0\u578b\u57fa\u4e8ePetri\u7f51\u7684\u6a21\u578b\u68c0\u6d4b\u6280\u672f\uff0c\u4fdd\u8bc1\u751f\u6210\u8865\u4e01\u7684\u6b63\u786e\u6027\u3002", "result": "\u572823\u4e2aOpenID\u771f\u5b9e\u6f0f\u6d1e\u4e0a\u6d4b\u8bd5\uff0cAuthFix\u4e3a\u5176\u4e2d17\u4e2a\u6f0f\u6d1e\uff08\u7ea674%\uff09\u751f\u6210\u4e86\u6b63\u786e\u7684\u4fee\u590d\u8865\u4e01\uff0c\u4e14\u9ad8\u6bd4\u4f8b\u8865\u4e01\u548c\u5f00\u53d1\u8005\u81ea\u884c\u4fee\u590d\u7684\u6548\u679c\u4e00\u81f4\u3002", "conclusion": "AuthFix\u5c55\u793a\u4e86LLM\u7ed3\u5408\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5728\u4fee\u590dOpenID\u7c7b\u5b89\u5168\u6f0f\u6d1e\u4e0a\u7684\u6f5c\u529b\u4e0e\u6709\u6548\u6027\uff0c\u4e3a\u5b89\u5168\u9886\u57df\u7684\u81ea\u52a8\u5316\u8865\u4e01\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.02336", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02336", "abs": "https://arxiv.org/abs/2510.02336", "authors": ["Abdulhady Abas Abdullah", "Hadi Veisi", "Hussein M. Al"], "title": "KurdSTS: The Kurdish Semantic Textual Similarity", "comment": null, "summary": "Semantic Textual Similarity (STS) measures the degree of meaning overlap\nbetween two texts and underpins many NLP tasks. While extensive resources exist\nfor high-resource languages, low-resource languages such as Kurdish remain\nunderserved. We present, to our knowledge, the first Kurdish STS dataset:\n10,000 sentence pairs spanning formal and informal registers, each annotated\nfor similarity. We benchmark Sentence-BERT, multilingual BERT, and other strong\nbaselines, obtaining competitive results while highlighting challenges arising\nfrom Kurdish morphology, orthographic variation, and code-mixing. The dataset\nand baselines establish a reproducible evaluation suite and provide a strong\nstarting point for future research on Kurdish semantics and low-resource NLP.", "AI": {"tldr": "\u4f5c\u8005\u9996\u6b21\u53d1\u5e03\u4e86\u5e93\u5c14\u5fb7\u8bedSTS\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u4e3b\u6d41\u6a21\u578b\u505a\u4e86\u57fa\u51c6\u8bc4\u6d4b\uff0c\u4e0d\u4ec5\u83b7\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u8fd8\u5206\u6790\u4e86\u5e93\u5c14\u5fb7\u8bed\u7684\u7279\u6b8a\u6311\u6218\uff0c\u4e3a\u8be5\u9886\u57df\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u8d44\u6e90\u548c\u65b9\u6cd5\u8bba\u57fa\u7840\u3002", "motivation": "\u5e93\u5c14\u5fb7\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u5145\u5206\u7684STS\u6570\u636e\u96c6\uff0c\u5236\u7ea6\u4e86\u76f8\u5173NLP\u4efb\u52a1\u7684\u53d1\u5c55\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u5e93\u5c14\u5fb7\u8bed\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\u8d44\u6e90\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b1\u4e07\u5bf9\u53e5\u5b50\u7684\u5e93\u5c14\u5fb7\u8bedSTS\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6b63\u5f0f\u548c\u975e\u6b63\u5f0f\u6587\u4f53\uff0c\u5e76\u4e3a\u6bcf\u5bf9\u53e5\u5b50\u6807\u6ce8\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3002\u91c7\u7528Sentence-BERT\u3001\u591a\u8bed\u8a00BERT\u7b49\u4e3b\u6d41\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u5e76\u63ed\u793a\u4e86\u5e93\u5c14\u5fb7\u8bed\u5f62\u6001\u7ed3\u6784\u3001\u5f02\u4f53\u4e66\u5199\u548c\u4ee3\u7801\u6df7\u6742\u7b49\u5e26\u6765\u7684\u6311\u6218\u3002\u6570\u636e\u96c6\u548c\u57fa\u7ebf\u6a21\u578b\u4e3a\u540e\u7eed\u5e93\u5c14\u5fb7\u8bed\u8bed\u4e49\u7814\u7a76\u548c\u4f4e\u8d44\u6e90NLP\u4efb\u52a1\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u53d1\u5e03\u4e86\u5e93\u5c14\u5fb7\u8bed\u7684\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\uff08STS\uff09\u6570\u636e\u96c6\uff0c\u5e76\u5efa\u7acb\u4e86\u53ef\u91cd\u590d\u8bc4\u6d4b\u57fa\u51c6\uff0c\u4e3a\u4f4e\u8d44\u6e90\u5e93\u5c14\u5fb7\u8bed\u8bed\u4e49\u76f8\u5173\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02854", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02854", "abs": "https://arxiv.org/abs/2510.02854", "authors": ["Boshuai Ye", "Arif Ali Khan", "Teemu Pihkakoski", "Peng Liang", "Muhammad Azeem Akbar", "Matti Silveri", "Lauri Malmi"], "title": "C2|Q>: A Robust Framework for Bridging Classical and Quantum Software Development", "comment": "46 pages, 8 images, 14 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "Quantum Software Engineering (QSE) is emerging as a critical discipline to\nmake quantum computing accessible to a broader developer community; however,\nmost quantum development environments still require developers to engage with\nlow-level details across the software stack - including problem encoding,\ncircuit construction, algorithm configuration, hardware selection, and result\ninterpretation - making them difficult for classical software engineers to use.\nTo bridge this gap, we present C2|Q>: a hardware-agnostic quantum software\ndevelopment framework that translates classical specifications (code) into\nquantum-executable programs while preserving methodological rigor. The\nframework applies modular software engineering principles by classifying the\nworkflow into three core modules: an encoder that classifies problems, produces\nQuantum-Compatible Formats (QCFs), and constructs quantum circuits, a\ndeployment module that generates circuits and recommends hardware based on\nfidelity, runtime, and cost, and a decoder that interprets quantum outputs into\nclassical solutions. In evaluation, the encoder module achieved a 93.8%\ncompletion rate, the hardware recommendation module consistently selected the\nappropriate quantum devices for workloads scaling up to 56 qubits, and the full\nC2|Q>: workflow successfully processed classical specifications (434 Python\nsnippets and 100 JSON inputs) with completion rates of 93.8% and 100%,\nrespectively. For case study problems executed on publicly available NISQ\nhardware, C2|Q>: reduced the required implementation effort by nearly 40X\ncompared to manual implementations using low-level quantum software development\nkits (SDKs), with empirical runs limited to small- and medium-sized instances\nconsistent with current NISQ capabilities. The open-source implementation of\nC2|Q>: is available at https://github.com/C2-Q/C2Q", "AI": {"tldr": "\u672c\u6587\u63d0\u51faC2|Q>\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u6846\u67b6\uff0c\u501f\u52a9\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u4ece\u7ecf\u5178\u4ee3\u7801\u5230\u91cf\u5b50\u7a0b\u5e8f\u7684\u81ea\u52a8\u5316\u8f6c\u6362\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u5de5\u5177\u663e\u8457\u964d\u4f4e\u4e86\u5b9e\u73b0\u95e8\u69db\u548c\u5f00\u53d1\u6210\u672c\uff0c\u63d0\u5347\u4e86\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u7684\u6613\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u8981\u6c42\u5f00\u53d1\u8005\u719f\u6089\u5e95\u5c42\u7ec6\u8282\uff08\u5982\u95ee\u9898\u7f16\u7801\u3001\u91cf\u5b50\u7535\u8def\u6784\u5efa\u3001\u7b97\u6cd5\u914d\u7f6e\u3001\u786c\u4ef6\u9009\u62e9\u548c\u7ed3\u679c\u89e3\u91ca\uff09\uff0c\u4f7f\u5f97\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u96be\u4ee5\u4f7f\u7528\u3002\u4e3a\u964d\u4f4e\u4f7f\u7528\u95e8\u69db\u3001\u63a8\u52a8\u91cf\u5b50\u8ba1\u7b97\u66f4\u5e7f\u6cdb\u843d\u5730\uff0c\u8feb\u5207\u9700\u8981\u65b0\u7684\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u548c\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86C2|Q>\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u4e0e\u786c\u4ef6\u65e0\u5173\u7684\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u6846\u67b6\u3002\u6846\u67b6\u5229\u7528\u6a21\u5757\u5316\u7684\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u5c06\u5de5\u4f5c\u6d41\u5206\u4e3a\u7f16\u7801\u5668\u3001\u90e8\u7f72\u6a21\u5757\u548c\u89e3\u7801\u5668\u4e09\u5927\u6838\u5fc3\u6a21\u5757\uff0c\u5bf9\u5e94\u5730\u5b9e\u73b0\u95ee\u9898\u5206\u7c7b\u3001\u91cf\u5b50\u683c\u5f0f\u751f\u6210\u3001\u7535\u8def\u6784\u5efa\u3001\u786c\u4ef6\u63a8\u8350\u53ca\u91cf\u5b50\u8f93\u51fa\u89e3\u91ca\u7b49\u529f\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u7f16\u7801\u5668\u6a21\u5757\u5b8c\u6210\u7387\u4e3a93.8%\uff1b\u786c\u4ef6\u63a8\u8350\u6a21\u5757\u5bf9\u4e8e\u89c4\u6a21\u6700\u9ad8\u8fbe56\u91cf\u5b50\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5747\u80fd\u9009\u51fa\u5408\u9002\u91cf\u5b50\u8bbe\u5907\uff1b\u6574\u4e2aC2|Q>\u6846\u67b6\u5904\u7406Python\u4ee3\u7801\u7247\u6bb5\uff08434\u4e2a\uff09\u548cJSON\u8f93\u5165\uff08100\u4e2a\uff09\u7684\u5b8c\u6210\u7387\u5206\u522b\u4e3a93.8%\u548c100%\u3002\u5728\u516c\u5f00NISQ\u786c\u4ef6\u4e0a\uff0c\u6846\u67b6\u80fd\u5c06\u5f00\u53d1\u5de5\u4f5c\u91cf\u964d\u4f4e\u8fd140\u500d\u3002", "conclusion": "C2|Q>\u6781\u5927\u7b80\u5316\u4e86\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\uff0c\u5e76\u6709\u6548\u964d\u4f4e\u4e86\u95e8\u69db\uff0c\u4f7f\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u80fd\u591f\u9ad8\u6548\u3001\u7cfb\u7edf\u5730\u5f00\u53d1\u91cf\u5b50\u5e94\u7528\uff0c\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u548c\u63a8\u5e7f\u6f5c\u529b\u3002"}}
{"id": "2510.02337", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02337", "abs": "https://arxiv.org/abs/2510.02337", "authors": ["Ishak Soltani", "Francisco Belo", "Bernardo Tavares"], "title": "CRACQ: A Multi-Dimensional Approach To Automated Document Assessment", "comment": null, "summary": "This paper presents CRACQ, a multi-dimensional evaluation framework tailored\nto evaluate documents across f i v e specific traits: Coherence, Rigor,\nAppropriateness, Completeness, and Quality. Building on insights from\ntraitbased Automated Essay Scoring (AES), CRACQ expands its fo-cus beyond\nessays to encompass diverse forms of machine-generated text, providing a\nrubricdriven and interpretable methodology for automated evaluation. Unlike\nsinglescore approaches, CRACQ integrates linguistic, semantic, and structural\nsignals into a cumulative assessment, enabling both holistic and trait-level\nanalysis. Trained on 500 synthetic grant pro-posals, CRACQ was benchmarked\nagainst an LLM-as-a-judge and further tested on both strong and weak real\napplications. Preliminary results in-dicate that CRACQ produces more stable and\ninterpretable trait-level judgments than direct LLM evaluation, though\nchallenges in reliability and domain scope remain", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u4e94\u4e2a\u7ef4\u5ea6\u7684\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6CRACQ\uff0c\u76f8\u8f83\u4e8e\u5927\u6a21\u578b\u76f4\u63a5\u8bc4\u5206\u5177\u5907\u66f4\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u7684trait-level\u6253\u5206\uff0c\u5bf9\u4e30\u5bcc\u591a\u6837\u7684\u751f\u6210\u6587\u672c\u5177\u5b9e\u9645\u8bc4\u4f30\u4ef7\u503c\uff0c\u4f46\u4ecd\u6709\u53ef\u9760\u6027\u548c\u9002\u7528\u8303\u56f4\u9700\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u81ea\u52a8\u6587\u672c\u8bc4\u4f30\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5355\u4e00\u8bc4\u5206\uff0c\u96be\u4ee5\u7ec6\u81f4\u3001\u89e3\u91ca\u6027\u5730\u8bc4\u4ef7\u6587\u672c\u5404\u65b9\u9762\u7279\u5f81\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u591a\u6837\u5316\u7684\u673a\u5668\u751f\u6210\u6587\u672c\u65f6\u66f4\u663e\u4e0d\u8db3\u3002\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u6587\u672c\u591a\u7ef4 trait \u8bc4\u4f30\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u8bc4\u4f30\u7684\u7ec6\u81f4\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86CRACQ\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u8fde\u8d2f\u6027\u3001\u4e25\u8c28\u6027\u3001\u9002\u5207\u6027\u3001\u5b8c\u6574\u6027\u548c\u8d28\u91cf\u4e94\u4e2a\u7ef4\u5ea6\u5bf9\u6587\u6863\u8fdb\u884c\u8bc4\u4ef7\u3002\u8be5\u65b9\u6cd5\u878d\u5408\u4e86\u8bed\u8a00\u3001\u8bed\u4e49\u53ca\u7ed3\u6784\u7279\u5f81\u4fe1\u53f7\uff0c\u5c06\u5176\u6574\u5408\u4e3a\u7d2f\u79ef\u5f0f\u8bc4\u4f30\u4f53\u7cfb\uff0c\u65e2\u80fd\u63d0\u4f9b\u6574\u4f53\u5206\u6570\uff0c\u4e5f\u53ef\u505atrait-level\u5206\u6790\u3002\u4f5c\u8005\u5bf9500\u4efd\u5408\u6210\u79d1\u7814\u8d44\u52a9\u9879\u76ee\u63d0\u6848\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4e0eLLM\u76f4\u8bc4\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u6d4b\u8bd5\u4e0d\u540c\u771f\u5b9e\u5e94\u7528\u6848\u4f8b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCRACQ\u5728trait-level\u5224\u5b9a\u4e0a\u7684\u7a33\u5b9a\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u4f18\u4e8e\u76f4\u63a5\u7528LLM\u8bc4\u4ef7\uff0c\u4f46\u7cfb\u7edf\u5728\u53ef\u9760\u6027\u548c\u9002\u7528\u9886\u57df\u7684\u5e7f\u5ea6\u4e0a\u4f9d\u7136\u5b58\u5728\u6311\u6218\u3002", "conclusion": "CRACQ\u6846\u67b6\u4e3a\u673a\u5668\u751f\u6210\u6587\u672c\u7684\u591a\u7ef4\u3001\u53ef\u89e3\u91ca\u6027\u81ea\u52a8\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u548c\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\uff0c\u4f46\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u53ef\u9760\u6027\u53ca\u9886\u57df\u9002\u5e94\u6027\u4ecd\u9700\u52aa\u529b\u3002"}}
{"id": "2510.02887", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02887", "abs": "https://arxiv.org/abs/2510.02887", "authors": ["Zhao Zhang", "Qingyuan Liang", "Zeyu Sun", "Yizhou Chen", "Guoqing Wang", "Yican Sun", "Lu Zhang", "Ge Li", "Yingfei Xiong"], "title": "GramTrans: A Better Code Representation Approach in Code Generation", "comment": null, "summary": "Code generation has shown great promise in assisting software development. A\nfundamental yet underexplored question is how the choice of code representation\naffects model performance. While existing studies employ various\nrepresentations, such as treating code as plain text, grammar rule sequences,\nor syntax tree sequences, they lack a principled understanding of the\nrelationship between parsing difficulty and model effectiveness. This paper\nproposes a conjecture: the easier a representation is to parse, the better\nperformance the model achieves. We formalize this idea using grammar classes,\nwhere representations in simpler classes (e.g., LL(1)) are easier to parse.\nThrough a controlled experiment on a Python-based DSL, we show that parsing\ndifficulty strongly correlates with model performance. Motivated by this\nfinding, we present GramTrans, a general approach that automatically transforms\na context-free language into a representation within the LL(1) class. GramTrans\nintroduces a novel hierarchical conflict elimination algorithm, enabling a\nflexible trade-off between syntactic simplicity and token efficiency. We\nevaluate GramTrans on both Python and Java using three code generation models:\nStarCoder 1B, DeepSeek-Coder 1.3B, and Qwen2.5 1.5B. Across multiple\nbenchmarks, GramTrans consistently delivers significant improvements over\nbaseline representations. Furthermore, our analysis of existing representations\nreconfirms the strong alignment between parsing difficulty and model\nperformance, providing additional support for the conjecture.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u63a2\u8ba8\u4e86\u4ee3\u7801\u8868\u793a\u89e3\u6790\u96be\u5ea6\u5bf9\u751f\u6210\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u6613\u89e3\u6790\u8868\u793a\u66f4\u4f18\u7684\u731c\u60f3\uff0c\u5e76\u901a\u8fc7GramTrans\u65b9\u6cd5\u81ea\u52a8\u6539\u8fdb\u8868\u793a\uff0c\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u9886\u57df\u5bf9\u4ee3\u7801\u8868\u793a\u672c\u8eab\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u5173\u6ce8\u4e0d\u591f\uff0c\u5c24\u5176\u662f\u7f3a\u4e4f\u5bf9\u89e3\u6790\u96be\u5ea6\u548c\u6a21\u578b\u6548\u679c\u5173\u7cfb\u7684\u7cfb\u7edf\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5bf9Python\u548cJava\u7684\u4ee3\u7801\uff0c\u91c7\u7528\u4e0d\u540c\u7684\u8868\u793a\uff08\u5305\u62ec\u65b0\u63d0\u51fa\u7684\u65b9\u6cd5GramTrans\uff0c\u4ee5\u53ca\u591a\u79cd\u73b0\u6709\u8868\u793a\uff09\uff0c\u5e76\u5728\u591a\u4e2a\u4e3b\u6d41\u4ee3\u7801\u751f\u6210\u6a21\u578b\u4e2d\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5b9a\u91cf\u5206\u6790\u4e86\u89e3\u6790\u96be\u5ea6\u4e0e\u6a21\u578b\u6027\u80fd\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u63d0\u51fa\u4e86\u81ea\u52a8\u5316\u5c06\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u8f6c\u6362\u4e3a\u6613\u4e8e\u89e3\u6790\uff08LL(1)\u7c7b\uff09\u8868\u793a\u7684\u65b9\u6cd5GramTrans\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e14\u518d\u5ea6\u9a8c\u8bc1\u4e86\u89e3\u6790\u96be\u5ea6\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5f3a\u76f8\u5173\u6027\u3002", "conclusion": "\u6587\u4e2d\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u731c\u60f3\uff1a\u8d8a\u5bb9\u6613\u89e3\u6790\u7684\u4ee3\u7801\u8868\u793a\u80fd\u591f\u5e2e\u52a9\u6a21\u578b\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4e14\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8be5\u731c\u60f3\u7684\u6b63\u786e\u6027\u3002"}}
{"id": "2510.02338", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02338", "abs": "https://arxiv.org/abs/2510.02338", "authors": ["Samyak Jhaveri", "Praphul Singh", "Jangwon Kim", "Tara Taghavi", "Krishnaram Kenthapadi"], "title": "Optimizing Long-Form Clinical Text Generation with Claim-Based Rewards", "comment": null, "summary": "Automating clinical documentation with large language models requires precise\nalignment with priorities such as completeness and factual grounding. We\npresent an evaluation-integrated reinforcement learning framework for long-form\nclinical text generation that couples Group Relative Policy Optimization (GRPO)\nwith DocLens, a claim-level evaluator that provides deterministic,\ndialogue-grounded rewards. Our method directly optimizes factual grounding and\ncompleteness without training a separate reward model or relying on\nhuman-authored references. Empirically, the approach improves clinical note\nquality and reduces training cost via a simple reward-gating strategy. An\nindependent GPT-5 qualitative evaluation further supports these gains, showing\nhigher preference for GRPO outputs in factuality, completeness, and brevity,\nwith fewer omissions and hallucinations. Because the benchmarks are relatively\nclean and the base model already well aligned, these improvements likely\nrepresent a conservative lower bound. The framework is scalable to real-world\nsettings and can incorporate custom objectives such as guideline adherence or\nbilling preferences.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u7ed3\u5408GRPO\u4e0eDocLens\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u5956\u52b1\u6a21\u578b\u5373\u53ef\u63d0\u5347\u81ea\u52a8\u5316\u4e34\u5e8a\u6587\u672c\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\uff0c\u5b9e\u9a8c\u4e0eGPT-5\u8bc4\u4f30\u5747\u8bc1\u5b9e\u6709\u6548\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u81ea\u52a8\u5316\u4e34\u5e8a\u6587\u6863\u751f\u6210\u9700\u9ad8\u5ea6\u5173\u6ce8\u5185\u5bb9\u7684\u5b8c\u6574\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4f46\u73b0\u6709\u5927\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u548c\u7f3a\u6f0f\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u4e0e\u4e34\u5e8a\u9700\u6c42\u9ad8\u5ea6\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u8bc4\u4f30\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528Group Relative Policy Optimization\uff08GRPO\uff09\u65b9\u6cd5\u7ed3\u5408DocLens\uff08\u57fa\u4e8e\u5bf9\u8bdd\u7684\u786e\u5b9a\u6027\u58f0\u79f0\u7ea7\u8bc4\u4f30\u5668\uff09\uff0c\u76f4\u63a5\u4f18\u5316\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\uff0c\u65e0\u9700\u5355\u72ec\u5956\u52b1\u6a21\u578b\u6216\u4eba\u5de5\u53c2\u8003\uff1b\u901a\u8fc7\u7b80\u5355\u5956\u52b1\u95e8\u63a7\u7b56\u7565\u63d0\u5347\u6210\u672c\u6548\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4e34\u5e8a\u6587\u672c\u7684\u4e8b\u5b9e\u6027\u548c\u5b8c\u6574\u6027\uff0c\u5e76\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c\uff1bGPT-5\u72ec\u7acb\u8bc4\u4f30\u663e\u793aGRPO\u751f\u6210\u7ed3\u679c\u5728\u4e8b\u5b9e\u6027\u3001\u5b8c\u6574\u6027\u548c\u7b80\u6d01\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9057\u6f0f\u548c\u5e7b\u89c9\u66f4\u5c11\u3002", "conclusion": "\u672c\u6846\u67b6\u5728\u5df2\u6709\u6a21\u578b\u57fa\u7840\u4e0a\u4f9d\u7136\u5e26\u6765\u53ef\u89c2\u7684\u3001\u8f83\u4e3a\u4fdd\u5b88\u7684\u63d0\u5347\uff0c\u5177\u5907\u73b0\u5b9e\u53ef\u6269\u5c55\u6027\u4e14\u80fd\u9002\u914d\u591a\u79cd\u5b9a\u5236\u76ee\u6807\u3002"}}
{"id": "2510.02917", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.02917", "abs": "https://arxiv.org/abs/2510.02917", "authors": ["Kriz Tahimic", "Charibeth Cheng"], "title": "Mechanistic Interpretability of Code Correctness in LLMs via Sparse Autoencoders", "comment": null, "summary": "As Large Language Models become integral to software development, with\nsubstantial portions of AI-suggested code entering production, understanding\ntheir internal correctness mechanisms becomes critical for safe deployment. We\napply sparse autoencoders to decompose LLM representations, identifying\ndirections that correspond to code correctness. We select predictor directions\nusing t-statistics and steering directions through separation scores from base\nmodel representations, then analyze their mechanistic properties through\nsteering, attention analysis, and weight orthogonalization. We find that code\ncorrectness directions in LLMs reliably predict incorrect code, while\ncorrection capabilities, though statistically significant, involve tradeoffs\nbetween fixing errors and preserving correct code. Mechanistically, successful\ncode generation depends on attending to test cases rather than problem\ndescriptions. Moreover, directions identified in base models retain their\neffectiveness after instruction-tuning, suggesting code correctness mechanisms\nlearned during pre-training are repurposed during fine-tuning. Our mechanistic\ninsights suggest three practical applications: prompting strategies should\nprioritize test examples over elaborate problem descriptions, predictor\ndirections can serve as error alarms for developer review, and these same\npredictors can guide selective steering, intervening only when errors are\nanticipated to prevent the code corruption from constant steering.", "AI": {"tldr": "\u901a\u8fc7\u5bf9LLM\u5185\u90e8\u8868\u5f81\u7684\u7a00\u758f\u5206\u89e3\uff0c\u672c\u6587\u63ed\u793a\u4e86\u4ee3\u7801\u6b63\u786e\u6027\u65b9\u5411\u53ef\u7528\u4e8e\u9884\u6d4b\u548c\u4fee\u6b63\u9519\u8bef\uff0c\u540c\u65f6\u4e3a\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u4e0e\u5b89\u5168\u6027\uff0c\u63d0\u51fa\u4e86\u6d4b\u8bd5\u7528\u4f8b\u4f18\u5148\u7684\u63d0\u793a\u548c\u9009\u62e9\u6027\u5f15\u5bfc\u7b49\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u7528\u4e8e\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u6709\u5927\u91cfAI\u5efa\u8bae\u4ee3\u7801\u8fdb\u5165\u5b9e\u9645\u751f\u4ea7\uff0c\u4e86\u89e3\u5176\u5185\u90e8\u6b63\u786e\u6027\u673a\u5236\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u6709\u6548\u7684\u90e8\u7f72\u3002", "method": "\u8be5\u7814\u7a76\u5e94\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5bf9LLM\u5185\u90e8\u8868\u5f81\u8fdb\u884c\u5206\u89e3\uff0c\u901a\u8fc7t\u7edf\u8ba1\u91cf\u9009\u62e9\u9884\u6d4b\u65b9\u5411\uff0c\u5e76\u7528\u5206\u79bb\u5206\u6570\u7b5b\u9009\u53ef\u5f15\u5bfc\u65b9\u5411\uff0c\u968f\u540e\u5229\u7528\u5f15\u5bfc\uff08steering\uff09\u3001\u6ce8\u610f\u529b\u5206\u6790\u548c\u6743\u91cd\u6b63\u4ea4\u5316\u7b49\u65b9\u6cd5\u5256\u6790\u5b83\u4eec\u7684\u673a\u7406\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0cLLMs\u4e2d\u7f16\u7801\u7684\u6b63\u786e\u6027\u65b9\u5411\u80fd\u6709\u6548\u9884\u6d4b\u9519\u8bef\u4ee3\u7801\u3002\u4fee\u590d\u9519\u8bef\u7684\u80fd\u529b\u867d\u663e\u8457\uff0c\u4f46\u53ef\u80fd\u5e26\u6765\u4fee\u6b63\u4e0e\u4fdd\u7559\u5df2\u6b63\u786e\u4fe1\u606f\u7684\u6743\u8861\u3002\u6a21\u578b\u751f\u6210\u4ee3\u7801\u65f6\u4e3b\u8981\u4f9d\u8d56\u5bf9\u6d4b\u8bd5\u7528\u4f8b\u7684\u5173\u6ce8\uff0c\u5176\u5728\u57fa\u7840\u6a21\u578b\u4e2d\u5b66\u5230\u7684\u6b63\u786e\u6027\u65b9\u5411\u80fd\u8fc1\u79fb\u5230\u6307\u4ee4\u5fae\u8c03\u540e\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u5411\u65e2\u53ef\u4f5c\u4e3a\u9519\u8bef\u8b66\u62a5\u4fe1\u53f7\uff0c\u4e5f\u80fd\u5f15\u5bfc\u6a21\u578b\u8fdb\u884c\u6709\u9009\u62e9\u7684\u5e72\u9884\uff0c\u4ece\u800c\u9632\u6b62\u6301\u7eed\u5f15\u5bfc\u5e26\u6765\u7684\u4ee3\u7801\u7834\u574f\u3002", "conclusion": "LLM\u4e2d\u7684\u4ee3\u7801\u6b63\u786e\u6027\u673a\u5236\u4e0e\u6a21\u578b\u9884\u8bad\u7ec3\u65f6\u5b66\u5230\u7684\u8868\u5f81\u7d27\u5bc6\u76f8\u5173\uff0c\u8fd9\u4e9b\u673a\u5236\u53ef\u5728\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u91cd\u7528\u3002\u901a\u8fc7\u9009\u62e9\u6027\u5e72\u9884\u548c\u65b0\u7684\u63d0\u793a\u7b56\u7565\uff0c\u53ef\u6709\u6548\u63d0\u5347\u4ee3\u7801\u751f\u6210\u7684\u6b63\u786e\u6027\u4e0e\u5b89\u5168\u6027\u3002"}}
{"id": "2510.02339", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02339", "abs": "https://arxiv.org/abs/2510.02339", "authors": ["Kevin Zhou", "Adam Dejl", "Gabriel Freedman", "Lihu Chen", "Antonio Rago", "Francesca Toni"], "title": "Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models", "comment": "Accepted at EMNLP Findings 2025", "summary": "Research in uncertainty quantification (UQ) for large language models (LLMs)\nis increasingly important towards guaranteeing the reliability of this\ngroundbreaking technology. We explore the integration of LLM UQ methods in\nargumentative LLMs (ArgLLMs), an explainable LLM framework for decision-making\nbased on computational argumentation in which UQ plays a critical role. We\nconduct experiments to evaluate ArgLLMs' performance on claim verification\ntasks when using different LLM UQ methods, inherently performing an assessment\nof the UQ methods' effectiveness. Moreover, the experimental procedure itself\nis a novel way of evaluating the effectiveness of UQ methods, especially when\nintricate and potentially contentious statements are present. Our results\ndemonstrate that, despite its simplicity, direct prompting is an effective UQ\nstrategy in ArgLLMs, outperforming considerably more complex approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7ed3\u5408\u5230\u8fa9\u8bba\u578b\u5927\u6a21\u578b\u7528\u4e8e\u51b3\u7b56\uff0c\u5b9e\u9a8c\u8bc1\u660e\u7b80\u5355\u7684\u76f4\u63a5\u63d0\u793a\u65b9\u5f0f\u5728\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u65f6\u6548\u679c\u7a81\u51fa\uff0c\u4e14\u8be5\u8bc4\u6d4b\u65b9\u5f0f\u672c\u8eab\u5177\u521b\u65b0\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u7814\u7a76\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u65e8\u5728\u63d0\u5347\u5176\u5728\u51b3\u7b56\u5236\u5b9a\u4e0a\u7684\u53ef\u9760\u6027\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u89e3\u91ca\u4e0e\u63a8\u7406\u7684\u573a\u666f\u4e0b\u3002\u8be5\u8bba\u6587\u5173\u6ce8\u4e8e\u5c06UQ\u65b9\u6cd5\u6574\u5408\u8fdb\u89e3\u91ca\u6027\u5f3a\u3001\u7528\u4e8e\u51b3\u7b56\u7684\u8fa9\u8bba\u578b\u5927\u6a21\u578b\uff08ArgLLMs\uff09\uff0c\u4ee5\u786e\u4fddAI\u63a8\u7406\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u8bba\u6587\u5728\u57fa\u4e8e\u8ba1\u7b97\u8bba\u8bc1\u7684ArgLLMs\u4e0a\uff0c\u5e94\u7528\u548c\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u5927\u8bed\u8a00\u6a21\u578bUQ\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5728\u4e3b\u5f20\u9a8c\u8bc1\u4efb\u52a1\uff08claim verification\uff09\u4e2d\u7684\u6548\u679c\uff0c\u4ece\u800c\u95f4\u63a5\u8bc4\u4f30\u4e86\u5404UQ\u65b9\u6cd5\u4f18\u52a3\u3002\u5b9e\u9a8c\u8fc7\u7a0b\u672c\u8eab\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684UQ\u65b9\u6cd5\u8bc4\u4f30\u65b9\u5f0f\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u3001\u6709\u4e89\u8bae\u7684\u8bed\u53e5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4fbf\u662f\u6700\u7b80\u5355\u7684\u76f4\u63a5\u63d0\u793a\uff08direct prompting\uff09\u65b9\u6cd5\uff0c\u5728ArgLLMs\u4e0a\u7684UQ\u4efb\u52a1\u4e2d\u4e5f\u76f8\u5f53\u6709\u6548\uff0c\u5e76\u8d85\u8d8a\u4e86\u4e00\u4e9b\u66f4\u4e3a\u590d\u6742\u7684UQ\u65b9\u6848\u3002", "conclusion": "\u76f4\u63a5\u63d0\u793a\u6cd5\u4f5c\u4e3a\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5728\u8fa9\u8bba\u578b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8868\u73b0\u4f18\u5f02\uff0c\u7b80\u5355\u6709\u6548\uff0c\u5bf9\u63d0\u5347\u51b3\u7b56AI\u7684\u53ef\u9760\u6027\u6709\u91cd\u8981\u610f\u4e49\u3002\u5229\u7528ArgLLMs\u53ca\u5176\u4efb\u52a1\uff0c\u4e5f\u80fd\u65b0\u9896\u3001\u6709\u6548\u5730\u8bc4\u4f30UQ\u65b9\u6cd5\u3002"}}
