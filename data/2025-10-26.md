<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 9]
- [cs.DM](#cs.DM) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs](https://arxiv.org/abs/2510.19850)
*Mostapha Kalami Heris*

Main category: cs.PL

TL;DR: 本文提出了Prompt Decorators，一种用紧凑控制标记提升大语言模型输出可控性的声明式语法框架，显著增强了提示设计的灵活性与可解释性，对AI系统的标准化和扩展性有积极意义。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在推理、写作和决策支持中非常重要，但用户难以稳定、系统地控制它们的推理与表达方式，且现有的自然语言提示工程冗长、不易复用、解释性差。

Method: 提出了一种声明式、可组合的新型语法——Prompt Decorators，使用紧凑的控制标记（如+++Reasoning, +++Tone(style=formal)等）对LLM的行为进行调控。该框架系统化了20种核心装饰器，分为两大功能家族，支持行为维度的细致控制，并定义了统一的语法、作用域模型和确定性处理流程。

Result: Prompt Decorators能将任务意图与执行行为分离，极大提升提示设计的可复用性与可解释性。实际应用中案例展示了推理更透明、提示更精简、模型行为更加标准化等优势。

Conclusion: Prompt Decorators为LLM提示设计提供了新的声明式接口，有助于提升AI系统的行为一致性、可互操作性和可扩展性。

Abstract: Large Language Models (LLMs) are central to reasoning, writing, and
decision-support workflows, yet users lack consistent control over how they
reason and express outputs. Conventional prompt engineering relies on verbose
natural-language instructions, limiting reproducibility, modularity, and
interpretability. This paper introduces Prompt Decorators, a declarative,
composable syntax that governs LLM behavior through compact control tokens such
as +++Reasoning, +++Tone(style=formal), and +++Import(topic="Systems
Thinking"). Each decorator modifies a behavioral dimension, such as reasoning
style, structure, or tone, without changing task content. The framework
formalizes twenty core decorators organized into two functional families
(Cognitive & Generative and Expressive & Systemic), each further decomposed
into subcategories that govern reasoning, interaction, expression, and
session-control. It defines a unified syntax, scoping model, and deterministic
processing pipeline enabling predictable and auditable behavior composition. By
decoupling task intent from execution behavior, Prompt Decorators create a
reusable and interpretable interface for prompt design. Illustrative use cases
demonstrate improved reasoning transparency, reduced prompt complexity, and
standardized model behavior across domains. The paper concludes with
implications for interoperability, behavioral consistency, and the development
of declarative interfaces for scalable AI systems.

</details>


### [2] [A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification](https://arxiv.org/abs/2510.19853)
*Assaf Marron,David Harel*

Main category: cs.PL

TL;DR: 本文提出“算法规范领域”文档，用于归纳执行算法规范所需知识。该领域有望通过自动化和文档复用实现，进而提升算法规范的独立性和机械实现有效性，也为评估算法执行的忠实度提供新视角。


<details>
  <summary>Details</summary>
Motivation: 目前算法使用自然语言或伪代码进行描述，但这些描述往往对执行者需要具备的知识并不明确。本文旨在明确划定“执行算法规范”所需的相关知识，促进算法规范的独立与机械化执行。

Method: 本文提出定义并归纳“算法规范领域”文档，系统性地分析该领域所需的各类知识。并探讨大型语言模型和已有文档复用在自动生成此领域的可行性。

Result: 提出了算法规范领域的初步概念，包括：规范语言的语法和语义、特定领域知识、实体间关系、因果规则与操作执行说明等。强调领域文档的小型化和可总结性，以及自动化生成的潜力。

Conclusion: 系统性整理算法执行所需知识，可以提升算法规范在多系统实现和机械验证中的可移植性、清晰性与执行的忠实度。提出了领域文档方法，并简要讨论了执行忠实度的评估问题。

Abstract: An algorithm specification in natural language or pseudocode is expected to
be clear and explicit enough to enable mechanical execution. In this position
paper we contribute an initial characterization of the knowledge that an
executing agent, human or machine, should possess in order to be able to carry
out the instructions of a given algorithm specification as a stand-alone
entity, independent of any system implementation. We argue that, for that
algorithm specification, such prerequisite knowledge, whether unique or shared
with other specifications, can be summarized in a document of practical size.
We term this document the realm of the algorithm specification. The generation
of such a realm is itself a systematic analytical process, significant parts of
which can be automated with the help of large language models and the reuse of
existing documents. The algorithm-specification's realm would consist of
specification language syntax and semantics, domain knowledge restricted to the
referenced entities, inter-entity relationships, relevant underlying
cause-and-effect rules, and detailed instructions and means for carrying out
certain operations. Such characterization of the realm can contribute to
methodological implementation of the algorithm specification in diverse systems
and to its formalization for mechanical verification. The paper also touches
upon the question of assessing execution faithfulness, which is distinct from
correctness: in the absence of a reference interpretation of natural language
or pseudocode specification with a given vocabulary, how can we determine if an
observed agent's execution indeed complies with the input specification.

</details>


### [3] [Deconstructed Proto-Quipper: A Rational Reconstruction](https://arxiv.org/abs/2510.20018)
*Ryan Kavanagh,Chuta Sano,Brigitte Pientka*

Main category: cs.PL

TL;DR: 本文提出Proto-Quipper-A语言，以线性λ-演算为基础简化并规范化量子电路生成，解决了Proto-Quipper原有语义复杂性问题，并证明该语言是可归一化的。


<details>
  <summary>Details</summary>
Motivation: Proto-Quipper语言的操作语义复杂且难以机械化，基于电路的构造涉及新名字生成和集合论操作，难以用传统技术形式化和推理。该研究旨在提供更简洁、便于推理和机械化的理论基础。

Method: 提出Proto-Quipper-A，一种基于线性λ-演算的电路生成语言，并通过标准逻辑关系方法证明其归一化，避免了现有方法的复杂性。

Result: Proto-Quipper-A拥有简单的归约语义且可以归一化，并且能用标准逻辑关系方法处理线性和子结构系统的归一化证明。

Conclusion: Proto-Quipper-A语言通过线性λ-演算和伴随逻辑基础，成功规范化了Proto-Quipper语言的静态电路生成，并证明其归一化性质。

Abstract: The Proto-Quipper family of programming languages aims to provide a formal
foundation for the Quipper quantum programming language. Unfortunately,
Proto-Quipper languages have complex operational semantics: they are inherently
effectful, and they rely on set-theoretic operations and fresh name generation
to manipulate quantum circuits. This makes them difficult to reason about using
standard programming language techniques and, ultimately, to mechanize. We
introduce Proto-Quipper-A, a rational reconstruction of Proto-Quipper languages
for static circuit generation. It uses a linear $\lambda$-calculus to describe
quantum circuits with normal forms that closely correspond to box-and-wire
circuit diagrams. Adjoint-logical foundations integrate this circuit language
with a linear/non-linear functional language and let us reconstruct
Proto-Quipper's circuit programming abstractions using more primitive
adjoint-logical operations. Proto-Quipper-A enjoys a simple call-by-value
reduction semantics, and to illustrate its tractability as a foundation for
Proto-Quipper languages, we show that it is normalizing. We show how to use
standard logical relations to prove normalization of linear and substructural
systems, thereby avoiding the inherent complexity of existing linear logical
relations.

</details>


### [4] [Deciding not to Decide: Sound and Complete Effect Inference in the Presence of Higher-Rank Polymorphism](https://arxiv.org/abs/2510.20532)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 本文提出了一种基于命题逻辑公式处理效应约束的方法，实现了具有高阶多态和子类型支持的类型与效应推断算法，并经过理论验证和实际实现，推动类型与效应系统更易于应用。


<details>
  <summary>Details</summary>
Motivation: 类型与效应系统能帮助程序员组织程序中的数据和计算效应，但相关系统由于复杂性高、推断算法在表达力、易用性和可判定性间的权衡，导致并未广泛应用。为此，需要推动更实用且高效的类型与效应推断算法。

Method: 提出了一种适用于具有子类型、高阶多态以及集合语义效应的类型与效应系统的效应推断算法。为解决高阶多态的作用域问题，将效应约束延迟求解，并转换为命题逻辑公式。算法的正确性在Rocq定理证明器中形式化证明，并实现于真实编程语言中。

Result: 证明了算法在声称的类型与效应系统下的正确性与完备性。算法已被实际实现并应用于现实编程语言。

Conclusion: 本文提出的高表达力、形式化保证的类型与效应推断算法，能够为具有子类型和高阶多态的语言提供实用且可靠的类型与效应分析。其理论和实现都达成了预设目标，并为类型与效应系统更广泛应用提供了基础。

Abstract: Type-and-effect systems help the programmer to organize data and
computational effects in a program. While for traditional type systems
expressive variants with sophisticated inference algorithms have been developed
and widely used in programming languages, type-and-effect systems did not yet
gain widespread adoption. One reason for this is that type-and-effect systems
are more complex and the existing inference algorithms make compromises between
expressiveness, intuitiveness, and decidability. In this work, we present an
effect inference algorithm for a type-and-effect system with subtyping,
expressive higher-rank polymorphism, and intuitive set-like semantics of
effects. In order to deal with scoping issues of higher-rank polymorphism, we
delay solving of effect constraints by transforming them into formulae of
propositional logic. We prove soundness and completeness of our algorithm with
respect to a declarative type-and-effect system. All the presented results have
been formalized in the Rocq proof assistant, and the algorithm has been
successfully implemented in a realistic programming language.

</details>


### [5] [Compiling the Mimosa programming language to RTOS tasks](https://arxiv.org/abs/2510.20547)
*Nikolaus Huber,Susanne Graf,Philipp Rümmer,Wang Yi*

Main category: cs.PL

TL;DR: 本文针对嵌入式系统的Mimosa编程语言，提出并形式化了一套编译方案，使其可通过实时操作系统原语进行实现，提升了系统的软件开发与运行效率。


<details>
  <summary>Details</summary>
Motivation: 当前嵌入式系统软件对时间触发式进程及FIFO队列通信的支持有限，Mimosa语言旨在更好地描述和实现这种模型。

Method: 将Lustre编译方案适配至Mimosa语言的语义，并详细说明如何将协调层映射到实时操作系统原语。

Result: 成功提出了Mimosa语言的编译流程，并实现了与操作系统原语的有效对应。

Conclusion: 本文提出了一种针对Mimosa编程语言的编译方案，将其应用于实时操作系统。

Abstract: This paper introduces a compilation scheme for programs written in the Mimosa
programming language, which builds upon the MIMOS model of computation. Mimosa
describes embedded systems software as a collection of time-triggered processes
which communicate through FIFO queues. We formally describe an adaptation of
the Lustre compilation scheme to the semantics of Mimosa and show how the
coordination layer can be mapped to real-time operating system primitives.

</details>


### [6] [SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe Code in Rust and Mixed-Language Applications](https://arxiv.org/abs/2510.20688)
*Oliver Braunsdorf,Tim Lange,Konrad Hohentanner,Julian Horsch,Johannes Kinder*

Main category: cs.PL

TL;DR: SafeFFI系统通过优化内存安全检查边界，显著减少Rust程序中的Sanitizer检测次数，有效提升性能且保证安全，适用于与C/C++互操作及使用unsafe代码场景。


<details>
  <summary>Details</summary>
Motivation: Rust语言虽然以高内存安全性著称，但在与C/C++库互操作和实现底层数据结构时，不可避免地需要使用unsafe代码，这可能导致内存安全问题。现有方法主要依赖Sanitizer动态检测，但会进行大量不必要的内存安全检查，增加运行开销。

Method: 提出了SafeFFI系统，将内存安全检查优化，主要在安全与非安全代码边界进行检查。该方法将内存安全的保障从Sanitizer转交至Rust类型系统，不采用昂贵的全程序分析方案，减少编译时开销。

Result: 在大量流行Rust crate和已知有漏洞的代码中，SafeFFI系统相较当前方案性能更好，最多能减少98%的Sanitizer检查，同时保持正确性，并能检测所有空间和时间上的内存安全违规。

Conclusion: SafeFFI有效在保证安全的前提下极大优化了Rust程序中的内存安全检测效率，展现出在性能和安全性之间的优越权衡。

Abstract: Unsafe Rust code is necessary for interoperability with C/C++ libraries and
implementing low-level data structures, but it can cause memory safety
violations in otherwise memory-safe Rust programs. Sanitizers can catch such
memory errors at runtime, but introduce many unnecessary checks even for memory
accesses guaranteed safe by the Rust type system. We introduce SafeFFI, a
system for optimizing memory safety instrumentation in Rust binaries such that
checks occur at the boundary between unsafe and safe code, handing over the
enforcement of memory safety from the sanitizer to the Rust type system. Unlike
previous approaches, our design avoids expensive whole-program analysis and
adds much less compile-time overhead (2.64x compared to over 8.83x). On a
collection of popular Rust crates and known vulnerable Rust code, SafeFFI
achieves superior performance compared to state-of-the-art systems, reducing
sanitizer checks by up to 98%, while maintaining correctness and flagging all
spatial and temporal memory safety violations.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Exploring Large Language Models for Access Control Policy Synthesis and Summarization](https://arxiv.org/abs/2510.20692)
*Adarsh Vatsa,Bethel Hall,William Eiers*

Main category: cs.SE

TL;DR: 论文研究LLMs应用于云计算访问控制策略的生成与分析。发现自动生成策略准确率有限，但在分析现有策略上表现突出，尤其与传统符号方法结合下效果最佳。


<details>
  <summary>Details</summary>
Motivation: 云计算服务普及，访问控制策略管理变得复杂且易出错，亟需自动化工具提升策略编写与分析的准确性和效率。

Method: 调研多种大语言模型（LLMs）在访问控制策略合成和摘要生成中的表现，尤其比较推理型与非推理型模型。同时，引入基于语义的请求摘要方法，通过LLMs分析现有策略。

Result: 非推理LLMs仅45.8%能生成等价策略，推理LLMs提升至93.7%，但自动生成策略仍有问题。组合符号方法后，LLMs在分析现有策略时表现优异。

Conclusion: LLMs在自动生成访问控制策略方面存在显著障碍，但在分析和理解复杂政策时，与符号方法结合能显著提升效果。

Abstract: Cloud computing is ubiquitous, with a growing number of services being hosted
on the cloud every day. Typical cloud compute systems allow administrators to
write policies implementing access control rules which specify how access to
private data is governed. These policies must be manually written, and due to
their complexity can often be error prone. Moreover, existing policies often
implement complex access control specifications and thus can be difficult to
precisely analyze in determining their behavior works exactly as intended.
Recently, Large Language Models (LLMs) have shown great success in automated
code synthesis and summarization. Given this success, they could potentially be
used for automatically generating access control policies or aid in
understanding existing policies. In this paper, we explore the effectiveness of
LLMs for access control policy synthesis and summarization. Specifically, we
first investigate diverse LLMs for access control policy synthesis, finding
that: although LLMs can effectively generate syntactically correct policies,
they have permissiveness issues, generating policies equivalent to the given
specification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time
for reasoning LLMs. We then investigate how LLMs can be used to analyze
policies by introducing a novel semantic-based request summarization approach
which leverages LLMs to generate a precise characterization of the requests
allowed by a policy. Our results show that while there are significant hurdles
in leveraging LLMs for automated policy generation, LLMs show promising results
when combined with symbolic approaches in analyzing existing policies.

</details>


### [8] [E-Test: E'er-Improving Test Suites](https://arxiv.org/abs/2510.19860)
*Ketai Qiu,Luca Di Grazia,Leonardo Mariani,Mauro Pezzè*

Main category: cs.SE

TL;DR: 本文提出E-Test，通过LLM自动识别并补充未覆盖的生产测试场景，显著提升测试套件覆盖率与质量，减少人工维护工作，实验中性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有测试套件难以覆盖所有实际执行场景，特别是生产环境中出现的新场景，补充这些缺口费时费力，亟需自动化方法提升测试有效性。

Method: E-Test利用大语言模型（LLMs），从大量生产场景收集数据，识别未被现有测试覆盖的执行场景，并自动生成新测试用例来扩展测试套件。

Result: 在包含1975个生产环境场景的数据集上，E-Test的F1分数达0.55，明显优于其它最新方法（最高F1为0.34），以及原生LLM方法（最高F1为0.39），表明其能更好识别和覆盖未测试场景。

Conclusion: E-Test能有效提升测试套件质量，通过增加覆盖生产环境新场景的测试用例，显著提高测试全面性，并减少手动维护工作量。

Abstract: Test suites are inherently imperfect, and testers can always enrich a suite
with new test cases that improve its quality and, consequently, the reliability
of the target software system. However, finding test cases that explore
execution scenarios beyond the scope of an existing suite can be extremely
challenging and labor-intensive, particularly when managing large test suites
over extended periods.
  In this paper, we propose E-Test, an approach that reduces the gap between
the execution space explored with a test suite and the executions experienced
after testing by augmenting the test suite with test cases that explore
execution scenarios that emerge in production. E-Test (i) identifies executions
that have not yet been tested from large sets of scenarios, such as those
monitored during intensive production usage, and (ii) generates new test cases
that enhance the test suite. E-Test leverages Large Language Models (LLMs) to
pinpoint scenarios that the current test suite does not adequately cover, and
augments the suite with test cases that execute these scenarios.
  Our evaluation on a dataset of 1,975 scenarios, collected from highly-starred
open-source Java projects already in production and Defects4J, demonstrates
that E-Test retrieves not-yet-tested execution scenarios significantly better
than state-of-the-art approaches. While existing regression testing and field
testing approaches for this task achieve a maximum F1-score of 0.34, and
vanilla LLMs achieve a maximum F1-score of 0.39, E-Test reaches 0.55. These
results highlight the impact of E-Test in enhancing test suites by effectively
targeting not-yet-tested execution scenarios and reducing manual effort
required for maintaining test suites.

</details>


### [9] [SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations](https://arxiv.org/abs/2510.19864)
*Amila Indika,Igor Molybog*

Main category: cs.SE

TL;DR: 提出一种AI方法将电子表格操作代码自动转化为自然语言文档，并构建了对比基准和主流模型评测，验证了该方法的应用前景和可行性。


<details>
  <summary>Details</summary>
Motivation: 工作表在商业、会计和金融等领域被广泛使用，但缺乏系统的文档化方法，导致自动化、协作和知识传递效率低下，存在关键知识流失的风险。

Method: 提出了Spreadsheet Operations Documentation (SOD)这一AI任务，即将工作表操作代码自动生成可读性强的文字解释。构建了包含111个代码及其对应自然语言描述的基准数据集，并用多种大语言模型（如GPT-4o、LLaMA等），借助BLEU、GLEU、ROUGE-L和METEOR等自动评测指标进行实验评估。

Result: 多种主流大语言模型在该任务中的表现较好，能生成准确的电子表格操作文档，证明SOD任务的可行性。但模型在部分细节和准确性方面仍然存在挑战。

Conclusion: SOD可作为提升电子表格可复现性、可维护性和协作性的前置步骤，有助于防止知识流失，但需要进一步改进以应对现有挑战。

Abstract: Numerous knowledge workers utilize spreadsheets in business, accounting, and
finance. However, a lack of systematic documentation methods for spreadsheets
hinders automation, collaboration, and knowledge transfer, which risks the loss
of crucial institutional knowledge. This paper introduces Spreadsheet
Operations Documentation (SOD), an AI task that involves generating
human-readable explanations from spreadsheet operations. Many previous studies
have utilized Large Language Models (LLMs) for generating spreadsheet
manipulation code; however, translating that code into natural language for SOD
is a less-explored area. To address this, we present a benchmark of 111
spreadsheet manipulation code snippets, each paired with a corresponding
natural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini,
LLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and
METEOR metrics. Our findings suggest that LLMs can generate accurate
spreadsheet documentation, making SOD a feasible prerequisite step toward
enhancing reproducibility, maintainability, and collaborative workflows in
spreadsheets, although there are challenges that need to be addressed.

</details>


### [10] [Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation](https://arxiv.org/abs/2510.19868)
*Qian Xiong,Bo Yang,Weisong Sun,Yiran Zhang,Tianlin Li,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: 本文提出了知识引导的多智能体代码生成框架KGACG，通过分工协作和反馈机制将需求与设计转化为可执行代码，并以坦克大战案例进行验证，显示出提升应用级代码生成自动化的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前使用大型语言模型进行自动化代码生成，尽管提高了开发效率，但在生成复杂的、应用级别的软件代码时仍面临挑战，尤其是在项目代码组织结构合理性和代码生成过程可维护性方面存在不足。多智能体框架有所助益，但现有方法在应用级代码生成上表现仍不理想。

Method: 提出了一个知识引导的应用级代码生成框架（KGACG），通过Code Organization & Planning Agent（COPA）、Coding Agent（CA）和Testing Agent（TA）三类智能体的协作循环，并结合反馈机制，将需求规范和架构设计文档转化为可执行代码。

Result: 在Java坦克大战游戏案例中展示了KGACG各智能体的协同过程，验证了框架的可行性和在自动化应用级软件开发上的潜力，尽管在实际应用中仍面临一定挑战。

Conclusion: KGACG框架可提高应用级软件代码自动化生成的质量和效率，尤其改善代码组织结构和维护过程，为软件开发自动化提供了新的思路。

Abstract: Automated code generation driven by Large Lan- guage Models (LLMs) has
enhanced development efficiency, yet generating complex application-level
software code remains challenging. Multi-agent frameworks show potential, but
existing methods perform inadequately in large-scale application-level software
code generation, failing to ensure reasonable orga- nizational structures of
project code and making it difficult to maintain the code generation process.
To address this, this paper envisions a Knowledge-Guided Application-Level Code
Generation framework named KGACG, which aims to trans- form software
requirements specification and architectural design document into executable
code through a collaborative closed- loop of the Code Organization & Planning
Agent (COPA), Coding Agent (CA), and Testing Agent (TA), combined with a
feedback mechanism. We demonstrate the collaborative process of the agents in
KGACG in a Java Tank Battle game case study while facing challenges. KGACG is
dedicated to advancing the automation of application-level software
development.

</details>


### [11] [BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills](https://arxiv.org/abs/2510.19898)
*Atharv Sonwane,Isadora White,Hyunji Lee,Matheus Pereira,Lucas Caccia,Minseon Kim,Zhengyan Shi,Chinmay Singh,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan*

Main category: cs.SE

TL;DR: 提出一种能产生更真实、多样的高质量bug的新方法，大幅提升语言模型软件工程代理的训练有效性。新bug集用更少数据让模型达到更优性能，刷新多个SWE-bench基准成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的bug生成方法多采用人为扰动代码，通常会造成分布外效应，不符合真实开发场景。高质量、真实的bug数据对训练更强大的软件工程代理至关重要。

Method: 通过指导SWE代理在引入新特性过程中无意中导致测试损坏，从而在代码库中生成贴近真实开发流程的多样化复杂bug。

Result: 所提出方法生成的bug数据在用更少训练样本(1.2k对比3k)情况下，模型表现超越其他bug数据集2%。基于新数据训练，FrogBoss模型在SWE-bench上达到pass@1 54.6%，FrogMini模型达到45.3%，均为同参数规模下的新SOTA。

Conclusion: 通过引入更真实且多样的高质量bug，可以更有效地提升基于语言模型的软件工程代理的训练效果。所提出的方法生成的bug比以往的数据集性能更优，显著提升了模型在SWE-bench的表现。

Abstract: High quality bugs are key to training the next generation of language model
based software engineering (SWE) agents. We introduce a novel method for
synthetic generation of difficult and diverse bugs. Our method instructs SWE
Agents to introduce a feature into the codebase whereby they may
unintentionally break tests, resulting in bugs. Prior approaches often induce
an out-of-distribution effect by generating bugs intentionally (e.g. by
introducing local perturbation to existing code), which does not reflect
realistic development processes. We perform qualitative analysis to demonstrate
that our approach for generating bugs more closely reflects the patterns found
in human-authored edits. Through extensive experiments, we demonstrate that our
bugs provide more efficient training data for supervised fine-tuning,
outperforming other bug datasets by 2% with half the training data (1.2k vs. 3k
bugs). We train on our newly generated bugs in addition to existing bug
datasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench
Verified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on
SWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over
three seeds.

</details>


### [12] [On Interaction Effects in Greybox Fuzzing](https://arxiv.org/abs/2510.19984)
*Konstantinos Kitsios,Marcel Böhme,Alberto Bacchelli*

Main category: cs.SE

TL;DR: 本文发现变异器应用顺序影响灰盒模糊测试效果，提出学习变异器序列更有效的 MuoFuzz，在多个基准测试上优于主流工具并发现额外漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有的灰盒模糊测试工具随机或独立选择变异器，未充分利用变异器之间顺序对测试有效性的潜在影响。希望通过优化变异器应用顺序，提高测试效率和漏洞发现能力。

Method: 提出了一种新的模糊测试器 MuoFuzz，通过拟合线性模型分析变异器应用顺序的有效性，学习变异器间的条件概率，并基于概率进行变异器选择。与现有方法的性能进行了对比实验。

Result: 在 FuzzBench 和 MAGMA 基准测试中，MuoFuzz 实现了最高的代码覆盖率，并发现了 AFL++ 未能检测到的 4 个漏洞，以及 AFL++ 和 MOPT 都未发现的 1 个漏洞。

Conclusion: MuoFuzz 能够通过学习并利用变异器序列间的关系，提升覆盖率，并发现其他主流模糊测试工具未能发现的漏洞。

Abstract: A greybox fuzzer is an automated software testing tool that generates new
test inputs by applying randomly chosen mutators (e.g., flipping a bit or
deleting a block of bytes) to a seed input in random order and adds all
coverage-increasing inputs to the corpus of seeds. We hypothesize that the
order in which mutators are applied to a seed input has an impact on the
effectiveness of greybox fuzzers. In our experiments, we fit a linear model to
a dataset that contains the effectiveness of all possible mutator pairs and
indeed observe the conjectured interaction effect. This points us to more
efficient fuzzing by choosing the most promising mutator sequence with a higher
likelihood. We propose MuoFuzz, a greybox fuzzer that learns and chooses the
most promising mutator sequences. MuoFuzz learns the conditional probability
that the next mutator will yield an interesting input, given the previously
selected mutator. Then, it samples from the learned probability using a random
walk to generate mutator sequences. We compare the performance of MuoFuzz to
AFL++, which uses a fixed selection probability, and MOPT, which optimizes the
selection probability of each mutator in isolation. Experimental results on the
FuzzBench and MAGMA benchmarks show that MuoFuzz achieves the highest code
coverage and finds four bugs missed by AFL++ and one missed by both AFL++ and
MOPT.

</details>


### [13] [A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)](https://arxiv.org/abs/2510.19997)
*Abraham Itzhak Weinberg*

Main category: cs.SE

TL;DR: 该论文提出了FAIGMOE框架，弥补了GenAI在组织应用过程中缺乏针对性指导的空白，为不同规模组织落地GenAI提供了具体、可操作的方法和工具。


<details>
  <summary>Details</summary>
Motivation: 本文关注生成式人工智能（GenAI）在不同规模组织（中型企业和大型企业）中的应用。由于现有技术采纳理论（如TAM、TOE、DOI）缺乏针对GenAI的具体指导，组织在采纳过程中遇到诸多障碍，促使作者提出新的解决方案。

Method: 作者提出了一个名为FAIGMOE的概念性框架，综合了技术采纳理论、组织变革管理和创新扩散视角，将采纳过程划分为战略评估、规划与用例开发、实施与集成、运营与优化四个阶段，并针对GenAI的特点给出可扩展的操作建议。

Result: FAIGMOE框架为中型和大型企业提供了针对GenAI采纳的详细实施协议、评估工具和治理模板，并涵盖了如提示工程、模型编排和幻觉管理等GenAI特有问题。

Conclusion: 这项工作首次系统性地提出了一个专门面向中型和大型组织的GenAI采纳与集成综合框架，为未来的实际应用和后续实证研究奠定了基础。

Abstract: Generative Artificial Intelligence (GenAI) presents transformative
opportunities for organizations, yet both midsize organizations and larger
enterprises face distinctive adoption challenges. Midsize organizations
encounter resource constraints and limited AI expertise, while enterprises
struggle with organizational complexity and coordination challenges. Existing
technology adoption frameworks, including TAM (Technology Acceptance Model),
TOE (Technology Organization Environment), and DOI (Diffusion of Innovations)
theory, lack the specificity required for GenAI implementation across these
diverse contexts, creating a critical gap in adoption literature. This paper
introduces FAIGMOE (Framework for the Adoption and Integration of Generative AI
in Midsize Organizations and Enterprises), a conceptual framework addressing
the unique needs of both organizational types. FAIGMOE synthesizes technology
adoption theory, organizational change management, and innovation diffusion
perspectives into four interconnected phases: Strategic Assessment, Planning
and Use Case Development, Implementation and Integration, and
Operationalization and Optimization. Each phase provides scalable guidance on
readiness assessment, strategic alignment, risk governance, technical
architecture, and change management adaptable to organizational scale and
complexity. The framework incorporates GenAI specific considerations including
prompt engineering, model orchestration, and hallucination management that
distinguish it from generic technology adoption frameworks. As a perspective
contribution, FAIGMOE provides the first comprehensive conceptual framework
explicitly addressing GenAI adoption across midsize and enterprise
organizations, offering actionable implementation protocols, assessment
instruments, and governance templates requiring empirical validation through
future research.

</details>


### [14] [The Cost of Downgrading Build Systems: A Case Study of Kubernetes](https://arxiv.org/abs/2510.20041)
*Gareema Ranjan,Mahmoud Alfadel,Gengyi Sun,Shane McIntosh*

Main category: cs.SE

TL;DR: 本文以Kubernetes及其他四个项目为例，分析从Bazel降级到Go Build的过程，发现降级虽提升了可维护性，却造成构建速度下降、资源消耗增加，建议在选择构建工具时需慎重权衡性能与可维护性。


<details>
  <summary>Details</summary>
Motivation: 构建系统的性能影响开发者生产力。尽管现代基于工件的构建工具（如Bazel）可以加速构建，但由于维护难度，团队可能会弃用它们选择易于维护的替代品。此前工作虽解释了弃用原因，弃用的具体影响尚未深入探讨。

Method: 以Kubernetes项目为例，分析从基于工件的构建工具（Bazel）降级到语言专用构建工具（Go Build）的过程，重新构建并分析降级期间的完整和增量构建数据。此外，在另外四个同样从Bazel降级的项目上复现并对比研究观察。

Result: Bazel构建速度整体快于Go Build（全量构建为23.06-38.66分钟），但内存占用更高（达到81.42-351.07MB），并且在更高并行度下CPU负载较大。降级后持续集成资源成本最多可增76%。在其他项目上重复实验后发现，虽然构建时间差异减小，但Bazel仍消耗更多内存。

Conclusion: 放弃基于工件的构建工具以改善可维护性，通常会为大型项目带来显著性能损失。研究结果有助于相关利益方在构建工具应用中权衡性能和维护性。

Abstract: Since developers invoke the build system frequently, its performance can
impact productivity. Modern artifact-based build tools accelerate builds, yet
prior work shows that teams may abandon them for alternatives that are easier
to maintain. While prior work shows why downgrades are performed, the
implications of downgrades remain largely unexplored. In this paper, we
describe a case study of the Kubernetes project, focusing on its downgrade from
an artifact-based build tool (Bazel) to a language-specific solution (Go
Build). We reproduce and analyze the full and incremental builds of change sets
during the downgrade period. On the one hand, we find that Bazel builds are
faster than Go Build, completing full builds in 23.06-38.66 up to 75.19 impose
a larger memory footprint than Go Build of 81.42-351.07 respectively. Bazel
builds also impose a greater CPU load at parallelism settings above eight for
full builds and above one for incremental builds. We estimate that downgrading
from Bazel can increase CI resource costs by up to 76 explore whether our
observations generalize by replicating our Kubernetes study on four other
projects that also downgraded from Bazel to older build tools. We observe that
while build time penalties decrease, Bazel consistently consumes more memory.
We conclude that abandoning artifact-based build tools, despite perceived
maintainability benefits, tends to incur considerable performance costs for
large projects. Our observations may help stakeholders to balance trade-offs in
build tool adoption

</details>


### [15] [Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience](https://arxiv.org/abs/2510.20121)
*Carlos J. Fernandez-Candel,Jesus Garcia-Molina,Francisco Javier Bermudez Ruiz,Jose Ramon Hoyos Barcelo,Diego Sevilla Ruiz,Benito Jose Cuesta Viera*

Main category: cs.SE

TL;DR: 本文提出并实现了一套基于KDM和模型驱动工程的遗留PL/SQL代码自动迁移到Java分层架构的解决方案，流程集成了增量开发和多维度验证，实验证明该方法有效提升了旧系统的迁移效率和质量。


<details>
  <summary>Details</summary>
Motivation: 随着现代软件技术的发展，越来越多企业希望将九十年代流行的RAD（快速应用开发）平台上的旧应用迁移至新平台，如Oracle Forms应用迁移。此迁移过程面对PL/SQL单体代码向现代分层Java代码转化的挑战。

Method: 采用模型驱动的再工程过程，将PL/SQL遗留代码转换为Java代码，并将遗留代码以KDM（知识发现元模型）模型进行表示。提出了一个模型驱动的再工程软件流程，集成类似TDD的方式，针对生成代码进行三类验证，细致描述了这一迁移工具的开发与验证流程。

Result: 开发出了用于PL/SQL到分层Java代码迁移的模型驱动工具，完成了对再工程流程的实现与验证，并对迁移过程中的一些MDE应用相关问题进行了评估。

Conclusion: 模型驱动工程不仅适用于新系统开发，同样能高效应用于旧系统迁移。通过系统化的模型驱动再工程流程及综合验证措施，能够实现高质量的遗留代码向现代架构迁移。

Abstract: Model-driven software engineering (MDE) techniques are not only useful in
forward engineering scenarios, but can also be successfully applied to evolve
existing systems. RAD (Rapid Application Development) platforms emerged in the
nineties, but the success of modern software technologies motivated that a
large number of enterprises tackled the migration of their RAD applications,
such as Oracle Forms. Our research group has collaborated with a software
company in developing a solution to migrate PL/SQL monolithic code on Forms
triggers and program units to Java code separated in several tiers.
  Our research focused on the model-driven reengineering process applied to
develop the migration tool for the conversion of PL/SQL code to Java. Legacy
code is represented in form of KDM (Knowledge-Discovery Metamodel) models. In
this paper, we propose a software process to implement a model-driven
re-engineering. This process integrates a TDD-like approach to incrementally
develop model transformations with three kinds of validations for the generated
code. The implementation and validation of the re-engineering approach are
explained in detail, as well as the evaluation of some issues related with the
application of MDE.

</details>


### [16] [Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents](https://arxiv.org/abs/2510.20211)
*Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen*

Main category: cs.SE

TL;DR: NSync系统通过追踪云API调用并结合LLM自动化识别与修正基础设施漂移，大幅提升了IaC配置与实际状态的一致性，实验显示准确率和效率均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统云基础设施管理工具（如控制台、CLI、SDK）与基础设施即代码（IaC）工具并存时，IaC失去了对外部变更的感知能力，导致基础设施漂移，造成配置失效、运维错误等问题。该问题在IaC得到广泛应用的现状下尤为突出。

Method: 提出了NSync系统，通过分析云API调用痕迹检测非IaC的变更（漂移），采用LLM推理API调用背后的意图，并自动化生成IaC更新以保持配置同步。同时NSync拥有自进化知识库，能持续从以往的对齐经验中提升效果，并设计了注入真实漂移的评测流程。

Result: 在5个真实Terraform项目和372个漂移场景中，NSync在准确率上显著超过基线方法（pass@3从0.71提升到0.97），且token效率提升了1.47倍。

Conclusion: NSync有效解决了IaC与传统云管理工具共存造成的基础设施漂移问题，实现了高效、准确的自动化对齐。

Abstract: Cloud infrastructure is managed through a mix of interfaces -- traditionally,
cloud consoles, command-line interfaces (CLI), and SDKs are the tools of
choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have
quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the
infrastructure in a "source-of-truth" configuration. They are capable of
automatically carrying out modifications to the cloud -- deploying, updating,
or destroying resources -- to bring the actual infrastructure into alignment
with the IaC configuration. However, when IaC is used alongside consoles, CLIs,
or SDKs, it loses visibility into external changes, causing infrastructure
drift, where the configuration becomes outdated, and later IaC operations may
undo valid updates or trigger errors.
  We present NSync, an automated system for IaC reconciliation that propagates
out-of-band changes back into the IaC program. Our key insight is that
infrastructure changes eventually all occur via cloud API invocations -- the
lowest layer for cloud management operations. NSync gleans insights from API
traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update
the IaC configuration to capture the changes). It employs an agentic
architecture that leverages LLMs to infer high-level intents from noisy API
sequences, synthesize targeted IaC updates using specialized tools, and
continually improve through a self-evolving knowledge base of past
reconciliations. We further introduce a novel evaluation pipeline for injecting
realistic drifts into cloud infrastructure and assessing reconciliation
performance. Experiments across five real-world Terraform projects and 372
drift scenarios show that NSync outperforms the baseline both in terms of
accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\times$
improvement).

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Resource-Aware Hybrid Quantum Programming with General Recursion and Quantum Control](https://arxiv.org/abs/2510.20452)
*Kostia Chardonnet,Emmanuel Hainry,Romain Péchoux,Thomas Vinet*

Main category: cs.LO

TL;DR: 本文提出了一种无需指定初始量子门集合的混合量子语言Hyrql，并给出了语义保持的编译方法，使其可利用项重写系统的复杂度分析技术以实现统一的量子程序资源评估，且在多个案例中验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的量子语言通常依赖于特定的量子门集合，导致在资源和复杂度分析方面面临限制。为了解决这一问题，作者提出一种无需预设量子门集合、更适用于泛化资源分析的新型量子编程语言。

Method: 设计了一种新型混合量子语言（Hyrql），并提出了一个能保持语义的编译算法，将该语言编译为简单类型项重写系统。这样可以利用现有所有项重写系统复杂度分析技术来分析量子程序。

Result: 通过多个示例证明了该方法的普适性和有效性，无论采用不同量子门集合，均可统一进行资源成本分析。

Conclusion: Hyrql为量子程序的资源分析提供了统一、灵活的工具，能够兼容不同量子门集合，成功连接了量子编程与项重写系统的复杂度分析领域。

Abstract: This paper introduces the hybrid quantum language with general recursion
$\mathtt{Hyrql}$, driven towards resource-analysis. By design, $\mathtt{Hyrql}$
does not require the specification of an initial set of quantum gates and,
hence, is well amenable towards a generic cost analysis. Indeed, languages
using different sets of quantum gates lead to representations of quantum
circuits whose complexity varies. Towards resource-analysis, a
semantics-preserving compilation algorithm to simply-typed term rewrite systems
is described; allowing a generic reuse of all known techniques for analyzing
the complexity of term rewrite systems. We prove the versatility of this
approach through many examples.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse](https://arxiv.org/abs/2510.19858)
*Jindi Wang,Yidi Zhang,Zhaoxing Li*

Main category: cs.CL

TL;DR: 本文提出DeBERTa-KC模型，自动识别YouTube科学频道评论的知识建构等级，在多项改进下取得优异表现，有效推动线上学习话语自动分析。


<details>
  <summary>Details</summary>
Motivation: 自动分析在线科学学习讨论中的知识建构水平是一项挑战，人工标注成本高，且需处理类别不均衡，因此需要更精确且可扩展的自动分类工具。

Method: 提出了基于transformer的DeBERTa-KC模型，对YouTube科学频道评论进行四类知识建构自动分类。利用带Focal Loss、标签平滑和R-Drop正则化的DeBERTa-v3，建立可复现的端到端流程，包括数据采集、标注、预处理、训练与评估。

Result: DeBERTa-KC模型在10折交叉验证中取得了0.836±0.008的macro-F1分数，显著优于传统和其他transformer基线，尤其在高阶知识建构类别表现突出。

Conclusion: 大型语言模型能有效解析数字化学习环境下知识建构的细致特征，为自动化话语分析和评估认知参与度提供了理论引导和可扩展的解决方案。

Abstract: This study presents DeBERTa-KC, a transformer-based model for automatic
classification of knowledge construction (KC) levels in online science learning
discourse. Using comments collected from four popular YouTube science channels
(2022--2024), a balanced corpus of 20,000 manually annotated samples was
created across four KC categories: \textit{nonKC}, \textit{Share},
\textit{Explore}, and \textit{Negotiate}. The proposed model extends DeBERTa-v3
with Focal Loss, Label Smoothing, and R-Drop regularization to address class
imbalance and enhance generalization. A reproducible end-to-end pipeline was
implemented, encompassing data extraction, annotation, preprocessing, training,
and evaluation. Across 10-fold stratified cross-validation, DeBERTa-KC achieved
a macro-F1 of $0.836 \pm 0.008$, significantly out-performing both classical
and transformer baselines ($p<0.01$). Per-category results indicate strong
sensitivity to higher-order epistemic engagement, particularly in
\textit{Explore} and \textit{Negotiate} discourse. These findings demonstrate
that large language models can effectively capture nuanced indicators of
knowledge construction in informal digital learning environments, offering
scalable, theory-informed approaches to discourse analysis and the development
of automated tools for assessing epistemic engagement.

</details>


### [19] [An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics](https://arxiv.org/abs/2510.19866)
*Xincheng Liu*

Main category: cs.CL

TL;DR: 本文系统评估了五大AI模型和三种提示结构在生成高中物理教学计划上的表现。发现模型决定可读性，RACE提示结构提升准确性和课程适配性，高阶学习目标较少。优化方案为可读性强的模型配合RACE框架和完整目标清单。


<details>
  <summary>Details</summary>
Motivation: AI生成教学计划在教育领域应用广泛，但其教学合理性和可用性尚未充分评估，尤其在不同大模型和提示框架下表现的差异，亟需系统分析。

Method: 研究对比了五种主流大语言模型（ChatGPT GPT-5、Claude Sonnet 4.5、Gemini 2.5 Flash、DeepSeek V3.2、Grok 4），并使用三种结构化提示框架（TAG、RACE、COSTAR），针对一个高中物理主题“电磁谱”各生成15份教学计划。通过可读性/语言复杂度、事实准确性/幻觉指标、与课程标准一致性、学习目标认知要求四项自动化指标进行分析评估。

Result: 模型选择显著影响教学计划的语言可读性，DeepSeek最易读（FKGL=8.64），Claude语言最复杂（FKGL=19.89）；提示框架对事实准确性和教学完整性影响最大，RACE框架幻觉指数最低，且与NGSS课程标准一致性最高。所有模型生成的学习目标多集中于布鲁姆认知分类的记忆和理解层级，高阶动词较少。

Conclusion: 模型的设计决定了教学文本的可读性，教学的可靠性和课程适配性更多依赖提示框架。最佳方案是结合高可读性的模型、RACE提示结构以及明确涵盖物理概念、课程标准和高阶目标的清单。

Abstract: This study evaluates the pedagogical soundness and usability of AI-generated
lesson plans across five leading large language models: ChatGPT (GPT-5), Claude
Sonnet 4.5, Gemini 2.5 Flash, DeepSeek V3.2, and Grok 4. Beyond model choice,
three structured prompt frameworks were tested: TAG (Task, Audience, Goal),
RACE (Role, Audience, Context, Execution), and COSTAR (Context, Objective,
Style, Tone, Audience, Response Format).
  Fifteen lesson plans were generated for a single high-school physics topic,
The Electromagnetic Spectrum. The lesson plans were analyzed through four
automated computational metrics: (1) readability and linguistic complexity, (2)
factual accuracy and hallucination detection, (3) standards and curriculum
alignment, and (4) cognitive demand of learning objectives.
  Results indicate that model selection exerted the strongest influence on
linguistic accessibility, with DeepSeek producing the most readable teaching
plan (FKGL = 8.64) and Claude generating the densest language (FKGL = 19.89).
  The prompt framework structure most strongly affected the factual accuracy
and pedagogical completeness, with the RACE framework yielding the lowest
hallucination index and the highest incidental alignment with NGSS curriculum
standards. Across all models, the learning objectives in the fifteen lesson
plans clustered at the Remember and Understand tiers of Bloom's taxonomy. There
were limited higher-order verbs in the learning objectives extracted.
  Overall, the findings suggest that readability is significantly governed by
model design, while instructional reliability and curricular alignment depend
more on the prompt framework. The most effective configuration for lesson plans
identified in the results was to combine a readability-optimized model with the
RACE framework and an explicit checklist of physics concepts, curriculum
standards, and higher-order objectives.

</details>


### [20] [From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model](https://arxiv.org/abs/2510.19871)
*Yatai Ji,Teng Wang,Yuying Ge,Zhiheng Liu,Sidi Yang,Ying Shan,Ping Luo*

Main category: cs.CL

TL;DR: 论文提出ReDiff，通过强化模型主动修正能力，有效解决了离散扩散模型在并行生成中的错误级联问题，实验结果显示其生成的内容在连贯性和事实准确性上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在视觉-语言任务中虽然有潜力，但面临训练和推理不一致的问题，初始生成的错误会引发连锁的错误级联，影响生成内容的语法和语义质量。

Method: 提出了ReDiff框架，将生成过程由被动去噪转变为主动修正，采用两阶段训练：第一阶段通过合成错误训练模型基本的修正能力，第二阶段引入自我修正环，利用专家纠正数据训练模型不断自我修正。

Result: 实验表明，ReDiff显著提升了生成内容的连贯性和事实准确性，使平行生成过程更加稳定高效，优于传统去噪方法。

Conclusion: ReDiff通过主动修正生成错误，有效打破错误级联，显著改善了离散扩散模型在视觉-语言生成任务中的表现。

Abstract: Discrete diffusion models have emerged as a promising direction for
vision-language tasks, offering bidirectional context modeling and theoretical
parallelization. However, their practical application is severely hindered by a
train-inference discrepancy, which leads to catastrophic error cascades:
initial token errors during parallel decoding pollute the generation context,
triggering a chain reaction of compounding errors and leading to syntactic
errors and semantic hallucinations. To address this fundamental challenge, we
reframe the generation process from passive denoising to active refining. We
introduce ReDiff, a refining-enhanced diffusion framework that teaches the
model to identify and correct its own errors. Our approach features a two-stage
training process: first, we instill a foundational revision capability by
training the model to revise synthetic errors; second, we implement a novel
online self-correction loop where the model is explicitly trained to revise its
own flawed drafts by learning from an expert's corrections. This mistake-driven
learning endows the model with the crucial ability to revisit and refine its
already generated output, effectively breaking the error cascade. Extensive
experiments demonstrate that ReDiff significantly improves the coherence and
factual accuracy of generated content, enabling stable and efficient parallel
generation far superior to traditional denoising methods. Our codes and models
are available at https://rediff-hku.github.io/.

</details>


### [21] [Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention](https://arxiv.org/abs/2510.19875)
*J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard*

Main category: cs.CL

TL;DR: 本文提出 Sparse Tracing 和 Stream 算法，实现对百万 Token 长上下文的高效 attention 解析，大幅降低计算与内存需求，保留推理关键路径，使长输入下的模型可解释性和推理追踪更为可行。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的上下文长度显著提升，现有机制可解释性方法在长上下文下计算和内存消耗迅速增长，难以实际应用，亟需高效的 attention 解析技术以推动链式推理等任务的可解释性与监控。

Method: 提出 Sparse Tracing 技术，通过动态稀疏 attention，有效分析长上下文；并实现了 Stream（一种可编译的分层剪枝算法），采用类似二分查找的方法估算每个 attention head 的稀疏 Mask，仅保留每个查询的 top-k 关键块，空间和时间复杂度分别为 O(T) 和 O(T log T)。

Result: 在链式思考追踪和 RULER 基准测试中，Sparse Tracing 可有效识别关键思考锚点，剪除 97-99% 的 Token 交互，且能够保留关键检索路径与模型行为特征，实现大幅降耗并扩展模型可解释性。

Conclusion: Sparse Tracing 技术通过高效稀疏 attention 分析，使得百万级 Token 的长上下文可解释性成为可能，对链式推理轨迹进行细粒度追踪与分析，同时极大减少了内存和计算消耗。

Abstract: As Large Language Models (LLMs) scale to million-token contexts, traditional
Mechanistic Interpretability techniques for analyzing attention scale
quadratically with context length, demanding terabytes of memory beyond 100,000
tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic
sparse attention to efficiently analyze long context attention patterns. We
present Stream, a compilable hierarchical pruning algorithm that estimates
per-head sparse attention masks in near-linear time $O(T \log T)$ and linear
space $O(T)$, enabling one-pass interpretability at scale. Stream performs a
binary-search-style refinement to retain only the top-$k$ key blocks per query
while preserving the model's next-token behavior. We apply Stream to long
chain-of-thought reasoning traces and identify thought anchors while pruning
97-99\% of token interactions. On the RULER benchmark, Stream preserves
critical retrieval paths while discarding 90-96\% of interactions and exposes
layer-wise routes from the needle to output. Our method offers a practical
drop-in tool for analyzing attention patterns and tracing information flow
without terabytes of caches. By making long context interpretability feasible
on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring.
Code is available at https://anonymous.4open.science/r/stream-03B8/.

</details>


### [22] [Automated HIV Screening on Dutch EHR with Large Language Models](https://arxiv.org/abs/2510.19879)
*Lang Zhou,Amrish Jhingoer,Yinghao Luo,Klaske Vliegenthart--Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 本研究提出使用大型语言模型分析电子健康记录中的临床文本，以提升HIV高危患者筛查准确率，并在实际数据测试中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 高效筛查和早期诊断HIV对于降低传播至关重要，但大规模实验室检测不可行。电子健康记录（EHR）的普及为应对这一挑战提供了新机遇，但现有研究多集中于结构化数据，忽略了可能包含关键信息的非结构化临床文本数据。

Method: 提出了一种新的流程，利用大型语言模型（LLM）分析非结构化EHR文本，以确定患者是否有必要进行进一步的HIV检测。

Result: 在鹿特丹伊拉斯谟大学医学中心的临床数据实验显示，该方法在保持低假阴性率的同时，实现了较高的准确率。

Conclusion: 利用LLM分析非结构化EHR数据可有效提高HIV筛查的准确性，并有助于早期发现高危患者。

Abstract: Efficient screening and early diagnosis of HIV are critical for reducing
onward transmission. Although large scale laboratory testing is not feasible,
the widespread adoption of Electronic Health Records (EHRs) offers new
opportunities to address this challenge. Existing research primarily focuses on
applying machine learning methods to structured data, such as patient
demographics, for improving HIV diagnosis. However, these approaches often
overlook unstructured text data such as clinical notes, which potentially
contain valuable information relevant to HIV risk. In this study, we propose a
novel pipeline that leverages a Large Language Model (LLM) to analyze
unstructured EHR text and determine a patient's eligibility for further HIV
testing. Experimental results on clinical data from Erasmus University Medical
Center Rotterdam demonstrate that our pipeline achieved high accuracy while
maintaining a low false negative rate.

</details>


### [23] [An Expert-grounded benchmark of General Purpose LLMs in LCA](https://arxiv.org/abs/2510.19886)
*Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard*

Main category: cs.CL

TL;DR: 本文系统评估了商用和开源LLM在LCA任务中的表现，发现其输出常存在不准确和虚假信息，解释质量和任务简化有益，但脱离专业机制易带来风险。


<details>
  <summary>Details</summary>
Motivation: AI特别是LLMs在LCA领域应用日益广泛，但缺乏关于其可靠性、稳健性及可用性的系统性实证，且无统一的评估标准或协议，因此亟需建立评估基准。

Method: 评估了11种通用型LLM（包括商用与开源），针对22个LCA相关任务，由17位专家基于科学准确性、解释质量、健壮性、可验证性和指令遵循性等标准审阅模型输出，收集了168份专家评价。

Result: 37%的模型输出被专家判定为不准确或误导，其中有的模型胡编乱造引用的比例高达40%。开源与闭源模型在准确性和解释质量上均有竞争力，未现明显优劣差异。格式遵循表现良好，但幻觉率（信息伪造）差异较大。

Conclusion: 应用大型语言模型（LLMs）于生命周期评估（LCA）存在风险，尤其是未经专业连接和校验时，但在解释质量和简化繁重任务方面有明显优势。缺乏可靠的标准化评估框架限制了其应用。

Abstract: Purpose: Artificial intelligence (AI), and in particular large language
models (LLMs), are increasingly being explored as tools to support life cycle
assessment (LCA). While demonstrations exist across environmental and social
domains, systematic evidence on their reliability, robustness, and usability
remains limited. This study provides the first expert-grounded benchmark of
LLMs in LCA, addressing the absence of standardized evaluation frameworks in a
field where no clear ground truth or consensus protocols exist.
  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial
and open-source families, across 22 LCA-related tasks. Seventeen experienced
practitioners reviewed model outputs against criteria directly relevant to LCA
practice, including scientific accuracy, explanation quality, robustness,
verifiability, and adherence to instructions. We collected 168 expert reviews.
  Results: Experts judged 37% of responses to contain inaccurate or misleading
information. Ratings of accuracy and quality of explanation were generally
rated average or good on many models even smaller models, and format adherence
was generally rated favourably. Hallucination rates varied significantly, with
some models producing hallucinated citations at rates of up to 40%. There was
no clear-cut distinction between ratings on open-weight versus closed-weight
LLMs, with open-weight models outperforming or competing on par with
closed-weight models on criteria such as accuracy and quality of explanation.
  Conclusion: These findings highlight the risks of applying LLMs na\"ively in
LCA, such as when LLMs are treated as free-form oracles, while also showing
benefits especially around quality of explanation and alleviating labour
intensiveness of simple tasks. The use of general-purpose LLMs without
grounding mechanisms presents ...

</details>


### [24] [Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities](https://arxiv.org/abs/2510.19892)
*Nishant Balepur,Dang Nguyen,Dayeon Ki*

Main category: cs.CL

TL;DR: 通过Dixit游戏来评价多模态大语言模型，比传统方法更加全面客观，可以发现模型与人的策略及推理能力差异，是一种更具挑战性的评测框架。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法要么是静态独立的基准测试，无法综合地评价MLM的多项能力；要么依赖主观的人或模型对比，容易产生偏见并被模型的表面特征（如啰嗦）误导结果。需要一个客观、综合且具有挑战性的评估方式。

Method: 通过将MLM参与Dixit游戏，比较其胜率，并与现有主流MLM基准测试成绩进行相关分析，同时举行人机对战以观察策略与推理差异。

Result: 五款MLM在Dixit游戏中的胜率排名与主流基准测试完全一致，但人机对战揭示了模型在策略和推理方面与人类玩家的明显差异，以及未来改进空间。

Conclusion: 采用游戏化的评估方式（以Dixit为实例）能够更全面客观地评估多模态大语言模型（MLM）的能力，并能发现模型与人的策略差异及其改进空间。

Abstract: Multi-modal large language models (MLMs) are often assessed on static,
individual benchmarks -- which cannot jointly assess MLM capabilities in a
single task -- or rely on human or model pairwise comparisons -- which is
highly subjective, expensive, and allows models to exploit superficial
shortcuts (e.g., verbosity) to inflate their win-rates. To overcome these
issues, we propose game-based evaluations to holistically assess MLM
capabilities. Games require multiple abilities for players to win, are
inherently competitive, and are governed by fix, objective rules, and makes
evaluation more engaging, providing a robust framework to address the
aforementioned challenges. We manifest this evaluation specifically through
Dixit, a fantasy card game where players must generate captions for a card that
trick some, but not all players, into selecting the played card. Our
quantitative experiments with five MLMs show Dixit win-rate rankings are
perfectly correlated with those on popular MLM benchmarks, while games between
human and MLM players in Dixit reveal several differences between agent
strategies and areas of improvement for MLM reasoning.

</details>


### [25] [Large Language Model enabled Mathematical Modeling](https://arxiv.org/abs/2510.19895)
*Guoyun Zhang*

Main category: cs.CL

TL;DR: 本文系统评估了DeepSeek-R1大语言模型在运筹学优化建模任务中的应用潜力。相较传统和现有主流模型，DeepSeek-R1在成本与性能上表现突出，通过多策略有效降低幻觉率，提高了模型自动化建模的准确性和实际可用性。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在运筹学中广泛应用，但其建模过程高度依赖专家知识，对实际问题的数学建模存在门槛。大语言模型（LLMs）具备自然语言理解和代码生成能力，有望通过降低建模门槛，促进优化方法在实际决策场景中的应用。现有主流模型（如GPT-4等）存在成本高和幻觉频发等问题，限制了其在供应链决策中的现实应用。本文旨在探索新模型DeepSeek-R1在此领域的潜力。

Method: 本文选择DeepSeek-R1模型，针对运筹学领域的四个基准数据集（NL4OPT、IndustryOR、EasyLP、ComplexOR）进行系统性评估，包括基线能力测评、幻觉分类体系构建、以及多种缓解幻觉策略（LLM-as-a-Judge、Few-shot Learning、工具调用、多智能体框架）的应用。这些方法用于提升模型在优化建模任务中的准确性、减少幻觉偏差，并提升结果与用户需求的契合度。

Result: DeepSeek-R1在决策优化建模任务中展现出高性价比和良好性能，初步验证了其在运筹学实际场景下的可用性。各类缓解策略有效减少了幻觉现象，提升了与用户意图的对齐和模型的建模准确率。

Conclusion: DeepSeek-R1作为一种高效低成本的大语言模型，可以在运筹学优化建模领域中有效缓解传统方法对专家知识的依赖，通过多种技术手段显著降低幻觉发生，推动自然语言到优化模型的自动化转化。

Abstract: The integration of Large Language Models (LLMs) with optimization modeling
offers a promising avenue for advancing decision-making in operations research
(OR). Traditional optimization methods,such as linear programming, mixed
integer programming, and simulation depend heavily on domain expertise to
translate real-world problems into solvable mathematical models. While solvers
like Gurobi and COPT are powerful, expert input remains essential for defining
objectives, constraints, and variables. This research investigates the
potential of LLMs, specifically the DeepSeek-R1 model, to bridge this
formulation gap using natural language understanding and code generation.
Although prior models like GPT-4, Claude, and Bard have shown strong
performance in NLP and reasoning tasks, their high token costs and tendency
toward hallucinations limit real-world applicability in supply chain contexts.
In contrast, DeepSeek-R1, a cost-efficient and high-performing model trained
with reinforcement learning, presents a viable alternative. Despite its success
in benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied
OR scenarios remains under explored. This study systematically evaluates
DeepSeek-R1 across four key OR benchmarks: NL4OPT, IndustryOR, EasyLP, and
ComplexOR. Our methodology includes baseline assessments, the development of a
hallucination taxonomy, and the application of mitigation strategies like
LLM-as-a-Judge, Few-shot Learning (FSL), Tool Calling, and a Multi-agent
Framework. These techniques aim to reduce hallucinations, enhance formulation
accuracy, and better align model outputs with user intent.

</details>


### [26] [Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation](https://arxiv.org/abs/2510.19897)
*Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka*

Main category: cs.CL

TL;DR: 本论文提出了结合标注数据和LLM生成批判反馈的记忆增强学习框架，在无需微调参数下提升多任务分类准确率，并通过创新性指标解释不同LLM表现，显示出更强的自适应性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的分类任务学习主要依赖参数微调，但这种方法通常成本高、灵活性差且难以解释。为了解决这些问题，作者旨在探索无需参数更新，通过增强记忆结构提升学习能力的方法。

Method: 提出了一种结合实例级批判（episodic memory）和任务级批判（semantic memory）的记忆增强框架，将标注数据与LLM生成的批判性反馈结合，用于指导模型学习。并提出了"suggestibility"这一新颖指标来解释和衡量模型对不同监督信息的响应。

Result: 在多个多样化任务上，利用LLM生成的批判反馈能显著提升性能，对比单纯标注检索基线最多可提升24.8%的准确率。同时，实验揭示了OpenAI与开源大模型在处理事实型与偏好型数据上的明显差异。

Conclusion: 记忆驱动、反思式学习能够让LLM智能体更加自适应且可解释，展现出比传统检索模型更大的潜力。

Abstract: We investigate how agents built on pretrained large language models can learn
target classification functions from labeled examples without parameter
updates. While conventional approaches like fine-tuning are often costly,
inflexible, and opaque, we propose a memory-augmented framework that leverages
both labeled data and LLM-generated critiques. Our framework uses episodic
memory to store instance-level critiques-capturing specific past
experiences-and semantic memory to distill these into reusable, task-level
guidance. Across a diverse set of tasks, incorporating critiques yields up to a
24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines
that rely only on labels. Through extensive empirical evaluation, we uncover
distinct behavioral differences between OpenAI and opensource models,
particularly in how they handle fact-oriented versus preference-based data. To
interpret how models respond to different representations of supervision
encoded in memory, we introduce a novel metric, suggestibility. This helps
explain observed behaviors and illuminates how model characteristics and memory
strategies jointly shape learning dynamics. Our findings highlight the promise
of memory-driven, reflective learning for building more adaptive and
interpretable LLM agents.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [27] [Labeling and folding multi-labeled trees](https://arxiv.org/abs/2510.20292)
*Vincent Moulton,Andreas Spillner*

Main category: cs.DM

TL;DR: 这篇论文将树与集合划分间的对应关系从单一标签拓展到多标签情况，并将其应用于系统发生网络的理论，提供了新算法和结构归类方法，丰富了生物信息学中的网络建模理论。


<details>
  <summary>Details</summary>
Motivation: Erdős和Székely提出了树结构与集合划分之间的双射关系，但原有算法仅针对单标签树。因此，动机是推广这一方法，处理树的叶子标签不唯一（即多标签树）的更一般情形，来适应更复杂的生物信息学结构（如系统发生网络）。

Method: 该文发展了一种针对多标签树的标签算法，通过对所有有限非空正整数多重集进行特定有序排列，来刻画多标签树所蕴涵的多重集的划分。同时，利用此方法在系统发生网络的理论模型中实现了结构稳定性的判定与归类。

Result: 作者证明了某些关于正整数多重集的排序可以用于刻画由多标签树所产生的多重集划分，还建立了可标记系统发生网络与多重集划分之间的双射。同时说明可标记系统发生网络正是多标签树折叠过程中保持稳定的网络。

Conclusion: 本文推广了树和集合划分之间的核心思想，从原本的单标签树拓展到多标签树，为系统发生网络的结构讨论和分类提供了新的理论工具。

Abstract: In 1989 Erd\H{o}s and Sz\'ekely showed that there is a bijection between (i)
the set of rooted trees with $n+1$ vertices whose leaves are bijectively
labeled with the elements of $[\ell]=\{1,2,\dots,\ell\}$ for some $\ell \leq
n$, and (ii) the set of partitions of $[n]=\{1,2,\dots,n\}$. They established
this via a labeling algorithm based on the anti-lexicographic ordering of
non-empty subsets of $[n]$ which extends the labeling of the leaves of a given
tree to a labeling of all of the vertices of that tree. In this paper, we
generalize their approach by developing a labeling algorithm for multi-labeled
trees, that is, rooted trees whose leaves are labeled by positive integers but
in which distinct leaves may have the same label. In particular, we show that
certain orderings of the set of all finite, non-empty multisets of positive
integers can be used to characterize partitions of a multiset that arise from
labelings of multi-labeled trees. As an application, we show that the recently
introduced class of labelable phylogenetic networks is precisely the class of
phylogenetic networks that are stable relative to the so-called folding process
on multi-labeled trees. We also give a bijection between the labelable
phylogenetic networks with leaf-set $[n]$ and certain partitions of multisets.

</details>


### [28] [Excluding a Line Minor via Design Matrices and Column Number Bounds for the Circuit Imbalance Measure](https://arxiv.org/abs/2510.20301)
*Daniel Dadush,Friedrich Eisenbrand,Rom Pinchasi,Thomas Rothvoss,Neta Singer*

Main category: cs.DM

TL;DR: 本文提出并分析了实矩阵的回路失衡度指标，首次证明所有参数下其列数多项式受控，为结构性拟阵理论和实际线性规划问题带来理论突破。


<details>
  <summary>Details</summary>
Motivation: 此前对于整数矩阵给出了关于其n与模数（如Δ-模性）之间的多项式界，但对实矩阵缺乏类似的普适性结果。为了推广已知的整数矩阵结论，并填补实矩阵参数范围内的理论空白，此文提出了‘回路失衡度’这一度量，并研究其上线性规划等领域的应用。

Method: 借鉴Geelen等人对Δ-模性矩阵的分析方法，本文对回路失衡度有界的实可表示拟阵进行了拟阵次小闭合性和次小排除性的矩阵理论推导，以及结构性分析。进一步，技术上证明了对复可表示拟阵，在排除了长度为l的line后，元素数有O(d^4 l)的多项式上界。

Result: 得到实矩阵A的列数n受限于O(d^4 κ_A)，其中κ_A为A的回路失衡度。这一结论将整数矩阵场景下n受O(d^4 Δ_A)控制的定理推广到了实数域，首次为所有参数范围提供了全面的多项式上界。

Conclusion: 本研究首次为所有参数范围的实矩阵A给出了基于回路失衡度κ_A的多项式列数上限，推广了整数矩阵下的相关结果。此界深入解释了实矩阵结构与其应用（如线性规划）中的限制条件，对理论和实践均有重要意义。

Abstract: For a real matrix $A \in \mathbb{R}^{d \times n}$ with non-collinear columns,
we show that $n \leq O(d^4 \kappa_A)$ where $\kappa_A$ is the \emph{circuit
imbalance measure} of $A$. The circuit imbalance measure $\kappa$ is a real
analogue of $\Delta$-modularity for integer matrices, satisfying $\kappa_A \leq
\Delta_A$ for integer $A$. The circuit imbalance measure has numerous
applications in the context of linear programming (see Ekbatani, Natura and
V{\'e}gh (2022) for a survey). Our result generalizes the $O(d^4 \Delta_A)$
bound of Averkov and Schymura (2023) for integer matrices and provides the
first polynomial bound holding for all parameter ranges on real matrices.
  To derive our result, similar to the strategy of Geelen, Nelson and Walsh
(2021) for $\Delta$-modular matrices, we show that real representable matroids
induced by $\kappa$-bounded matrices are minor closed and exclude a rank $2$
uniform matroid on $O(\kappa)$ elements as a minor (also known as a line of
length $O(\kappa)$).
  As our main technical contribution, we show that any simple rank $d$ complex
representable matroid which excludes a line of length $l$ has at most $O(d^4
l)$ elements. This complements the tight bound of $(l-3)\binom{d}{2} + d$ for
$l \geq 4$, of Geelen, Nelson and Walsh which holds when the rank $d$ is
sufficiently large compared to $l$ (at least doubly exponential in $l$).

</details>


### [29] [Partial Optimality in Cubic Correlation Clustering for General Graphs](https://arxiv.org/abs/2510.20431)
*David Stein,Bjoern Andres,Silvia Di Gregorio*

Main category: cs.DM

TL;DR: 本文针对最多三节点团的高阶相关聚类问题，提出判断部分最优性条件的算法，理论和实验验证其有效性，为实际聚类优化提供新工具。


<details>
  <summary>Details</summary>
Motivation: 高阶相关聚类问题是一个在图的基础上，对包含在同一聚类中的团（cliques）最小化总成本的NP难问题，广泛用于实际应用中，但求解困难。

Method: 针对至多3节点的团（3-cliques）的相关聚类（即立方相关聚类），提出并实现了决定部分最优性条件的算法，通过局部搜索启发式方法，并在两个数据集上进行数值实验评估。

Result: 所提出的部分最优性判断算法可以在实际数据中有效地识别部分最优的聚类分布，验证了方法在实际数据集上的有效性。

Conclusion: 部分最优性条件为高阶相关聚类（特别是立方相关聚类）提供了理论保障，并通过算法实现及实验验证，有助于提升聚类质量和求解效率。

Abstract: The higher-order correlation clustering problem for a graph $G$ and costs
associated with cliques of $G$ consists in finding a clustering of $G$ so as to
minimize the sum of the costs of those cliques whose nodes all belong to the
same cluster. To tackle this NP-hard problem in practice, local search
heuristics have been proposed and studied in the context of applications. Here,
we establish partial optimality conditions for cubic correlation clustering,
i.e., for the special case of at most 3-cliques. We define and implement
algorithms for deciding these conditions and examine their effectiveness
numerically, on two data sets.

</details>


### [30] [A Classification of Long-Refinement Graphs for Colour Refinement](https://arxiv.org/abs/2510.20802)
*Sandra Kiefer,T. Devini de Mel*

Main category: cs.DM

TL;DR: 本文全面分类了让颜色细化算法迭代次数达到最大值的图（长细化图），尤其是度数不高和很高的情况，发现这些图有特定家族且结构很紧凑，解决了最后一次区分图是否存在的疑问，对图算法理论有补充和完善意义。


<details>
  <summary>Details</summary>
Motivation: 颜色细化（Colour Refinement）算法是检测图对称性的重要工具，尤其用于图同构测试。长期以来，是否存在使颜色细化达到理论最大迭代次数的图，一直是一个开放问题。作者的工作动机是理解和分类这些“长细化”图的结构。

Method: 作者采用逆向工程（reverse-engineering）方法，系统性地分析最大度数不超过3和4的图结构，并使用紧凑字符串表示这些图，从而获得结构性洞察。同时结合以往的穷举和理论分析，完成全部小度长细化图及其高度数补图的分类。

Result: （1）证明除了一个例外，只有已知的家族是最大度不超过3的“长细化”图；（2）对最大度为4的“长细化”图进行了完全分类；（3）发现这些图可用紧凑字符串表示，且其结构闭合于边补运算；（4）证明不存在仅在颜色细化终止前最后一次区分的图，从而解决了此前的悬案。

Conclusion: 这项工作完成了最大度数不超过3和4的长细化图的分类，进一步揭示了这些图的结构特征，并澄清了关于最后一次区分的特殊图的存在性问题，为相关算法和理论提供了基础。

Abstract: The Colour Refinement algorithm is a classical procedure to detect symmetries
in graphs, whose most prominent application is in graph-isomorphism tests. The
algorithm and its generalisation, the Weisfeiler-Leman algorithm, evaluate
local information to compute a colouring for the vertices in an iterative
fashion. Different final colours of two vertices certify that no isomorphism
can map one onto the other. The number of iterations that the algorithm takes
to terminate is its central complexity parameter. For a long time, it was open
whether graphs that take the maximum theoretically possible number of Colour
Refinement iterations actually exist. Starting from an exhaustive search on
graphs of low degrees, Kiefer and McKay proved the existence of infinite
families of such long-refinement graphs with degrees 2 and 3, thereby showing
that the trivial upper bound on the iteration number of Colour Refinement is
tight. In this work, we provide a complete characterisation of the
long-refinement graphs with low (or, equivalently, high) degrees. We show that,
with one exception, the aforementioned families are the only long-refinement
graphs with maximum degree at most 3, and we fully classify the long-refinement
graphs with maximum degree 4. To this end, via a reverse-engineering approach,
we show that all low-degree long-refinement graphs can be represented as
compact strings, and we derive multiple structural insights from this
surprising fact. Since long-refinement graphs are closed under taking edge
complements, this also yields a classification of long-refinement graphs with
high degrees. Kiefer and McKay initiated a search for long-refinement graphs
that are only distinguished in the last iteration of Colour Refinement before
termination. We conclude it in this submission by showing that such graphs
cannot exist.

</details>
