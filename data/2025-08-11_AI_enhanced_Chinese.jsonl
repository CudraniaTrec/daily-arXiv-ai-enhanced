{"id": "2508.06216", "categories": ["cs.DM", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2508.06216", "abs": "https://arxiv.org/abs/2508.06216", "authors": ["Jesse Beisegel", "Nina Chiarelli", "Ekkehard K\u00f6hler", "Matja\u017e Krnc", "Martin Milani\u010d", "Nevena Piva\u010d", "Robert Scheffler", "Martin Strehler"], "title": "Sandwich Monotonicity and the Recognition of Weighted Graph Classes", "comment": null, "summary": "Edge-weighted graphs play an important role in the theory of Robinsonian\nmatrices and similarity theory, particularly via the concept of level graphs,\nthat is, graphs obtained from an edge-weighted graph by removing all\nsufficiently light edges. This suggest a natural way of associating to any\nclass $\\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted\ngraphs, namely by requiring that all level graphs belong to $\\mathcal{G}$. We\nshow that weighted graphs for which all level graphs are split, threshold, or\nchain graphs can be recognized in linear time using special edge elimination\norderings. We obtain these results by introducing the notion of degree sandwich\nmonotone graph classes. A graph class $\\mathcal{G}$ is sandwich monotone if\nevery edge set which may be removed from a graph in $\\mathcal{G}$ without\nleaving the class also contains a single edge that can be safely removed.\nFurthermore, if we require the safe edge to fulfill a certain degree property,\nthen $\\mathcal{G}$ is called degree sandwich monotone. We present necessary and\nsufficient conditions for the existence of a linear-time recognition algorithm\nfor any weighted graph class whose corresponding unweighted class is degree\nsandwich monotone and contains all edgeless graphs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528\u5ea6\u5939\u5fc3\u5355\u8c03\u6027\u8d28\uff0c\u901a\u8fc7\u8fb9\u6d88\u9664\u987a\u5e8f\uff0c\u5bf9\u5206\u88c2\u56fe\u3001\u9608\u503c\u56fe\u548c\u94fe\u56fe\u7b49\u7c7b\u522b\u7684\u52a0\u6743\u56fe\u8fdb\u884c\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u3002\u8fd8\u4e3a\u66f4\u4e00\u822c\u7684\u56fe\u7c7b\u8bc6\u522b\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5145\u8981\u6761\u4ef6\u3002", "motivation": "\u52a0\u6743\u56fe\u5728Robinsonian\u77e9\u9635\u548c\u76f8\u4f3c\u6027\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5c42\u6b21\u56fe\u7684\u6982\u5ff5\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u5982\u4f55\u5c06\u65e0\u6743\u56fe\u7684\u67d0\u4e2a\u7c7b\u522b\u81ea\u7136\u5730\u6269\u5c55\u5230\u52a0\u6743\u56fe\uff0c\u5e76\u57fa\u4e8e\u6240\u6709\u5c42\u6b21\u56fe\u5c5e\u4e8e\u67d0\u4e00\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\u8bc6\u522b\u3002", "method": "\u5f15\u5165\u201c\u5ea6\u5939\u5fc3\u5355\u8c03\u56fe\u7c7b\u201d\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u5b9a\u4e49\u201c\u5939\u5fc3\u5355\u8c03\u6027\u201d\u548c\u201c\u5ea6\u5939\u5fc3\u5355\u8c03\u6027\u201d\uff0c\u7814\u7a76\u8fd9\u4e9b\u5c5e\u6027\u5bf9\u52a0\u6743\u56fe\u7684\u5c42\u6b21\u56fe\u8bc6\u522b\u95ee\u9898\u3002\u5229\u7528\u7279\u6b8a\u7684\u8fb9\u6d88\u9664\u987a\u5e8f\uff0c\u5b9e\u73b0\u5bf9\u6240\u6709\u5c42\u6b21\u56fe\u4e3a\u5206\u88c2\u56fe\u3001\u9608\u503c\u56fe\u6216\u94fe\u56fe\u7684\u52a0\u6743\u56fe\u8fdb\u884c\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u6709\u5c42\u6b21\u56fe\u4e3a\u5206\u88c2\u56fe\u3001\u9608\u503c\u56fe\u6216\u94fe\u56fe\u7684\u52a0\u6743\u56fe\u53ef\u901a\u8fc7\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u8bc6\u522b\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u4efb\u610f\u5ea6\u5939\u5fc3\u5355\u8c03\u4e14\u5305\u542b\u7a7a\u56fe\u7684\u65e0\u6743\u56fe\u7c7b\uff0c\u5bf9\u5176\u52a0\u6743\u7248\u672c\u7ed9\u51fa\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u7684\u5145\u8981\u6761\u4ef6\u3002", "conclusion": "\u4f7f\u7528\u5ea6\u5939\u5fc3\u5355\u8c03\u7684\u601d\u60f3\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u8bc6\u522b\u5728\u7279\u5b9a\u65e0\u6743\u56fe\u7c7b\u57fa\u7840\u4e0a\u6269\u5c55\u7684\u52a0\u6743\u56fe\u7c7b\uff0c\u5e76\u4e14\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u4e8e\u5206\u88c2\u56fe\u3001\u9608\u503c\u56fe\u548c\u94fe\u56fe\u8868\u73b0\u51fa\u826f\u597d\u7684\u8bc6\u522b\u6548\u7387\uff08\u7ebf\u6027\u65f6\u95f4\uff09\u3002\u540c\u6837\u4e3a\u66f4\u5e7f\u6cdb\u7684\u56fe\u7c7b\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.06343", "categories": ["cs.DM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06343", "abs": "https://arxiv.org/abs/2508.06343", "authors": ["V\u00e1clav Bla\u017eej", "Micha\u0142 D\u0119bski ad Zbigniew Lonc", "Marta Piecyk", "Pawe\u0142 Rz\u0105\u017cewski"], "title": "On Approximate MMS Allocations on Restricted Graph Classes", "comment": null, "summary": "We study the problem of fair division of a set of indivisible goods with\nconnectivity constraints. Specifically, we assume that the goods are\nrepresented as vertices of a connected graph, and sets of goods allocated to\nthe agents are connected subgraphs of this graph. We focus on the\nwidely-studied maximin share criterion of fairness. It has been shown that an\nallocation satisfying this criterion may not exist even without connectivity\nconstraints, i.e., if the graph of goods is complete. In view of this, it is\nnatural to seek approximate allocations that guarantee each agent a connected\nbundle of goods with value at least a constant fraction of the maximin share\nvalue to the agent. It is known that for some classes of graphs, such as\ncomplete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such\napproximate allocations indeed exist. However, it is an open problem whether\nthey exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of\napproximate allocations on restricted graph classes. In particular, we show\nthat such allocations exist for several well-studied classes, including block\ngraphs, cacti, complete multipartite graphs, and split graphs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u7814\u7a76\u4e86\u5e26\u8fde\u901a\u7ea6\u675f\u4e0b\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u5206\u914d\u7684\u516c\u5e73\u6027\uff0c\u8bc1\u660e\u4e86\u591a\u7c7b\u5178\u578b\u56fe\u7ed3\u6784\u4e0a\u5b58\u5728\u8fde\u901a\u7684\u8fd1\u4f3cmaximin share\u5206\u914d\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u7406\u8bba\u8fdb\u5c55\u3002", "motivation": "\u8bba\u6587\u8003\u8651\u5728\u5b58\u5728\u8fde\u901a\u6027\u7ea6\u675f\u65f6\uff0c\u5c06\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u516c\u5e73\u5206\u914d\u7ed9\u591a\u4e2a\u4ee3\u7406\u7684\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7269\u54c1\u88ab\u8868\u793a\u4e3a\u8fde\u901a\u56fe\u7684\u9876\u70b9\uff0c\u6bcf\u4e2a\u4ee3\u7406\u83b7\u5f97\u7684\u7269\u54c1\u96c6\u5408\u5fc5\u987b\u4e3a\u8be5\u56fe\u7684\u8fde\u901a\u5b50\u56fe\u3002\u6b64\u524d\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u6ca1\u6709\u8fde\u901a\u6027\u7ea6\u675f\uff08\u5373\u7269\u54c1\u56fe\u4e3a\u5b8c\u5168\u56fe\uff09\uff0c\u6ee1\u8db3maximin share\u6807\u51c6\u7684\u5206\u914d\u53ef\u80fd\u4e5f\u4e0d\u5b58\u5728\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u7814\u7a76\u8fd1\u4f3c\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u5728\u5404\u7c7b\u53d7\u9650\u56fe\u7ed3\u6784\uff08\u5982\u5757\u56fe\u3001\u4ed9\u4eba\u638c\u56fe\u3001\u5b8c\u5168\u591a\u90e8\u56fe\u548c\u5206\u5272\u56fe\uff09\u4e0b\uff0c\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u662f\u5426\u5b58\u5728\u8fd1\u4f3cmaximin share\u5206\u914d\u3002\u65b9\u6cd5\u4e0a\uff0c\u7ed3\u5408\u56fe\u8bba\u4e0e\u5206\u914d\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5728\u8fd9\u4e9b\u7279\u5b9a\u56fe\u7ed3\u6784\u4e0b\uff0c\u80fd\u591f\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u5206\u914d\u4ef7\u503c\u81f3\u5c11\u4e3amaximin share\u5e38\u6570\u500d\u4e14\u8fde\u901a\u7684\u7269\u54c1\u5b50\u96c6\u3002", "result": "\u8bba\u6587\u8bc1\u660e\u4e86\u4e0a\u8ff0\u7279\u6b8a\u7c7b\u578b\u7684\u56fe\uff08\u5757\u56fe\u3001\u4ed9\u4eba\u638c\u56fe\u3001\u5b8c\u5168\u591a\u90e8\u56fe\u548c\u5206\u5272\u56fe\uff09\u90fd\u5b58\u5728\u8fde\u901a\u7684\u8fd1\u4f3cmaximin share\u5206\u914d\u3002\u8fd9\u4e3a\u8be5\u9886\u57df\u5185\u66f4\u5e7f\u6cdb\u56fe\u7ed3\u6784\u7684\u53ef\u884c\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u8fdb\u5c55\u3002", "conclusion": "\u5bf9\u4e8e\u8bb8\u591a\u7279\u6b8a\u7684\u56fe\u7ed3\u6784\uff0c\u672c\u6587\u8bc1\u660e\u4e86\u53ef\u4ee5\u5b9e\u73b0\u5177\u5907\u8fde\u901a\u6027\u7684\u8fd1\u4f3cmaximin share\u5206\u914d\uff0c\u4f46\u5728\u6240\u6709\u4e00\u822c\u56fe\u4e0a\u7684\u5b58\u5728\u6027\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\u3002"}}
{"id": "2508.05997", "categories": ["cs.PL", "cs.LO", "I.2.2; I.2.4"], "pdf": "https://arxiv.org/pdf/2508.05997", "abs": "https://arxiv.org/abs/2508.05997", "authors": ["Aditi Kabra", "Jonathan Laurent", "Stefan Mitsch", "Andr\u00e9 Platzer"], "title": "Hybrid Game Control Envelope Synthesis", "comment": null, "summary": "Control problems for embedded systems like cars and trains can be modeled by\ntwo-player hybrid games. Control envelopes, which are families of safe control\nsolutions, correspond to nondeterministic winning policies of hybrid games,\nwhere each deterministic specialization of the policy is a control solution.\nThis paper synthesizes nondeterministic winning policies for hybrid games that\nare as permissive as possible. It introduces subvalue maps, a compositional\nrepresentation of such policies that enables verification and synthesis along\nthe structure of the game. An inductive logical characterization in\ndifferential game logic (dGL) checks whether a subvalue map induces a sound\ncontrol envelope which always induces a winning play. A policy is said to win\nif it always achieves the desirable outcome when the player follows it, no\nmatter what actions the opponent plays. The maximal subvalue map, which allows\nthe most action options while still winning, is shown to exist and satisfy a\nlogical characterization. A family of algorithms for nondeterministic policy\nsynthesis can be obtained from the inductive subvalue map soundness\ncharacterization. An implementation of these findings is evaluated on examples\nthat use the expressivity of dGL to model a range of diverse control\nchallenges.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u63a7\u5236\u95ee\u9898\u7684\u666e\u9002\u83b7\u80dc\u7b56\u7565\u5408\u6210\u65b9\u6cd5\uff0c\u91c7\u7528\u4e8c\u4eba\u6df7\u5408\u6e38\u620f\u548csubvalue map\u8868\u793a\uff0c\u5229\u7528\u5fae\u5206\u6e38\u620f\u903b\u8f91\u9a8c\u8bc1\u6700\u5927\u53ef\u884c\u7b56\u7565\u5b58\u5728\u6027\uff0c\u5e76\u7528\u7b97\u6cd5\u5b9e\u73b0\uff0c\u5728\u591a\u79cd\u63a7\u5236\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff08\u5982\u6c7d\u8f66\u548c\u706b\u8f66\uff09\u7684\u63a7\u5236\u95ee\u9898\u590d\u6742\uff0c\u9700\u8981\u786e\u4fdd\u5b89\u5168\u5e76\u63d0\u4f9b\u591a\u6837\u5316\u7684\u63a7\u5236\u7b56\u7565\u3002\u4f20\u7edf\u65b9\u6cd5\u5f80\u5f80\u9488\u5bf9\u5355\u4e00\u7b56\u7565\uff0c\u800c\u5b9e\u9645\u8fd0\u884c\u4e2d\u9700\u8981\u80fd\u591f\u9002\u5e94\u591a\u79cd\u60c5\u51b5\u7684\u63a7\u5236\u65b9\u6848\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u4e8c\u4eba\u6df7\u5408\u6e38\u620f\u6a21\u578b\uff0c\u5c06\u63a7\u5236\u65b9\u6848\u8868\u793a\u4e3a\u6df7\u5408\u6e38\u620f\u7684\u975e\u786e\u5b9a\u6027\u83b7\u80dc\u7b56\u7565\u3002\u540c\u65f6\u5f15\u5165\u4e86subvalue map\uff08\u5b50\u503c\u6620\u5c04\uff09\u4f5c\u4e3a\u975e\u786e\u5b9a\u6027\u7b56\u7565\u7684\u7ec4\u5408\u5f0f\u8868\u793a\uff0c\u5e76\u5229\u7528\u5fae\u5206\u6e38\u620f\u903b\u8f91\uff08dGL\uff09\u8fdb\u884c\u5f52\u7eb3\u903b\u8f91\u7279\u5f81\u5316\uff0c\u786e\u4fdd\u8fd9\u4e9b\u6620\u5c04\u80fd\u591f\u5f62\u6210\u59cb\u7ec8\u83b7\u80dc\u7684\u63a7\u5236\u5305\u7edc\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u5927subvalue map\u7684\u5b58\u5728\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u6ee1\u8db3\u903b\u8f91\u7279\u5f81\u5316\u7684\u6761\u4ef6\u3002\u57fa\u4e8e\u6b64\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7cfb\u5217\u7528\u4e8e\u975e\u786e\u5b9a\u6027\u7b56\u7565\u5408\u6210\u7684\u7b97\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684\u63a7\u5236\u6311\u6218\u5b9e\u4f8b\u4e0a\u8fdb\u884c\u4e86\u5b9e\u73b0\u548c\u8bc4\u4f30\uff0c\u663e\u793a\u8be5\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u5e94\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u901a\u8fc7\u5f52\u7eb3\u903b\u8f91\u548csubvalue maps\u5b9e\u73b0\u6700\u5927\u5316\u3001\u53ef\u9a8c\u8bc1\u7684\u975e\u786e\u5b9a\u6027\u63a7\u5236\u5305\u7edc\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u5d4c\u5165\u5f0f\u63a7\u5236\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.05693", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05693", "abs": "https://arxiv.org/abs/2508.05693", "authors": ["Siamak Farshidi", "Amir Saberhabibi", "Behbod Eskafi", "Niloofar Nikfarjam", "Sadegh Eskandari", "Slinger Jansen", "Michel Chaudron", "Bedir Tekinerdogan"], "title": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach", "comment": null, "summary": "Selecting third-party software packages in open-source ecosystems like Python\nis challenging due to the large number of alternatives and limited transparent\nevidence for comparison. Generative AI tools are increasingly used in\ndevelopment workflows, but their suggestions often overlook dependency\nevaluation, emphasize popularity over suitability, and lack reproducibility.\nThis creates risks for projects that require transparency, long-term\nreliability, maintainability, and informed architectural decisions. This study\nformulates software package selection as a Multi-Criteria Decision-Making\n(MCDM) problem and proposes a data-driven framework for technology evaluation.\nAutomated data pipelines continuously collect and integrate software metadata,\nusage trends, vulnerability information, and developer sentiment from GitHub,\nPyPI, and Stack Overflow. These data are structured into a decision model\nrepresenting relationships among packages, domain features, and quality\nattributes. The framework is implemented in PySelect, a decision support system\nthat uses large language models to interpret user intent and query the model to\nidentify contextually appropriate packages. The approach is evaluated using\n798,669 Python scripts from 16,887 GitHub repositories and a user study based\non the Technology Acceptance Model. Results show high data extraction\nprecision, improved recommendation quality over generative AI baselines, and\npositive user evaluations of usefulness and ease of use. This work introduces a\nscalable, interpretable, and reproducible framework that supports\nevidence-based software selection using MCDM principles, empirical data, and\nAI-assisted intent modeling.", "AI": {"tldr": "\u9762\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u5305\u9009\u62e9\u96be\u9898\uff0c\u672c\u6587\u63d0\u51fa\u7528\u591a\u51c6\u5219\u51b3\u7b56\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684PySelect\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u9ad8\u5305\u63a8\u8350\u8d28\u91cf\u548c\u7528\u6237\u6ee1\u610f\u5ea6\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u8f6f\u4ef6\u5305\u9009\u62e9\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002", "motivation": "\u5728\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\uff08\u5982Python\uff09\u4e2d\uff0c\u7531\u4e8e\u53ef\u9009\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u5305\u6570\u91cf\u4f17\u591a\u4e14\u7f3a\u4e4f\u900f\u660e\u7684\u5bf9\u6bd4\u8bc1\u636e\uff0c\u5305\u9009\u62e9\u53d8\u5f97\u6781\u4e3a\u56f0\u96be\u3002\u751f\u6210\u5f0fAI\u5de5\u5177\u5e38\u7528\u4e8e\u5f00\u53d1\u6d41\u7a0b\uff0c\u4f46\u5176\u63a8\u8350\u5f80\u5f80\u5ffd\u7565\u4f9d\u8d56\u6027\u8bc4\u4f30\u3001\u8fc7\u5206\u5f3a\u8c03\u6d41\u884c\u5ea6\u3001\u7f3a\u4e4f\u53ef\u590d\u73b0\u6027\uff0c\u7ed9\u9879\u76ee\u7684\u900f\u660e\u6027\u548c\u957f\u671f\u53ef\u9760\u6027\u5e26\u6765\u98ce\u9669\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u900f\u660e\u548c\u4e0d\u53ef\u9760\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5c06\u8f6f\u4ef6\u5305\u9009\u62e9\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u591a\u51c6\u5219\u51b3\u7b56\uff08MCDM\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u6280\u672f\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u7ba1\u9053\u6301\u7eed\u6536\u96c6\u5e76\u6574\u5408GitHub\u3001PyPI\u3001Stack Overflow\u4e0a\u7684\u8f6f\u4ef6\u5143\u6570\u636e\u3001\u4f7f\u7528\u8d8b\u52bf\u3001\u6f0f\u6d1e\u4fe1\u606f\u548c\u5f00\u53d1\u8005\u60c5\u611f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6570\u636e\u7ed3\u6784\u5316\u4e3a\u51b3\u7b56\u6a21\u578b\u3002\u6700\u7ec8\uff0c\u8be5\u6846\u67b6\u4ee5PySelect\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5b9e\u73b0\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u7528\u6237\u610f\u56fe\u5e76\u67e5\u8be2\u6a21\u578b\uff0c\u63a8\u8350\u5408\u9002\u7684\u8f6f\u4ef6\u5305\u3002", "result": "\u8be5\u65b9\u6cd5\u752816,887\u4e2aGitHub\u4ed3\u5e93\u4e2d\u7684798,669\u4e2aPython\u811a\u672c\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ee5\u53ca\u7528\u6237\u7814\u7a76\u3002\u7ed3\u679c\u663e\u793a\uff1a\u6570\u636e\u63d0\u53d6\u7cbe\u5ea6\u9ad8\uff0c\u63a8\u8350\u8d28\u91cf\u8d85\u8d8a\u751f\u6210\u5f0fAI\u57fa\u7ebf\uff0c\u7528\u6237\u5728\u5b9e\u7528\u6027\u4e0e\u6613\u7528\u6027\u4e0a\u5747\u7ed9\u51fa\u6b63\u9762\u8bc4\u4ef7\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u590d\u73b0\u7684\u8f6f\u4ef6\u5305\u9009\u62e9\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408MCDM\u539f\u5219\u3001\u5b9e\u8bc1\u6570\u636e\u548cAI\u8f85\u52a9\u610f\u56fe\u5efa\u6a21\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u8f6f\u4ef6\u5305\u9009\u62e9\uff0c\u5e76\u5728\u63a8\u8350\u8d28\u91cf\u4e0e\u7528\u6237\u4f53\u9a8c\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2508.05798", "categories": ["cs.LO", "cs.CL", "math.LO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.05798", "abs": "https://arxiv.org/abs/2508.05798", "authors": ["Yuri Gurevich"], "title": "Basic interactive algorithms: Preview", "comment": null, "summary": "This dialog paper offers a preview and provides a foretaste of an upcoming\nwork on the axiomatization of basic interactive algorithms.\n  The modern notion of algorithm was elucidated in the 1930s--1950s. It was\naxiomatized a quarter of a century ago as the notion of ``sequential\nalgorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm\"\nnow. The axiomatization was used to show that for every basic algorithm there\nis a behaviorally equivalent abstract state machine. It was also used to prove\nthe Church-Turing thesis as it has been understood by the logicians.\n  Starting from the 1960s, the notion of algorithm has expanded --\nprobabilistic algorithms, quantum algorithms, etc. -- prompting introduction of\na much more ambitious version of the Church-Turing thesis commonly known as the\n``physical thesis.'' We emphasize the difference between the two versions of\nthe Church-Turing thesis and illustrate how nondeterministic and probabilistic\nalgorithms can be viewed as basic algorithms with appropriate oracles. The same\nview applies to quantum circuit algorithms and many other classes of\nalgorithms.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5373\u5c06\u53d1\u8868\u7684\u57fa\u672c\u4ea4\u4e92\u5f0f\u7b97\u6cd5\u516c\u7406\u5316\u5de5\u4f5c\u8fdb\u884c\u4e86\u9884\u89c8\u3002\u4f5c\u8005\u7b80\u8ff0\u4e86\u4ece\u4f20\u7edf\u5230\u73b0\u4ee3\u7b97\u6cd5\u7406\u8bba\u7684\u53d1\u5c55\uff0c\u5f3a\u8c03\u901a\u8fc7\u5f15\u5165\u201c\u795e\u8c15\u201d\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u7528\u7edf\u4e00\u7684\u57fa\u672c\u7b97\u6cd5\u6846\u67b6\u63cf\u8ff0\u786e\u5b9a\u6027\u3001\u975e\u786e\u5b9a\u6027\u3001\u6982\u7387\u53ca\u91cf\u5b50\u7b97\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86Church-Turing\u8bba\u9898\u53e4\u5178\u4e0e\u7269\u7406\u7248\u7684\u533a\u522b\u53ca\u5176\u7406\u8bba\u610f\u4e49\u3002", "motivation": "\u8fd1\u51e0\u5341\u5e74\u6765\uff0c\u7b97\u6cd5\u7684\u6982\u5ff5\u4e0d\u65ad\u6269\u5c55\uff0c\u5305\u62ec\u6982\u7387\u7b97\u6cd5\u3001\u91cf\u5b50\u7b97\u6cd5\u7b49\uff0c\u8fd9\u4fc3\u4f7f\u5b66\u754c\u91cd\u65b0\u5ba1\u89c6\u548c\u5f62\u5f0f\u5316\u7b97\u6cd5\u7684\u57fa\u7840\u5b9a\u4e49\u3002\u7ecf\u5178\u7b97\u6cd5\u7684\u516c\u7406\u5316\u5df2\u6210\u4e3a\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u91cd\u8981\u57fa\u7840\uff0c\u4f46\u66f4\u590d\u6742\u7684\u65b0\u578b\u7b97\u6cd5\u9700\u8981\u66f4\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u672c\u6587\u9884\u89c8\u548c\u63a2\u8ba8\u5373\u5c06\u53d1\u8868\u7684\u57fa\u672c\u4ea4\u4e92\u5f0f\u7b97\u6cd5\u7684\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u9610\u8ff0\u73b0\u6709\u7b97\u6cd5\uff08\u5982\u7ecf\u5178\u3001\u6982\u7387\u3001\u91cf\u5b50\u7b49\uff09\u5728\u884c\u4e3a\u7b49\u4ef7\u548c\u62bd\u8c61\u72b6\u6001\u673a\u4e0b\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u63d0\u51fa\u7528\u201c\u5408\u9002\u7684\u795e\u8c15\u201d\u5c06\u5404\u79cd\u7c7b\u578b\u7b97\u6cd5\u7eb3\u5165\u57fa\u672c\u7b97\u6cd5\u7684\u6846\u67b6\u3002", "result": "\u4f5c\u8005\u5f3a\u8c03\u4e24\u79cd\u4e0d\u540c\u7248\u672c\u7684Church-Turing\u8bba\u9898\u4e4b\u95f4\u7684\u533a\u522b\uff0c\u6307\u51fa\u975e\u786e\u5b9a\u6027\u548c\u6982\u7387\u7b97\u6cd5\u3001\u751a\u81f3\u91cf\u5b50\u7ebf\u8def\u7b97\u6cd5\u90fd\u53ef\u89c6\u4f5c\u5e26\u6709\u7279\u5b9a\u795e\u8c15\u7684\u57fa\u672c\u7b97\u6cd5\uff0c\u4ece\u800c\u6269\u5c55\u4e86\u57fa\u672c\u7b97\u6cd5\u7406\u8bba\u9002\u7528\u7684\u8303\u56f4\u548c\u89e3\u91ca\u529b\u3002", "conclusion": "\u5c06\u66f4\u591a\u7c7b\u578b\uff08\u5982\u6982\u7387\u3001\u91cf\u5b50\uff09\u7684\u7b97\u6cd5\u7eb3\u5165\u57fa\u672c\u7b97\u6cd5\u516c\u7406\u5316\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u548c\u7814\u7a76\u4ea4\u4e92\u5f0f\u53ca\u65b0\u578b\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4e5f\u6709\u52a9\u4e8e\u66f4\u6e05\u6670\u5730\u533a\u5206\u548c\u7406\u89e3Church-Turing\u8bba\u9898\u7684\u4e0d\u540c\u8868\u8ff0\u3002"}}
{"id": "2508.05722", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05722", "abs": "https://arxiv.org/abs/2508.05722", "authors": ["Rania Al-Sabbagh"], "title": "PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare", "comment": null, "summary": "This paper introduces PEACH, a sentence-aligned parallel English-Arabic\ncorpus of healthcare texts encompassing patient information leaflets and\neducational materials. The corpus contains 51,671 parallel sentences, totaling\napproximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths\nvary between 9.52 and 11.83 words on average. As a manually aligned corpus,\nPEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,\ntranslation studies, and natural language processing. It can be used to derive\nbilingual lexicons, adapt large language models for domain-specific machine\ntranslation, evaluate user perceptions of machine translation in healthcare,\nassess patient information leaflets and educational materials' readability and\nlay-friendliness, and as an educational resource in translation studies. PEACH\nis publicly accessible.", "AI": {"tldr": "PEACH\u662f\u4e00\u4e2a\u516c\u5f00\u7684\u82f1-\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u6587\u672c\u624b\u5de5\u5bf9\u9f50\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u67095\u4e07\u591a\u53e5\u5bf9\uff0c\u5e7f\u6cdb\u9002\u7528\u4e8eNLP\u3001\u7ffb\u8bd1\u548c\u5065\u5eb7\u4fe1\u606f\u7814\u7a76\u3002", "motivation": "\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u624b\u5de5\u5bf9\u9f50\u7684\u82f1-\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u6587\u672c\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u9650\u5236\u4e86\u8de8\u8bed\u8a00\u533b\u5b66\u4fe1\u606f\u83b7\u53d6\u548c\u76f8\u5173NLP\u5e94\u7528\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efaPEACH\u8bed\u6599\u5e93\uff0c\u6536\u96c6\u5e76\u624b\u5de5\u5bf9\u9f50\u542b\u6709\u60a3\u8005\u4fe1\u606f\u8bf4\u660e\u4e66\u548c\u5065\u5eb7\u6559\u80b2\u6750\u6599\u7684\u82f1-\u963f\u62c9\u4f2f\u8bed\u53e5\u5bf9\uff0c\u603b\u8ba151,671\u53e5\uff0c\u7edf\u8ba1\u57fa\u672c\u6570\u636e\uff0c\u4fdd\u8bc1\u8bed\u6599\u8d28\u91cf\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u3002", "result": "PEACH\u5305\u542b51,671\u53e5\u624b\u5de5\u5bf9\u9f50\u7684\u5e73\u884c\u53e5\uff0c\u603b\u8bcd\u6570\u5206\u522b\u4e3a\u82f1\u6587\u7ea659\u4e07\u3001\u963f\u62c9\u4f2f\u6587\u7ea656\u4e07\uff0c\u9002\u7528\u4e8e\u5bf9\u6bd4\u8bed\u8a00\u5b66\u3001\u7ffb\u8bd1\u7814\u7a76\u3001NLP\u5e94\u7528\u7b49\u591a\u4e2a\u573a\u666f\u3002", "conclusion": "PEACH\u8bed\u6599\u5e93\u4e3a\u7814\u7a76\u8005\u5728\u533b\u7597\u8bed\u8a00\u5904\u7406\u3001\u7ffb\u8bd1\u548c\u5bf9\u6bd4\u8bed\u8a00\u5b66\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u57fa\u7840\u8d44\u6e90\uff0c\u53ef\u7528\u4e8e\u8bcd\u5178\u6784\u5efa\u3001\u6a21\u578b\u9002\u914d\u3001\u673a\u5668\u7ffb\u8bd1\u8bc4\u4ef7\u3001\u60a3\u8005\u4fe1\u606f\u8bc4\u4f30\u4e0e\u6559\u5b66\u7b49\u591a\u4e2a\u7528\u9014\u3002"}}
{"id": "2508.05710", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05710", "abs": "https://arxiv.org/abs/2508.05710", "authors": ["Jia Fu", "Xinyu Yang", "Hongzhi Zhang", "Yahui Liu", "Jingyuan Zhang", "Qi Wang", "Fuzheng Zhang", "Guorui Zhou"], "title": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning", "comment": "21 pages, 11 figures", "summary": "Precise, correct feedback is crucial for effectively training large language\nmodels (LLMs) in code reinforcement learning. However, synthesizing\nhigh-quality test cases remains a profoundly challenging and unsolved problem.\nIn this work, we present Klear-CodeTest, a comprehensive test case synthesis\nframework featuring rigorous verification to ensure quality and reliability of\ntest cases. Our approach achieves broad coverage of programming problems via a\nnovel Generator-Validation (G-V) framework, ensuring correctness through a\nconsistency validation mechanism that verifies outputs against gold solutions.\nThe proposed G-V framework generates comprehensive test cases including both\nregular and corner cases, enhancing test coverage and discriminative power for\nsolution correctness assessment in code reinforcement learning. In addition, we\ndesign a multi-layered security sandbox system optimized for online\nverification platforms, guaranteeing safe and reliable code execution. Through\ncomprehensive experiments, we demonstrate the effectiveness of our curated\ndataset, showing significant improvements in model performance and training\nstability. The source codes, curated dataset and sandbox system are available\nat: https://github.com/Kwai-Klear/CodeTest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faKlear-CodeTest\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u751f\u6210-\u9a8c\u8bc1\u673a\u5236\u751f\u6210\u6db5\u76d6\u5e7f\u6cdb\u95ee\u9898\u548c\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u6837\u4f8b\uff0c\u5e76\u901a\u8fc7\u5b89\u5168\u6c99\u7bb1\u4fdd\u969c\u4ee3\u7801\u6267\u884c\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u76f8\u5173\u8d44\u6e90\u5df2\u5f00\u6e90\u3002", "motivation": "\u5728\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6709\u6548\u8bad\u7ec3\u9700\u8981\u51c6\u786e\u3001\u53ef\u9760\u7684\u53cd\u9988\uff0c\u800c\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u6837\u4f8b\u7684\u81ea\u52a8\u751f\u6210\u4ecd\u7136\u662f\u4e00\u4e2a\u96be\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u4e8e\u7efc\u5408\u6027\u548c\u4e25\u8c28\u9a8c\u8bc1\u7684\u8986\u76d6\u8fd8\u6709\u9650\u3002", "method": "\u63d0\u51faKlear-CodeTest\u6d4b\u8bd5\u6837\u4f8b\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b\u201c\u751f\u6210-\u9a8c\u8bc1\u201d\uff08Generator-Validation\uff0cG-V\uff09\u673a\u5236\uff0c\u901a\u8fc7\u4e0e\u6807\u51c6\u89e3\u4e00\u81f4\u6027\u9a8c\u8bc1\u786e\u4fdd\u6d4b\u8bd5\u6837\u4f8b\u7684\u6b63\u786e\u6027\u3002\u6846\u67b6\u751f\u6210\u5168\u9762\u7684\u5e38\u89c4\u4e0e\u8fb9\u754c\u6d4b\u8bd5\u6837\u4f8b\uff0c\u5e76\u914d\u5907\u591a\u5c42\u5b89\u5168\u6c99\u7bb1\u7cfb\u7edf\u7528\u4e8e\u4ee3\u7801\u5728\u7ebf\u9a8c\u8bc1\uff0c\u4fdd\u8bc1\u5b89\u5168\u3001\u53ef\u9760\u6267\u884c\u3002", "result": "\u7ecf\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u751f\u6210\u7684\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u6d4b\u8bd5\u6837\u4f8b\u6570\u636e\u96c6\u53ca\u7cfb\u7edf\u5df2\u5f00\u6e90\u3002", "conclusion": "Klear-CodeTest\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u4e2d\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u6837\u4f8b\u81ea\u52a8\u7efc\u5408\u4e0e\u9a8c\u8bc1\u95ee\u9898\uff0c\u4e3a\u6a21\u578b\u8bad\u7ec3\u5e26\u6765\u66f4\u5f3a\u7684\u53cd\u9988\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2508.06088", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.06088", "abs": "https://arxiv.org/abs/2508.06088", "authors": ["Kittiphon Phalakarn", "Yun Chen Tsai", "Ichiro Hasuo"], "title": "Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games", "comment": null, "summary": "For model checking stochastic games (SGs), bounded value iteration (BVI)\nalgorithms have gained attention as efficient approximate methods with rigorous\nprecision guarantees. However, BVI may not terminate or converge when the\ntarget SG contains end components. Most existing approaches address this issue\nby explicitly detecting and processing end components--a process that is often\ncomputationally expensive. An exception is the widest path-based BVI approach\npreviously studied by Phalakarn et al., which we refer to as 1WP-BVI. The\nmethod performs particularly well in the presence of numerous end components.\nNonetheless, its theoretical foundations remain somewhat ad hoc. In this paper,\nwe identify and formalize the core principles underlying the widest path-based\nBVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on\n(2-player) widest path games, and (ii) proving its correctness using what we\ncall the maximality inheritance principle--a proof principle previously\nemployed in a well-known result in probabilistic model checking. Our\nexperimental results demonstrate the practical relevance and potential of our\nproposed 2WP-BVI algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e2-\u73a9\u5bb6\u6700\u5bbd\u8def\u5f84\u535a\u5f08\u76842WP-BVI\u7b97\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edfBVI\u5728\u542b\u7ec8\u7aef\u5206\u91cf\u65f6\u7684\u6536\u655b\u95ee\u9898\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u7684\u6709\u754c\u503c\u8fed\u4ee3\u65b9\u6cd5\u5728\u542b\u6709\u7ec8\u7aef\u5206\u91cf\u7684\u968f\u673a\u535a\u5f08\u6a21\u578b\u4e2d\uff0c\u53ef\u80fd\u65e0\u6cd5\u7ec8\u6b62\u6216\u6536\u655b\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u68c0\u6d4b\u5e76\u5904\u7406\u7ec8\u7aef\u5206\u91cf\uff0c\u4f46\u8fd9\u5f88\u8017\u8ba1\u7b97\u8d44\u6e90\u3002\u5bbd\u8def\u5f84BVI\u65b9\u6cd5\u5bf9\u5927\u91cf\u7ec8\u7aef\u5206\u91cf\u6709\u6548\uff0c\u4f46\u7406\u8bba\u57fa\u7840\u4e0d\u5b8c\u5584\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u57fa\u4e8e2-\u73a9\u5bb6\u6700\u5bbd\u8def\u5f84\u535a\u5f08\u7684\u6709\u754c\u503c\u8fed\u4ee3\u7b97\u6cd5\uff082WP-BVI\uff09\uff0c\u5e76\u91c7\u7528\u6700\u5927\u6027\u7ee7\u627f\u539f\u7406\u8fdb\u884c\u8bc1\u660e\u3002", "result": "2WP-BVI\u7b97\u6cd5\u5728\u5177\u6709\u4f17\u591a\u7ec8\u7aef\u5206\u91cf\u7684\u968f\u673a\u535a\u5f08\u6a21\u578b\u4e2d\u6548\u679c\u663e\u8457\uff0c\u4e14\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5176\u6b63\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e862WP-BVI\u7b97\u6cd5\uff0c\u8bc1\u660e\u5176\u6b63\u786e\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u6548\u679c\u3002"}}
{"id": "2508.05775", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.05775", "abs": "https://arxiv.org/abs/2508.05775", "authors": ["Chi Zhang", "Changjia Zhu", "Junjie Xiong", "Xiaoran Xu", "Lingyao Li", "Yao Liu", "Zhuo Lu"], "title": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized content creation across\ndigital platforms, offering unprecedented capabilities in natural language\ngeneration and understanding. These models enable beneficial applications such\nas content generation, question and answering (Q&A), programming, and code\nreasoning. Meanwhile, they also pose serious risks by inadvertently or\nintentionally producing toxic, offensive, or biased content. This dual role of\nLLMs, both as powerful tools for solving real-world problems and as potential\nsources of harmful language, presents a pressing sociotechnical challenge. In\nthis survey, we systematically review recent studies spanning unintentional\ntoxicity, adversarial jailbreaking attacks, and content moderation techniques.\nWe propose a unified taxonomy of LLM-related harms and defenses, analyze\nemerging multimodal and LLM-assisted jailbreak strategies, and assess\nmitigation efforts, including reinforcement learning with human feedback\n(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the\nevolving landscape of LLM safety, identifies limitations in current evaluation\nmethodologies, and outlines future research directions to guide the development\nof robust and ethically aligned language technologies.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e26\u6765\u7684\u5185\u5bb9\u521b\u4f5c\u53d8\u9769\u4e0e\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51fa\u5206\u7c7b\u6846\u67b6\uff0c\u5206\u6790\u6700\u65b0\u653b\u51fb\u4e0e\u9632\u62a4\u624b\u6bb5\uff0c\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3aLLM\u5b89\u5168\u53d1\u5c55\u548c\u4f26\u7406\u89c4\u8303\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5185\u5bb9\u521b\u4f5c\u9886\u57df\u5e26\u6765\u4e86\u5de8\u5927\u7684\u53d8\u9769\uff0c\u4e0d\u4ec5\u6781\u5927\u63d0\u5347\u4e86\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4e0e\u7406\u89e3\u7684\u80fd\u529b\uff0c\u4e5f\u663e\u73b0\u51fa\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4fbf\u5229\u6027\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u540c\u65f6\u5374\u53ef\u80fd\u4ea7\u751f\u6709\u6bd2\u3001\u5192\u72af\u6216\u504f\u89c1\u6027\u5185\u5bb9\uff0c\u6210\u4e3a\u6f5c\u5728\u7684\u793e\u4f1a\u6280\u672f\u95ee\u9898\u3002\u4fc3\u4f7f\u672c\u8bba\u6587\u5bf9LLM\u7684\u8d1f\u9762\u5f71\u54cd\u53ca\u5e94\u5bf9\u63aa\u65bd\u5c55\u5f00\u7cfb\u7edf\u6027\u7efc\u8ff0\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u5bf9LLM\u5728\u65e0\u610f\u4e2d\u4ea7\u751f\u6709\u5bb3\u5185\u5bb9\u3001\u88ab\u5229\u7528\u8fdb\u884c\u8d8a\u72f1\u653b\u51fb\uff0c\u4ee5\u53ca\u5185\u5bb9\u6cbb\u7406\u6280\u672f\u7b49\u65b9\u9762\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u884c\u4e86\u68b3\u7406\u3002\u63d0\u51fa\u4e86\u7edf\u4e00\u7684LLM\u76f8\u5173\u5371\u5bb3\u4e0e\u9632\u5fa1\u5206\u7c7b\u6846\u67b6\uff0c\u5e76\u5206\u6790\u591a\u6a21\u6001\u53caLLM\u8f85\u52a9\u8d8a\u72f1\u7b56\u7565\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u73b0\u6709\u7684\u591a\u79cd\u7f13\u89e3\u624b\u6bb5\uff08\u5982RLHF\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u5b89\u5168\u5bf9\u9f50\uff09\u3002", "result": "\u672c\u6587\u603b\u7ed3\u4e86LLM\u5b89\u5168\u6027\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u660e\u786e\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u5f00\u53d1\u66f4\u5b89\u5168\u3001\u66f4\u5177\u4f26\u7406\u6027\u7684\u8bed\u8a00\u6280\u672f\u3002", "conclusion": "LLM\u5728\u5e26\u6765\u521b\u65b0\u4e0e\u4fbf\u5229\u7684\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u91cd\u5927\u5b89\u5168\u4e0e\u4f26\u7406\u6311\u6218\u3002\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u4e0e\u9632\u5fa1\u63aa\u65bd\uff0c\u672c\u6587\u5bf9\u672a\u6765LLM\u5b89\u5168\u6027\u63d0\u5347\u53ca\u8bc4\u4f30\u65b9\u6cd5\u6539\u8fdb\u63d0\u4f9b\u4e86\u6709\u76ca\u5efa\u8bae\u3002"}}
{"id": "2508.05747", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.05747", "abs": "https://arxiv.org/abs/2508.05747", "authors": ["Rohaizah Abdul Wahid", "Muhamad Said Nizamuddin Nadim", "Suliana Sulaiman", "Syahmi Akmal Shaharudin", "Muhammad Danial Jupikil", "Iqqwan Jasman Su Azlan Su"], "title": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework", "comment": null, "summary": "Laravel has emerged as a foundational framework in university web development\ncurricula. However, despite its scaffolding capabilities, students often\nstruggle to complete projects within limited academic timelines. This\nconceptual paper introduces Composer, PHP's standard dependency manager, and\ncategorizes a curated selection of Composer packages that significantly reduce\ndevelopment effort while fostering professional software practices. Grounded in\npractical and pedagogical considerations, the paper illustrates how educators\nand learners can strategically leverage these tools to build typical academic\nor personal Laravel-based systems. Central to this approach is maintaining code\nquality and reinforcing conceptual understanding. The paper also addresses\npotential risks such as package conflicts and over-reliance on tools, providing\nbest-practice recommendations to mitigate them. While the goal is to accelerate\ndevelopment, the deeper objective is to reinforce professional workflows and\nindustry readiness. Exposure to Composer packages enhances curriculum relevance\nand smooths the transition from academia to the workplace. However, effective\nintegration requires deliberate instructional design aligned with learning\nobjectives. Without guidance, students may treat packages as black boxes. Thus,\neducators must teach not only how to use these tools, but also when and why,\nencouraging critical evaluation of their utility and limitations. This ensures\nthat practical convenience supports rather than supplants deep learning.", "AI": {"tldr": "\u8be5\u6587\u8ba8\u8bba\u5728\u5927\u5b66Laravel\u8bfe\u7a0b\u4e2d\u5f15\u5165Composer\u548c\u4f18\u8d28\u5f00\u6e90\u5305\u53ef\u5927\u5e45\u63d0\u5347\u5f00\u53d1\u6548\u7387\u548c\u6559\u5b66\u8d28\u91cf\uff0c\u4f46\u5f3a\u8c03\u6559\u5e08\u9700\u6307\u5bfc\u5b66\u751f\u614e\u7528\u5de5\u5177\u3001\u7406\u89e3\u539f\u7406\uff0c\u9632\u6b62\u53ea\u4f1a\u201c\u5957\u5a03\u201d\u3002", "motivation": "\u5b66\u751f\u5728\u6709\u9650\u7684\u5b66\u671f\u65f6\u95f4\u5185\u7528Laravel\u5b8c\u6210\u9879\u76ee\u5b58\u5728\u56f0\u96be\uff0c\u4e9f\u9700\u6709\u6548\u63d0\u5347\u5f00\u53d1\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u8f6f\u4ef6\u5f00\u53d1\u7684\u4e13\u4e1a\u6027\u548c\u6559\u5b66\u7684\u6df1\u5ea6\u3002", "method": "\u5f52\u7eb3\u548c\u5206\u7c7b\u73b0\u6709Composer\u5305\uff0c\u7ed3\u5408\u5b9e\u9645\u4e0e\u6559\u5b66\u9700\u6c42\uff0c\u63d0\u51fa\u5305\u7684\u5e94\u7528\u7b56\u7565\u5e76\u5206\u6790\u5176\u5728\u8bfe\u7a0b\u4e2d\u7684\u4f5c\u7528\u4e0e\u98ce\u9669\u3002", "result": "\u7cbe\u5fc3\u6311\u9009\u7684Composer\u5305\u80fd\u663e\u8457\u51cf\u8f7b\u5b66\u751f\u5f00\u53d1\u8d1f\u62c5\uff0c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\uff0c\u4fc3\u8fdb\u5176\u4e13\u4e1a\u80fd\u529b\u6210\u957f\uff0c\u4f46\u5fc5\u987b\u901a\u8fc7\u6559\u5e08\u6307\u5bfc\u786e\u4fdd\u5b66\u751f\u7406\u89e3\u5de5\u5177\u80cc\u540e\u7684\u539f\u7406\u4e0e\u5e94\u7528\u573a\u666f\uff0c\u4ece\u800c\u907f\u514d\u76f2\u76ee\u4f9d\u8d56\u3002", "conclusion": "\u5f15\u5165Composer\u53ca\u5176\u7cbe\u9009\u5305\u4e0d\u4ec5\u53ef\u4ee5\u52a0\u5feb\u5f00\u53d1\u8fdb\u5ea6\uff0c\u8fd8\u80fd\u589e\u5f3a\u5b66\u751f\u7684\u4e13\u4e1a\u7d20\u517b\uff0c\u4f46\u9700\u6709\u9488\u5bf9\u6027\u7684\u6559\u5b66\u8bbe\u8ba1\u4ee5\u907f\u514d\u5b66\u751f\u9677\u5165\u5de5\u5177\u4f9d\u8d56\u548c\u6982\u5ff5\u7f3a\u5931\u3002"}}
{"id": "2508.05782", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05782", "abs": "https://arxiv.org/abs/2508.05782", "authors": ["Xiangyan Chen", "Yufeng Li", "Yujian Gan", "Arkaitz Zubiaga", "Matthew Purver"], "title": "FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification", "comment": null, "summary": "Large Language Models (LLMs) are known to produce hallucinations - factually\nincorrect or fabricated information - which poses significant challenges for\nmany Natural Language Processing (NLP) applications, such as dialogue systems.\nAs a result, detecting hallucinations has become a critical area of research.\nCurrent approaches to hallucination detection in dialogue systems primarily\nfocus on verifying the factual consistency of generated responses. However,\nthese responses often contain a mix of accurate, inaccurate or unverifiable\nfacts, making one factual label overly simplistic and coarse-grained. In this\npaper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact\nverification, which involves verifying atomic facts extracted from dialogue\nresponses. To support this, we construct a dataset based on publicly available\ndialogue datasets and evaluate it using various baseline methods. Experimental\nresults demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning\ncan enhance performance in dialogue fact verification. Despite this, the best\nF1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is\nonly 0.75, indicating that the benchmark remains a challenging task for future\nresearch. Our dataset and code will be public on GitHub.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7ec6\u7c92\u5ea6\u4e8b\u5b9e\u9a8c\u8bc1\u57fa\u51c6FineDialFact\uff0c\u5e76\u5c55\u793a\u5176\u6311\u6218\u6027\uff0cChain-of-Thought\u63a8\u7406\u6709\u52a9\u4e8e\u63d0\u5347\u6027\u80fd\uff0c\u76f8\u5173\u6570\u636e\u4e0e\u4ee3\u7801\u516c\u5f00\uff0c\u4fbf\u4e8e\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5f88\u5bb9\u6613\u4ea7\u751f\u65e5\u5fd7\uff08\u4e8b\u5b9e\u4e0d\u51c6\u786e\u6216\u865a\u6784\u4fe1\u606f\uff09\uff0c\u8fd9\u5728\u5bf9\u8bdd\u7cfb\u7edf\u7b49NLP\u5e94\u7528\u4e2d\u9020\u6210\u663e\u8457\u6311\u6218\uff0c\u56e0\u6b64\u5982\u4f55\u68c0\u6d4b\u65e5\u5fd7\u6210\u4e3a\u7814\u7a76\u91cd\u70b9\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u91c7\u7528\u4e8b\u5b9e\u4e00\u81f4\u6027\u9a8c\u8bc1\uff0c\u4f46\u5bf9\u8bdd\u4e2d\u5e38\u6709\u591a\u79cd\u51c6\u786e\u5ea6\u4e0d\u4e00\u7684\u4e8b\u5b9e\uff0c\u7b80\u5355\u6807\u7b7e\u663e\u5f97\u8fc7\u4e8e\u7c97\u7cd9\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u5bf9\u8bdd\u4e8b\u5b9e\u9a8c\u8bc1\u57fa\u51c6FineDialFact\uff0c\u5c06\u5bf9\u8bdd\u56de\u590d\u4e2d\u7684\u539f\u5b50\u4e8b\u5b9e\u8fdb\u884c\u9010\u4e00\u9a8c\u8bc1\uff0c\u5e76\u57fa\u4e8e\u516c\u5f00\u5bf9\u8bdd\u6570\u636e\u96c6\u6784\u5efa\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5e76\u63a2\u7d22Chain-of-Thought\u63a8\u7406\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408Chain-of-Thought\u63a8\u7406\u7684\u65b9\u6cd5\u63d0\u5347\u4e86\u7ec6\u7c92\u5ea6\u4e8b\u5b9e\u9a8c\u8bc1\u6027\u80fd\uff0c\u5728\u5f00\u653e\u9886\u57df\u5bf9\u8bdd\u6570\u636e\u96c6HybriDialogue\u4e0a\u6700\u9ad8F1\u5206\u6570\u4e3a0.75\uff0c\u4ecd\u8868\u660e\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u4e8b\u5b9e\u9a8c\u8bc1\u6bd4\u4f20\u7edf\u6574\u4f53\u6807\u7b7e\u66f4\u9002\u7528\u4e8e\u5bf9\u8bdd\u65e5\u5fd7\u68c0\u6d4b\uff0cFineDialFact\u57fa\u51c6\u4e0e\u6570\u636e\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5f53\u524d\u65b9\u6cd5\u4ecd\u6709\u8fdb\u4e00\u6b65\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2508.05799", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.05799", "abs": "https://arxiv.org/abs/2508.05799", "authors": ["Yoseph Berhanu Alebachew"], "title": "AI-Guided Exploration of Large-Scale Codebases", "comment": null, "summary": "Understanding large-scale, complex software systems is a major challenge for\ndevelopers, who spend a significant portion of their time on program\ncomprehension. Traditional tools such as static visualizations and reverse\nengineering techniques provide structural insights but often lack\ninteractivity, adaptability, and integration with contextual information.\nRecent advancements in large language models (LLMs) offer new opportunities to\nenhance code exploration workflows, yet their lack of grounding and integration\nwith structured views limits their effectiveness. This work introduces a hybrid\napproach that integrates deterministic reverse engineering with LLM-guided,\nintent-aware visual exploration. The proposed system combines UML-based\nvisualization, dynamic user interfaces, historical context, and collaborative\nfeatures into an adaptive tool for code comprehension. By interpreting user\nqueries and interaction patterns, the LLM helps developers navigate and\nunderstand complex codebases more effectively. A prototype implementation for\nJava demonstrates the feasibility of this approach. Future work includes\nempirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM\ninteraction models. This research lays the groundwork for intelligent,\ninteractive environments that align with developer cognition and collaborative\nworkflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9006\u5411\u5de5\u7a0b\u548cLLM\u7684\u65b0\u578b\u4ee3\u7801\u53ef\u89c6\u5316\u7406\u89e3\u5de5\u5177\uff0c\u63d0\u5347\u4e86\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u548c\u4ee3\u7801\u63a2\u7d22\u4f53\u9a8c\uff0c\u5e76\u5c55\u793a\u4e86Java\u539f\u578b\u9a8c\u8bc1\u6548\u679c\u3002\u672a\u6765\u5c06\u62d3\u5c55\u5230\u591a\u8bed\u8a00\u548c\u66f4\u4e30\u5bcc\u7684\u4eba\u673a\u4ea4\u4e92\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u5bf9\u4e8e\u5f00\u53d1\u8005\u6765\u8bf4\u59cb\u7ec8\u662f\u96be\u9898\uff0c\u76ee\u524d\u7684\u9759\u6001\u53ef\u89c6\u5316\u548c\u9006\u5411\u5de5\u7a0b\u5de5\u5177\u7f3a\u4e4f\u4e92\u52a8\u6027\u3001\u9002\u5e94\u6027\u548c\u4e0a\u4e0b\u6587\u6574\u5408\u3002\u8fd1\u671f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5d1b\u8d77\u4e3a\u4ee3\u7801\u63a2\u7d22\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u4f46\u5176\u6548\u679c\u56e0\u7f3a\u4e4f\u4e0e\u7ed3\u6784\u5316\u89c6\u56fe\u7ed3\u5408\u800c\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u5c06\u786e\u5b9a\u6027\u7684\u9006\u5411\u5de5\u7a0b\u4e0eLLM\u5f15\u5bfc\u3001\u610f\u56fe\u611f\u77e5\u7684\u53ef\u89c6\u5316\u4ee3\u7801\u63a2\u7d22\u7ed3\u5408\u3002\u8be5\u7cfb\u7edf\u96c6\u6210\u4e86\u57fa\u4e8eUML\u7684\u53ef\u89c6\u5316\u3001\u52a8\u6001\u7528\u6237\u754c\u9762\u3001\u5386\u53f2\u4e0a\u4e0b\u6587\u4e0e\u534f\u4f5c\u529f\u80fd\uff0c\u901a\u8fc7\u89e3\u8bfb\u7528\u6237\u67e5\u8be2\u548c\u4ea4\u4e92\u6a21\u5f0f\uff0c\u7531LLM\u8f85\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u5730\u7406\u89e3\u4ee3\u7801\u5e93\u3002\u5e76\u5b9e\u73b0\u4e86Java\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645Java\u9879\u76ee\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3a\u5f00\u53d1\u8005\u5bf9\u590d\u6742\u4ee3\u7801\u5e93\u7684\u7406\u89e3\u4e0e\u63a2\u7d22\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u667a\u80fd\u4e14\u4e92\u52a8\u6027\u5f3a\u7684\u8f6f\u4ef6\u7406\u89e3\u73af\u5883\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u53ef\u66f4\u597d\u5730\u5951\u5408\u5f00\u53d1\u8005\u8ba4\u77e5\u548c\u534f\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u3002\u672a\u6765\u5c06\u6269\u5c55\u5230\u591a\u8bed\u8a00\u7cfb\u7edf\uff0c\u8bc4\u4f30\u5b9e\u7528\u6027\u5e76\u5f00\u53d1\u57fa\u4e8eGUI\u7684LLM\u4ea4\u4e92\u6a21\u5f0f\u3002"}}
{"id": "2508.05803", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.05803", "abs": "https://arxiv.org/abs/2508.05803", "authors": ["Abishek Thamma", "Micha Heilbron"], "title": "Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models", "comment": null, "summary": "Human memory is fleeting. As words are processed, the exact wordforms that\nmake up incoming sentences are rapidly lost. Cognitive scientists have long\nbelieved that this limitation of memory may, paradoxically, help in learning\nlanguage - an idea supported by classic connectionist modelling work. The rise\nof Transformers appears to challenge this idea, as these models can learn\nlanguage effectively, despite lacking memory limitations or other architectural\nrecency biases. Here, we investigate the hypothesized benefit of fleeting\nmemory for language learning in tightly controlled experiments on transformer\nlanguage models. Training transformers with and without fleeting memory on a\ndevelopmentally realistic training set, we find that fleeting memory\nconsistently improves language learning (as quantified by both overall language\nmodelling performance and targeted syntactic evaluation) but, unexpectedly,\nimpairs surprisal-based prediction of human reading times. Interestingly,\nfollow up analyses revealed that this discrepancy - better language modeling,\nyet worse reading time prediction - could not be accounted for by prior\nexplanations of why better language models sometimes fit human reading time\nworse. Together, these results support a benefit of memory limitations on\nneural network language learning - but not on predicting behavior.", "AI": {"tldr": "\u8bb0\u5fc6\u77ed\u6682\u6027\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u8bed\u8a00\u4e60\u5f97\uff0c\u5374\u964d\u4f4e\u5bf9\u4eba\u7c7b\u9605\u8bfb\u884c\u4e3a\u7684\u62df\u5408\uff0c\u6311\u6218\u4e86\u65e2\u6709\u8ba4\u77e5\u7406\u8bba\u3002", "motivation": "\u4f20\u7edf\u8ba4\u77e5\u79d1\u5b66\u8ba4\u4e3a\uff0c\u8bb0\u5fc6\u77ed\u6682\u6027\u53cd\u800c\u6709\u52a9\u4e8e\u8bed\u8a00\u5b66\u4e60\u3002\u968f\u7740Transformer\u7684\u5174\u8d77\uff0c\u5176\u65e0\u8bb0\u5fc6\u9650\u5236\u5374\u4f9d\u7136\u9ad8\u6548\u4e60\u5f97\u8bed\u8a00\uff0c\u8fd9\u4e00\u73b0\u8c61\u6311\u6218\u4e86\u7ecf\u5178\u89c2\u70b9\uff0c\u56e0\u6b64\u4f5c\u8005\u60f3\u63a2\u7a76\u8bb0\u5fc6\u77ed\u6682\u6027\u5bf9\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u8bed\u8a00\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "method": "\u5728\u6a21\u62df\u771f\u5b9e\u8bed\u8a00\u5b66\u4e60\u73af\u5883\u4e0b\uff0c\u5bf9Transformer\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff1a\u4e00\u7ec4\u52a0\u5165\u4e86\u8bb0\u5fc6\u77ed\u6682\u6027\u673a\u5236\uff0c\u4e00\u7ec4\u672a\u52a0\u5165\u3002\u8bc4\u4f30\u5176\u8bed\u8a00\u5b66\u4e60\u80fd\u529b\u548c\u5bf9\u4eba\u7c7b\u9605\u8bfb\u65f6\u95f4\u7684\u9884\u6d4b\u8868\u73b0\u3002", "result": "\u5f15\u5165\u77ed\u6682\u8bb0\u5fc6\u673a\u5236\u540e\uff0c\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u6cd5\u53ca\u6574\u4f53\u8868\u73b0\u4e0a\u4f18\u4e8e\u6807\u51c6Transformer\uff0c\u4f46\u5bf9\u4eba\u7c7b\u9605\u8bfb\u65f6\u95f4\u7684\u9884\u6d4b\u8868\u73b0\u53cd\u5012\u53d8\u5dee\uff0c\u4e14\u8fd9\u4e00\u73b0\u8c61\u65e0\u6cd5\u7528\u73b0\u6709\u7406\u8bba\u89e3\u91ca\u3002", "conclusion": "\u8bb0\u5fc6\u7684\u77ed\u6682\u6027\u6709\u5229\u4e8e\u795e\u7ecf\u7f51\u7edc\u5bf9\u8bed\u8a00\u5b66\u4e60\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u8fd9\u79cd\u9650\u5236\u5e76\u4e0d\u5e2e\u52a9\u9884\u6d4b\u4eba\u7c7b\u7684\u884c\u4e3a\uff08\u5982\u9605\u8bfb\u65f6\u95f4\uff09\u3002"}}
{"id": "2508.05923", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05923", "abs": "https://arxiv.org/abs/2508.05923", "authors": ["Yanusha Mehendran", "Maolin Tang", "Yi Lu"], "title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "comment": "26 Pages, 3 figures, 6 Tables, Submitted to Empirical Software\n  Engineering and it is under review", "summary": "Software vulnerabilities continue to undermine the reliability and security\nof modern systems, particularly as software complexity outpaces the\ncapabilities of traditional detection methods. This study introduces a genetic\nalgorithm-based method for test input generation that innovatively integrates\ngenetic operators and adaptive learning to enhance software vulnerability\ndetection. A key contribution is the application of the crossover operator,\nwhich facilitates exploration by searching across a broader space of potential\ntest inputs. Complementing this, an adaptive feedback mechanism continuously\nlearns from the system's execution behavior and dynamically guides input\ngeneration toward promising areas of the input space. Rather than relying on\nfixed or randomly selected inputs, the approach evolves a population of\nstructurally valid test cases using feedback-driven selection, enabling deeper\nand more effective code traversal. This strategic integration of exploration\nand exploitation ensures that both diverse and targeted test inputs are\ndeveloped over time. Evaluation was conducted across nine open-source\nJSON-processing libraries. The proposed method achieved substantial\nimprovements in coverage compared to a benchmark evolutionary fuzzing method,\nwith average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%\nin line coverage, 114.0% in instruction coverage, and 166.0% in branch\ncoverage. These results highlight the method's capacity to detect deeper and\nmore complex vulnerabilities, offering a scalable and adaptive solution to\nsoftware security testing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u8986\u76d6\u7387\u6307\u6807\u4e0a\u8f83\u4f20\u7edf\u8fdb\u5316\u6a21\u7cca\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u6f5c\u529b\u3002", "motivation": "\u8f6f\u4ef6\u590d\u6742\u6027\u589e\u52a0\uff0c\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u73b0\u4ee3\u7cfb\u7edf\u7684\u5b89\u5168\u4e0e\u53ef\u9760\u6027\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u3001\u66f4\u6709\u6548\u7684\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u65b9\u6cd5\u4ee5\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86\u9057\u4f20\u64cd\u4f5c\u7b26\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u673a\u5236\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ea4\u53c9\u64cd\u4f5c\u7b26\u6269\u5c55\u6d4b\u8bd5\u8f93\u5165\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u53cd\u9988\u673a\u5236\uff0c\u6839\u636e\u7cfb\u7edf\u6267\u884c\u884c\u4e3a\u52a8\u6001\u8c03\u6574\u8f93\u5165\u751f\u6210\u65b9\u5411\u3002\u6d4b\u8bd5\u7528\u4f8b\u4ee5\u53cd\u9988\u9a71\u52a8\u65b9\u5f0f\u8fdb\u5316\u9009\u62e9\uff0c\u4ece\u800c\u5b9e\u73b0\u7ed3\u6784\u6709\u6548\u4e14\u66f4\u6df1\u5165\u7684\u4ee3\u7801\u904d\u5386\u3002", "result": "\u57289\u4e2a\u5f00\u6e90\u7684JSON\u5904\u7406\u5e93\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u57fa\u51c6\u8fdb\u5316\u5f0f\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u8986\u76d6\u7387\u6709\u663e\u8457\u63d0\u5347\uff1a\u7c7b\u8986\u76d6\u7387\u63d0\u534739.8%\uff0c\u65b9\u6cd5\u8986\u76d6\u7387\u63d0\u534762.4%\uff0c\u884c\u8986\u76d6\u7387\u63d0\u5347105.0%\uff0c\u6307\u4ee4\u8986\u76d6\u7387\u63d0\u5347114.0%\uff0c\u5206\u652f\u8986\u76d6\u7387\u63d0\u5347166.0%\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u80fd\u53d1\u73b0\u66f4\u6df1\u5c42\u6b21\u3001\u66f4\u590d\u6742\u7684\u8f6f\u4ef6\u6f0f\u6d1e\uff0c\u662f\u4e00\u79cd\u5177\u5907\u53ef\u6269\u5c55\u6027\u548c\u81ea\u9002\u5e94\u80fd\u529b\u7684\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u65b0\u65b9\u6848\u3002"}}
{"id": "2508.05830", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.05830", "abs": "https://arxiv.org/abs/2508.05830", "authors": ["Tong Li", "Rasiq Hussain", "Mehak Gupta", "Joshua R. Oltmanns"], "title": "\"Mirror\" Language AI Models of Depression are Criterion-Contaminated", "comment": "39 pages, 9 figures", "summary": "A growing number of studies show near-perfect LLM language-based prediction\nof depression assessment scores (up to R2 of .70). However, many develop these\nmodels directly from language responses to depression assessments. These\n\"Mirror models\" suffer from \"criterion contamination\", which arises when a\npredicted score depends in part on the predictors themselves. This causes\nartificial effect size inflation which reduces model generalizability. The\npresent study compares the performance of Mirror models versus \"Non-Mirror\nmodels\", which are developed from language that does not mirror the assessment\nthey are developed to predict. N = 110 research participants completed two\ndifferent interviews: structured diagnostic and life history interviews. GPT-4,\nGPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic\ninterview depression scores from the two transcripts separately. Mirror models\n(using structured diagnostic data) showed very large effect sizes (e.g., R2 =\n.80). As expected, NonMirror models (using life history data) demonstrated\nsmaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror\nand Non-Mirror model-predicted structured interview depression scores were\ncorrelated with self-reported depression symptoms, Mirror and NonMirror\nperformed the same (e.g., r = ~.54), indicating that Mirror models contain bias\nperhaps due to criterion contamination. Topic modeling identified clusters\nacross Mirror and Non-Mirror models, as well as between true-positive and\nfalse-positive predictions. In this head-to-head comparison study, Mirror\nlanguage AI models of depression showed artificially inflated effect sizes and\nless generalizability. As language AI models for depression continue to evolve,\nincorporating Non-Mirror models may identify interpretable, and generalizable\nsemantic features that have unique utility in real-world psychological\nassessment.", "AI": {"tldr": "\u76f4\u63a5\u7528\u95ee\u5377\u5185\u5bb9\u8ba9AI\u9884\u6d4b\u6291\u90c1\u5f88\u51c6\u4f46\u8fc7\u62df\u5408\uff0c\u6362\u7528\u65e5\u5e38\u8c08\u8bdd\u51c6\u786e\u7387\u4e0b\u964d\u4f46\u66f4\u6cdb\u5316\uff0c\u5b9e\u9645\u5e94\u7528\u5e94\u504f\u5411\u540e\u8005\u3002", "motivation": "\u8d8a\u6765\u8d8a\u591a\u7684\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u6291\u90c1\u75c7\u8bc4\u4f30\u5206\u6570\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u53d6\u5f97\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6548\u679c\uff08R2\u6700\u9ad8\u53ef\u8fbe0.70\uff09\u3002\u4f46\u8bb8\u591a\u65b9\u6cd5\u76f4\u63a5\u7528\u8bc4\u4f30\u95ee\u5377\u7684\u56de\u7b54\u8bad\u7ec3\u6a21\u578b\uff08\u5373\u201c\u955c\u50cf\u6a21\u578b\u201d\uff09\uff0c\u8fd9\u79cd\u505a\u6cd5\u5e26\u6765\u4e86\u201c\u6807\u51c6\u6c61\u67d3\u201d\uff0c\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u6cdb\u5316\u6027\u964d\u4f4e\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76\u4e0d\u540c\u6570\u636e\u6765\u6e90\u7684\u6a21\u578b\u8868\u73b0\u3001\u6cdb\u5316\u80fd\u529b\u548c\u89e3\u8bfb\u6027\u3002", "method": "\u5bf9110\u540d\u7814\u7a76\u53c2\u4e0e\u8005\u5206\u522b\u8fdb\u884c\u7ed3\u6784\u5316\u8bca\u65ad\u8bbf\u8c08\u548c\u751f\u6d3b\u53f2\u8bbf\u8c08\u3002\u8ba9GPT-4\u3001GPT-4o\u53caLLaMA3-70B\u5206\u522b\u57fa\u4e8e\u8fd9\u4e24\u7c7b\u8bbf\u8c08\u8f6c\u5f55\u6587\u672c\u9884\u6d4b\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u6291\u90c1\u8bc4\u4f30\u5206\u6570\u3002\u5bf9\u6bd4\u201c\u955c\u50cf\u6a21\u578b\u201d\uff08\u7528\u7ed3\u6784\u5316\u8bca\u65ad\u6587\u672c\u6784\u5efa\uff09\u4e0e\u201c\u975e\u955c\u50cf\u6a21\u578b\u201d\uff08\u7528\u751f\u6d3b\u53f2\u6587\u672c\u6784\u5efa\uff09\u7684\u9884\u6d4b\u6548\u679c\uff0c\u5e76\u5206\u6790\u5176\u4e0e\u81ea\u8bc4\u6291\u90c1\u75c7\u72b6\u7684\u76f8\u5173\u6027\uff0c\u53ca\u7528\u4e3b\u9898\u5efa\u6a21\u5206\u6790\u9884\u6d4b\u8bef\u5dee\u3002", "result": "\u955c\u50cf\u6a21\u578b\u9884\u6d4b\u6548\u679c\u6781\u4f73\uff08R2\u7ea60.80\uff09\uff0c\u4f46\u975e\u955c\u50cf\u6a21\u578b\u6548\u679c\u8f83\u4f4e\uff08R2\u7ea60.27\uff09\uff0c\u4f46\u4ecd\u76f8\u5bf9\u8f83\u9ad8\u3002\u4e24\u7c7b\u6a21\u578b\u9884\u6d4b\u5206\u6570\u4e0e\u81ea\u8bc4\u6291\u90c1\u75c7\u72b6\u76f8\u5173\u6027\u76f8\u5f53\uff08r\u7ea60.54\uff09\uff0c\u8868\u660e\u955c\u50cf\u6a21\u578b\u5b58\u5728\u6807\u51c6\u6c61\u67d3\u5bfc\u81f4\u7684\u4eba\u5de5\u653e\u5927\u6548\u5e94\u3002\u4e3b\u9898\u5efa\u6a21\u53d1\u73b0\u4e86\u4e0d\u540c\u6a21\u578b\u7c7b\u578b\u548c\u9884\u6d4b\u5206\u5bf9\u7684\u8bed\u4e49\u7279\u5f81\u5dee\u5f02\u3002", "conclusion": "\u4ec5\u51ed\u4e0e\u8bc4\u4f30\u5185\u5bb9\u9ad8\u5ea6\u91cd\u5408\u7684\u5bf9\u8bdd\u8bad\u7ec3AI\u6a21\u578b\uff0c\u4f1a\u9ad8\u4f30\u5176\u9884\u6d4b\u80fd\u529b\u548c\u6cdb\u5316\u6027\u3002\u975e\u955c\u50cf\u6a21\u578b\u867d\u6548\u679c\u8f83\u5f31\u4f46\u66f4\u80fd\u53cd\u6620\u53ef\u8fc1\u79fb\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u5bf9\u4e8e\u5b9e\u9645\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u66f4\u6709\u5e94\u7528\u4ef7\u503c\u3002\u4eca\u540e\u9700\u66f4\u591a\u91c7\u7528\u975e\u955c\u50cf\u65b9\u6cd5\uff0c\u4ee5\u83b7\u5f97\u66f4\u53ef\u89e3\u91ca\u548c\u6cdb\u5316\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2508.05949", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.05949", "abs": "https://arxiv.org/abs/2508.05949", "authors": ["Jialin Yang", "Zainab Saad", "Jiajun Wu", "Xiaoguang Niu", "Henry Leung", "Steve Drew"], "title": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration", "comment": "Submitted to ACM Computing Surveys", "summary": "The soaring energy demands of large-scale software ecosystems and cloud data\ncenters, accelerated by the intensive training and deployment of large language\nmodels, have driven energy consumption and carbon footprint to unprecedented\nlevels. In response, both industry and academia are increasing efforts to\nreduce the carbon emissions associated with cloud computing through more\nefficient task scheduling and infrastructure orchestration. In this work, we\npresent a systematic review of various Kubernetes scheduling strategies,\ncategorizing them into hardware-centric and software-centric, annotating each\nwith its sustainability objectives, and grouping them according to the\nalgorithms they use. We propose a comprehensive taxonomy for cloud task\nscheduling studies, with a particular focus on the environmental sustainability\naspect. We analyze emerging research trends and open challenges, and our\nfindings provide critical insight into the design of sustainable scheduling\nsolutions for next-generation cloud computing systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86 Kubernetes \u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u4ee5\u53ef\u6301\u7eed\u5316\u4e3a\u6838\u5fc3\uff0c\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u5206\u4e3a\u786c\u4ef6\u548c\u8f6f\u4ef6\u5bfc\u5411\u4e24\u7c7b\uff0c\u4ece\u73af\u5883\u5f71\u54cd\u89c6\u89d2\u5206\u6790\u4e86\u5176\u4f18\u7f3a\u70b9\u3002\u63d0\u51fa\u4e86\u4e91\u4efb\u52a1\u8c03\u5ea6\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u6307\u51fa\u4e86\u65b0\u5174\u7814\u7a76\u65b9\u5411\u4e0e\u6311\u6218\uff0c\u4e3a\u8bbe\u8ba1\u4f4e\u78b3\u73af\u4fdd\u7684\u4e91\u7cfb\u7edf\u8c03\u5ea6\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "motivation": "\u9762\u5bf9\u5927\u89c4\u6a21\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u548c\u4e91\u6570\u636e\u4e2d\u5fc3\u56e0\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e0e\u90e8\u7f72\u5bfc\u81f4\u7684\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u6fc0\u589e\uff0c\u4e1a\u754c\u4e0e\u5b66\u672f\u754c\u4e9f\u9700\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u4efb\u52a1\u8c03\u5ea6\u4e0e\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u65b9\u6cd5\u4ee5\u964d\u4f4e\u78b3\u6392\u653e\u3002", "method": "\u7cfb\u7edf\u6027\u56de\u987e\u73b0\u6709 Kubernetes \u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u5c06\u5176\u5206\u4e3a\u786c\u4ef6\u5bfc\u5411\u548c\u8f6f\u4ef6\u5bfc\u5411\u4e24\u5927\u7c7b\uff0c\u5206\u6790\u5176\u53ef\u6301\u7eed\u6027\u76ee\u6807\uff0c\u5e76\u4f9d\u636e\u6240\u7528\u7b97\u6cd5\u8fdb\u884c\u5f52\u7c7b\u3002\u540c\u65f6\u63d0\u51fa\u4e91\u4efb\u52a1\u8c03\u5ea6\u7814\u7a76\u7684\u7efc\u5408\u5206\u7c7b\u4f53\u7cfb\uff0c\u91cd\u70b9\u5173\u6ce8\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002", "result": "\u5bf9\u73b0\u6709 Kubernetes \u8c03\u5ea6\u7b56\u7565\u8fdb\u884c\u4e86\u7ec6\u81f4\u7684\u68b3\u7406\u4e0e\u5206\u7c7b\uff0c\u5206\u6790\u4e86\u5404\u65b9\u6cd5\u5bf9\u5e94\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u53ca\u5176\u7b97\u6cd5\u5206\u7ec4\uff0c\u5f52\u7eb3\u51fa\u4e91\u4efb\u52a1\u8c03\u5ea6\u9886\u57df\u7684\u7814\u7a76\u8d8b\u52bf\u548c\u5c1a\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u63ed\u793a\u4e86\u5b9e\u73b0\u4e0b\u4e00\u4ee3\u4e91\u8ba1\u7b97\u7cfb\u7edf\u53ef\u6301\u7eed\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u7684\u5173\u952e\u6d1e\u5bdf\uff0c\u5e76\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u6307\u5bfc\u3002"}}
{"id": "2508.05843", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05843", "abs": "https://arxiv.org/abs/2508.05843", "authors": ["Miles Gilberti", "Shane Storks", "Huteng Dai"], "title": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication", "comment": null, "summary": "Emergent communication (EmCom) with deep neural network-based agents promises\nto yield insights into the nature of human language, but remains focused\nprimarily on a few subfield-specific goals and metrics that prioritize\ncommunication schemes which represent attributes with unique characters\none-to-one and compose them syntactically. We thus reinterpret a common EmCom\nsetting, the attribute-value reconstruction game, by imposing a\nsmall-vocabulary constraint to simulate double articulation, and formulating a\nnovel setting analogous to naturalistic inflectional morphology (enabling\nmeaningful comparison to natural language communication schemes). We develop\nnew metrics and explore variations of this game motivated by real properties of\ninflectional morphology: concatenativity and fusionality. Through our\nexperiments, we discover that simulated phonological constraints encourage\nconcatenative morphology, and emergent languages replicate the tendency of\nnatural languages to fuse grammatical attributes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5728\u65b0\u5174\u901a\u4fe1\u6e38\u620f\u4e2d\u5f15\u5165\u5c0f\u8bcd\u6c47\u91cf\u7ea6\u675f\u4e0e\u5c48\u6298\u5f62\u6001\u5b66\u8bbe\u5b9a\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7406\u4eba\u751f\u6210\u7684\u8bed\u8a00\u7ed3\u6784\u53ef\u4ee5\u6a21\u62df\u81ea\u7136\u8bed\u8a00\u4e2d\u5c5e\u6027\u878d\u5408\u548c\u8fde\u7ed3\u7684\u7279\u6027\uff0c\u5b9e\u73b0\u5bf9\u81ea\u7136\u8bed\u8a00\u89c4\u5f8b\u7684\u6709\u610f\u4e49\u590d\u73b0\u3002", "motivation": "\u73b0\u6709\u65b0\u5174\u901a\u4fe1\uff08EmCom\uff09\u7814\u7a76\u591a\u5173\u6ce8\u4e00\u5bf9\u4e00\u7684\u5c5e\u6027\u6620\u5c04\u548c\u8bcd\u8bed\u5408\u6210\uff0c\u7f3a\u4e4f\u4e0e\u81ea\u7136\u8bed\u8a00\u5f62\u6001\u5b66\u7ed3\u6784\u7684\u5bf9\u6bd4\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6a21\u62df\u81ea\u7136\u8bed\u8a00\u5c48\u6298\u5f62\u6001\u5b66\u5c5e\u6027\uff0c\u63a2\u7d22\u80fd\u5426\u66f4\u8d34\u8fd1\u4eba\u7c7b\u8bed\u8a00\u672c\u8d28\u7684\u901a\u4fe1\u7cfb\u7edf\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u7406\u89e3\u4e0e\u751f\u6210\u81ea\u7136\u8bed\u8a00\u63d0\u4f9b\u65b0\u52a8\u529b\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u5c5e\u6027\u503c\u91cd\u6784\u6e38\u620f\uff0c\u52a0\u5165\u5c0f\u8bcd\u6c47\u91cf\u7ea6\u675f\uff0c\u63d0\u51fa\u7c7b\u4f3c\u5c48\u6298\u5f62\u6001\u5b66\uff08\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u8bcd\u5f62\u53d8\u5316\uff09\u7684\u65b0\u5b9e\u9a8c\u8bbe\u5b9a\uff0c\u5e76\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6765\u8861\u91cf\u8fde\u7ed3\u6027\u548c\u878d\u5408\u6027\u3002\u901a\u8fc7\u5b9e\u9a8c\u63a2\u7d22\u8fd9\u4e9b\u7ea6\u675f\u5bf9\u65b0\u5174\u8bed\u8a00\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "result": "\u5728\u5c0f\u8bcd\u6c47\u91cf\u4e0e\u8bed\u97f3\u5b66\u7ea6\u675f\u4e0b\uff0c\u4ee3\u7406\u4eba\u53d1\u5c55\u51fa\u7684\u65b0\u5174\u8bed\u8a00\u5c55\u73b0\u51fa\u8fde\u7ed3\u6027\u548c\u5c5e\u6027\u878d\u5408\u6027\uff0c\u4e0e\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u5c48\u6298\u5f62\u6001\u6709\u8f83\u5927\u76f8\u4f3c\u6027\uff0c\u7279\u522b\u662f\u590d\u5236\u4e86\u81ea\u7136\u8bed\u8a00\u4e2d\u5c06\u591a\u79cd\u8bed\u6cd5\u5c5e\u6027\u878d\u5408\u4e3a\u5355\u4e00\u8bcd\u7d20\u7684\u503e\u5411\u3002", "conclusion": "\u5728\u65bd\u52a0\u5c0f\u8bcd\u6c47\u91cf\u7ea6\u675f\u4ee5\u6a21\u62df\u53cc\u91cd\u5206\u8282\u540e\uff0c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u4eba\u80fd\u591f\u751f\u6210\u5177\u6709\u81ea\u7136\u8bed\u8a00\u5c48\u6298\u5f62\u6001\u5b66\u7279\u5f81\uff08\u8fde\u7ed3\u6027\u548c\u878d\u5408\u6027\uff09\u7684\u65b0\u5174\u901a\u4fe1\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u8bed\u8a00\u6709\u53ef\u6bd4\u6027\uff0c\u5e76\u4e14\u5c55\u73b0\u51fa\u4e0e\u81ea\u7136\u8bed\u8a00\u4e00\u81f4\u7684\u5c5e\u6027\u878d\u5408\u503e\u5411\u3002"}}
{"id": "2508.05970", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05970", "abs": "https://arxiv.org/abs/2508.05970", "authors": ["Yanzhou Li", "Shangqing Liu", "Kangjie Chen", "Tianwei Zhang", "Yang Liu"], "title": "Impact-driven Context Filtering For Cross-file Code Completion", "comment": null, "summary": "Retrieval-augmented generation (RAG) has recently demonstrated considerable\npotential for repository-level code completion, as it integrates cross-file\nknowledge with in-file preceding code to provide comprehensive contexts for\ngeneration. To better understand the contribution of the retrieved cross-file\ncontexts, we introduce a likelihood-based metric to evaluate the impact of each\nretrieved code chunk on the completion. Our analysis reveals that, despite\nretrieving numerous chunks, only a small subset positively contributes to the\ncompletion, while some chunks even degrade performance. To address this issue,\nwe leverage this metric to construct a repository-level dataset where each\nretrieved chunk is labeled as positive, neutral, or negative based on its\nrelevance to the target completion. We then propose an adaptive retrieval\ncontext filtering framework, CODEFILTER, trained on this dataset to mitigate\nthe harmful effects of negative retrieved contexts in code completion.\nExtensive evaluation on the RepoEval and CrossCodeLongEval benchmarks\ndemonstrates that CODEFILTER consistently improves completion accuracy compared\nto approaches without filtering operations across various tasks. Additionally,\nCODEFILTER significantly reduces the length of the input prompt, enhancing\ncomputational efficiency while exhibiting strong generalizability across\ndifferent models. These results underscore the potential of CODEFILTER to\nenhance the accuracy, efficiency, and attributability of repository-level code\ncompletion.", "AI": {"tldr": "\u672c\u5de5\u4f5c\u53d1\u73b0RAG\u65b9\u6cd5\u5728\u4ee3\u7801\u8865\u5168\u4e2d\u68c0\u7d22\u5230\u7684\u591a\u6570\u4e0a\u4e0b\u6587\u5757\u65e0\u76ca\u751a\u81f3\u6709\u5bb3\uff0c\u63d0\u51faCODEFILTER\u6846\u67b6\uff0c\u80fd\u81ea\u9002\u5e94\u7b5b\u9009\u6389\u8d1f\u9762\u5757\uff0c\u63d0\u5347\u8865\u5168\u51c6\u786e\u7387\u53ca\u6548\u7387\u3002", "motivation": "RAG\u65b9\u6cd5\u5df2\u5728\u4ee3\u7801\u81ea\u52a8\u8865\u5168\u65b9\u5411\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5b9e\u9645\u68c0\u7d22\u7684\u8de8\u6587\u4ef6\u4ee3\u7801\u5757\u4e2d\uff0c\u53ea\u6709\u90e8\u5206\u5757\u5bf9\u8865\u5168\u6709\u79ef\u6781\u4f5c\u7528\uff0c\u90e8\u5206\u751a\u81f3\u4f1a\u524a\u5f31\u6027\u80fd\u3002\u4f5c\u8005\u5e0c\u671b\u6df1\u5165\u7406\u89e3\u3001\u533a\u5206\u8fd9\u4e9b\u68c0\u7d22\u5757\u7684\u4f5c\u7528\uff0c\u5e76\u63d0\u5347\u4ee3\u7801\u8865\u5168\u6548\u679c\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4f3c\u7136\u7684\u5ea6\u91cf\uff0c\u7528\u4e8e\u8bc4\u4f30\u6bcf\u4e2a\u68c0\u7d22\u5230\u7684\u4ee3\u7801\u5757\u5bf9\u8865\u5168\u7684\u5f71\u54cd\uff0c\u5e76\u636e\u6b64\u4e3a\u68c0\u7d22\u5757\u6253\u4e0a\u79ef\u6781\u3001\u4e2d\u6027\u3001\u6d88\u6781\u6807\u7b7e\uff0c\u6784\u5efa\u6570\u636e\u96c6\u3002\u8fdb\u800c\u63d0\u51fa\u4e86\u9002\u5e94\u6027\u68c0\u7d22\u4e0a\u4e0b\u6587\u7b5b\u9009\uff08CODEFILTER\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u81ea\u52a8\u8fc7\u6ee4\u4e0d\u5229\u4e8e\u8865\u5168\u7684\u68c0\u7d22\u7ed3\u679c\u3002", "result": "\u5728RepoEval\u548cCrossCodeLongEval\u4e24\u4e2a\u57fa\u51c6\u4e0a\uff0cCODEFILTER\u4e0d\u8bba\u54ea\u79cd\u4efb\u52a1\u76f8\u8f83\u4e8e\u672a\u7b5b\u9009\u7684RAG\u90fd\u663e\u8457\u63d0\u5347\u4e86\u8865\u5168\u51c6\u786e\u7387\u3002\u540c\u65f6\u6709\u6548\u7f29\u77ed\u4e86\u8f93\u5165\u957f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CODEFILTER\u80fd\u591f\u4f18\u5316\u8de8\u6587\u4ef6\u68c0\u7d22\u4ee3\u7801\u5757\u7684\u8d28\u91cf\uff0c\u63d0\u5347\u4ee3\u7801\u8865\u5168\u7684\u51c6\u786e\u6027\u4e0e\u6548\u7387\uff0c\u5bf9\u4e0d\u540c\u6a21\u578b\u5747\u6709\u8f83\u597d\u9002\u5e94\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u5bf9\u5b58\u50a8\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u5177\u6709\u8f83\u5927\u63d0\u5347\u6f5c\u529b\u3002"}}
{"id": "2508.05880", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.05880", "abs": "https://arxiv.org/abs/2508.05880", "authors": ["Sree Bhattacharyya", "Lucas Craig", "Tharun Dilliraj", "Jia Li", "James Z. Wang"], "title": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models", "comment": null, "summary": "Affective Computing has been established as a crucial field of inquiry to\nadvance the holistic development of Artificial Intelligence (AI) systems.\nFoundation models -- especially Large Language Models (LLMs) -- have been\nevaluated, trained, or instruction-tuned in several past works, to become\nbetter predictors or generators of emotion. Most of these studies, however,\napproach emotion-related tasks in a supervised manner, assessing or training\nthe capabilities of LLMs using discrete emotion labels associated with stimuli\n(e.g., text, images, video, audio). Evaluation studies, in particular, have\noften been limited to standard and superficial emotion-related tasks, such as\nthe recognition of evoked or expressed emotions. In this paper, we move beyond\nsurface-level emotion tasks to investigate how LLMs reason about emotions\nthrough cognitive dimensions. Drawing from cognitive appraisal theory, we\nexamine whether LLMs produce coherent and plausible cognitive reasoning when\nreasoning about emotionally charged stimuli. We introduce a large-scale\nbenchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal\ncognitive structures implicitly used by LLMs for emotional reasoning. Through a\nplethora of evaluation experiments and analysis, we seek to answer: (a) Are\nmodels more likely to implicitly rely on specific cognitive appraisal\ndimensions?, (b) What cognitive dimensions are important for characterizing\nspecific emotions?, and, (c) Can the internal representations of different\nemotion categories in LLMs be interpreted through cognitive appraisal\ndimensions? Our results and analyses reveal diverse reasoning patterns across\ndifferent LLMs. Our benchmark and code will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u516c\u5f00\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u60c5\u611f\u8ba4\u77e5\u63a8\u7406\u80fd\u529b\u7684\u5927\u89c4\u6a21\u57fa\u51c6CoRE\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u60c5\u611f\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u8868\u73b0\u4e0e\u5dee\u5f02\uff0c\u4e3a\u60c5\u611f\u8ba1\u7b97\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u5de5\u5177\u548c\u7406\u89e3\u89d2\u5ea6\u3002", "motivation": "\u60c5\u611f\u8ba1\u7b97\u4f5c\u4e3a\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5168\u9762\u53d1\u5c55\u7684\u5173\u952e\u9886\u57df\uff0c\u73b0\u6709\u7814\u7a76\u591a\u91c7\u7528\u76d1\u7763\u5f0f\u5b66\u4e60\uff0c\u901a\u8fc7\u79bb\u6563\u60c5\u611f\u6807\u7b7e\u8bc4\u4f30\u5927\u6a21\u578b\u611f\u77e5\u548c\u751f\u6210\u60c5\u611f\u7684\u80fd\u529b\u3002\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u591a\u5c40\u9650\u4e8e\u60c5\u611f\u8bc6\u522b\u7b49\u8868\u5c42\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u60c5\u611f\u63a8\u7406\u80cc\u540e\u8ba4\u77e5\u8fc7\u7a0b\u7684\u6df1\u5165\u63a2\u7d22\u3002", "method": "\u672c\u7814\u7a76\u57fa\u4e8e\u8ba4\u77e5\u8bc4\u4ef7\u7406\u8bba\uff0c\u8bbe\u8ba1\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u60c5\u611f\u8ba4\u77e5\u63a8\u7406\u8bc4\u6d4b\u57fa\u51c6\uff08CoRE\uff09\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u60c5\u611f\u76f8\u5173\u523a\u6fc0\u65f6\uff0c\u662f\u5426\u80fd\u591f\u4ea7\u751f\u4e00\u81f4\u4e14\u5408\u4e4e\u903b\u8f91\u7684\u8ba4\u77e5\u63a8\u7406\u3002\u901a\u8fc7\u591a\u8f6e\u5b9e\u9a8c\u4e0e\u5206\u6790\uff0c\u8054\u5408\u8003\u5bdf\u6a21\u578b\u662f\u5426\u9690\u5f0f\u4f9d\u8d56\u67d0\u4e9b\u8ba4\u77e5\u7ef4\u5ea6\u3001\u4e0d\u540c\u60c5\u611f\u7684\u5173\u952e\u8ba4\u77e5\u7ef4\u5ea6\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u7ef4\u5ea6\u80fd\u5426\u7528\u6765\u89e3\u91ca\u6a21\u578b\u5185\u90e8\u7684\u60c5\u611f\u5206\u7c7b\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u8ba4\u77e5\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u591a\u6837\u5316\u7684\u63a8\u7406\u6a21\u5f0f\u3002\u57fa\u4e8eCoRE\u57fa\u51c6\u7684\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u60c5\u611f\u63a8\u7406\u65f6\u9690\u542b\u7684\u8ba4\u77e5\u7ed3\u6784\uff0c\u5bf9\u60c5\u611f\u7406\u89e3\u7684\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u89c6\u89d2\u3002", "conclusion": "\u672c\u5de5\u4f5c\u5b9e\u73b0\u4e86\u60c5\u611f\u4efb\u52a1\u4ece\u8868\u5c42\u8bc6\u522b\u5411\u6df1\u5c42\u8ba4\u77e5\u63a8\u7406\u7684\u62d3\u5c55\uff0c\u6784\u5efa\u4e86\u53ef\u516c\u5f00\u83b7\u53d6\u7684\u60c5\u611f\u8ba4\u77e5\u63a8\u7406\u57fa\u51c6\uff08CoRE\uff09\uff0c\u4e3a\u672a\u6765AI\u60c5\u611f\u63a8\u7406\u673a\u5236\u7814\u7a76\u63d0\u4f9b\u8bc4\u6d4b\u5e73\u53f0\uff0c\u5e76\u4e30\u5bcc\u4e86\u5bf9\u5927\u6a21\u578b\u60c5\u611f\u80fd\u529b\u7684\u7406\u89e3\u3002"}}
{"id": "2508.06017", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06017", "abs": "https://arxiv.org/abs/2508.06017", "authors": ["Xiangzhe Xu", "Shiwei Feng", "Zian Su", "Chengpeng Wang", "Xiangyu Zhang"], "title": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "comment": "The first two authors contributed equally to this work", "summary": "Intelligent coding systems are transforming software development by enabling\nusers to specify code behavior in natural language. However, the opaque\ndecision-making of AI-driven coders raises trust and usability concerns,\nparticularly for non-expert users who cannot inspect low-level implementations.\nWe argue that these systems should not only generate code but also produce\nclear, consistent justifications that bridge model reasoning and user\nunderstanding. To this end, we identify two critical justification\nproperties-cognitive alignment and semantic faithfulness-and highlight the\nlimitations of existing methods, including formal verification, static\nanalysis, and post-hoc explainability. We advocate exploring neuro-symbolic\napproaches for justification generation, where symbolic constraints guide model\nbehavior during training and program semantics are enriched through neural\nrepresentations, enabling automated consistency checks at inference time.", "AI": {"tldr": "\u73b0\u72b6\uff1aAI\u7f16\u7a0b\u7cfb\u7edf\u4e0d\u900f\u660e\uff1b\u95ee\u9898\uff1a\u7528\u6237\u96be\u4fe1\u4efb\u4e0e\u7406\u89e3\uff1b\u65b9\u6cd5\uff1a\u795e\u7ecf\u7b26\u53f7\u7406\u7531\u751f\u6210\uff1b\u4ef7\u503c\uff1a\u63d0\u5347\u7406\u7531\u89e3\u91ca\u6027\u4e0e\u7528\u6237\u4fe1\u4efb\u3002", "motivation": "AI\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\u6b63\u5728\u6539\u53d8\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\uff0c\u4f46\u5176\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u5c24\u5176\u8ba9\u975e\u4e13\u5bb6\u7528\u6237\u96be\u4ee5\u4fe1\u4efb\u548c\u7406\u89e3\u751f\u6210\u7684\u4ee3\u7801\u3002\u5f53\u524d\u7528\u6237\u96be\u4ee5\u68c0\u67e5\u5e95\u5c42\u5b9e\u73b0\uff0c\u56e0\u6b64\u4e9f\u9700\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u7528\u6027\u3002", "method": "\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u5982\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3001\u9759\u6001\u5206\u6790\u548c\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u5b58\u5728\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u5229\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u751f\u6210\u7406\u7531\u8bf4\u660e\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7b26\u53f7\u7ea6\u675f\u6765\u6307\u5bfc\u6a21\u578b\uff0c\u540c\u65f6\u7528\u795e\u7ecf\u8868\u793a\u4e30\u5bcc\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4ece\u800c\u5728\u63a8\u7406\u9636\u6bb5\u81ea\u52a8\u8fdb\u884c\u4e00\u81f4\u6027\u68c0\u67e5\u3002", "result": "\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u6709\u6f5c\u529b\u751f\u6210\u66f4\u6e05\u6670\u3001\u4e00\u81f4\u7684\u53ef\u89e3\u91ca\u7406\u7531\uff0c\u63d0\u5347\u6a21\u578b\u63a8\u7406\u4e0e\u7528\u6237\u7406\u89e3\u4e4b\u95f4\u7684\u6865\u6881\u6548\u679c\u3002", "conclusion": "\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\u9664\u4e86\u751f\u6210\u4ee3\u7801\u5916\uff0c\u8fd8\u9700\u63d0\u4f9b\u8ba4\u77e5\u5bf9\u9f50\u548c\u8bed\u4e49\u5fe0\u5b9e\u7684\u7406\u7531\u8bf4\u660e\u3002\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u662f\u5b9e\u73b0\u81ea\u52a8\u5316\u7406\u7531\u751f\u6210\u548c\u4e00\u81f4\u6027\u68c0\u67e5\u7684\u6709\u6548\u9014\u5f84\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u7528\u6237\u4fe1\u4efb\u4e0e\u7cfb\u7edf\u53ef\u7528\u6027\u3002"}}
{"id": "2508.05909", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05909", "abs": "https://arxiv.org/abs/2508.05909", "authors": ["Zhanghao Hu", "Qinglin Zhu", "Siya Qi", "Yulan He", "Hanqi Yan", "Lin Gui"], "title": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation", "comment": null, "summary": "Large Language Models (LLMs) have shown improved generation performance\nthrough retrieval-augmented generation (RAG) following the retriever-reader\nparadigm, which supplements model inputs with externally retrieved knowledge.\nHowever, prior work often evaluates RAG holistically, assessing the retriever\nand reader jointly, making it difficult to isolate the true contribution of\nretrieval, particularly given the prompt sensitivity of LLMs used as readers.\nWe introduce Spectrum Projection Score (SPS), a lightweight, supervision-free\nmetric that allows the reader to gauge the semantic alignment of a retrieved\nsummary with its hidden representation by comparing the area formed by\ngenerated tokens from the summary, and the principal directions of subspace in\nthe reader and to measure the relevance. Building on SPS we present xCompress,\nan inference time controller framework that dynamically samples, ranks, and\ncompresses retrieval summary candidates. Extensive experiments on five QA\nbenchmarks with four open source LLMs show that SPS not only enhances\nperformance across a range of tasks but also provides a principled perspective\non the interaction between retrieval and generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u53ef\u5206\u79bb\u5206\u6790\u68c0\u7d22\u4e0e\u751f\u6210\u534f\u540c\u7684\u65b0\u65b9\u6cd5SPS\uff0c\u5e76\u8bbe\u8ba1\u4e86\u63d0\u5347\u6027\u80fd\u7684\u63a7\u5236\u6846\u67b6xCompress\uff0c\u7ecf\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u53ca\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684RAG\u65b9\u6cd5\u8bc4\u4f30\u6574\u5408\u4e86\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\uff0c\u96be\u4ee5\u5355\u72ec\u8861\u91cf\u68c0\u7d22\u73af\u8282\u7684\u4f5c\u7528\uff0c\u4e14LLMs\u4f5c\u4e3a\u751f\u6210\u5668\u5b58\u5728\u63d0\u793a\u654f\u611f\u6027\uff0c\u5bfc\u81f4\u8d21\u732e\u4e0d\u6613\u533a\u5206\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u65b9\u6cd5Spectrum Projection Score (SPS)\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u5730\u6bd4\u8f83\u751f\u6210token\u548c\u751f\u6210\u5668\uff08reader\uff09\u9690\u7a7a\u95f4\u7684\u4e3b\u65b9\u5411\uff0c\u5b9e\u73b0\u8861\u91cf\u68c0\u7d22\u6458\u8981\u4e0eLLM\u5185\u90e8\u8bed\u4e49\u7684\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u57fa\u4e8eSPS\u63d0\u51faxCompress\u6846\u67b6\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u52a8\u6001\u91c7\u6837\u3001\u6392\u5e8f\u548c\u538b\u7f29\u68c0\u7d22\u6458\u8981\u5019\u9009\u3002", "result": "\u5728\u4e94\u4e2aQA\u57fa\u51c6\u4e0e\u56db\u79cd\u5f00\u6e90LLM\u4e0a\u5b9e\u9a8c\uff0cSPS\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff1b\u540c\u65f6SPS\u4e3aRAG\u4e24\u73af\u8282\uff08\u68c0\u7d22\u4e0e\u751f\u6210\uff09\u5173\u7cfb\u63d0\u4f9b\u4e86\u7406\u8bba\u89c6\u89d2\u3002", "conclusion": "SPS\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u3001\u65e0\u76d1\u7763\u7684\u65b0\u6307\u6807\uff0c\u6709\u6548\u523b\u753b\u4e86\u68c0\u7d22\u5185\u5bb9\u548c\u751f\u6210\u6548\u679c\u7684\u5173\u8054\u6027\uff0c\u5e76\u901a\u8fc7xCompress\u63d0\u5347\u4e86RAG\u6574\u4f53\u8868\u73b0\uff0c\u5bf9LLM\u751f\u6210\u548c\u68c0\u7d22\u534f\u540c\u5177\u6709\u7406\u8bba\u4e0e\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2508.06192", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06192", "abs": "https://arxiv.org/abs/2508.06192", "authors": ["Lantian Li", "Yuyu Chen", "Jingwen Wu", "Yue Pan", "Zhongxing Yu"], "title": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts", "comment": "31 pages, 11 figures", "summary": "Smart contracts enable contract terms to be automatically executed and\nverified on the blockchain, and recent years have witnessed numerous\napplications of them in areas such as financial institutions and supply chains.\nThe execution logic of a smart contract is closely related to the contract\nstate, and thus the correct and safe execution of the contract depends heavily\non the precise control and update of the contract state. However, the contract\nstate update process can have issues. In particular, inconsistent state update\nissues can arise for reasons such as unsynchronized modifications. Inconsistent\nstate update bugs have been exploited by attackers many times, but existing\ndetection tools still have difficulty in effectively identifying them. This\npaper conducts the first large-scale empirical study about inconsistent state\nupdate vulnerabilities (that is, inconsistent state update bugs that are\nexploitable) in smart contracts, aiming to shed light for developers,\nresearchers, tool builders, and language or library designers in order to avoid\ninconsistent state update vulnerabilities. We systematically investigate 116\ninconsistent state update vulnerabilities in 352 real-world smart contract\nprojects, summarizing their root causes, fix strategies, and exploitation\nmethods. Our study provides 11 original and important findings, and we also\ngive the implications of our findings. To illustrate the potential benefits of\nour research, we also develop a proof-of-concept checker based on one of our\nfindings. The checker effectively detects issues in 64 popular GitHub projects,\nand 19 project owners have confirmed the detected issues at the time of\nwriting. The result demonstrates the usefulness and importance of our findings\nfor avoiding inconsistent state update vulnerabilities in smart contracts.", "AI": {"tldr": "\u672c\u8bba\u6587\u9996\u6b21\u5bf9\u667a\u80fd\u5408\u7ea6\u72b6\u6001\u4e0d\u4e00\u81f4\u6027\u6f0f\u6d1e\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u5f52\u7eb3\u6210\u56e0\u4e0e\u4fee\u590d\u65b9\u6cd5\uff0c\u603b\u7ed311\u6761\u91cd\u8981\u53d1\u73b0\uff0c\u5e76\u5f00\u53d1\u68c0\u6d4b\u5de5\u5177\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5bf9\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u5177\u6709\u5b9e\u9645\u6307\u5bfc\u610f\u4e49\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u5408\u7ea6\u5728\u91d1\u878d\u3001\u4f9b\u5e94\u94fe\u7b49\u9886\u57df\u5e94\u7528\u7684\u589e\u52a0\uff0c\u5408\u7ea6\u72b6\u6001\u7684\u6b63\u786e\u540c\u6b65\u6210\u4e3a\u5408\u7ea6\u5b89\u5168\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u667a\u80fd\u5408\u7ea6\u7684\u72b6\u6001\u66f4\u65b0\u5b58\u5728\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u653b\u51fb\u8005\u4e5f\u591a\u6b21\u5229\u7528\u6b64\u7c7b\u6f0f\u6d1e\uff0c\u76ee\u524d\u4e3b\u6d41\u5de5\u5177\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u6b64\u7c7b\u95ee\u9898\u3002\u4f5c\u8005\u56e0\u6b64\u9488\u5bf9\u667a\u80fd\u5408\u7ea6\u72b6\u6001\u4e0d\u4e00\u81f4\u6027\u6f0f\u6d1e\u5c55\u5f00\u7814\u7a76\uff0c\u4ee5\u671f\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u4f5c\u8005\u5bf9352\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u667a\u80fd\u5408\u7ea6\u9879\u76ee\u4e2d116\u4e2a\u72b6\u6001\u4e0d\u4e00\u81f4\u6027\u6f0f\u6d1e\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u6f0f\u6d1e\u6210\u56e0\u3001\u4fee\u590d\u7b56\u7565\u548c\u5229\u7528\u65b9\u6cd5\uff0c\u5e76\u603b\u7ed3\u51fa11\u6761\u91cd\u8981\u53d1\u73b0\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u5176\u4e2d\u4e00\u9879\u53d1\u73b0\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u68c0\u6d4b\u5668\u5e76\u5bf9GitHub\u4e0a\u768464\u4e2a\u9879\u76ee\u8fdb\u884c\u68c0\u6d4b\u3002", "result": "\u63d0\u51fa\u4e8611\u9879\u5173\u4e8e\u667a\u80fd\u5408\u7ea6\u72b6\u6001\u4e0d\u4e00\u81f4\u6027\u6f0f\u6d1e\u7684\u539f\u521b\u4e14\u91cd\u8981\u7684\u53d1\u73b0\uff0c\u5f00\u53d1\u7684\u68c0\u6d4b\u5668\u6210\u529f\u572864\u4e2a\u70ed\u95e8GitHub\u9879\u76ee\u4e2d\u68c0\u6d4b\u5230\u95ee\u9898\uff0c\u5176\u4e2d19\u4e2a\u9879\u76ee\u7684\u6240\u6709\u8005\u5df2\u786e\u8ba4\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u6df1\u5165\u63ed\u793a\u4e86\u667a\u80fd\u5408\u7ea6\u72b6\u6001\u4e0d\u4e00\u81f4\u6027\u6f0f\u6d1e\u7684\u6839\u672c\u539f\u56e0\u4e0e\u4fee\u590d\u601d\u8def\uff0c\u540c\u65f6\u901a\u8fc7\u5b9e\u9645\u68c0\u6d4b\u5de5\u5177\u9a8c\u8bc1\u4e86\u7814\u7a76\u6210\u679c\u7684\u6709\u6548\u6027\uff0c\u5bf9\u5f00\u53d1\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u5de5\u5177\u5f00\u53d1\u8005\u6709\u91cd\u8981\u6307\u5bfc\u4ef7\u503c\u3002"}}
{"id": "2508.05938", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; K.4"], "pdf": "https://arxiv.org/pdf/2508.05938", "abs": "https://arxiv.org/abs/2508.05938", "authors": ["Rafal Kocielnik", "Min Kim", "Penphob", "Boonyarungsrit", "Fereshteh Soltani", "Deshawn Sambrano", "Animashree Anandkumar", "R. Michael Alvarez"], "title": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale", "comment": "9 pages, 4 figures, 4 tables", "summary": "Detecting prosociality in text--communication intended to affirm, support, or\nimprove others' behavior--is a novel and increasingly important challenge for\ntrust and safety systems. Unlike toxic content detection, prosociality lacks\nwell-established definitions and labeled data, requiring new approaches to both\nannotation and deployment. We present a practical, three-stage pipeline that\nenables scalable, high-precision prosocial content classification while\nminimizing human labeling effort and inference costs. First, we identify the\nbest LLM-based labeling strategy using a small seed set of human-labeled\nexamples. We then introduce a human-AI refinement loop, where annotators review\nhigh-disagreement cases between GPT-4 and humans to iteratively clarify and\nexpand the task definition-a critical step for emerging annotation tasks like\nprosociality. This process results in improved label quality and definition\nalignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train\na two-stage inference system: a lightweight classifier handles high-confidence\npredictions, while only $\\sim$35\\% of ambiguous instances are escalated to\nGPT-4o. This architecture reduces inference costs by $\\sim$70% while achieving\nhigh precision ($\\sim$0.90). Our pipeline demonstrates how targeted human-AI\ninteraction, careful task formulation, and deployment-aware architecture design\ncan unlock scalable solutions for novel responsible AI tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6df7\u5408\u4eba\u673a\u6d41\u7a0b\uff0c\u7528\u4e8e\u9ad8\u6548\u7cbe\u51c6\u5730\u8bc6\u522b\u6587\u672c\u4e2d\u7684\u4eb2\u793e\u4f1a\u5185\u5bb9\uff0c\u663e\u8457\u51cf\u5c11\u6807\u6ce8\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u53ef\u4e3aAI\u4fe1\u4efb\u4e0e\u5b89\u5168\u65b0\u4efb\u52a1\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u6587\u672c\u4e2d\u4eb2\u793e\u4f1a\u6027\uff08\u5373\u65e8\u5728\u80af\u5b9a\u3001\u652f\u6301\u6216\u6539\u5584\u4ed6\u4eba\u884c\u4e3a\u7684\u4ea4\u6d41\uff09\u68c0\u6d4b\u8d8a\u6765\u8d8a\u53d7\u5230\u4fe1\u4efb\u4e0e\u5b89\u5168\u7cfb\u7edf\u7684\u91cd\u89c6\uff0c\u4f46\u76f8\u6bd4\u6709\u6bd2\u5185\u5bb9\u68c0\u6d4b\uff0c\u4eb2\u793e\u4f1a\u6027\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\u548c\u6807\u6ce8\u6570\u636e\uff0c\u4e9f\u9700\u65b0\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u81ea\u52a8\u68c0\u6d4b\u4e0e\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u9645\u7684\u4e09\u9636\u6bb5\u6d41\u7a0b\u3002\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u5c11\u91cf\u4eba\u5de5\u6807\u6ce8\u6570\u636e\uff0c\u9009\u62e9\u6700\u4f73\u7684\u57fa\u4e8e\u5927\u6a21\u578bLLM\u7684\u6807\u6ce8\u7b56\u7565\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u4eba\u673a\u4e92\u52a8\u4fee\u6b63\u6d41\u7a0b\uff0c\u8ba9\u6807\u6ce8\u8005\u9488\u5bf9GPT-4\u548c\u4eba\u5de5\u5224\u65ad\u5206\u6b67\u5927\u7684\u6837\u672c\u8fdb\u884c\u590d\u5ba1\uff0c\u8fed\u4ee3\u5b8c\u5584\u4efb\u52a1\u5b9a\u4e49\u548c\u6807\u51c6\uff1b\u7b2c\u4e09\u9636\u6bb5\u4f7f\u7528GPT-4\u751f\u6210\u9ad8\u8d28\u91cf\u5927\u89c4\u6a21\u6807\u6ce8\uff081\u4e07\u6761\uff09\uff0c\u5e76\u8bad\u7ec3\u4e24\u9636\u6bb5\u63a8\u7406\u7cfb\u7edf\uff1a\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u8d1f\u8d23\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\uff0c\u7ea635%\u7684\u6a21\u7cca\u5b9e\u4f8b\u4ea4\u7531GPT-4o\u5904\u7406\u3002", "result": "\u5728\u4eba\u529b\u6807\u6ce8\u6295\u5165\u548c\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u6700\u5c0f\u5316\u7684\u524d\u63d0\u4e0b\uff0c\u7cfb\u7edf\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\uff08\u7ea60.90\uff09\u4eb2\u793e\u4f1a\u6027\u5185\u5bb9\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u5408\u7406\u7684\u7cfb\u7edf\u8bbe\u8ba1\u5c06\u63a8\u7406\u6210\u672c\u964d\u4f4e\u7ea670%\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u6709\u9488\u5bf9\u6027\u7684\u4eba\u673a\u534f\u4f5c\u3001\u9ad8\u8d28\u91cf\u4efb\u52a1\u5b9a\u4e49\u548c\u9762\u5411\u5b9e\u9645\u90e8\u7f72\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u80fd\u591f\u63a8\u52a8\u4eb2\u793e\u4f1a\u6027\u7b49\u65b0\u5174\u8d1f\u8d23\u4efbAI\u4efb\u52a1\u5b9e\u73b0\u89c4\u6a21\u5316\u3001\u4f4e\u6210\u672c\u3001\u9ad8\u7cbe\u5ea6\u843d\u5730\u3002"}}
{"id": "2508.06299", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06299", "abs": "https://arxiv.org/abs/2508.06299", "authors": ["Henrique Henriques", "Hugo Louren\u00e7o", "Vasco Amaral", "Miguel Goul\u00e3o"], "title": "Improving the Developer Experience with a Low-Code Process Modelling Language", "comment": "Preprint", "summary": "Context: The OutSystems Platform is a development environment composed of\nseveral DSLs, used to specify, quickly build, and validate web and mobile\napplications. The DSLs allow users to model different perspectives such as\ninterfaces and data models, define custom business logic and construct process\nmodels. Problem: The DSL for process modelling (Business Process Technology\n(BPT)), has a low adoption rate and is perceived as having usability problems\nhampering its adoption. This is problematic given the language maintenance\ncosts. Method: We used a combination of interviews, a critical review of BPT\nusing the \"Physics of Notation\" and empirical evaluations of BPT using the\nSystem Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a\nnew version of BPT, taking these inputs and Outsystems' engineers' culture into\naccount. Results: Evaluations conducted with 25 professional software engineers\nshowed an increase of the semantic transparency on the new version, from 31% to\n69%, an increase in the correctness of responses, from 51% to 89%, an increase\nin the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from\n36.50 to 20.78. These differences were statistically significant. Conclusions:\nThese results suggest that the new version of BPT significantly improved the\ndeveloper experience of the previous version. The end users' background with\nOutSystems had a relevant impact on the final concrete syntax choices and\nachieved usability indicators.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc6\u522b\u4e14\u89e3\u51b3\u4e86OutSystems\u5e73\u53f0BPT\u7684\u53ef\u7528\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u7cfb\u7edf\u65b9\u6cd5\u6539\u8fdb\u540e\uff0c\u5728\u5f00\u53d1\u8005\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6613\u7528\u6027\u548c\u6548\u7387\u3002", "motivation": "OutSystems\u5e73\u53f0\u4e2d\u7684\u6d41\u7a0b\u5efa\u6a21DSL\uff08BPT\uff09\u4f7f\u7528\u7387\u4f4e\uff0c\u88ab\u8ba4\u4e3a\u5b58\u5728\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5f71\u54cd\u63a8\u5e7f\uff0c\u540c\u65f6\u9020\u6210\u7ef4\u62a4\u6210\u672c\u589e\u52a0\u3002", "method": "\u91c7\u7528\u8bbf\u8c08\u3001\u5bf9BPT\u8fdb\u884c\u201c\u7b26\u53f7\u7269\u7406\u5b66\u201d\u6279\u5224\u6027\u8bc4\u5ba1\uff0c\u4ee5\u53ca\u57fa\u4e8eSUS\u548cTLX\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u7ed3\u5408\u5e73\u53f0\u5f00\u53d1\u8005\u6587\u5316\uff0c\u5f00\u53d1\u65b0\u7248BPT\u3002", "result": "\u65b0\u7248BPT\u572825\u540d\u4e13\u4e1a\u5f00\u53d1\u8005\u4e2d\uff0c\u8bed\u4e49\u900f\u660e\u5ea6\u63d0\u5347\uff0831%\u219269%\uff09\uff0c\u7b54\u9898\u6b63\u786e\u7387\u63d0\u5347\uff0851%\u219289%\uff09\uff0cSUS\u5f97\u5206\u63d0\u5347\uff0842.25\u219264.78\uff09\uff0cTLX\u5f97\u5206\u4e0b\u964d\uff0836.50\u219220.78\uff09\uff0c\u5747\u5177\u7edf\u8ba1\u5b66\u610f\u4e49\u3002", "conclusion": "\u65b0\u7248BPT\u663e\u8457\u6539\u5584\u4e86\u5f00\u53d1\u8005\u4f53\u9a8c\uff0c\u7528\u6237\u80cc\u666f\u5bf9\u5177\u4f53\u8bed\u6cd5\u8bbe\u8ba1\u4e0e\u53ef\u7528\u6027\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2508.05987", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.05987", "abs": "https://arxiv.org/abs/2508.05987", "authors": ["Chunyun Zhang", "Hongyan Zhao", "Chaoran Cui", "Qilong Song", "Zhiqing Lu", "Shuai Gong", "Kailin Liu"], "title": "Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring", "comment": null, "summary": "Cross-topic automated essay scoring (AES) aims to develop a transferable\nmodel capable of effectively evaluating essays on a target topic. A significant\nchallenge in this domain arises from the inherent discrepancies between topics.\nWhile existing methods predominantly focus on extracting topic-shared features\nthrough distribution alignment of source and target topics, they often neglect\ntopic-specific features, limiting their ability to assess critical traits such\nas topic adherence. To address this limitation, we propose an Adversarial\nTOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns\ntopic-shared and topic-specific features to improve cross-topic AES. ATOP\nachieves this by optimizing a learnable topic-aware prompt--comprising both\nshared and specific components--to elicit relevant knowledge from pre-trained\nlanguage models (PLMs). To enhance the robustness of topic-shared prompt\nlearning and mitigate feature scale sensitivity introduced by topic alignment,\nwe incorporate adversarial training within a unified regression and\nclassification framework. In addition, we employ a neighbor-based classifier to\nmodel the local structure of essay representations and generate pseudo-labels\nfor target-topic essays. These pseudo-labels are then used to guide the\nsupervised learning of topic-specific prompts tailored to the target topic.\nExtensive experiments on the publicly available ASAP++ dataset demonstrate that\nATOP significantly outperforms existing state-of-the-art methods in both\nholistic and multi-trait essay scoring. The implementation of our method is\npublicly available at: https://anonymous.4open.science/r/ATOP-A271.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u63d0\u51fa\u65b0\u7684\u5bf9\u6297\u6027\u4e3b\u9898\u611f\u77e5Prompt\u8c03\u4f18\u65b9\u6cd5\uff08ATOP\uff09\uff0c\u9996\u6b21\u8054\u5408\u5b66\u4e60\u4e3b\u9898\u5171\u4eab\u4e0e\u7279\u6709\u7279\u5f81\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8de8\u4e3b\u9898\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u51c6\u786e\u6027\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u8de8\u4e3b\u9898\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\uff08AES\uff09\u6a21\u578b\u5728\u76ee\u6807\u4e3b\u9898\u4e0b\u6709\u8f6c\u79fb\u80fd\u529b\uff0c\u4f46\u4e0d\u540c\u4e3b\u9898\u95f4\u5b58\u5728\u56fa\u6709\u5206\u5e03\u5dee\u5f02\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u5173\u6ce8\u4e8e\u4e3b\u9898\u95f4\u7684\u5171\u540c\u7279\u5f81\u62bd\u53d6\uff0c\u5ffd\u7565\u4e86\u5bf9\u4e3b\u9898\u7279\u6709\u7279\u5f81\u7684\u6316\u6398\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u5bf9\u4e3b\u9898\u76f8\u5173\u6027\u7b49\u91cd\u8981\u6307\u6807\u7684\u8bc4\u4f30\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u6027\u4e3b\u9898\u611f\u77e5Prompt\u8c03\u4f18\u65b9\u6cd5\uff08ATOP\uff09\uff0c\u8054\u5408\u5b66\u4e60\u4e3b\u9898\u5171\u4eab\u4e0e\u7279\u6709\u7279\u5f81\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53ef\u5b66\u4e60\u7684\u4e3b\u9898\u611f\u77e5Prompt\uff08\u5305\u62ec\u5171\u4eab\u4e0e\u7279\u5b9a\u7ec4\u4ef6\uff09\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5bf9\u77e5\u8bc6\u8fdb\u884c\u5f15\u51fa\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u63d0\u5347\u5171\u4eabPrompt\u7684\u9c81\u68d2\u6027\uff0c\u7edf\u4e00\u56de\u5f52\u548c\u5206\u7c7b\u4efb\u52a1\u3002\u8fd8\u91c7\u7528\u90bb\u57df\u5206\u7c7b\u5668\u9488\u5bf9\u76ee\u6807\u4e3b\u9898\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u7528\u4e8e\u6307\u5bfc\u7279\u6709Prompt\u7684\u6709\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728ASAP++\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cATOP\u5728\u6574\u4f53\u548c\u591a\u7279\u5f81\u4f5c\u6587\u8bc4\u5206\u6307\u6807\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684ATOP\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8de8\u4e3b\u9898\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u517c\u987e\u4e3b\u9898\u5171\u540c\u4e0e\u7279\u6709\u7279\u5f81\u3002"}}
{"id": "2508.06365", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06365", "abs": "https://arxiv.org/abs/2508.06365", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Execution-Feedback Driven Test Generation from SWE Issues", "comment": null, "summary": "A software engineering issue (SWE issue) is easier to resolve when\naccompanied by a reproduction test. Unfortunately, most issues do not come with\nfunctioning reproduction tests, so this paper explores how to generate them\nautomatically. The primary challenge in this setting is that the code to be\ntested is either missing or wrong, as evidenced by the existence of the issue\nin the first place. This has held back test generation for this setting:\nwithout the correct code to execute, it is difficult to leverage execution\nfeedback to generate good tests. This paper introduces novel techniques for\nleveraging execution feedback to get around this problem, implemented in a new\nreproduction test generator called e-Otter++. Experiments show that e-Otter++\nrepresents a leap ahead in the state-of-the-art for this problem, generating\ntests with an average fail-to-pass rate of 63% on the TDD-Bench Verified\nbenchmark.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86e-Otter++\uff0c\u9996\u6b21\u5728\u4ee3\u7801\u5b58\u5728\u9519\u8bef\u65f6\u6709\u6548\u751f\u6210\u590d\u73b0\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u53d6\u5f97\u4e8663% fail-to-pass\u7684\u4f18\u79c0\u7ed3\u679c\uff0c\u63d0\u5347\u4e86\u8f6f\u4ef6\u7f3a\u9677\u5b9a\u4f4d\u4e0e\u4fee\u590d\u7684\u81ea\u52a8\u5316\u80fd\u529b\u3002", "motivation": "\u591a\u6570\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u62a5\u544a\u6ca1\u6709\u914d\u5957\u7684\u53ef\u6267\u884c\u590d\u73b0\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5bfc\u81f4\u95ee\u9898\u96be\u4ee5\u6709\u6548\u590d\u73b0\u548c\u89e3\u51b3\u3002\u73b0\u6709\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7684\u6280\u672f\u96be\u4ee5\u5e94\u5bf9\u76ee\u6807\u4ee3\u7801\u6709\u9519\u8bef\u6216\u7f3a\u5931\u7684\u573a\u666f\uff0c\u56e0\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u5728\u4ee3\u7801\u4e0d\u6b63\u786e\u65f6\u81ea\u52a8\u751f\u6210\u9ad8\u6548\u7684\u590d\u73b0\u6d4b\u8bd5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5229\u7528\u6267\u884c\u53cd\u9988\u751f\u6210\u590d\u73b0\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u81ea\u52a8\u590d\u73b0\u6d4b\u8bd5\u751f\u6210\u5668e-Otter++\u3002\u8be5\u65b9\u6cd5\u80fd\u5728\u76ee\u6807\u4ee3\u7801\u7f3a\u5931\u6216\u9519\u8bef\u7684\u60c5\u51b5\u4e0b\uff0c\u4f9d\u7136\u751f\u6210\u6709\u6548\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "e-Otter++\u5728TDD-Bench Verified\u57fa\u51c6\u96c6\u4e0a\u6d4b\u8bd5\u751f\u6210\u7684\u7528\u4f8b\u4e2d\uff0c\u5e73\u5747fail-to-pass\u7387\u9ad8\u8fbe63%\uff0c\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\uff0ce-Otter++\u5b9e\u73b0\u4e86\u5728\u4ee3\u7801\u6709\u7f3a\u9677\u65f6\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u590d\u73b0\u6d4b\u8bd5\u7684\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u6280\u672f\u8fdb\u6b65\u3002"}}
{"id": "2508.06016", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06016", "abs": "https://arxiv.org/abs/2508.06016", "authors": ["Sagar Gandhi", "Vishal Gandhi"], "title": "Crisp Attention: Regularizing Transformers via Structured Sparsity", "comment": null, "summary": "The quadratic computational cost of the self-attention mechanism is a primary\nchallenge in scaling Transformer models. While attention sparsity is widely\nstudied as a technique to improve computational efficiency, it is almost\nuniversally assumed to come at the cost of model accuracy. In this paper, we\nreport a surprising counter-example to this common wisdom. By introducing\nstructured, post-hoc sparsity to the attention mechanism of a DistilBERT model\nduring fine-tuning on the SST-2 sentiment analysis task, we find that model\naccuracy improves significantly. Our model with 80\\% attention sparsity\nachieves a validation accuracy of 91.59\\%, a 0.97\\% absolute improvement over\nthe dense baseline. We hypothesize that this phenomenon is due to sparsity\nacting as a powerful implicit regularizer, preventing the model from\noverfitting by forcing it to make predictions with a more constrained and\nrobust set of features. Our work recasts attention sparsity not just as a tool\nfor computational efficiency, but as a potential method for improving the\ngeneralization and performance of Transformer models.", "AI": {"tldr": "\u901a\u8fc7\u5728\u5fae\u8c03\u65f6\u7ed9DistilBERT\u5f15\u5165\u6ce8\u610f\u529b\u7a00\u758f\uff0c\u4f5c\u8005\u53d1\u73b0\u6a21\u578b\u7cbe\u5ea6\u4e0d\u4ec5\u6ca1\u4e0b\u964d\uff0c\u53cd\u800c\u63d0\u5347\uff0c\u7a00\u758f\u6ce8\u610f\u529b\u8fd8\u53ef\u80fd\u6539\u5584\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8ba1\u7b97\u6210\u672c\u9650\u5236\u4e86Transformer\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u3002\u867d\u7136\u5f15\u5165\u6ce8\u610f\u529b\u7a00\u758f\u6027\u53ef\u4ee5\u63d0\u5347\u6548\u7387\uff0c\u4f46\u901a\u5e38\u8ba4\u4e3a\u8fd9\u4f1a\u635f\u5bb3\u6a21\u578b\u7cbe\u5ea6\u3002\u4f5c\u8005\u5e0c\u671b\u9a8c\u8bc1\u8fd9\u79cd\u5047\u8bbe\u662f\u5426\u4e00\u5b9a\u6210\u7acb\u3002", "method": "\u5728DistilBERT\u6a21\u578b\u4e0a\uff0c\u901a\u8fc7\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\uff08SST-2\u6570\u636e\u96c6\uff09\u5fae\u8c03\u9636\u6bb5\u540e\u5904\u7406\u5f15\u5165\u7ed3\u6784\u5316\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u6a21\u578b\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u5f53\u6ce8\u610f\u529b\u7a00\u758f\u5ea6\u8fbe\u523080%\u65f6\uff0c\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u523091.59%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u7a20\u5bc6\u57fa\u7ebf\u6a21\u578b\u9ad80.97%\u3002", "conclusion": "\u6ce8\u610f\u529b\u7a00\u758f\u6027\u4e0d\u4ec5\u80fd\u5e26\u6765\u8ba1\u7b97\u6548\u7387\uff0c\u6709\u65f6\u8fd8\u53ef\u80fd\u4f5c\u4e3a\u9690\u5f0f\u6b63\u5219\u5316\u5668\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002"}}
{"id": "2508.06414", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06414", "abs": "https://arxiv.org/abs/2508.06414", "authors": ["Dongze Li", "Songqiang Chen", "Jialun Cao", "Shing-Chi Cheung"], "title": "What Builds Effective In-Context Examples for Code Generation?", "comment": null, "summary": "In-Context Learning (ICL) has emerged as a promising solution to enhance the\ncode generation capabilities of Large Language Models (LLMs), which\nincorporates code examples inside the prompt to let LLMs learn from\ndemonstrations. However, despite the substantial effectiveness of the code\nexample-based ICL approach, the specific features (e.g., identifier naming\nstyles, code formatting, solution insight) within the ICL-provided code\nexamples that significantly contribute to the ICL's effectiveness remain\nunclear. This paper systematically investigates the impact of various code\nfeatures on ICL with code examples through controlled ablation studies. Our\nfindings reveal that the appropriate naming of variables and functions is\ncrucial for effective code generation, with their elimination leading to\nperformance decreases of up to 30 percentage points. We further demonstrate\nthat LLMs prioritize semantically meaningful identifier names over formatting\nconventions, with language-specific preferences regarding identifier verbosity.\nAdditionally, our investigation into ICL's potential for enhancing reflection\nand inference capabilities reveals that current LLMs struggle to extract\ngeneralizable problem-solving insights from similar code solutions, despite\nbeing capable of utilizing direct information effectively. These findings are\nexpected to provide valuable insights for optimizing ICL systems in code\ngeneration applications and highlight fundamental challenges in\nreflection-based learning for code generation tasks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u63ed\u793a\u53d8\u91cf/\u51fd\u6570\u547d\u540d\u89c4\u8303\u5bf9\u63d0\u5347\u5927\u6a21\u578b\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5173\u952e\uff0c\u6a21\u578b\u5728\u76f4\u63a5\u4fe1\u606f\u5229\u7528\u5f3a\u4f46\u53cd\u601d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e3aICL\u7cfb\u7edf\u4f18\u5316\u4e0e\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u4ee3\u7801\u793a\u4f8b\u9a71\u52a8\u7684ICL\u65b9\u6cd5\u6548\u679c\u663e\u8457\uff0c\u4f46\u5c1a\u672a\u660e\u786e\u54ea\u4e9b\u4ee3\u7801\u7279\u6027\u5bf9ICL\u8d21\u732e\u6700\u5927\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u8fdb\u884c\u7ec6\u81f4\u5206\u6790\u4ee5\u4f18\u5316ICL\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5bf9\u4ee3\u7801\u793a\u4f8b\u4e2d\u4e0d\u540c\u7279\u5f81\u8fdb\u884c\u63a7\u5236\u6d88\u878d\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u5206\u6790\u53d8\u91cf\u547d\u540d\u3001\u683c\u5f0f\u3001\u89e3\u51b3\u601d\u8def\u7b49\u5143\u7d20\u5bf9ICL\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u6d88\u9664\u6709\u610f\u4e49\u7684\u53d8\u91cf\u548c\u51fd\u6570\u547d\u540d\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u9ad8\u8fbe30\u4e2a\u767e\u5206\u70b9\uff0c\u6a21\u578b\u66f4\u91cd\u89c6\u8bed\u4e49\u6709\u610f\u4e49\u7684\u6807\u8bc6\u7b26\u800c\u975e\u4ee3\u7801\u683c\u5f0f\uff0c\u5e76\u5728\u501f\u52a9\u76f4\u63a5\u4fe1\u606f\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u63d0\u53d6\u901a\u7528\u89e3\u9898\u601d\u8def\uff08\u53cd\u601d\u4e0e\u63a8\u7406\uff09\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u53d8\u91cf\u548c\u51fd\u6570\u7684\u5408\u9002\u547d\u540d\u5bf9\u4ee3\u7801\u751f\u6210\u6548\u679c\u81f3\u5173\u91cd\u8981\uff0c\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u800c\u5f53\u524d\u5927\u6a21\u578b\u5bf9\u5229\u7528\u901a\u7528\u6027\u3001\u53cd\u601d\u6027\u4ee3\u7801\u4fe1\u606f\u5b58\u5728\u8f83\u5927\u6311\u6218\u3002"}}
{"id": "2508.06026", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06026", "abs": "https://arxiv.org/abs/2508.06026", "authors": ["Yidong Wang", "Xin Wang", "Cunxiang Wang", "Junfeng Fang", "Qiufeng Wang", "Jianing Chu", "Xuran Meng", "Shuxun Yang", "Libo Qin", "Yue Zhang", "Wei Ye", "Shikun Zhang"], "title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future", "comment": "12 pages, 5 figures", "summary": "Self-Rewarding Language Models propose an architecture in which the Large\nLanguage Models(LLMs) both generates responses and evaluates its own outputs\nvia LLM-as-a-Judge prompting, dynamically improving its generative capabilities\nthrough iterative Direct Preference Optimization (DPO). However, our analysis\nreveals a critical limitation in existing Self-Rewarding paradigms: the\nsynchronized improvement of chosen and rejected responses progressively narrows\nthe representational difference between contrasting samples, undermining\neffective preference learning. We propose \\textbf{Temporal Self-Rewarding\nLanguage Models} that strategically coordinate past, present, and future model\ngenerations to sustain learning signals. Our dual-phase framework introduces:\n(1) \\textit{Anchored Rejection} - fixing rejected responses using the past\ninitial model's outputs and (2) \\textit{Future-Guided Chosen} - dynamically\ncurating chosen samples using next-generation model predictions. Extensive\nexperiments across three model families (Llama, Qwen, Mistral) and different\nmodel sizes (Llama3B/8B/70B) demonstrate significant improvements when trained\nwith our method compared to Self-Rewarding using same computation resources.\nFor example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our\nmethod, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our\nmethod also demonstrates superior out-of-distribution generalization across\nmathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code\ngeneration (HumanEval) tasks, even though we do not specifically collect such\ntraining data.", "AI": {"tldr": "\u9488\u5bf9\u81ea\u6211\u5956\u52b1\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u4fe1\u53f7\u9010\u6e10\u6d88\u5931\u7684\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u5229\u7528\u8fc7\u53bb\u548c\u672a\u6765\u6a21\u578b\u8f93\u51fa\u5bf9\u6837\u672c\u8fdb\u884c\u951a\u5b9a\u4e0e\u9009\u62e9\u7684\u65b9\u6cd5\uff08\u65f6\u95f4\u81ea\u6211\u5956\u52b1\u6a21\u578b\uff09\uff0c\u5927\u5e45\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u548c\u4e3b\u6d41\u6a21\u578b\u4e0a\u8868\u73b0\u663e\u8457\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u6211\u5956\u52b1\u8bed\u8a00\u6a21\u578b\u5728\u4f18\u5316\u504f\u597d\u5b66\u4e60\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u968f\u7740\u6a21\u578b\u751f\u6210\u80fd\u529b\u7684\u540c\u6b65\u63d0\u5347\uff0c\u9009\u62e9\u7684\u548c\u62d2\u7edd\u7684\u6837\u672c\u95f4\u5dee\u5f02\u53d8\u5c0f\uff0c\u5bfc\u81f4\u504f\u597d\u4fe1\u53f7\u9010\u6e10\u6d88\u5931\uff0c\u5f71\u54cd\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u65f6\u95f4\u81ea\u6211\u5956\u52b1\u8bed\u8a00\u6a21\u578b\uff08Temporal Self-Rewarding Language Models\uff09\uff0c\u901a\u8fc7\u534f\u8c03\u6a21\u578b\u4ee3\u9645\uff08\u8fc7\u53bb\u3001\u73b0\u5728\u3001\u672a\u6765\uff09\u7684\u751f\u6210\u7ed3\u679c\uff0c\u6301\u7eed\u7ef4\u6301\u6709\u6548\u7684\u5b66\u4e60\u4fe1\u53f7\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\uff1a\uff081\uff09\u951a\u5b9a\u62d2\u7edd\uff08Anchored Rejection\uff09\uff1a\u7528\u8fc7\u53bb\u521d\u59cb\u6a21\u578b\u7684\u8f93\u51fa\u4f5c\u4e3a\u62d2\u7edd\u6837\u672c\uff1b\uff082\uff09\u672a\u6765\u5bfc\u5411\u9009\u62e9\uff08Future-Guided Chosen\uff09\uff1a\u7528\u4e0b\u4e00\u4ee3\u6a21\u578b\u52a8\u6001\u751f\u6210\u9009\u62e9\u6837\u672c\u3002", "result": "\u5728Llama\u3001Qwen\u3001Mistral\u4e09\u5927\u5bb6\u65cf\u548c\u4e0d\u540c\u89c4\u6a21\uff08Llama3B/8B/70B\uff09\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u5bf9\u6bd4\u540c\u6837\u8ba1\u7b97\u8d44\u6e90\u4e0b\u7684\u81ea\u6211\u5956\u52b1\u57fa\u7ebf\u3002\u4ee5Llama3.1-8B\u4e3a\u4f8b\uff0cAlpacaEval 2.0\u80dc\u7387\u63d0\u5347\u81f329.44\uff0c\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\u768419.69\u3002\u540c\u65f6\uff0c\u5728\u6570\u5b66\u63a8\u7406\uff08GSM8K\uff09\u3001\u77e5\u8bc6\u95ee\u7b54\uff08ARC\u3001TruthfulQA\uff09\u548c\u4ee3\u7801\u751f\u6210\uff08HumanEval\uff09\u7b49\u5206\u5e03\u5916\u4efb\u52a1\u4e2d\u4e5f\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u4e13\u95e8\u6536\u96c6\u8bad\u7ec3\u6570\u636e\u3002", "conclusion": "\u672c\u7814\u7a76\u9488\u5bf9\u81ea\u6211\u5956\u52b1\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u4fe1\u53f7\u8870\u51cf\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u65f6\u95f4\u81ea\u6211\u5956\u52b1\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.06030", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06030", "abs": "https://arxiv.org/abs/2508.06030", "authors": ["Kartik Sharma", "Yiqiao Jin", "Rakshit Trivedi", "Srijan Kumar"], "title": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings", "comment": null, "summary": "Large language models (LLMs) acquire knowledge across diverse domains such as\nscience, history, and geography encountered during generative pre-training.\nHowever, due to their stochasticity, it is difficult to predict what LLMs have\nacquired. Prior work has developed different ways to probe this knowledge by\ninvestigating the hidden representations, crafting specific task prompts,\ncurating representative samples, and estimating their uncertainty. However,\nthese methods require making forward passes through the underlying model to\nprobe the LLM's knowledge about a specific fact, making them computationally\nexpensive and time-consuming. To bridge this gap, we propose $\\textbf{PEEK}$ or\n$\\textbf{P}$roxy $\\textbf{E}$mbeddings to $\\textbf{E}$stimate\n$\\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models\nthat effectively encode factual knowledge as text or graphs as proxies for\nLLMs. First, we identify a training set of facts known by LLMs through various\nprobing strategies and then adapt embedding models to predict the LLM outputs\nwith a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived\ndatasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict\nLLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find\nthat sentence embedding models are more suitable than graph embeddings to\npredict LLM knowledge, shedding light on the underlying representation of the\nfactual landscape. Thus, we believe that knowledge-adapted embeddings can be\nused to identify knowledge gaps in LLMs at scale and can provide deeper\ninsights into LLMs' internal inductive bias. The code and data are made\navailable at https://github.com/claws-lab/peek.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u9884\u8bad\u7ec3\u6587\u672c\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3a\u4ee3\u7406\uff0c\u901a\u8fc7\u7b80\u5355\u5fae\u8c03\u5373\u53ef\u9ad8\u6548\u63a8\u65adLLM\u77e5\u8bc6\u5206\u5e03\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u9884\u6d4b\u51c6\u786e\u7387\u8fbe90%\u3002\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u77e5\u8bc6\u8bc4\u4f30\u548c\u5185\u90e8\u673a\u7406\u5206\u6790\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u638c\u63e1\u4e86\u5927\u91cf\u8de8\u9886\u57df\u7684\u77e5\u8bc6\uff0c\u4f46\u7531\u4e8e\u5176\u968f\u673a\u6027\uff0c\u76ee\u524d\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u5b83\u4eec\u5177\u4f53\u638c\u63e1\u4e86\u54ea\u4e9b\u77e5\u8bc6\u3002\u4ee5\u5f80\u63a2\u6d4bLLM\u77e5\u8bc6\u7684\u65b9\u6cd5\u591a\u4f9d\u8d56\u6a21\u578b\u6b63\u5411\u63a8\u7406\uff0c\u8ba1\u7b97\u4ee3\u4ef7\u9ad8\u3001\u8017\u65f6\u957f\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u89c4\u6a21\u77e5\u8bc6\u8bc4\u4f30\u7684\u53ef\u80fd\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86PEEK\u65b9\u6cd5\uff1a\u901a\u8fc7\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6587\u672c\u6216\u56fe\u7ed3\u6784\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3aLLM\u7684\u77e5\u8bc6\u4ee3\u7406\u3002\u6d41\u7a0b\u4e3a\uff1a\u9996\u5148\u5229\u7528\u5df2\u6709\u7684\u63a2\u6d4b\u65b9\u6cd5\u786e\u5b9aLLM\u5df2\u77e5\u7684\u4e8b\u5b9e\u8bad\u7ec3\u96c6\uff1b\u7136\u540e\u7528\u4e00\u4e2a\u7ebf\u6027\u89e3\u7801\u5c42\u5c06\u5d4c\u5165\u6a21\u578b\u5fae\u8c03\uff0c\u4f7f\u5176\u53ef\u4ee5\u9884\u6d4bLLM\u8f93\u51fa\uff0c\u4ece\u800c\u63a8\u65adLLM\u638c\u63e1\u7684\u77e5\u8bc6\u3002", "result": "\u57283\u4e2a\u7ef4\u57fa\u767e\u79d1\u884d\u751f\u6570\u636e\u96c6\u30014\u4e2aLLM\u4ee5\u53ca7\u4e2a\u5d4c\u5165\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8fd9\u79cd\u57fa\u4e8e\u5d4c\u5165\u7684\u4ee3\u7406\u65b9\u6cd5\u80fd\u5728\u7559\u51fa\u6d4b\u8bd5\u96c6\u4e0a\u9ad8\u8fbe90%\u7684\u51c6\u786e\u7387\u9884\u6d4bLLM\u77e5\u8bc6\u3002\u8fdb\u4e00\u6b65\u53d1\u73b0\uff0c\u76f8\u6bd4\u4e8e\u56fe\u5d4c\u5165\u6a21\u578b\uff0c\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u66f4\u9002\u5408\u5145\u5f53LLM\u77e5\u8bc6\u4ee3\u7406\u3002", "conclusion": "\u77e5\u8bc6\u9002\u914d\u540e\u7684\u5d4c\u5165\u6a21\u578b\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u8bc6\u522bLLM\u7684\u77e5\u8bc6\u76f2\u70b9\uff0c\u5e76\u5e2e\u52a9\u63a2\u7d22LLM\u5185\u5728\u7684\u5f52\u7eb3\u504f\u7f6e\u673a\u5236\u3002"}}
{"id": "2508.06046", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06046", "abs": "https://arxiv.org/abs/2508.06046", "authors": ["Xinda Wang", "Zhengxu Hou", "Yangshijie Zhang", "Bingren Yan", "Zhibo Yang", "Xingsheng Zhang", "Luxi Xing", "Qiang Zhou", "Chen Zhang"], "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "comment": null, "summary": "Although the effectiveness of Large Language Models (LLMs) as judges\n(LLM-as-a-judge) has been validated, their performance remains limited in\nopen-ended tasks, particularly in story evaluation. Accurate story evaluation\nis crucial not only for assisting human quality judgment but also for providing\nkey signals to guide story generation. However, existing methods face a\ndilemma: prompt engineering for closed-source models suffers from poor\nadaptability, while fine-tuning approaches for open-source models lack the\nrigorous reasoning capabilities essential for story evaluation. To address\nthis, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.\nGrounded in pairwise comparison, the framework first self-synthesizes\nscore-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To\nensure data quality, these raw CoTs undergo a self-filtering process, utilizing\nmulti-agents to guarantee their logical rigor and robustness. Finally, the\nevaluator trained on the refined data is deployed as a reward model to guide\nthe story generation task. Experimental results demonstrate that our framework\nachieves state-of-the-art (SOTA) performance on three evaluation benchmarks\nincluding StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward\nmodel, it significantly enhances the quality of generated stories, thereby\nfully validating the superiority of our self-evolving approach.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faEvolvR\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u7b56\u7565\u751f\u6210\u9ad8\u8d28\u91cf\u63a8\u7406\u94fe\u6570\u636e\uff0c\u8bad\u7ec3\u66f4\u5f3a\u7684\u6545\u4e8b\u8bc4\u4f30\u6a21\u578b\uff0c\u4e0d\u4ec5\u5728\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u53d6\u5f97\u6700\u597d\u6210\u7ee9\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u6545\u4e8b\u751f\u6210\u7684\u63d0\u5347\u3002", "motivation": "\u73b0\u6709LLM\u8bc4\u5224\u65b9\u6cd5\u5728\u6545\u4e8b\u7c7b\u5f00\u653e\u6027\u4efb\u52a1\u4e2d\u6027\u80fd\u53d7\u9650\u3002\u73b0\u6709closed-source\u6a21\u578b\u7684prompt\u5de5\u7a0b\u9002\u5e94\u6027\u5dee\uff0copen-source\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\u7f3a\u4e4f\u4e25\u683c\u63a8\u7406\uff0c\u6025\u9700\u517c\u5177\u9ad8\u63a8\u7406\u80fd\u529b\u4e0e\u9002\u5e94\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u81ea\u8fdb\u5316\u6210\u5bf9\u63a8\u7406\uff08EvolvR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89d2\u8272\u7b56\u7565\u81ea\u5408\u6210\u4e0e\u5206\u6570\u5bf9\u9f50\u7684CoT\u6570\u636e\uff0c\u518d\u7ecf\u591a\u667a\u80fd\u4f53\u81ea\u8fc7\u6ee4\uff0c\u6700\u540e\u7528\u7cbe\u70bc\u540e\u6570\u636e\u8bad\u7ec3\u8bc4\u4f30\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u6307\u5bfc\u6545\u4e8b\u751f\u6210\u3002", "result": "EvolvR \u5728StoryER\u3001HANNA\u3001OpenMEVA\u7b49\u8bc4\u6d4b\u57fa\u51c6\u53d6\u5f97SOTA\u8868\u73b0\uff0c\u540c\u65f6\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6545\u4e8b\u7684\u8d28\u91cf\u3002", "conclusion": "EvolvR \u6846\u67b6\u4f5c\u4e3a\u8bc4\u4f30\u8005\u5728\u591a\u4e2a\u6545\u4e8b\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\uff0c\u5e76\u663e\u8457\u63d0\u5347\u6545\u4e8b\u751f\u6210\u7684\u8d28\u91cf\uff0c\u6709\u6548\u9a8c\u8bc1\u4e86\u5176\u81ea\u8fdb\u5316\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.06094", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06094", "abs": "https://arxiv.org/abs/2508.06094", "authors": ["Morris Alper", "Moran Yanuka", "Raja Giryes", "Ga\u0161per Begu\u0161"], "title": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline", "comment": "Project page: https://conlangcrafter.github.io", "summary": "Constructed languages (conlangs) such as Esperanto and Quenya have played\ndiverse roles in art, philosophy, and international communication. Meanwhile,\nlarge-scale foundation models have revolutionized creative generation in text,\nimages, and beyond. In this work, we leverage modern LLMs as computational\ncreativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a\nmulti-hop pipeline that decomposes language design into modular stages --\nphonology, morphology, syntax, lexicon generation, and translation. At each\nstage, our method leverages LLMs' meta-linguistic reasoning capabilities,\ninjecting randomness to encourage diversity and leveraging self-refinement\nfeedback to encourage consistency in the emerging language description. We\nevaluate ConlangCrafter on metrics measuring coherence and typological\ndiversity, demonstrating its ability to produce coherent and varied conlangs\nwithout human linguistic expertise.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa ConlangCrafter\uff0c\u57fa\u4e8e\u5927\u6a21\u578b\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u7a0b\u81ea\u52a8\u751f\u6210\u6784\u9020\u8bed\u8a00\uff0c\u65e0\u9700\u4eba\u5de5\u53c2\u4e0e\uff0c\u80fd\u521b\u4f5c\u51fa\u8fde\u8d2f\u548c\u591a\u6837\u7684\u865a\u6784\u8bed\u8a00\u3002", "motivation": "\u6784\u9020\u8bed\u8a00\u5728\u827a\u672f\u3001\u54f2\u5b66\u548c\u56fd\u9645\u4ea4\u6d41\u7b49\u9886\u57df\u5177\u6709\u591a\u6837\u4f5c\u7528\uff0c\u4f46\u4f20\u7edf\u6784\u9020\u65b9\u6cd5\u5bf9\u4eba\u5de5\u8bed\u8a00\u5b66\u77e5\u8bc6\u8981\u6c42\u9ad8\u3002\u968f\u7740\u5927\u6a21\u578b\u5728\u521b\u4f5c\u9886\u57df\u7684\u9769\u547d\u6027\u8fdb\u5c55\uff0c\u63a2\u7d22\u5176\u5728\u81ea\u52a8\u5316\u521b\u9020\u6784\u9020\u8bed\u8a00\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u4e86 ConlangCrafter\uff0c\u591a\u9636\u6bb5\u7ba1\u9053\u5229\u7528\u5927\u6a21\u578b\u5728\u97f3\u7cfb\u3001\u5f62\u6001\u3001\u53e5\u6cd5\u3001\u8bcd\u6c47\u7b49\u6a21\u5757\u5316\u6d41\u7a0b\u4e2d\uff0c\u7ed3\u5408\u968f\u673a\u6027\u4e0e\u81ea\u6211\u53cd\u9988\u673a\u5236\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u6784\u9020\u8bed\u8a00\u751f\u6210\u3002", "result": "\u7cfb\u7edf\u5728\u8fde\u8d2f\u6027\u4e0e\u7c7b\u578b\u5b66\u591a\u6837\u6027\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u8bc1\u660e\u5176\u53ef\u751f\u6210\u8fde\u8d2f\u4e14\u591a\u6837\u5316\u7684\u6784\u9020\u8bed\u8a00\u3002", "conclusion": "ConlangCrafter \u80fd\u591f\u5728\u6ca1\u6709\u4eba\u5de5\u8bed\u8a00\u5b66\u4e13\u4e1a\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u5927\u6a21\u578b\u81ea\u52a8\u751f\u6210\u8fde\u8d2f\u4e14\u591a\u6837\u7684\u6784\u9020\u8bed\u8a00\u3002"}}
{"id": "2508.06103", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.06103", "abs": "https://arxiv.org/abs/2508.06103", "authors": ["Mohamed Basem", "Islam Oshallah", "Ali Hamdi", "Ammar Mohammed"], "title": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs", "comment": "6 pages , 2 figures , Accepted in IMSA 2025,Egypt ,\n  https://imsa.msa.edu.eg/", "summary": "This paper presents two effective approaches for Extractive Question\nAnswering (QA) on the Quran. It addresses challenges related to complex\nlanguage, unique terminology, and deep meaning in the text. The second uses\nfew-shot prompting with instruction-tuned large language models such as Gemini\nand DeepSeek. A specialized Arabic prompt framework is developed for span\nextraction. A strong post-processing system integrates subword alignment,\noverlap suppression, and semantic filtering. This improves precision and\nreduces hallucinations. Evaluations show that large language models with Arabic\ninstructions outperform traditional fine-tuned models. The best configuration\nachieves a pAP10 score of 0.637. The results confirm that prompt-based\ninstruction tuning is effective for low-resource, semantically rich QA tasks.", "AI": {"tldr": "\u901a\u8fc7\u4e13\u95e8\u4e3a\u963f\u62c9\u4f2f\u8bed\u53e4\u5170\u7ecf\u95ee\u7b54\u8bbe\u8ba1\u7684\u5c11\u6837\u672c\u6307\u4ee4\u63d0\u793a\u548c\u540e\u5904\u7406\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7b54\u6848\u51c6\u786e\u7387\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u9002\u5408\u5904\u7406\u8bed\u4e49\u590d\u6742\u3001\u4f4e\u8d44\u6e90\u7684\u62bd\u53d6\u5f0f\u95ee\u7b54\u4efb\u52a1\u3002", "motivation": "\u53e4\u5170\u7ecf\u6587\u672c\u5177\u6709\u590d\u6742\u8bed\u8a00\u3001\u72ec\u7279\u672f\u8bed\u548c\u6df1\u5c42\u542b\u4e49\uff0c\u5e38\u89c4\u95ee\u7b54\u7cfb\u7edf\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u9762\u5411\u8bed\u4e49\u4e30\u5bcc\u3001\u4f4e\u8d44\u6e90\u573a\u666f\u7684\u62bd\u53d6\u5f0f\u95ee\u7b54\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a\u4e00\u662f\u5c11\u6837\u672c\u6307\u4ee4\u63d0\u793a\u5fae\u8c03\uff08few-shot prompting with instruction-tuned LLMs\uff09\uff0c\u5982Gemini\u548cDeepSeek\uff1b\u4e8c\u662f\u5f00\u53d1\u4e13\u95e8\u7684\u963f\u62c9\u4f2f\u8bed\u63d0\u793a\u6846\u67b6\u7528\u4e8e\u7b54\u6848\u7247\u6bb5\u62bd\u53d6\uff0c\u5e76\u8f85\u4ee5\u5f3a\u5927\u7684\u540e\u5904\u7406\u7cfb\u7edf\uff0c\u5305\u62ec\u5b50\u8bcd\u5bf9\u9f50\u3001\u91cd\u53e0\u6291\u5236\u548c\u8bed\u4e49\u8fc7\u6ee4\u3002", "result": "\u6240\u63d0\u6307\u4ee4\u5fae\u8c03\u7684LLMs\u5728\u8bc4\u6d4b\u4e2d\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u6a21\u578b\uff0c\u6700\u4f73\u914d\u7f6epAP10\u5f97\u5206\u4e3a0.637\uff0c\u8bf4\u660e\u5f00\u53d1\u7684\u65b9\u6cd5\u5728\u8bed\u4e49\u4e30\u5bcc\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u6548\u3002", "conclusion": "\u57fa\u4e8e\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u53e4\u5170\u7ecf\u7684\u62bd\u53d6\u5f0f\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u6a21\u578b\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u5e7b\u89c9\u53d1\u751f\u3002"}}
{"id": "2508.06105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06105", "abs": "https://arxiv.org/abs/2508.06105", "authors": ["Shengyuan Chen", "Chuang Zhou", "Zheng Yuan", "Qinggang Zhang", "Zeyang Cui", "Hao Chen", "Yilin Xiao", "Jiannong Cao", "Xiao Huang"], "title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures", "comment": null, "summary": "Large language models (LLMs) often suffer from hallucination, generating\nfactually incorrect statements when handling questions beyond their knowledge\nand perception. Retrieval-augmented generation (RAG) addresses this by\nretrieving query-relevant contexts from knowledge bases to support LLM\nreasoning. Recent advances leverage pre-constructed graphs to capture the\nrelational connections among distributed documents, showing remarkable\nperformance in complex tasks. However, existing Graph-based RAG (GraphRAG)\nmethods rely on a costly process to transform the corpus into a graph,\nintroducing overwhelming token cost and update latency. Moreover, real-world\nqueries vary in type and complexity, requiring different logic structures for\naccurate reasoning. The pre-built graph may not align with these required\nstructures, resulting in ineffective knowledge retrieval. To this end, we\npropose a \\textbf{\\underline{Logic}}-aware\n\\textbf{\\underline{R}}etrieval-\\textbf{\\underline{A}}ugmented\n\\textbf{\\underline{G}}eneration framework (\\textbf{LogicRAG}) that dynamically\nextracts reasoning structures at inference time to guide adaptive retrieval\nwithout any pre-built graph. LogicRAG begins by decomposing the input query\ninto a set of subproblems and constructing a directed acyclic graph (DAG) to\nmodel the logical dependencies among them. To support coherent multi-step\nreasoning, LogicRAG then linearizes the graph using topological sort, so that\nsubproblems can be addressed in a logically consistent order. Besides, LogicRAG\napplies graph pruning to reduce redundant retrieval and uses context pruning to\nfilter irrelevant context, significantly reducing the overall token cost.\nExtensive experiments demonstrate that LogicRAG achieves both superior\nperformance and efficiency compared to state-of-the-art baselines.", "AI": {"tldr": "LogicRAG\u662f\u4e00\u79cd\u65e0\u9700\u9884\u5efa\u56fe\u7684\u903b\u8f91\u611f\u77e5\u578bRAG\u65b9\u6cd5\u3002\u5b83\u6309\u9700\u6784\u5efa\u903b\u8f91\u4f9d\u8d56\u7ed3\u6784\u3001\u4f18\u5316\u68c0\u7d22\u987a\u5e8f\uff0c\u5e76\u526a\u679d\u5197\u4f59\u4fe1\u606f\uff0c\u4ece\u800c\u660e\u663e\u63d0\u5347\u4e86\u591a\u6b65\u63a8\u7406\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5904\u7406\u8d85\u51fa\u5176\u77e5\u8bc6\u8303\u56f4\u7684\u95ee\u9898\u65f6\uff0c\u5e38\u5e38\u51fa\u73b0\u201c\u5e7b\u89c9\u201d\uff0c\u751f\u6210\u4e8b\u5b9e\u4e0d\u51c6\u786e\u7684\u5185\u5bb9\u3002\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u53ef\u901a\u8fc7\u77e5\u8bc6\u5e93\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\u6765\u652f\u6301\u63a8\u7406\uff0c\u73b0\u6709\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\u5374\u9700\u8981\u9ad8\u6602\u7684\u4ee3\u4ef7\u6765\u5efa\u7acb\u56fe\u7ed3\u6784\uff0c\u4e14\u4e0d\u6613\u9002\u5e94\u4e0d\u540c\u7c7b\u578b\u4e0e\u590d\u6742\u5ea6\u7684\u67e5\u8be2\u3002\u9884\u5148\u6784\u5efa\u7684\u56fe\u4e5f\u65e0\u6cd5\u9488\u5bf9\u4e0d\u540c\u95ee\u9898\u63d0\u4f9b\u6700\u5408\u9002\u7684\u903b\u8f91\u7ed3\u6784\uff0c\u5bfc\u81f4\u68c0\u7d22\u6548\u679c\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51fa\u4e86LogicRAG\u6846\u67b6\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u52a8\u6001\u63d0\u53d6\u903b\u8f91\u7ed3\u6784\u4ee5\u6307\u5bfc\u68c0\u7d22\uff0c\u65e0\u9700\u9884\u5148\u6784\u5efa\u56fe\u3002\u5177\u4f53\u65b9\u6cd5\u4e3a\uff1a\u5c06\u8f93\u5165\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6784\u5efa\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u6765\u5efa\u6a21\u5b83\u4eec\u4e4b\u95f4\u7684\u903b\u8f91\u4f9d\u8d56\uff1b\u518d\u5229\u7528\u62d3\u6251\u6392\u5e8f\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u7684\u591a\u6b65\u63a8\u7406\uff1b\u901a\u8fc7\u56fe\u526a\u679d\u548c\u4e0a\u4e0b\u6587\u526a\u679d\u51cf\u5c11\u5197\u4f59\u68c0\u7d22\u548c\u65e0\u5173\u5185\u5bb9\uff0c\u4ece\u800c\u5927\u5e45\u964d\u4f4etoken\u6d88\u8017\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLogicRAG\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u65e2\u63d0\u9ad8\u4e86\u63a8\u7406\u8d28\u91cf\uff0c\u4e5f\u6709\u6548\u63a7\u5236\u4e86\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "conclusion": "LogicRAG\u901a\u8fc7\u52a8\u6001\u903b\u8f91\u7ed3\u6784\u5efa\u6a21\u4e0e\u526a\u679d\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfGraphRAG\u5728\u7075\u6d3b\u6027\u548c\u8d44\u6e90\u6d88\u8017\u4e0a\u7684\u74f6\u9888\uff0c\u4e3a\u590d\u6742\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u7cbe\u51c6\u4e14\u9ad8\u6548\u7684\u63a8\u7406\u548c\u68c0\u7d22\u65b9\u6848\u3002"}}
{"id": "2508.06124", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06124", "abs": "https://arxiv.org/abs/2508.06124", "authors": ["Sayantan Adak", "Pratyush Chatterjee", "Somnath Banerjee", "Rima Hazra", "Somak Aditya", "Animesh Mukherjee"], "title": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models", "comment": null, "summary": "Present day LLMs face the challenge of managing affordance-based safety\nrisks-situations where outputs inadvertently facilitate harmful actions due to\noverlooked logical implications. Traditional safety solutions, such as scalar\noutcome-based reward models, parameter tuning, or heuristic decoding\nstrategies, lack the granularity and proactive nature needed to reliably detect\nand intervene during subtle yet crucial reasoning steps. Addressing this\nfundamental gap, we introduce AURA, an innovative, multi-layered framework\ncentered around Process Reward Models (PRMs), providing comprehensive, step\nlevel evaluations across logical coherence and safety-awareness. Our framework\nseamlessly combines introspective self-critique, fine-grained PRM assessments,\nand adaptive safety-aware decoding to dynamically and proactively guide models\ntoward safer reasoning trajectories. Empirical evidence clearly demonstrates\nthat this approach significantly surpasses existing methods, significantly\nimproving the logical integrity and affordance-sensitive safety of model\noutputs. This research represents a pivotal step toward safer, more\nresponsible, and contextually aware AI, setting a new benchmark for\nalignment-sensitive applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AURA\u6846\u67b6\uff0c\u5229\u7528\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u7ed3\u5408\u81ea\u6211\u6279\u5224\u548c\u5b89\u5168\u89e3\u7801\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u5b89\u5168\u6027\u548c\u903b\u8f91\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5904\u7406\u57fa\u4e8e\u53ef\u4f9b\u6027\uff08affordance\uff09\u7684\u5b89\u5168\u98ce\u9669\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5373\u6a21\u578b\u8f93\u51fa\u53ef\u80fd\u56e0\u5ffd\u89c6\u67d0\u4e9b\u903b\u8f91\u63a8\u65ad\u800c\u610f\u5916\u4fc3\u4f7f\u6709\u5bb3\u884c\u4e3a\u3002\u4f20\u7edf\u7684\u5b89\u5168\u89e3\u51b3\u65b9\u6848\uff08\u5982\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u6a21\u578b\u3001\u53c2\u6570\u8c03\u8282\u6216\u542f\u53d1\u5f0f\u89e3\u7801\u7b56\u7565\uff09\u65e0\u6cd5\u7ec6\u81f4\u4e14\u4e3b\u52a8\u5730\u68c0\u6d4b\u548c\u5e72\u9884\u8fd9\u4e9b\u5173\u952e\u63a8\u7406\u73af\u8282\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u591a\u5c42\u6b21\u6846\u67b6AURA\uff0c\u6838\u5fc3\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08Process Reward Models, PRM\uff09\uff0c\u901a\u8fc7\u903b\u8f91\u4e00\u81f4\u6027\u548c\u5b89\u5168\u610f\u8bc6\u5728\u6bcf\u4e00\u6b65\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002\u8be5\u6846\u67b6\u878d\u5408\u81ea\u6211\u53cd\u601d\u3001\u7ec6\u81f4\u7684PRM\u8bc4\u4f30\u548c\u81ea\u9002\u5e94\u7684\u5b89\u5168\u89e3\u7801\u65b9\u6cd5\uff0c\u4ee5\u52a8\u6001\u5f15\u5bfc\u6a21\u578b\u5b89\u5168\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8bc1\u636e\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u8f93\u51fa\u7684\u903b\u8f91\u5b8c\u6574\u6027\u548c\u57fa\u4e8e\u53ef\u4f9b\u6027\u7684\u5b89\u5168\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AURA\u6846\u67b6\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u66f4\u5b89\u5168\u3001\u8d1f\u8d23\u4efb\u548c\u73af\u5883\u611f\u77e5\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u5e76\u4e3a\u5bf9\u9f50\u654f\u611f\u578b\u5e94\u7528\u8bbe\u7acb\u4e86\u65b0\u6807\u6746\u3002"}}
{"id": "2508.06135", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06135", "abs": "https://arxiv.org/abs/2508.06135", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models", "comment": null, "summary": "Knowledge Distillation (KD) is a fundamental technique for compressing large\nlanguage models (LLMs) into compact, efficient student models. However,\nexisting white-box KD methods mainly focus on balancing ground truth and\nstudent-generated responses while overlooking two critical factors: training\ndata quality and student-model compatibility. To address these limitations, we\npropose Selective Reflection Distillation (SRD), a novel data curation\nframework that leverages reflections from student models to systematically\nrefine training data. SRD dynamically evaluates and selects prompt-response\npairs by comparing ground truth data with student model outputs, selectively\ncurating high-quality, student-compatible training instances through automated\nranking based on difficulty. Furthermore, after selecting the training data, a\ncurriculum scheduling strategy is employed to incrementally introduce these\ncurated subsets into the distillation process at fixed intervals. As a\nplug-and-play enhancement, SRD consistently improves distillation outcomes\nacross diverse white-box KD approaches and model architectures, as well as\ndecreases computational cost significantly during KD training. Experiments on a\nrange of language model benchmarks demonstrate SRD's consistent improvements in\ndistilled model performance, as well as a reduction in training runtime by up\nto 39%, under diverse KD methods and model families. Notably, SRD operates as a\nplug-and-play module, enhancing sample efficiency without modifying underlying\nKD algorithms. Our findings highlight that data quality and compatibility are\npivotal to effective and efficient distillation of LLMs, and SRD provides a\nprincipled framework to achieve both. This work advances the understanding of\ndata-centric factors in KD and offers practical insights for enhancing the\ncapability and efficiency of compressed LLMs.", "AI": {"tldr": "SRD\u662f\u4e00\u79cd\u9488\u5bf9KD\u8bad\u7ec3\u6570\u636e\u7b5b\u9009\u4f18\u5316\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u53cd\u601d\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5b9e\u73b0\u66f4\u5feb\u4e14\u66f4\u6709\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u538b\u7f29\uff0c\u63d0\u5347\u6a21\u578b\u8868\u73b0\u5e76\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u5728\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u9ad8\u6548\u7684\u5c0f\u6a21\u578b\u65f6\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5e73\u8861\u771f\u5b9e\u6807\u7b7e\u4e0e\u5b66\u751f\u6a21\u578b\u751f\u6210\u7684\u54cd\u5e94\uff0c\u5ffd\u7565\u4e86\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u548c\u5b66\u751f\u6a21\u578b\u517c\u5bb9\u6027\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff0c\u63d0\u5347\u84b8\u998f\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Selective Reflection Distillation\uff08SRD\uff09\u6846\u67b6\uff1a\u5229\u7528\u5b66\u751f\u6a21\u578b\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u201c\u53cd\u601d\u201d\u52a8\u6001\u7b5b\u9009\u9ad8\u8d28\u91cf\u3001\u4e0e\u5b66\u751f\u6a21\u578b\u517c\u5bb9\u7684\u8bad\u7ec3\u6837\u672c\u3002\u5177\u4f53\u505a\u6cd5\u662f\u6bd4\u8f83\u771f\u5b9e\u6807\u7b7e\u4e0e\u5b66\u751f\u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u81ea\u52a8\u96be\u5ea6\u6392\u5e8f\uff0c\u4f9d\u6b64\u9009\u62e9\u6837\u672c\uff0c\u5e76\u91c7\u7528\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u5206\u6279\u5f15\u5165\u6837\u672c\u5230\u84b8\u998f\u6d41\u7a0b\u4e2d\u3002SRD\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u4e0d\u6539\u52a8\u539f\u6709KD\u7b97\u6cd5\uff0c\u4ec5\u4f18\u5316\u6570\u636e\u9009\u62e9\u4e0e\u8c03\u5ea6\u3002", "result": "SRD\u5728\u591a\u79cd\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u548cKD\u65b9\u6cd5\u4e0b\u5747\u5e26\u6765\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u6700\u591a\u53ef\u51cf\u5c1139%\u7684\u8bad\u7ec3\u65f6\u95f4\u3002SRD\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u6a21\u578b\u8868\u73b0\uff0c\u5e76\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0b\u9002\u7528\u3002", "conclusion": "\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u4e0e\u6a21\u578b\u517c\u5bb9\u6027\u5bf9\u84b8\u998f\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002SRD\u6846\u67b6\u4e3a\u9ad8\u8d28\u91cf\u3001\u517c\u5bb9\u6027\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u548c\u8c03\u5ea6\u63d0\u4f9b\u53ef\u884c\u65b9\u6848\uff0c\u663e\u8457\u589e\u5f3a\u4e86KD\u6027\u80fd\u4e0e\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u52a0\u6df1\u4e86\u5bf9\u6570\u636e\u9a71\u52a8KD\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u538b\u7f29LLMs\u63d0\u4f9b\u4e86\u5b9e\u9645\u6539\u8fdb\u8def\u5f84\u3002"}}
{"id": "2508.06149", "categories": ["cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.06149", "abs": "https://arxiv.org/abs/2508.06149", "authors": ["Gunhee Cho", "Yun-Gyung Cheong"], "title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "comment": null, "summary": "We present Big5-Scaler, a prompt-based framework for conditioning large\nlanguage models (LLMs) with controllable Big Five personality traits. By\nembedding numeric trait values into natural language prompts, our method\nenables fine-grained personality control without additional training. We\nevaluate Big5-Scaler across trait expression, dialogue generation, and human\ntrait imitation tasks. Results show that it induces consistent and\ndistinguishable personality traits across models, with performance varying by\nprompt type and scale. Our analysis highlights the effectiveness of concise\nprompts and lower trait intensities, providing a efficient approach for\nbuilding personality-aware dialogue agents.", "AI": {"tldr": "Big5-Scaler\u80fd\u901a\u8fc7\u4fee\u6539\u63d0\u793a\u8bcd\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u7cbe\u51c6\u63a7\u5236LLM\u7684\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff0c\u662f\u6784\u5efa\u4e2a\u6027\u5316\u5bf9\u8bdd\u7cfb\u7edf\u7684\u9ad8\u6548\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e2a\u6027\u5316\u65b9\u9762\u53d7\u9650\uff0c\u5e0c\u671b\u901a\u8fc7\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u5b9e\u73b0\u5bf9\u6a21\u578b\u6027\u683c\u7279\u8d28\u7684\u7ec6\u7c92\u5ea6\u53ef\u63a7\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u6a21\u578b\u3002", "method": "\u63d0\u51faBig5-Scaler\u6846\u67b6\uff0c\u5c06\u6570\u503c\u5316\u7684\u4eba\u683c\u7279\u8d28\u5d4c\u5165\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8bcd\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u5373\u53ef\u5b9e\u73b0\u5bf9LLM\u7684\u6027\u683c\u7279\u8d28\u7cbe\u51c6\u8c03\u63a7\u3002", "result": "\u5728\u6027\u683c\u8868\u8fbe\u3001\u5bf9\u8bdd\u751f\u6210\u4ee5\u53ca\u6a21\u4eff\u4eba\u7c7b\u6027\u683c\u7279\u8d28\u7b49\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cBig5-Scaler\u80fd\u7a33\u5b9a\u3001\u6709\u533a\u5206\u5ea6\u5730\u8bf1\u5bfc\u6a21\u578b\u5c55\u73b0\u4e0d\u540c\u6027\u683c\u7279\u8d28\uff0c\u4e0d\u540c\u63d0\u793a\u7c7b\u578b\u4e0e\u5f3a\u5ea6\u5f71\u54cd\u8868\u73b0\u3002\u7b80\u6d01\u63d0\u793a\u8bed\u548c\u8f83\u4f4e\u7279\u8d28\u5f3a\u5ea6\u6548\u679c\u66f4\u4f73\u3002", "conclusion": "Big5-Scaler\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u65e0\u9700\u518d\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba9\u5bf9\u8bdd\u667a\u80fd\u4f53\u66f4\u597d\u5730\u5177\u5907\u548c\u5c55\u73b0\u4e2a\u6027\u7279\u5f81\uff0c\u5bf9\u6784\u5efa\u5177\u5907\u4eba\u683c\u610f\u8bc6\u7684\u5bf9\u8bdd\u4ee3\u7406\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
