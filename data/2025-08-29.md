<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 10]
- [cs.DM](#cs.DM) [Total: 3]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Solvable Tuple Patterns and Their Applications to Program Verification](https://arxiv.org/abs/2508.20365)
*Naoki Kobayashi,Ryosuke Sato,Ayumi Shinohara,Ryo Yoshinaka*

Main category: cs.PL

TL;DR: 本文提出STP方法可高效自动推断递归数据结构的不变量，并成功集成到CHC求解器中，在2025年CHC-COMP竞赛中表现突出。


<details>
  <summary>Details</summary>
Motivation: 目前自动化程序验证技术虽然取得了进展，但对操作递归数据结构的程序进行全自动验证仍很困难。因此，急需新的有效方法来提升递归数据结构程序的自动化验证能力。

Method: 本文提出了一种新的不变量表达方式——可解元组模式（STP），用于表示链表类递归数据结构间的不变量。STP可以通过极少量正样本高效推断得到，无需负样本。基于支持序列理论的SMT求解器可用来验证推断出的STP是否为归纳不变量。此外，作者提出了STP推断算法，并将其集成到支持链表类数据结构的CHC求解器中，作为自动程序验证工具的统一后端。

Result: 集成STP推断算法的CHC求解器在2025年的CHC-COMP竞赛ADT-LIN类别中大幅领先并取得了胜利，证明了方法的有效性。

Conclusion: 提出的STP方法不仅能够通过极少正样本自动推断递归数据结构程序的不变量，还能有效提升自动程序验证工具在相关竞赛中的表现，具有先进性和实用价值。

Abstract: Despite the recent progress of automated program verification techniques,
fully automated verification of programs manipulating recursive data structures
remains a challenge. We introduce the notion of solvable tuple patterns (STPs)
to express invariants between list-like recursive data structures. A
distinguishing feature of STPs is that they can be efficiently inferred from
only a small number of positive samples; no negative samples are required. An
SMT solver that supports the sequence theory can be used to check that an
inferred STP is indeed an inductive invariant. After presenting basic
properties of STPs and an STP inference algorithm, we show how to incorporate
the STP inference into a CHC (Constrained Horn Clauses) solver supporting
list-like data structures, which serves as a uniform backend for automated
program verification tools. A CHC solver incorporating the STP inference has
won the ADT-LIN category of CHC-COMP 2025 by a big margin.

</details>


### [2] [Static Factorisation of Probabilistic Programs With User-Labelled Sample Statements and While Loops](https://arxiv.org/abs/2508.20922)
*Markus Böck,Jürgen Cito*

Main category: cs.PL

TL;DR: 本文提出了对带循环和动态采样标签的概率程序进行静态图形化展现和优化的新方法，提升了推断和计算效率，为概率程序的理论与实践带来进展。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯网络可以用概率程序实现，但不清楚概率程序（含标记采样语句与while循环）能否图形化表示。作者希望研究概率程序的可图形化程度。

Method: 扩展概率编程语言的操作语义，支持用户标记的采样语句和while循环，将程序转换为控制流图，再进行静态分析以近似程序中随机变量的依赖关系，得到静态因子分解，发明一种程序切片技术进行优化。

Result: 提出的静态因子分解方法对于无循环与常量标签的程序等价于已知的贝叶斯网络因子分解，但对包含循环或动态标签的程序，提供了一种新颖的图形化表示。应用提出的切片技术，在变分推断、单点Metropolis Hastings与顺序蒙特卡洛三项优化中，理论与实验证明方法正确且性能优于现有技术。

Conclusion: 本文证明了带有采样语句和while循环的概率程序可用图形结构近似描述，并开发出有效的静态优化工具，提升了推断效率并扩展了概率编程的理论基础。

Abstract: It is commonly known that any Bayesian network can be implemented as a
probabilistic program, but the reverse direction is not so clear. In this work,
we address the open question to what extent a probabilistic program with
user-labelled sample statements and while loops - features found in languages
like Gen, Turing, and Pyro - can be represented graphically. To this end, we
extend existing operational semantics to support these language features. By
translating a program to its control-flow graph, we define a sound static
analysis that approximates the dependency structure of the random variables in
the program. As a result, we obtain a static factorisation of the implicitly
defined program density, which is equivalent to the known Bayesian network
factorisation for programs without loops and constant labels, but constitutes a
novel graphical representation for programs that define an unbounded number of
random variables via loops or dynamic labels. We further develop a sound
program slicing technique to leverage this structure to statically enable three
well-known optimisations for the considered program class: we reduce the
variance of gradient estimates in variational inference and we speed up both
single-site Metropolis Hastings and sequential Monte Carlo. These optimisations
are proven correct and empirically shown to match or outperform existing
techniques.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Evaluating LLMs on microservice-based applications: how complex is your specification?](https://arxiv.org/abs/2508.20119)
*Daniel M. Yellin*

Main category: cs.SE

TL;DR: 本文评估LLM生成微服务架构代码能力，搭建自动化测试框架，证明LLM在高难度规范下表现不佳，分析了其主要挑战并建议未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 评估当前LLMs在实际应用中代码生成能力，特别是在广泛使用的微服务架构下，探索其面临的挑战并为未来改进研究提供参考。

Method: 定义了微服务应用的标准规范模板及难度评分指标，搭建了自动化测试LLM生成代码的框架，通过单元测试评估代码质量，并对生成结果进行了详细错误分析。

Result: 实验显示LLMs对于中等难度应用生成代码效果较好，但在高难度规范下，复杂业务逻辑等因素极大影响其表现，作者总结了主要瓶颈并提出未来改进方向。

Conclusion: 强大的LLMs在生成中等难度微服务应用的代码时表现尚可，但在处理高难度规范时表现较差，主要受限于复杂业务逻辑、外部服务、数据库集成和非功能性能力等问题。

Abstract: In this paper we evaluate how far LLMs have advanced in generating code for
real-world problems. Specifically, we explore code synthesis for
microservice-based applications, a widely used architecture pattern. We define
a standard template for specifying these applications, and we propose a metric
for judging the difficulty level of a specification. The higher the score, the
more difficult it is to generate code for the specification. We develop a
framework to automate the process of testing LLM-synthesized code for a
microservice using unit tests. Our experimental results show that strong LLMs
(like GPT-3o-mini) do fairly well on medium difficulty specifications but do
very poorly on those of higher difficulty levels. This is due to more intricate
business logic, a greater use of external services, database integration and
inclusion of non-functional capabilities such as authentication. We analyzed
the errors in LLM-synthesized code and report on the key challenges LLMs face
in generating code for these specifications thereby suggesting future research
directions to improve code synthesis for real-world problems.

</details>


### [4] [Towards Better Correctness and Efficiency in Code Generation](https://arxiv.org/abs/2508.20124)
*Yunlong Feng,Yang Xu,Xiao Xu,Binyuan Hui,Junyang Lin*

Main category: cs.SE

TL;DR: 本文针对代码生成模型效率低下的问题，提出强化学习+性能奖励的新方法，通过动态探索、容错优化等创新设计，有效兼顾正确性与运行效率，在较小模型上实现了大幅提升，达到大模型水平。


<details>
  <summary>Details</summary>
Motivation: 现有代码大语言模型生成的代码效率较低，限制了在性能敏感场景下的应用。

Method: 以强化学习为主，设计新颖的性能奖励；提出动态探索、容错强化学习及高反差效率信号，并采用两阶段调优方法。

Result: 方法在7B模型上提升了代码正确性10.18%和运行效率7.75%，表现接近更大规模模型。

Conclusion: 提出了一种面向效率的强化学习框架，通过性能奖励提升代码生成模型的运行效率，最终达到正确性和效率的高平衡。

Abstract: While code large language models have demonstrated remarkable progress in
code generation, the generated code often exhibits poor runtime efficiency,
limiting its practical application in performance-sensitive scenarios. To
address this limitation, we propose an efficiency-oriented reinforcement
learning framework guided by a novel performance reward. Based on this
framework, we take a deeper dive into the code efficiency problem, identifying
then proposing methods to overcome key bottlenecks: (1) Dynamic exploration
overcomes the static data constraints of offline fine-tuning, enabling the
discovery of more efficient code implementations. (2) The error-insensitive
reinforcement learning method and high-contrast efficiency signals are crucial
for mitigating systematic errors and achieving effective optimization. (3)
Online exploration is most effective when starting from a high-correctness
baseline, as this allows for efficiency improvements without sacrificing
accuracy. With these discoveries, we finally propose a two-stage tuning method,
which achieves high and balanced performance across correctness and efficiency.
The results of experiments show the effectiveness of the method, which improves
code correctness by 10.18\% and runtime efficiency by 7.75\% on a 7B model,
achieving performance comparable to much larger model.

</details>


### [5] [Boosting Skeleton-Driven SMT Solver Fuzzing by Leveraging LLM to Produce Formula Generators](https://arxiv.org/abs/2508.20340)
*Maolin Sun,Yibiao Yang,Yuming Zhou*

Main category: cs.SE

TL;DR: 该文提出Chimera——一种用LLM一次性生成可复用生成器的SMT模糊测试新方法，既提高了测试用例的语法准确性与多样性，又显著降低LLM调用成本，实验在两大求解器中挖掘出大量新bug，推动了求解器质量提升。


<details>
  <summary>Details</summary>
Motivation: SMT求解器在系统与编程语言研究中至关重要，其正确性直接影响诸如符号执行和自动化验证等任务。然而，现有的测试方法难以跟上求解器新特性的变化，且基于大语言模型的生成往往存在公式语法无效和开销大的问题。

Method: 提出了Chimera，一种借助LLM的模糊测试框架。Chimera以自动抽取SMT理论的上下文无关文法(CFG)并合成可复用布尔项生成器为核心，采用一次性LLM交互，生成结构骨架填充，保证公式的语法有效且语义多样。

Result: 在主流SMT求解器Z3和cvc5上的实验表明，Chimera发现了43个确认的bug，其中40个已被开发者修复。

Conclusion: Chimera框架有效提高了测试用例的有效性和多样性，大幅减少了对LLM调用的开销，对提升SMT求解器质量具有重要意义。

Abstract: Satisfiability Modulo Theory (SMT) solvers are foundational to modern systems
and programming languages research, providing the foundation for tasks like
symbolic execution and automated verification. Because these solvers sit on the
critical path, their correctness is essential, and high-quality test formulas
are key to uncovering bugs. However, while prior testing techniques performed
well on earlier solver versions, they struggle to keep pace with rapidly
evolving features. Recent approaches based on Large Language Models (LLMs) show
promise in exploring advanced solver capabilities, but two obstacles remain:
nearly half of the generated formulas are syntactically invalid, and iterative
interactions with the LLMs introduce substantial computational overhead. In
this study, we present Chimera, a novel LLM-assisted fuzzing framework that
addresses both issues by shifting from direct formula generation to the
synthesis of reusable term (i.e., logical expression) generators. Particularly,
Chimera uses LLMs to (1) automatically extract context-free grammars (CFGs) for
SMT theories, including solver-specific extensions, from documentation, and (2)
synthesize composable Boolean term generators that adhere to these grammars.
During fuzzing, Chimera populates structural skeletons derived from existing
formulas with the terms iteratively produced by the LLM-synthesized generators.
This design ensures syntactic validity while promoting semantic diversity.
Notably, Chimera requires only one-time LLM interaction investment,
dramatically reducing runtime cost. We evaluated Chimera on two leading SMT
solvers: Z3 and cvc5. Our experiments show that Chimera has identified 43
confirmed bugs, 40 of which have already been fixed by developers.

</details>


### [6] [Adaptive Root Cause Localization for Microservice Systems with Multi-Agent Recursion-of-Thought](https://arxiv.org/abs/2508.20370)
*Lingzhe Zhang,Tong Jia,Kangjin Wang,Weijie Hong,Chiming Duan,Minghua He,Ying Li*

Main category: cs.SE

TL;DR: 当前微服务系统根因定位方法存在适应性和可解释性不足的问题。本文调研SRE实践，总结其推理特点，提出了RCLAgent多智能体递归推理新方法，在多个场景下实现了更高效、更精准的根因定位，且仅需一次请求。


<details>
  <summary>Details</summary>
Motivation: 随着微服务系统变得越来越复杂且大规模，系统故障变得更加频繁，对系统可靠性的要求提升，因此准确的根因定位变得非常重要。而现有方法要么过度依赖预定义数据模式，难以适应不断变化的运维场景，要么其推理过程缺乏可解释性，让SRE工程师难以理解和信任。该研究针对这些不足，希望提出更有效且易于理解的解决方案。

Method: 通过对多个组织中专业SRE的调研，归纳总结人工进行根因定位时的三大特点：递归性、多维度扩展和跨模态推理。基于此，提出了RCLAgent方法，它采用多智能体“思维递归”框架，利用大模型推动推理，多智能体协同及工具辅助分析，有效融合多源数据，实现对微服务系统故障根因的自适应高效定位。

Result: 实验结果表明，RCLAgent在多个公开数据集上的根因定位表现优于当前主流方法，且能够仅利用单个请求进行准确定位，无需依赖多个请求的数据聚合，显著提升根因定位的效率和精准度。

Conclusion: RCLAgent方法基于SRE实际经验和推理模式，提出了创新性思维递归策略，并通过多智能体协作实现了对微服务系统中复杂故障根因的高效、精确定位，具有较好的可解释性，对提升复杂系统的可靠性有重要作用。

Abstract: As contemporary microservice systems become increasingly popular and
complex-often comprising hundreds or even thousands of fine-grained,
interdependent subsystems-they are facing more frequent failures. Ensuring
system reliability thus demands accurate root cause localization. While traces
and metrics have proven to be effective data sources for this task, existing
methods either heavily rely on pre-defined schemas, which struggle to adapt to
evolving operational contexts, or lack interpretability in their reasoning
process, thereby leaving Site Reliability Engineers (SREs) confused. In this
paper, we conduct a comprehensive study on how SREs localize the root cause of
failures, drawing insights from multiple professional SREs across different
organizations. Our investigation reveals that human root cause analysis
exhibits three key characteristics: recursiveness, multi-dimensional expansion,
and cross-modal reasoning. Motivated by these findings, we introduce RCLAgent,
an adaptive root cause localization method for microservice systems that
leverages a multi-agent recursion-of-thought framework. RCLAgent employs a
novel recursion-of-thought strategy to guide the LLM's reasoning process,
effectively integrating data from multiple agents and tool-assisted analysis to
accurately pinpoint the root cause. Experimental evaluations on various public
datasets demonstrate that RCLAgent achieves superior performance by localizing
the root cause using only a single request-outperforming state-of-the-art
methods that depend on aggregating multiple requests. These results underscore
the effectiveness of RCLAgent in enhancing the efficiency and precision of root
cause localization in complex microservice environments.

</details>


### [7] [AI and Agile Software Development: A Research Roadmap from the XP2025 Workshop](https://arxiv.org/abs/2508.20563)
*Zheying Zhang,Tomas Herda,Victoria Pichler,Pekka Abrahamsson,Geir K. Hanssen,Joshua Kerievsky,Alex Polyakov,Mohit Chandna,Marius Irgens,Kai-Kristian Kemell,Ayman Asad Khan,Crystal Kwok,Evan Leybourn,Munish Malik,Dorota Mleczko,Morteza Moalagh,Christopher Morales,Yuliia Pieskova,Daniel Planötscher,Mika Saari,Anastasiia Tkalich,Karl Josef Gstettner,Xiaofeng Wang*

Main category: cs.SE

TL;DR: 本文总结了XP2025工作坊关于AI与敏捷开发交汇的核心发现，明确了主要挑战，提出了多维研究路线，为行业AI与敏捷融合提供方向。


<details>
  <summary>Details</summary>
Motivation: 面对生成式人工智能与敏捷软件开发交汇处日益突出的挑战与机遇，急需学术界与产业界共同探讨痛点和前景，为行业发展提供理论与实践参考。

Method: 通过结构化的互动分组讨论，分析了参与者提出的主要痛点和挑战，并共同制定了研究计划。涉及到工具碎片化、治理、数据质量、AI素养与提示工程等方面的具体问题。

Result: 工作坊确定了AI集成敏捷开发中的主要挑战（如工具碎片化、治理、数据质量、技能缺口），分析了成因，并提出了行动方案和未来研究方向。

Conclusion: 工作坊最终联合制定了一个多主题研究路线图，包含可实施的短期行动和前瞻性的长期研究方向，以指导未来在敏捷开发中负责任且以人为本地集成生成式人工智能（GenAI）。

Abstract: This paper synthesizes the key findings from a full-day XP2025 workshop on
"AI and Agile: From Frustration to Success", held in Brugg-Windisch,
Switzerland. The workshop brought together over 30 interdisciplinary academic
researchers and industry practitioners to tackle the concrete challenges and
emerging opportunities at the intersection of Generative Artificial
Intelligence (GenAI) and agile software development. Through structured,
interactive breakout sessions, participants identified shared pain points like
tool fragmentation, governance, data quality, and critical skills gaps in AI
literacy and prompt engineering. These issues were further analyzed, revealing
underlying causes and cross-cutting concerns. The workshop concluded by
collaboratively co-creating a multi-thematic research roadmap, articulating
both short-term, implementable actions and visionary, long-term research
directions. This cohesive agenda aims to guide future investigation and drive
the responsible, human-centered integration of GenAI into agile practices.

</details>


### [8] [Rethinking Testing for LLM Applications: Characteristics, Challenges, and a Lightweight Interaction Protocol](https://arxiv.org/abs/2508.20737)
*Wei Ma,Yixiao Yang,Qiang Hu,Shi Ying,Zhi Jin,Bo Du,Zhenchang Xing,Tianlin Li,Junjie Shi,Yang Liu,Linxiao Jiang*

Main category: cs.SE

TL;DR: 本文针对大语言模型应用的测试和质量保障问题，提出分层架构分析、跨领域方法融合、协作策略和AICL协议，为未来LLM应用的标准化测试和可靠部署提供了方法和工具。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）应用已经不仅限于文本生成，而是演变为集成检索增强、工具调用和多轮交互的复杂系统，这给质量保障带来了前所未有的挑战。本文旨在系统性分解LLM应用，探索各层次的测试难题和对策。

Method: 本文将LLM应用分为三层架构：系统外壳层、Prompt编排层和LLM推理核心层，分析传统软件测试方法在各层可适用性，并结合软件工程与AI社区的方法做比较。同时，本文提出四类协作策略及一套闭环、可信的质量保障框架，并提出AICL协议用于AI代理间通信。

Result: 分析发现，现有测试方法在层次抽象、评估指标和生命周期管理上存在结构性脱节，导致了四个根本差异和六大核心挑战。为此，提出了四种协作策略和一个集成部署前验证与运行时监控的QA框架，并设计了支持测试的AI通信协议AICL，具备易集成和测试导向等特点。

Conclusion: LLM应用的复杂性要求重新思考质量保障方法，本文提出的分层架构、协作策略和AICL协议为LLM应用标准化测试和工具化提供了方向，促进了软件工程与AI社区的融合，推动了LLM应用的可靠性和可测试性向前发展。

Abstract: Applications of Large Language Models~(LLMs) have evolved from simple text
generators into complex software systems that integrate retrieval augmentation,
tool invocation, and multi-turn interactions. Their inherent non-determinism,
dynamism, and context dependence pose fundamental challenges for quality
assurance. This paper decomposes LLM applications into a three-layer
architecture: \textbf{\textit{System Shell Layer}}, \textbf{\textit{Prompt
Orchestration Layer}}, and \textbf{\textit{LLM Inference Core}}. We then assess
the applicability of traditional software testing methods in each layer:
directly applicable at the shell layer, requiring semantic reinterpretation at
the orchestration layer, and necessitating paradigm shifts at the inference
core. A comparative analysis of Testing AI methods from the software
engineering community and safety analysis techniques from the AI community
reveals structural disconnects in testing unit abstraction, evaluation metrics,
and lifecycle management. We identify four fundamental differences that
underlie 6 core challenges. To address these, we propose four types of
collaborative strategies (\emph{Retain}, \emph{Translate}, \emph{Integrate},
and \emph{Runtime}) and explore a closed-loop, trustworthy quality assurance
framework that combines pre-deployment validation with runtime monitoring.
Based on these strategies, we offer practical guidance and a protocol proposal
to support the standardization and tooling of LLM application testing. We
propose a protocol \textbf{\textit{Agent Interaction Communication Language}}
(AICL) that is used to communicate between AI agents. AICL has the
test-oriented features and is easily integrated in the current agent framework.

</details>


### [9] [From Law to Gherkin: A Human-Centred Quasi-Experiment on the Quality of LLM-Generated Behavioural Specifications from Food-Safety Regulations](https://arxiv.org/abs/2508.20744)
*Shabnam Hassani,Mehrdad Sabetzadeh,Daniel Amyot*

Main category: cs.SE

TL;DR: 本研究验证了大型语言模型可将法律条文高效转化为开发友好的行为规范，大幅减轻人工负担，并有实际开发价值。


<details>
  <summary>Details</summary>
Motivation: 法律法规已经逐渐对软件设计和质量保证产生重大影响，但法律文本通常采用技术中立的语言，给工程师带来将法规转化为合规工件（如需求、验收标准）的挑战。手动创建这些工件耗时、易错，且需要专业知识，因此自动化这一过程具有重要意义。生成式AI（如大型语言模型）为自动化此任务提供了新机遇。

Method: 作者开展了首次系统性的人体实验，采用准实验设计分析LLMs根据法律文本生成行为规格的能力。用Claude和Llama根据食品安全法规，通过Gherkin语言生成了60份规格，10名参与者依据相关性、清晰性、完整性、单一性、节省时间5个标准评估了这些规格。每份规格有2位参与者评审，总计120次评估。

Result: 结果显示LLMs生成的规格在相关性、清晰性、完整性、单一性和节省时间等方面均表现优秀，大多数评分为最高或次高分。Llama在清晰性、完整性和时间节省方面略优于Claude，而Claude在单一性上表现更好。未出现最低分。反馈中指出了部分幻觉和遗漏，但总体肯定其有用性。统计检验未显示不同模型和参与者间有显著差别。

Conclusion: 大型语言模型可从法律文本高质量生成Gherkin规范，显著减少人工工作量，并为实现、质量保证和测试生成提供有结构的工件。

Abstract: Context: Laws and regulations increasingly affect software design and quality
assurance, but legal texts are written in technology-neutral language. This
creates challenges for engineers who must develop compliance artifacts such as
requirements and acceptance criteria. Manual creation is labor-intensive,
error-prone, and requires domain expertise. Advances in Generative AI (GenAI),
especially Large Language Models (LLMs), offer a way to automate deriving such
artifacts.
  Objective: We present the first systematic human-subject study of LLMs'
ability to derive behavioral specifications from legal texts using a
quasi-experimental design. These specifications translate legal requirements
into a developer-friendly form.
  Methods: Ten participants evaluated specifications generated from food-safety
regulations by Claude and Llama. Using Gherkin, a structured BDD language, 60
specifications were produced. Each participant assessed 12 across five
criteria: Relevance, Clarity, Completeness, Singularity, and Time Savings. Each
specification was reviewed by two participants, yielding 120 assessments.
  Results: For Relevance, 75% of ratings were highest and 20% second-highest.
Clarity reached 90% highest. Completeness: 75% highest, 19% second.
Singularity: 82% highest, 12% second. Time Savings: 68% highest, 24% second. No
lowest ratings occurred. Mann-Whitney U tests showed no significant differences
across participants or models. Llama slightly outperformed Claude in Clarity,
Completeness, and Time Savings, while Claude was stronger in Singularity.
Feedback noted hallucinations and omissions but confirmed the utility of the
specifications.
  Conclusion: LLMs can generate high-quality Gherkin specifications from legal
texts, reducing manual effort and providing structured artifacts useful for
implementation, assurance, and test generation.

</details>


### [10] [Towards an Architectural Perspective for Sustainability: Bundle the Needs from Industry](https://arxiv.org/abs/2508.20774)
*Markus Funke,Patricia Lago*

Main category: cs.SE

TL;DR: 本文提出并初步验证了一种服务于软件可持续性问题的架构视角方法，为架构师在设计阶段解决可持续性难题提供了实用参考。


<details>
  <summary>Details</summary>
Motivation: 可持续性作为软件系统中日益重要的质量属性，现有架构师在设计阶段缺乏有效的指导去系统性地解决相关问题。

Method: 提出了一种面向可持续性的问题的架构视角（sustainability perspective）并通过文献追溯（snowballing）和专家焦点小组讨论来构建和验证该视角的有效性。

Result: 研究确认了不同架构视角元素在实际中的相关性，并强调了构建符合工业需求的可持续性视角的实际意义。

Conclusion: 基于文献和专家意见，形成了针对可持续性问题的架构视角雏型，为业界提供了结构化、可实际应用的指导。

Abstract: Sustainability is increasingly recognized as an emerging quality property in
software-intensive systems, yet architects lack structured guidance to address
it effectively throughout the software design phase. Architectural
perspectives-an architectural knowledge artifact composed of concerns,
activities, tactics, pitfalls, and checklists-offer a promising approach to
tackle such emerging quality properties across architectural views and are also
independent of architecture frameworks and industry contexts. In this paper, we
present a sustainability perspective vision, i.e., a revised notion of
architectural perspective meant to be filled with its own elements to target
sustainability concerns. We formulate our sustainability perspective vision
through evidence from applying snowballing to seminal literature and from
conducting a focus group with experts in the field. Our findings confirm the
relevance of the different perspective elements in practice and highlight
implications for shaping a sustainability perspective that meets industrial
needs.

</details>


### [11] [Automated Test Oracles for Flaky Cyber-Physical System Simulators: Approach and Evaluation](https://arxiv.org/abs/2508.20902)
*Baharin A. Jodat,Khouloud Gaaloul,Mehrdad Sabetzadeh,Shiva Nejati*

Main category: cs.SE

TL;DR: 提出断言式自动测试判据，可解释且不需实际运行系统，GP+Ochiai方法效果最佳，对模拟器异常表现稳定，有效降低CPS测试成本和不确定性。


<details>
  <summary>Details</summary>
Motivation: 针对网络物理系统（CPS）模拟测试成本高、模拟器结果不稳定（flaky）的问题，现有自动化测试判据仍需系统实际运行，导致测试成本难以降低。作者希望探索不依赖系统执行且可解释、对模拟器异常具有鲁棒性的自动测试判据。

Method: 提出了一种基于断言的测试判据，用一组逻辑和算术谓词在测试输入上判断测试是否通过，无需执行系统。构建断言的方法包括：一是利用遗传编程（GP），以光谱定位（SBFL）中的Ochiai、Tarantula和Naish判据作为适应度函数；二是利用决策树（DT）和决策规则（DR）生成断言。采用航空航天、网络与自动驾驶三个领域进行实际案例评估。

Result: 采用GP结合Ochiai公式生成的断言测试判据在准确率上远高于GP结合Tarantula、Naish和DT、DR生成的方法。其对系统flakiness具有良好鲁棒性，在四个有不稳定行为的网络与自动驾驶系统中，准确率平均仅波动4%。

Conclusion: 基于GP和Ochiai公式的断言测试判据不仅能在无需系统执行的情况下，显著提高测试准确率，还具备可解释性和对系统异常的鲁棒性，可以有效降低CPS测试成本。

Abstract: Simulation-based testing of cyber-physical systems (CPS) is costly due to the
time-consuming execution of CPS simulators. In addition, CPS simulators may be
flaky, leading to inconsistent test outcomes and requiring repeated test
re-execution for reliable test verdicts. Automated test oracles that do not
require system execution are therefore crucial for reducing testing costs.
Ideally, such test oracles should be interpretable to facilitate human
understanding of test verdicts, and they must be robust against the potential
flakiness of CPS simulators. In this article, we propose assertion-based test
oracles for CPS as sets of logical and arithmetic predicates defined over the
inputs of the system under test. Given a test input, our assertion-based test
oracle determines, without requiring test execution, whether the test passes,
fails, or if the oracle is inconclusive in predicting a verdict. We describe
two methods for generating assertion-based test oracles: one using genetic
programming~(GP) that employs well-known spectrum-based fault localization
(SBFL) ranking formulas, namely Ochiai, Tarantula, and Naish, as fitness
functions; and the other using decision trees (DT) and decision rules (DR). We
evaluate our assertion-based test oracles through case studies in the domains
of aerospace, networking and autonomous driving. We show that test oracles
generated using GP with Ochiai are significantly more accurate than those
obtained using GP with Tarantula and Naish or using DT or DR. Moreover, this
accuracy advantage remains even when accounting for the flakiness of the system
under test. We further show that the assertion-based test oracles generated by
GP with Ochiai are robust against flakiness with only 4% average variation in
their accuracy results across four different network and autonomous driving
systems with flaky behaviours.

</details>


### [12] [Deep Learning Based Concurrency Bug Detection and Localization](https://arxiv.org/abs/2508.20911)
*Zuocheng Feng,Kaiwen Zhang,Miaomiao Wang,Yiming Cheng,Yuandao Cai,Xiaofeng Li,Guanjun Liu*

Main category: cs.SE

TL;DR: 作者提出一种结合新的并发语义图与GNN的方法，不仅提升了并发错误检测的准确性，还能将错误定位到具体代码行，实验结果较现有方法有大幅提升。


<details>
  <summary>Details</summary>
Motivation: 并发错误由于多线程或分布式系统中对共享资源同步不当而引发，检测难度极大，影响软件可靠性与安全性。现有深度学习方法在数据集规模、并发语义表达、及缺乏细粒度定位支持等方面存在明显短板，亟需更优解决方案。

Method: 作者提出了一种新颖的方法：首先构建专门用于并发错误的多样化数据集；然后，结合预训练模型与异构图神经网络（GNN），提出了新的并发感知代码属性图（CCPG）以更好地表达并发语义；最后，通过GNN可解释性方法SubgraphX，实现对并发错误的精准定位，将检测到的错误映射到具体代码行。

Result: 所提方法在多样化评测设置下，准确率和精确率提升10%，召回率提升26%，均优于当前最先进的方法。

Conclusion: 本研究为并发错误检测和定位提供了有效的新方法，在性能和精度上都有显著提升，能够为调试过程提供细粒度的错误定位信息，推动了相关领域研究的进步。

Abstract: Concurrency bugs, caused by improper synchronization of shared resources in
multi-threaded or distributed systems, are notoriously hard to detect and thus
compromise software reliability and security. The existing deep learning
methods face three main limitations. First, there is an absence of large and
dedicated datasets of diverse concurrency bugs for them. Second, they lack
sufficient representation of concurrency semantics. Third, binary
classification results fail to provide finer-grained debug information such as
precise bug lines. To address these problems, we propose a novel method for
effective concurrency bug detection as well as localization. We construct a
dedicated concurrency bug dataset to facilitate model training and evaluation.
We then integrate a pre-trained model with a heterogeneous graph neural network
(GNN), by incorporating a new Concurrency-Aware Code Property Graph (CCPG) that
concisely and effectively characterizes concurrency semantics. To further
facilitate debugging, we employ SubgraphX, a GNN-based interpretability method,
which explores the graphs to precisely localize concurrency bugs, mapping them
to specific lines of source code. On average, our method demonstrates an
improvement of 10\% in accuracy and precision and 26\% in recall compared to
state-of-the-art methods across diverse evaluation settings.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [13] [Exploiting Instantiations from Paramodulation Proofs in Isabelle/HOL](https://arxiv.org/abs/2508.20738)
*Lukas Bartl,Jasmin Blanchette,Tobias Nipkow*

Main category: cs.LO

TL;DR: 文章提出了一种新工具，能自动分析Metis证明并推导变量实例化，从而提升Sledgehammer工具的成功率、效率，并增强用户对证明过程的理解。


<details>
  <summary>Details</summary>
Motivation: Metis作为Isabelle/HOL中的有序参数归结证明器，依赖外部证明工具Sledgehammer所找到的引理进行自动化证明，但原有流程对于变量替换细节的把握不够，影响证明效率与可解释性。

Method: 作者提出了一种新工具，可以分析Metis成功证明过程，自动推导出变量的替换方式（变量实例化）。

Result: 该工具能够提升Sledgehammer的证明成功率，加快Sledgehammer生成证明的速度，同时帮助用户理解为何结论能由相关引理得出。

Conclusion: 通过自动推导Metis 证明中的变量实例化，不仅增强了Sledgehammer的自动化能力，还提升了证明过程的透明度和效率。

Abstract: Metis is an ordered paramodulation prover built into the Isabelle/HOL proof
assistant. It attempts to close the current goal using a given list of lemmas.
Typically these lemmas are found by Sledgehammer, a tool that integrates
external automatic provers. We present a new tool that analyzes successful
Metis proofs to derive variable instantiations. These increase Sledgehammer's
success rate, improve the speed of Sledgehammer-generated proofs, and help
users understand why a goal follows from the lemmas.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 本文系统综述多语言偏见评估与缓解相关研究，揭示主流方法在语言覆盖和跨文化层面存在不足，强调未来需加强包容和多元。


<details>
  <summary>Details</summary>
Motivation: 多语言预训练模型在不同语言和文化背景下存在社会偏见，现有偏见评估与缓解方法对多语言场景的覆盖不足，因此需要总结现状，并推动该领域的改进。

Method: 对扩展偏见评估及缓解方法到多语言和非英语语境的最新研究进行系统性文献回顾，包括对语言多样性、文化意识、评价指标及缓解技术的分析。

Result: 研究发现主流方法在语言选择上存在偏好，多语言缓解实验稀缺，跨语言和文化的偏见基准转化存在共性问题与解决方案。基于这些发现，为未来研究提出改善包容性与文化适应性的方向。

Conclusion: 该综述指出目前多语言预训练模型仍存在与单一英语模型类似的社会偏见，并提出未来研究需提升方法的包容性和跨文化适应性。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [15] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 优化结构化提示及微调中等规模语言模型（如Gemma），能在有限数据下生成高质量的K-12多选题，效果可媲美或优于大型模型；提出的评价及流程可规模化、实用。


<details>
  <summary>Details</summary>
Motivation: 人工出题成本高且一致性差，需要自动化方法提升形态学评估类多选题的生成效率。

Method: 采用两步法：（1）对比微调后的中等规模模型（Gemma, 2B）和大模型未调优（GPT-3.5, 175B）在MCQ生成上的表现；（2）测试七种结构化提示策略（如zero-shot、few-shot、chain-of-thought等组合），用自动化指标及专家评分评估五个维度，同时用GPT-4.1模拟大规模专家评分。

Result: 结构化提示，尤其是chain-of-thought和sequential等策略结合，显著提升了Gemma模型的质量。中等规模模型Gemma在结构化提示下生成的题目，在构念契合度和教学适宜性上优于GPT-3.5 zero-shot输出，提示设计对中等模型尤为关键。

Conclusion: 结构化提示设计和高效微调能在有限数据下提升中等规模模型自动出题能力。多维评估流程（自动化+专家+大模型）有助确保题目与评测目标对齐，所述工作流程为K-12语言评测题目的规模化开发与验证提供了实用方案。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [16] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 本文提出并验证了一种开源方法，将 SystemC TLM 模型标准化封装后，无缝集成到基于 FMI 的协同仿真环境，解决了跨域系统协同仿真的关键问题。


<details>
  <summary>Details</summary>
Motivation: 随着网络物理系统尤其是汽车应用系统的复杂性增长，需要高效的建模与跨域协同仿真技术。当前 SystemC TLM 虽有助于软硬件协同设计，但与其他工程领域模型的互操作性有限，集成存在挑战。

Method: 提出了一种完全开源的方法，将 SystemC TLM 模型封装为 FMI 3.0 协同仿真功能单元（FMUs），并开发了轻量级开源工具链，主要解决时间同步和数据交换等技术难题。

Result: 通过典型案例展示，该方法能够有效将 SystemC TLM 模型集成到基于 FMI 的协同仿真流程，实现标准化跨域仿真。

Conclusion: 该研究提出了基于 FMI 3.0 协议的 SystemC TLM 跨域集成方法，有效提升了多域协同仿真的互操作性和易用性，推动了复杂网络物理系统的高效开发。

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [17] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 提出了DGPO方法，用蒸馏和教师指导提升小规模语言模型在Agentic RAG任务的能力，经实验验证方法有效且可用性强，适用于资源受限环境，部分场景下甚至优于大模型。


<details>
  <summary>Details</summary>
Motivation: 紧凑型语言模型（如0.5B参数模型）由于推理能力较弱，在利用强化学习训练获取搜索和规划等Agentic RAG行为时，面临奖励稀疏和训练不稳定的难题。作者希望解决这些小模型应用于Agentic RAG任务时的局限性。

Method: 提出了Distillation-Guided Policy Optimization（DGPO）方法，利用教师模型的演示进行冷启动初始化，并在策略优化过程中引入持续教师指导。同时，设计了Agentic RAG Capabilities（ARC）微观指标用于从推理、搜索协调和答复生成三个方面系统评价方法有效性。

Result: 实验表明，DGPO能够让紧凑型模型实现复杂的agentic搜索行为，甚至在个别场景下超越了更大规模的教师模型。该方法使得在计算资源受限环境下实现Agentic RAG具备可行性。

Conclusion: DGPO方法不仅提升了紧凑型模型在Agentic RAG任务中的表现，还证明了在资源有限条件下部署高效智能体的可能性。基于蒸馏和持续教师指导，该方法为小模型应用于复杂推理任务提供了新思路。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [18] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 该论文提出了能将高层政府AI伦理准则自动化转为测试问题的GUARD工具，有效检测大语言模型的合规性和“越狱”风险，并生成合规报告，为安全可靠的LLM应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有的政府AI伦理准则过于抽象，难以直接用于大语言模型的合规性测试，亟需一种能自动化转化准则为可操作测试问题，并系统评估模型合规性的工具和方法。

Method: 提出GUARD测试方法，将政府人工智能伦理准则自动转化为具体的违规测试问题，并通过与LLM的交互检测其合规性。引入“jailbreak诊断”即GUARD-JD，设计特殊场景诱发潜在违规行为。最后生成合规性报告。

Result: 实证结果显示，GUARD方法在七种主流LLM（如GPT-4等）上有效把关三项政府准则，并可扩展至多模态模型（视觉-语言模型），对提升LLM合规性和社会可靠性具有实际意义。

Conclusion: GUARD方法能有效将高层次人工智能伦理准则转化为具体的测试问题，实现对大语言模型（LLM）合规性的评估和报告。该方法不仅能检测直接违反准则的回复，还能通过“jailbreak”诊断识别更隐蔽的不合规风险。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [19] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR框架结合梗概提取、图结构构建与MCTS推理，有效提升了大型语言模型对长文本和复杂任务的理解及表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在处理长文本、复杂推理任务时，受到内存限制和模型本身能力的制约，容易出现幻觉和缺乏透明性的问题。

Method: 提出JERR框架，包括三大组件：1）通过策略性分块提取文本梗概，2）构建有向无环图（DAG）解决信息冗余，保证逻辑一致和清晰，3）用蒙特卡罗树搜索（MCTS）推动模型完成复杂推理。

Result: 实验结果表明，JERR框架在ROUGE和F1指标上均优于所有基线方法，并在LLM-Rater评估中取得了最高评分。

Conclusion: JERR提供了一种通过图结构推理增强LLM处理长文本和复杂推理的新方法，大幅提升了模型的可靠性和输出的可解释性。

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [20] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 本文提出以NP-hard图问题为合成语料，通过两阶段微调和强化学习，显著提升大模型的长链式推理能力，并在多个领域实现强泛化和更高效率，为后训练资源提供新拓展路径。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在复杂推理任务上取得了显著进展，但其长链式推理能力（Long CoT）需要依赖高质量的、人工精心整理的数据集进行后训练，这类数据集如数学及代码领域的数据，获取成本高且不易扩展。因此，探索可扩展且具有推理深度的替代训练资源成为了研究的动力。

Method: 提出使用NP难（NP-hard）图问题作为新型合成训练语料，因其本身具备深度推理、广泛探索及反思策略等长链式推理的核心特征。设计了两阶段后训练框架：1）对拒绝采样的NP-hard图实例进行长链式推理监督微调（SFT），提升推理深度；2）结合精细粒度奖励的强化学习（RL），提高推理效率。

Result: 新模型Graph-R1-7B在数学、编程、STEM和逻辑等多领域具有较强泛化能力，并在NP-hard图问题的准确率和推理效率上显著超越QwQ-32B模型。NP-hard图问题成为提升LLM长链式推理的新型可扩展资源。

Conclusion: 以NP-hard图问题为基础的后训练方法，不仅提升了LLM在多领域的推理能力和效率，也为后训练资源开辟了新的可扩展方向，有望推动大模型长链式推理能力的进一步发展。

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [21] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出了考虑对话历史的大模型性格评估新方法（CAPE），经过实验发现主流大模型对上下文依赖不同，GPT系列较为鲁棒而其他模型敏感，通过RPA实验证明方法贴近人类判断。


<details>
  <summary>Details</summary>
Motivation: 现有的研究在用心理测量测试评估大模型时，多采用无上下文的独立问答方法，忽略了实际应用中对话上下文对模型行为的影响。为解决该不足，本文提出新的评测框架，更贴近真实应用场景。

Method: 提出了首个考虑上下文信息的大模型性格评估框架CAPE，并设计了新的度量指标来量化模型响应的一致性。同时，进行了大量实验，分析了七个主流大模型在有无对话历史的不同情形下的表现，包括对RPA进行测试。

Result: 研究发现，对话历史可提升模型响应一致性但也可能诱发性格转变，尤其是GPT系列的偏移更显著。GPT模型对问题顺序较鲁棒，而Gemini-1.5-Flash和Llama-8B对上下文极为敏感。GPT的回答受本身性格和历史影响，而后两者几乎完全依赖上下文。应用于RPA后，文中方法提高了一致性，更符合人工判断。

Conclusion: CAPE框架能有效分析并量化上下文对大模型性格表现的影响，不同模型在一致性和性格稳定性上表现出明显差异。该框架为大模型的行为和性格评估提供了更真实、科学的新方法。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [22] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 该研究构建了判断推理步骤效用的oracle评价体系，发现推理链条件熵的变化能解释答案正确性，为未来发展更高效的LLM推理路径提供理论依据和方向。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）常通过生成中间推理步骤来提升准确性，但很少有工作探讨这些推理步骤的实际效用与最终答案正确性的关系。

Method: 对MATH数据集进行oracle研究，使用Qwen2.5-32B和GPT-4o生成推理链，再利用Qwen3-8B对推理链在最终答案准确性上的效用进行量化。具体方法为：在每一步推理拓展上下文时，测量答案区间Y上的不确定性（条件熵），以跟踪模型对最终答案的信心变化。

Result: 发现条件熵随步骤递减明显关联于正确答案，条件熵持平或递增则多为错误答案。不正确的推理路径通常较长，表明更长推理未必更好。

Conclusion: 推理步骤的效用能通过条件熵动态反映，未来可用来设计更高效的推理pipeline，通过提前检测无效推理来提升模型性能。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [23] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench公开了首个用于评估AI文本生成应用工具视觉质量的大规模基准，建立了标准流程、工具和排行榜，并促进AI驱动网页设计的透明发展。


<details>
  <summary>Details</summary>
Motivation: AI文本生成应用工具号称能在短时间内生成高质量的网站和应用，但业界缺乏公开的严谨基准来验证这些工具的实际效果。

Method: 提出了UI-Bench，这是首个大规模、通过专家成对对比评估视觉质量的AI文本生成应用工具基准，涵盖10个工具、30个提示、300个生成站点和4000+次专家评判，并利用TrueSkill模型进行排名和区间置信度校准。

Result: UI-Bench为AI驱动网页设计领域建立了可复现的、公开的评测标准，并发布了完整的提示集合、开源评估框架以及公共排行榜，未来还将公开参与者评定过的生成站点。

Conclusion: UI-Bench为评估和推动AI文本生成应用工具在网页设计中的实际表现提供了科学、公正的平台和标准，有助于行业和研究的发展。

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [24] [Unclustered BWTs of any Length over Non-Binary Alphabets](https://arxiv.org/abs/2508.20879)
*Gabriele Fici,Estéban Gabory,Giuseppe Romana,Marinella Sciortino*

Main category: cs.DM

TL;DR: 构造并证明了多元字母表下BWT最坏聚类情形，量化了其存在性和数量，下界明显不同于二进制情况。


<details>
  <summary>Details</summary>
Motivation: BWT在压缩算法中重要，通常希望其输出聚类（即同一字符聚集），该工作研究BWT输出聚类的最坏情况及相关组合结构，填补了k≥3时全不聚类情形的理论空白。

Method: 通过构造法证明了在k≥3的字母表下，总能找到长度为n的完全不聚类项链，并对这类项链的数量给出了下界证明。涉及组合数学及字符串分析方法。

Result: 证实了k≥3任意长度下均存在最坏聚类BWT，明确了与二元字母表下的巨大差异，并给出了这些结构数量的下界。这揭示BWT聚类性能受字母表大小影响。

Conclusion: 对于任何大于0的整数n和任意字母表大小k≥3，都存在长度为n的项链，其BWT完全不聚类，即有n个无相邻相同字母的run。这代表了BWT聚类的最坏情形。对于二进制（k=2）情况，是否存在无限多个完全不聚类的BWT仍是公开问题。

Abstract: We prove that for every integer $n > 0$ and for every alphabet $\Sigma_k$ of
size $k \geq 3$, there exists a necklace of length $n$ whose Burrows-Wheeler
Transform (BWT) is completely unclustered, i.e., it consists of exactly $n$
runs with no two consecutive equal symbols. These words represent the
worst-case behavior of the BWT for clustering, since the number of BWT runs is
maximized. We also establish a lower bound on their number. This contrasts with
the binary case, where the existence of infinitely many completely unclustered
BWTs is still an open problem, related to Artin's conjecture on primitive
roots.

</details>


### [25] [Enhancing Soft Happiness via Evolutionary Algorithms](https://arxiv.org/abs/2508.20934)
*Mohammad Hadi Shekarriza,Dhananjay Thiruvadya,Asef Nazari*

Main category: cs.DM

TL;DR: 本文提出了针对soft happy colouring问题的Genetic Algorithm（GA）与Memetic Algorithm（MA），并用实验验证了其有效性。MA表现优于GA，特别是在初始种群经过本地优化（例如LMC或LS）后，两种算法都可以获得更好的结果。进化算法在社区检测和寻找完全解方面均优于其他方法。


<details>
  <summary>Details</summary>
Motivation: soft happy colouring问题与图的社区结构有密切关系，且已知该问题为NP-hard。传统启发式方法虽有效，但在精度和求解能力上仍有提升空间，因此作者希望通过进化算法进一步提高$ho$-happy顶点数量和完整解的发现率。

Method: 作者设计并实现了两类进化算法（遗传算法与混合算法）用于扩展部分着色图使得$ho$-happy顶点数量最大化。针对优化初始种群，还引入了已有的本地最大着色（LMC）和局部搜索（LS）方法，并在大量随机生成的部分着色图上进行了实验对比。

Result: 实验结果表明，混合算法（Memetic Algorithm）能获得更多的$ho$-happy顶点。遗传算法若将初始种群用LMC或LS方法进行局部改进，也能表现良好。统计意义上，经过本地优化初始种群的进化算法在社区检测准确率上表现突出，并能找到最多的完整解方案。

Conclusion: 进化算法（尤其是经过本地优化的初始种群）在soft happy colouring问题上表现优异，既提升了$ho$-happy顶点数量又具备较高的社区检测能力，在找到完整着色解上优于现有启发式方法。

Abstract: For $0\leq \rho\leq 1$, a $\rho$-happy vertex $v$ in a coloured graph shares
colour with at least $\rho\mathrm{deg}(v)$ of its neighbours. Soft happy
colouring of a graph $G$ with $k$ colours extends a partial $k$-colouring to a
complete vertex $k$-colouring such that the number of $\rho$-happy vertices is
maximum among all such colouring extensions. The problem is known to be
NP-hard, and an optimal solution has a direct relation with the community
structure of the graph. In addition, some heuristics and local search
algorithms, such as {\sf Local Maximal Colouring} ({\sf LMC}) and {\sf Local
Search} ({\sf LS}), have already been introduced in the literature. In this
paper, we design Genetic and Memetic Algorithms for soft happy colouring and
test them for a large set of randomly generated partially coloured graphs.
Memetic Algorithms yield a higher number of $\rho$-happy vertices, but Genetic
Algorithms can perform well only when their initial populations are locally
improved by {\sf LMC} or {\sf LS}. Statistically significant results indicate
that both Genetic and Memetic Algorithms achieve high average accuracy in
community detection when their initial populations are enhanced using {\sf
LMC}. Moreover, among the competing methods, the evolutionary algorithms
identified the greatest number of complete solutions.

</details>


### [26] [Measuring Ransomware Lateral Movement Susceptibility via Privilege-Weighted Adjacency Matrix Exponentiation](https://arxiv.org/abs/2508.21005)
*Satyam Tyagi,Ganesh Murugesan*

Main category: cs.DM

TL;DR: 本文提出用概率图论方法评估勒索软件横向移动和影响半径，核心在于对不同服务评估枢纽潜力，有效指导隔离策略和安全投入优先级。


<details>
  <summary>Details</summary>
Motivation: 勒索软件攻击危害取决于攻击者横向移动并感染更多资产的能力，现实中网络安全防护体系亟需更有效评估横向渗透和爆炸半径（受影响范围）的方法，以指导防御措施优先级。

Method: 作者提出一种基于图论的方法，网络中的资产建模为有向多重图的节点，节点间通过对应可访问服务（如RDP/SSH端口）建立边。每种服务赋予不同的枢纽潜力系数π(s)，以概率过程模拟横向移动，通过迭代式地计算K跳内受损概率矩阵及相关指标。通过调整高风险端口可明显抑制横移和扩散。

Result: 该方法定义横向移动易感性（LMS_K）和爆炸半径估算（BRE_K）等度量，用于量化网络在特定结构与服务开放下的横向移动与资产易受危害性。实际企业快照实验显示，针对高风险服务（如SSH、RDP）对网络边的裁剪能高效降低横向攻击风险，支持现有安全标准和最佳实践。

Conclusion: 基于图论与服务枢纽的横向移动建模能有效分析与量化勒索软件威胁的扩散能力，为细粒度分段（微隔离）和优先加强防御措施提供理论依据与评估工具。

Abstract: Ransomware impact hinges on how easily an intruder can move laterally and
spread to the maximum number of assets. We present a graph-theoretic method to
measure lateral-movement susceptibility and estimate blast radius. We build a
directed multigraph where vertices represent assets and edges represent
reachable services (e.g., RDP/SSH) between them. We model lateral movement as a
probabilistic process using a pivot potential factor $\pi(s)$ for each service.
This allows us to iteratively compute a $K$-hop compromise probability matrix
that captures how compromise propagates through the network. Metrics derived
from this model include: (1) Lateral-Movement Susceptibility (LMS$_K$): the
average probability of a successful lateral movement between any two assets
(0-1 scale); and (2) Blast-Radius Estimate (BRE$_K$): the expected percentage
of assets compromised in an average attack scenario. Interactive control (SSH
22, RDP 3389) gets higher $\pi(s)$ than app-only ports (MySQL 3306, MSSQL
1433), which seldom enable pivoting without an RCE. Across anonymized
enterprise snapshots, pruning high-$\pi(s)$ edges yields the largest
LMS$_K$/BRE$_K$ drop, aligning with CISA guidance, MITRE ATT\&CK (TA0008:
Lateral Movement), and NIST SP~800-207. The framework evaluates
(micro)segmentation and helps prioritize controls that reduce lateral movement
susceptibility and shrink blast radius.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [27] [Formal equivalence between global optimization consistency and random search](https://arxiv.org/abs/2508.20671)
*Gaëtan Serré*

Main category: cs.FL

TL;DR: 正式证明了只有“全搜索空间采样”的随机迭代全局优化算法才在Lipschitz函数上是一致的，方法基于L$\exists$$\forall$N定理证明器和概率测度工具。


<details>
  <summary>Details</summary>
Motivation: 在全局优化领域，确定什么条件下随机和迭代的全局优化算法在Lipschitz连续函数上是一致的，是理论与实践的基础问题，作者欲以形式化手段严谨阐明一致性条件。

Method: 利用L$\exists$$\forall$N定理证明系统和Mathlib库，对随机和迭代全局优化算法一致性的证明进行形式化。通过定义算法为一组初始概率测度和马尔可夫核序列，并使用Ionescu-Tulcea定理构建在有限及无限迭代序列上的概率测度。

Result: 证明了只要且仅当算法能采样整个搜索空间时，其对Lipschitz连续函数的全局优化是一致的。

Conclusion: 该工作给出了一个统一且可正式化的框架，为全局优化算法一致性的理论研究提供了坚实基础。算法只有在搜索空间全覆盖时才能保证一致性。

Abstract: We formalize a proof that any stochastic and iterative global optimization
algorithm is consistent over Lipschitz continuous functions if and only if it
samples the whole search space. To achieve this, we use the
L$\exists$$\forall$N theorem prover and the Mathlib library. The major
challenge of this formalization, apart from the technical aspects of the proof
itself, is to converge to a definition of a stochastic and iterative global
optimization algorithm that is both general enough to encompass all algorithms
of this type and specific enough to be used in a formal proof. We define such
an algorithm as a pair of an initial probability measure and a sequence of
Markov kernels that describe the distribution of the next point sampled by the
algorithm given the previous points and their evaluations. We then construct a
probability measure on finite and infinite sequences of iterations of the
algorithm using the Ionescu-Tulcea theorem.

</details>


### [28] [Evaluating Massively Parallel Algorithms for DFA Minimisation, Equivalence Checking and Inclusion Checking](https://arxiv.org/abs/2508.20735)
*Jan Heemstra,Jan Martens,Anton Wijs*

Main category: cs.FL

TL;DR: 在GPU上并行化DFA最小化与等价性检查，传统最优算法不适用，分区细化算法更实用，新算法和并行Hopcroft-Karp在实践中有突出表现。


<details>
  <summary>Details</summary>
Motivation: DFA最小化和等价性检查在自动机理论和实际应用中很重要，利用GPU的并行计算能力有望加速这些任务，但不同算法在并行环境下表现差异未知。

Method: 在GPU上实现并实验四种大规模并行DFA最小化算法，包括基于分区细化和传递闭包的新算法。并分析并行Hopcroft-Karp算法及其与GPUexplore结合。

Result: 理论上最佳时间复杂度的算法在GPU上表现不佳，分区细化类算法实际更快。新算法在特定任务下优于现有方法。DFA等价性算法可GPU并行并接入GPUexplore。

Conclusion: 并行DFA最小化理论上最优的算法在GPU上并不高效，实际效果更好的是并行分区细化算法。文中提出的新分区细化+并行部分传递闭包的算法在某些基准测试上有更好的性能。DFA等价性检查的Hopcroft-Karp算法也可并行化，相关问题可用GPUexplore实现。

Abstract: We study parallel algorithms for the minimisation and equivalence checking of
Deterministic Finite Automata (DFAs). Regarding DFA minimisation, we implement
four different massively parallel algorithms on Graphics Processing
Units~(GPUs). Our results confirm the expectations that the algorithm with the
theoretically best time complexity is not practically suitable to run on GPUs
due to the large amount of resources needed. We empirically verify that
parallel partition refinement algorithms from the literature perform better in
practice, even though their time complexity is worse. Furthermore, we introduce
a novel algorithm based on partition refinement with an extra parallel partial
transitive closure step and show that on specific benchmarks it has better
run-time complexity and performs better in practice.
  In addition, we address checking the language equivalence and inclusion of
two DFAs. We consider the Hopcroft-Karp algorithm, and explain how a variant of
it can be parallelised for GPUs. We note that these problems can be encoded for
the GPU-accelerated model checker \GPUexplore, allowing the use its lockless
hash table and fine-grained parallel work distribution mechanism.

</details>
