<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: 提出了用范畴论统一描述和推广 Howe 方法的理论框架，从而在概率性高阶语言等新的场景下，自动保证最大行为一致性为共轭，进而简化了余归纳推理的适配和验证。


<details>
  <summary>Details</summary>
Motivation: 随着带有定量特性的编程语言（如概率性语言）的兴起，传统的余归纳(coinduction)方法需要扩展以支持更精细的行为一致性如行为距离（behavioural distance）等。但保证余归纳推理的正确性，需要证明行为一致性（conformance）在程序语言操作中的兼容性（即形成共轭/congruence），而现有方法（如 Howe 方法）繁琐且需针对具体场景多次适配。

Method: 作者提出了一种统一的范畴论框架来推广 Howe 方法：第一，提出了抽象高阶规范（AHOS）来泛化描述高阶语言的操作语义；第二，通过在 AHOS 基范畴上的纤维化（fibration）手段来建模行为一致性（如关系、度量）。主要工作是在这种高度抽象的层面上提出并证明了一个基本的共轭定理。

Result: 在上述统一范畴论框架和自然条件下，证明了其下的最大行为一致性关系（如最大双仿射关系、行为伪度量）形成共轭。通过对概率性高阶语言的双仿射性及行为伪度量，为理论提供了具体实例佐证。

Conclusion: 文章为复杂语言和高级行为一致性定义了一种通用且高度抽象的方法，不仅简化了 Howe 方法的适配过程，而且大大提升了剩余归纳方法在不同语言和度量下的适用性和可扩展性。

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations](https://arxiv.org/abs/2507.17930)
*Vahid Garousi,Zafar Jafarov*

Main category: cs.SE

TL;DR: 论文基于企业实地观察，提出了AI辅助软件工程的过程模型和决策框架，关注人-机协作下的实际决策与优化过程，提高开发效率和质量。


<details>
  <summary>Details</summary>
Motivation: 尽管AI工具如GitHub Copilot和ChatGPT正不断改变软件开发方式，但软件工程师在日常任务中如何实际与这些AI工具交互（比如信任、修正或拒绝AI输出的决策过程）还缺乏深入研究。

Method: 通过分析相关从业者报告以及对三家企业的实地观察，总结归纳出一套AI辅助软件工程活动的过程模型和一个二维决策框架。

Result: 提出了一个现实的AI辅助软件工程过程模型（包括提示设计、结果检查、备选方案和优化步骤），以及一个帮助开发者在节省精力与输出质量之间权衡的二维决策框架。模型在实际环境下经过验证，能有效指导AI在软件开发中的应用。

Conclusion: 该论文提出了两种模型，为AI辅助软件工程中的实际应用和决策过程提供了结构化的指导。模型基于对土耳其和阿塞拜疆三个行业环境的观察，有助于工程师更有效地利用AI工具，并促进了实际人机协作的讨论。

Abstract: Artificial Intelligence (AI) has the potential to transform Software
Engineering (SE) by enhancing productivity, efficiency, and decision support.
Tools like GitHub Copilot and ChatGPT have given rise to "vibe coding"-an
exploratory, prompt-driven development style. Yet, how software engineers
engage with these tools in daily tasks, especially in deciding whether to
trust, refine, or reject AI-generated outputs, remains underexplored. This
paper presents two complementary contributions. First, a pragmatic process
model capturing real-world AI-assisted SE activities, including prompt design,
inspection, fallback, and refinement. Second, a 2D decision framework that
could help developers reason about trade-offs between effort saved and output
quality. Grounded in practitioner reports and direct observations in three
industry settings across Turkiye and Azerbaijan, our work illustrates how
engineers navigate AI use with human oversight. These models offer structured,
lightweight guidance to support more deliberate and effective use of AI tools
in SE, contributing to ongoing discussions on practical human-AI collaboration.

</details>


### [3] [Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work](https://arxiv.org/abs/2507.17991)
*Peter Eckmann,Adrian Barnett,Alexandra Bannach-Brown,Elisa Pilar Bascunan Atria,Guillaume Cabanac,Louise Delwen Owen Franzen,Małgorzata Anna Gazda,Kaitlyn Hair,James Howison,Halil Kilicoglu,Cyril Labbe,Sarah McCann,Vladislav Nachev,Martijn Roelandse,Maia Salholz-Hillel,Robert Schulz,Gerben ter Riet,Colby Vorland,Anita Bandrowski,Tracey Weissgerber*

Main category: cs.SE

TL;DR: 本研究广泛评估了11种自动化工具在科研报告严谨性标准检测中的表现，结果显示某些标准下有显著优劣分化，多工具协作可进一步提升覆盖率，并针对工具开发和推广提出了建设性建议。


<details>
  <summary>Details</summary>
Motivation: 为应对科学研究复现性危机，尤其是手动勾选清单（如ARRIVE与CONSORT）未能被广泛执行，以及同行评审遗漏问题，分析自动化工具在改进报告标准化和透明度中的作用。

Method: 对来自ScreenIT小组的11种自动化工具在9项不同的严谨性标准上进行了广泛对比分析。

Result: 发现某些标准下有明显优胜的工具，部分标准下多工具组合优于单一工具，并指出了需改进的重点方向；为工具开发和使用方提供了具体建议。

Conclusion: 自动化工具在某些严谨性标准（如开放数据的检测）上表现突出，但在其他方面（如入选/排除标准的检测）则需要多工具组合。论文最后对工具开发者和相关方提出了改进建议。

Abstract: The causes of the reproducibility crisis include lack of standardization and
transparency in scientific reporting. Checklists such as ARRIVE and CONSORT
seek to improve transparency, but they are not always followed by authors and
peer review often fails to identify missing items. To address these issues,
there are several automated tools that have been designed to check different
rigor criteria. We have conducted a broad comparison of 11 automated tools
across 9 different rigor criteria from the ScreenIT group. We found some
criteria, including detecting open data, where the combination of tools showed
a clear winner, a tool which performed much better than other tools. In other
cases, including detection of inclusion and exclusion criteria, the combination
of tools exceeded the performance of any one tool. We also identified key areas
where tool developers should focus their effort to make their tool maximally
useful. We conclude with a set of insights and recommendations for stakeholders
in the development of rigor and transparency detection tools. The code and data
for the study is available at https://github.com/PeterEckmann1/tool-comparison.

</details>


### [4] [An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges](https://arxiv.org/abs/2507.18029)
*Xiang Echo Chen,Wenhan Zhu,Guoshuai Albert Shi,Michael W. Godfrey*

Main category: cs.SE

TL;DR: 本研究通过分析Github开源游戏项目的issue，比较了生成式AI、传统AI及非AI话题，揭示了生成式AI在实际开发中独特的使用模式和开发挑战，丰富了对生成式AI在游戏工业中实际作用的理解。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GenAI）能力的提升正重塑游戏设计与开发流程，但关于GenAI在现实开源开发中的应用和讨论，仍缺乏实证研究。研究动机在于填补GenAI如何被开源游戏开发者采纳与集成的知识空白。

Method: 以Github上的开源游戏项目为对象，采集涉及AI相关主题的issue，采用开放卡片分类（open card sorting）与主题分析（thematic analysis），对比分析GenAI、传统AI（TradAI）与非AI话题。对issue内容进行逐项标注，揭示不同AI类型的讨论模式与开发难点。

Result: 研究获得了GenAI相关issue在工具使用、任务类型、面临挑战等方面的具体数据，对比了GenAI、TradAI和NonAI话题在开发者关注点、使用模式及集成实践上的差异。发现GenAI在开发流程和痛点上具有明显特征，与传统方法存在区别。

Conclusion: 开源游戏开发者们对GenAI的应用和讨论已初具规模，GenAI与传统AI相比，在集成方式、开发难点和开发者关注点等方面表现出不同特征。

Abstract: The growing capabilities of generative AI (GenAI) have begun to reshape how
games are designed and developed, offering new tools for content creation,
gameplay simulation, and design ideation. While prior research has explored
traditional uses of AI in games, such as controlling agents or generating
procedural content. There is limited empirical understanding of how GenAI is
adopted by developers in real-world contexts, especially within the open-source
community. This study aims to explore how GenAI technologies are discussed,
adopted, and integrated into open-source game development by analyzing issue
discussions on GitHub. We investigate the tools, tasks, and challenges
associated with GenAI by comparing GenAI-related issues to those involving
traditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI
differs from other approaches in terms of usage patterns, developer concerns,
and integration practices. To address this objective, we construct a dataset of
open-source game repositories that discuss AI-related topics. We apply open
card sorting and thematic analysis to a stratified sample of GitHub issues,
labelling each by type and content. These annotations enable comparative
analysis across GenAI, TradAI, and NonAI groups, and provide insight into how
GenAI is shaping the workflows and pain points of open-source game developers.

</details>


### [5] [Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping](https://arxiv.org/abs/2507.18037)
*Sivana Hamer,Jacob Bowen,Md Nazmul Haque,Chris Madden,Laurie Williams*

Main category: cs.SE

TL;DR: 该文基于MITRE ATT&CK和P-SSCRM框架，利用四项独立策略，实现多框架攻击应对任务的映射，帮助软件组织明晰供应链安全防护举措。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击日益频繁，企业需要有效的方法来识别和管理相关风险。当前多个安全框架内容分散，缺乏系统的对应和整合，难以支撑一体化防护。本文旨在为软件组织提供一套能够系统应对攻击技术的任务映射方案，提升供应链安全能力。

Method: 通过四种独立策略，对MITRE ATT&CK攻击技术与P-SSCRM（主动软件供应链风险管理框架）任务进行映射。每个P-SSCRM任务进一步与十个主要政府和行业框架的任务建立关联，从而构建起多框架之间的统一映射体系。

Result: 实现了MITRE ATT&CK与P-SSCRM以及其它10个主流框架的任务映射，为软件组织明确如何通过不同任务和措施减缓具体的软件供应链攻击提供了系统支持。

Conclusion: 通过多策略的映射方法，将主流攻击技术与供应链风险管理的具体对策挂钩，为组织建立跨框架的安全实践和攻防对应关系，显著提升了供应链攻击防护的可操作性和体系化水平。

Abstract: The MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK)
Attack Technique to Proactive Software Supply Chain Risk Management Framework
(P-SSCRM) Task mapping described in this document helps software organizations
to determine how different tasks mitigate the attack techniques of software
supply chain attacks. The mapping was created through four independent
strategies to find agreed-upon mappings. Because each P-SSCRM task is mapped to
one or more tasks from the 10 frameworks, the mapping we provide is also a
mapping between MITRE ATT&CK and other prominent government and industry
frameworks.

</details>


### [6] [Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey](https://arxiv.org/abs/2507.18039)
*Ahmad D. Suleiman,Yiming Tang,Daqing Hou*

Main category: cs.SE

TL;DR: 本文调查了影响计算类课程教师采用基于项目的学习（PjBL）的因素，发现主要障碍为项目设计难、缺乏支持和资源。制度激励、同行协作和获取合适项目可促进PjBL的采用。建议学校提供系统性支持以推广PjBL。


<details>
  <summary>Details</summary>
Motivation: PjBL（基于项目的学习）作为一种以学生为中心的教学方法，在提高学生的积极性、参与度、批判性思维、协作和问题解决能力方面有突出优势，但其在软件工程及计算机课程中的教师采用率并不理想。研究动机是揭示造成这种采用率低的原因，以及探索促进采用的方法和资源。

Method: 本文采用混合方法研究。通过在线问卷向80名计算机教师收集数据，包括封闭式问题用于量化障碍、推动因素和资源需求，以及开放式问题获得定性洞见。定量数据采用统计分析，定性数据则进行主题分析。

Result: 研究发现，虽然教师普遍认可PjBL的价值，但其采用往往是选择性的，受到课程规划与管理难度、项目设计难、缺乏制度支持（时间、经费和助教等）等因素影响。有同行协作、专业发展支持和制度激励时，教师更可能采用或持续使用PjBL。同时，从科研、行业合作及同行借用项目为新项目获取提供了关键支持。

Conclusion: 系统性支持结构，包括同行协作、专业发展和制度激励等，对于促进教师采用和扩大PjBL实践具有重要作用。需要从制度层面为教师探索和实践PjBL提供更多支持。

Abstract: This research full paper investigates the factors influencing computing
educators' adoption of project-based learning (PjBL) in software engineering
and computing curricula. Recognized as a student-centered pedagogical approach,
PjBL has the potential to enhance student motivation, engagement, critical
thinking, collaboration, and problem-solving skills. Despite these benefits,
faculty adoption remains inconsistent due to challenges such as insufficient
institutional support, time constraints, limited training opportunities,
designing or sourcing projects, and aligning them with course objectives. This
research explores these barriers and investigates the strategies and resources
that facilitate a successful adoption. Using a mixed-methods approach, data
from 80 computing faculty were collected through an online survey comprising
closed-ended questions to quantify barriers, enablers, and resource needs,
along with an open-ended question to gather qualitative insights. Quantitative
data were analyzed using statistical methods, while qualitative responses
underwent thematic analysis. Results reveal that while PjBL is widely valued,
its adoption is often selective and impacted by challenges in planning and
managing the learning process, designing suitable projects, and a lack of
institutional support, such as time, funding, and teaching assistants. Faculty
are more likely to adopt or sustain PjBL when they have access to peer
collaboration, professional development, and institutional incentives. In
addition, sourcing projects from research, industry partnerships, and borrowing
from peers emerged as key facilitators for new projects. These findings
underscore the need for systemic support structures to empower faculty to
experiment with and scale PjBL practices.

</details>


### [7] [An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows](https://arxiv.org/abs/2507.18062)
*Edward Abrokwah,Taher A. Ghaleb*

Main category: cs.SE

TL;DR: 本文分析了大量GitHub Actions工作流，发现其复杂性较高、遵循最佳实践程度不一，且不同语言的CI设计有所不同。建议CI服务加强文档和示例，推动工作流规范化和简化。


<details>
  <summary>Details</summary>
Motivation: 尽管GHA官方文档和社区提供了大量最佳实践指导，但实际上开源项目的CI工作流是否遵循这些实践尚缺乏实证研究。部分工作流可能不必要地复杂，偏离了CI应有的简洁目标。

Method: 本文基于大规模的GHA工作流数据集，涵盖Java、Python与C++等多种语言的开源库，进行结构、复杂度、多样性及规范性分析。具体方法包括模式识别、复杂度分析及合规性评估。

Result: 研究发现，部分仓库良好遵守了GHA最佳实践，但也有不少工作流结构复杂、多样且存在合规性不足的现象。不同编程语言在CI设计上也表现出一定差异。研究还提出，GHA及其他CI服务应优化文档与案例，帮助开发者更好地理解和应用最佳实践。

Conclusion: 本研究揭示了GitHub Actions（GHA）在开源项目中的实际使用情况，包括对最佳实践的遵守度以及存在的改进空间。研究结果指出，部分工作流存在复杂度过高或与CI简洁性目标不符的情况。

Abstract: Continuous Integration (CI) has evolved from a tooling strategy to a
fundamental mindset in modern CI engineering. It enables teams to develop,
test, and deliver software rapidly and collaboratively. Among CI services,
GitHub Actions (GHA) has emerged as a dominant service due to its deep
integration with GitHub and a vast ecosystem of reusable workflow actions.
Although GHA provides official documentation and community-supported best
practices, there appears to be limited empirical understanding of how
open-source real-world CI workflows align with such practices. Many workflows
might be unnecessarily complex and not aligned with the simplicity goals of CI
practices. This study will investigate the structure, complexity,
heterogeneity, and compliance of GHA workflows in open-source software
repositories. Using a large dataset of GHA workflows from Java, Python, and C++
repositories, our goal is to (a) identify workflow complexities, (b) analyze
recurring and heterogeneous structuring patterns, (c) assess compliance with
GHA best practices, and (d) uncover differences in CI pipeline design across
programming languages. Our findings are expected to reveal both areas of strong
adherence to best practices and areas for improvement where needed. These
insights will also have implications for CI services, as they will highlight
the need for clearer guidelines and comprehensive examples in CI documentation.

</details>


### [8] [Identifier Name Similarities: An Exploratory Study](https://arxiv.org/abs/2507.18081)
*Carol Wong,Mai Abe,Silvia De Benedictis,Marissa Halim,Anthony Peruma*

Main category: cs.SE

TL;DR: 论文指出名称相似性会影响代码理解与合作，提出了标识符名称相似性的初步分类法，为未来相关问题的研究提供了参考。


<details>
  <summary>Details</summary>
Motivation: 标识符名称在代码理解中起着关键作用，但不恰当或相似的名称会增加认知负担、妨碍合作。之前研究通常关注单个名称的可读性，较少关注相似名称间的混淆问题。作者希望探讨这一被忽视的风险。

Method: 本文采用探索性研究，分析软件项目中标识符名称相似性出现的情况，并据此开发出一种对不同类型名称相似性进行分类的初步分类法（taxonomy）。

Result: 研究初步提出了一套标识符名称相似性的分类法，可以反映名称相似性在结构或功能层面上的多种表现形式。

Conclusion: 初步分类法有助于为后续分析标识符名称相似性对代码理解、可维护性和团队协作的影响提供理论基础，并为进一步完善和扩展分类体系奠定基础。

Abstract: Identifier names, which comprise a significant portion of the codebase, are
the cornerstone of effective program comprehension. However, research has shown
that poorly chosen names can significantly increase cognitive load and hinder
collaboration. Even names that appear readable in isolation may lead to
misunderstandings in contexts when they closely resemble other names in either
structure or functionality. In this exploratory study, we present our
preliminary findings on the occurrence of identifier name similarity in
software projects through the development of a taxonomy that categorizes
different forms of identifier name similarity. We envision our initial taxonomy
providing researchers with a platform to analyze and evaluate the impact of
identifier name similarity on code comprehension, maintainability, and
collaboration among developers, while also allowing for further refinement and
expansion of the taxonomy.

</details>


### [9] [Understanding the Supply Chain and Risks of Large Language Model Applications](https://arxiv.org/abs/2507.18105)
*Yujie Ma,Lili Quan,Xiaofei Xie,Qiang Hu,Jiongchi Yu,Yao Zhang,Sen Chen*

Main category: cs.SE

TL;DR: 本研究建立了首个LLM供应链安全评测数据集，通过对真实应用的依赖结构和漏洞分析，发现LLM应用存在深层依赖和多点安全漏洞，强调LLM系统需从供应链全局进行综合安全防护。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）广泛应用于不同领域，但其供应链日益复杂。现有风险评估通常局限于模型或数据层面，容易忽略整个供应链中的安全漏洞，相关系统性研究也缺乏标准化基准。

Method: 提出并构建了首个系统性的LLM供应链安全分析与评测数据集。收集了3,859个真实世界LLM应用，进行了关联性分析，涵盖109,211个模型、2,474个数据集和9,862个第三方库。同时从公开漏洞库收集了1,555个安全风险事件，并对其进行梳理和风险评估。

Result: 揭示了LLM应用中存在多层嵌套的组件依赖结构，以及供应链各环节均存在较大安全隐患。通过数据分析，发现真实应用广泛依赖第三方模型、库和数据集，供应链脆弱性明显。

Conclusion: LLM系统的安全性需从全供应链视角进行综合评估与防护。论文提出了提高LLM系统安全性和可信度的实用建议，呼吁业界制定标准、加强依赖关系管理，并持续开展供应链安全研究。

Abstract: The rise of Large Language Models (LLMs) has led to the widespread deployment
of LLM-based systems across diverse domains. As these systems proliferate,
understanding the risks associated with their complex supply chains is
increasingly important. LLM-based systems are not standalone as they rely on
interconnected supply chains involving pretrained models, third-party
libraries, datasets, and infrastructure. Yet, most risk assessments narrowly
focus on model or data level, overlooking broader supply chain vulnerabilities.
While recent studies have begun to address LLM supply chain risks, there
remains a lack of benchmarks for systematic research.
  To address this gap, we introduce the first comprehensive dataset for
analyzing and benchmarking LLM supply chain security. We collect 3,859
real-world LLM applications and perform interdependency analysis, identifying
109,211 models, 2,474 datasets, and 9,862 libraries. We extract model
fine-tuning paths, dataset reuse, and library reliance, mapping the ecosystem's
structure. To evaluate security, we gather 1,555 risk-related issues-50 for
applications, 325 for models, 18 for datasets, and 1,229 for libraries from
public vulnerability databases.
  Using this dataset, we empirically analyze component dependencies and risks.
Our findings reveal deeply nested dependencies in LLM applications and
significant vulnerabilities across the supply chain, underscoring the need for
comprehensive security analysis. We conclude with practical recommendations to
guide researchers and developers toward safer, more trustworthy LLM-enabled
systems.

</details>


### [10] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
*Le Deng,Zhonghao Jiang,Jialun Cao,Michael Pradel,Zhongxin Liu*

Main category: cs.SE

TL;DR: 本文提出NoCode-bench基准，用以系统评估LLM在实际无代码开发任务中的表现，结果显示最新LLM完成率仅15.79%，远不能满足自然语言驱动开发需求。该基准为进一步研究提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）虽然具备将自然语言指令转换为代码的能力，但在实际无代码开发场景（即用自然语言指定功能而非编写代码）下，其效果和能力仍不明确，尤其是在真实项目和较大规模数据下缺乏客观评测基准。

Method: 作者提出并发布了NoCode-bench基准，涵盖了634个真实软件项目中的NL驱动特性添加任务，每个任务包括文档更新和代码实现，并由开发者测试用例校验。此外，抽取了114个人工验证的高质量子集（NoCode-bench Verified）以保证评测结果的可靠性。使用这些数据评估了当前主流LLM的性能。

Result: 实验显示，即使是最先进的LLM也仅在15.79%的任务上成功完成，暴露了其在跨文件编辑、整体代码库理解和工具调用方面的不足。

Conclusion: 目前的LLM尚无法胜任完全由自然语言驱动的无代码开发任务，NoCode-bench为后续相关研究和能力提升提供了标准和基础。

Abstract: Natural language-driven no-code development allows users to specify software
functionality using natural language (NL) instead of editing source code,
promising increased productivity and democratized development. Large language
models (LLMs) show potential in enabling this paradigm. In this context,
software documentation acts as an NL specification for functionality. This work
introduces NoCode-bench, a benchmark designed to evaluate LLMs on real-world
NL-driven feature addition tasks, consisting of 634 tasks across 10 projects
and 114k code changes. Each task pairs documentation updates with corresponding
code implementations, validated by developer-written test cases. A subset of
114 high-quality, human-verified instances, NoCode-bench Verified, ensures
reliable evaluation. Our experiments reveal that, despite high token usage, the
best LLMs achieve a task success rate of only 15.79%, highlighting challenges
in cross-file editing, codebase understanding, and tool calling. These findings
indicate that LLMs are not yet ready for fully NL-driven no-code development.
NoCode-bench lays the foundation for future advances in this area.

</details>


### [11] [SMECS: A Software Metadata Extraction and Curation Software](https://arxiv.org/abs/2507.18159)
*Stephan Ferenz,Aida Jafarbigloo,Oliver Werth,Astrid Nieße*

Main category: cs.SE

TL;DR: 本文提出并验证了一种元数据提取与管理工具SMECS，极大减轻了科研软件元数据创建负担，提高了软件的FAIR化水平。


<details>
  <summary>Details</summary>
Motivation: 高质量元数据是实现FAIR原则（可查找、可访问、可互操作、可重用）的基础，但元数据的创建对科研人员和研发工程师来说耗时耗力，存在实际困难。

Method: 研发了一款软件工具SMECS（Software Metadata Extraction and Curation Software），能够从如GitHub等在线代码库自动提取元数据，并通过交互式界面让用户完善和管理元数据，最后生成标准化CodeMeta文件。

Result: 通过易用性实验评估，SMECS被证实具有良好的用户体验，能够帮助用户更高效地创建和整理软件元数据。

Conclusion: SMECS有效简化了科研软件元数据的生成过程，支持软件FAIR化目标，提升了元数据的可用性与再用性。

Abstract: Metadata play a crucial role in adopting the FAIR principles for research
software and enables findability and reusability. However, creating
high-quality metadata can be resource-intensive for researchers and research
software engineers. To address this challenge, we developed the Software
Metadata Extraction and Curation Software (SMECS) which integrates the
extraction of metadata from existing sources together with a user-friendly
interface for metadata curation. SMECS extracts metadata from online
repositories such as GitHub and presents it to researchers through an
interactive interface for further curation and export as a CodeMeta file. The
usability of SMECS was evaluated through usability experiments which confirmed
that SMECS provides a satisfactory user experience. SMECS supports the
FAIRification of research software by simplifying metadata creation.

</details>


### [12] [GenAI for Automotive Software Development: From Requirements to Wheels](https://arxiv.org/abs/2507.18223)
*Nenad Petrovic,Fengjunjie Pan,Vahid Zolfaghari,Krzysztof Lebioda,Andre Schamschurko,Alois Knoll*

Main category: cs.SE

TL;DR: 本文提出了一种结合生成式AI和大语言模型的自动化ADAS车载软件开发流程，能够自动从需求生成模型、测试场景及实现代码，提升开发及测试效率，缩短上市周期。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶和高级驾驶辅助系统（ADAS）软件开发流程耗时较长、合规性验证复杂，急需高效自动化的开发和测试方法。

Method: 提出基于生成式人工智能（GenAI）的自动化车载软件开发方法。流程包括：以需求为输入，借助大语言模型（LLM）进行模型化需求摘要（如Ecore元模型、XMI模型实例与OCL约束生成），自动生成测试场景模拟代码（Python）、目标平台实现代码（C++），并利用检索增强生成（RAG）机制充分利用法规文档辅助生成测试场景。采用模型驱动工程（MDE）手段进行需求一致性检查。

Result: 实验结果表明，该方法能够自动生成测试用例和目标实现代码，显著缩短ADAS系统开发、测试与合规验证周期。

Conclusion: 通过引入GenAI和LLM，方法有效提升了ADAS软件的自动化开发与测试效率，实现了更快的合规和重构循环，降低了整体开发与验证成本。

Abstract: This paper introduces a GenAI-empowered approach to automated development of
automotive software, with emphasis on autonomous and Advanced Driver Assistance
Systems (ADAS) capabilities. The process starts with requirements as input,
while the main generated outputs are test scenario code for simulation
environment, together with implementation of desired ADAS capabilities
targeting hardware platform of the vehicle connected to testbench. Moreover, we
introduce additional steps for requirements consistency checking leveraging
Model-Driven Engineering (MDE). In the proposed workflow, Large Language Models
(LLMs) are used for model-based summarization of requirements (Ecore metamodel,
XMI model instance and OCL constraint creation), test scenario generation,
simulation code (Python) and target platform code generation (C++).
Additionally, Retrieval Augmented Generation (RAG) is adopted to enhance test
scenario generation from autonomous driving regulations-related documents. Our
approach aims shorter compliance and re-engineering cycles, as well as reduced
development and testing time when it comes to ADAS-related capabilities.

</details>


### [13] [An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs](https://arxiv.org/abs/2507.18267)
*Zeqin Liao,Zibin Zheng,Peifan Reng,Henglong Liang,Zixu Gao,Zhixiang Chen,Wei Li,Yuhong Nan*

Main category: cs.SE

TL;DR: 本文首次系统性地分析了885个EAIR系统缺陷，揭示了其独有的症状和成因，并建立了缺陷成因与系统模块的映射关系，有助于提升EAIR缺陷检测和修复效率。


<details>
  <summary>Details</summary>
Motivation: EAIR（具身人工智能机器人）领域技术迅速发展，但目前缺乏对其系统缺陷（bug）的深入和系统性了解，进而影响了相应检测和修复技术的发展。

Method: 作者首次对80个EAIR项目中收集的885个系统缺陷进行了系统性研究，分析了其症状、根本原因及分布模块，对缺陷进行了详细分类。

Result: 发现了15种症状、18种根本原因、13个受影响模块，并识别出8种EAIR特有的症状和8种EAIR特有的根本原因。研究还建立了缺陷原因与模块的映射关系，为缺陷预测和修复提供参考。

Conclusion: 本研究为EAIR系统缺陷的识别、预测和修复奠定了基础，为未来相关研究提供了新视角和理论基础。

Abstract: Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly
evolving technological domain. Ensuring their program correctness is
fundamental to their successful deployment. However, a general and in-depth
understanding of EAIR system bugs remains lacking, which hinders the
development of practices and techniques to tackle EAIR system bugs.
  To bridge this gap, we conducted the first systematic study of 885 EAIR
system bugs collected from 80 EAIR system projects to investigate their
symptoms, underlying causes, and module distribution. Our analysis takes
considerable effort, which classifies these bugs into 18 underlying causes, 15
distinct symptoms, and identifies 13 affected modules. It reveals several new
interesting findings and implications which help shed light on future research
on tackling or repairing EAIR system bugs. First, among the 15 identified
symptoms, our findings highlight 8 symptoms specific to EAIR systems, which is
characterized by severe functional failures and potential physical hazards.
Second, within the 18 underlying causes, we define 8 EAIR-specific causes, the
majority of which stem from the intricate issues of AI- agent reasoning and
decision making. Finally, to facilitate precise and efficient bug prediction,
detection, and repair, we constructed a mapping between underlying causes and
the modules in which they most frequently occur, which enables researchers to
focus diagnostic efforts on the modules most susceptible to specific bug types.

</details>


### [14] [Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling](https://arxiv.org/abs/2507.18289)
*Yan Li,Wenzhang Yang,Yuekun Wang,Jian Gao,Shaohua Wang,Yinxing Xue,Lijun Zhang*

Main category: cs.SE

TL;DR: Scheduzz利用大语言模型实现有效的API组合和驱动调度，提升了库模糊测试的效率和质量，显著超越多项现有技术，在真实项目中发现了大量新漏洞。


<details>
  <summary>Details</summary>
Motivation: 库模糊测试（fuzzing）需要专家深入理解库的用法并手工编写高质量的fuzz驱动程序，这一过程繁琐且复杂。当前自动生成fuzz驱动的技术无法很好地遵循库使用规范，因此生成了大量不合理的驱动，浪费算力并产生虚假的漏洞报告。

Method: 提出了一种新颖的基于大语言模型（LLM）的自动库模糊测试技术Scheduzz。它利用LLM理解合理的库使用，并提取API组合约束。引入双调度框架，将API组合与fuzz驱动管理建模为在线优化问题，实现驱动生成和fuzz测试过程的高效调度和资源优化。

Result: Scheduzz在33个真实库中进行了评测，相比现有方法，显著减少计算资源开销。在21个库中，Scheduzz在16个上优于UTopia；总覆盖率比CKGFuzzer、Promptfuzz和人工OSS-Fuzz分别高1.62x、1.50x和1.89x。Scheduzz还发现了33个新漏洞，有3个获得CVE。

Conclusion: Scheduzz通过LLM理解库使用方式并优化API组合与驱动调度，大幅提升了自动库模糊测试的效率和覆盖率，发现了更多高价值漏洞，证明了其在实际中的有效性和先进性。

Abstract: Fuzzing a library requires experts to understand the library usage well and
craft high-quality fuzz drivers, which is tricky and tedious. Therefore, many
techniques have been proposed to automatically generate fuzz drivers. However,
they fail to generate rational fuzz drivers due to the lack of adherence to
proper library usage conventions, such as ensuring a resource is closed after
being opened. To make things worse, existing library fuzzing techniques
unconditionally execute each driver, resulting in numerous irrational drivers
that waste computational resources while contributing little coverage and
generating false positive bug reports.
  To tackle these challenges, we propose a novel automatic library fuzzing
technique, Scheduzz, an LLM-based library fuzzing technique. It leverages LLMs
to understand rational usage of libraries and extract API combination
constraints. To optimize computational resource utilization, a dual scheduling
framework is implemented to efficiently manage API combinations and fuzz
drivers. The framework models driver generation and the corresponding fuzzing
campaign as an online optimization problem. Within the scheduling loop,
multiple API combinations are selected to generate fuzz drivers, while
simultaneously, various optimized fuzz drivers are scheduled for execution or
suspension.
  We implemented Scheduzz and evaluated it in 33 real-world libraries. Compared
to baseline approaches, Scheduzz significantly reduces computational overhead
and outperforms UTopia on 16 out of 21 libraries. It achieves 1.62x, 1.50x, and
1.89x higher overall coverage than the state-of-the-art techniques CKGFuzzer,
Promptfuzz, and the handcrafted project OSS-Fuzz, respectively. In addition,
Scheduzz discovered 33 previously unknown bugs in these well-tested libraries,
3 of which have been assigned CVEs.

</details>


### [15] [YATE: The Role of Test Repair in LLM-Based Unit Test Generation](https://arxiv.org/abs/2507.18316)
*Michael Konstantinou,Renzo Degiovanni,Jie M. Zhang,Mark Harman,Mike Papadakis*

Main category: cs.SE

TL;DR: YATE通过修复LLM生成的错误单元测试，大幅提升了代码覆盖率和缺陷检测效果，超越了多种同类方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于语言模型的自动化测试生成虽然有效，但生成的测试用例中存在大量语法或语义错误，不加利用直接丢弃是一种资源浪费。

Method: 提出了一种结合规则驱动静态分析和二次提示（re-prompting）的简单修复技术，并在六个开源项目上进行了实验。

Result: 该方法命名为YATE，实验证明YATE相比仅用语言模型的基线方法，平均多覆盖32.06%的代码行，消除21.77%的变异体，且覆盖率、杀死变异体等核心指标均大幅优于HITS、SYMPROMPT、TESTSPARK和COVERUP等四种现有LLM测试生成方法。

Conclusion: 通过对不正确自动化单元测试的修复，可以显著提升基于语言模型的自动化测试生成工具的有效性和测试价值，尤其是在无须显著增加算力消耗（LLM调用次数）的情况下。

Abstract: Recent advances in automated test generation utilises language models to
produce unit tests. While effective, language models tend to generate many
incorrect tests with respect to both syntax and semantics. Although such
incorrect tests can be easily detected and discarded, they constitute a "missed
opportunity" -- if fixed, they are often valuable as they directly add testing
value (they effectively target the underlying program logic to be tested) and
indirectly form good seeds for generating additional tests. To this end, we
propose a simple technique for repairing some of these incorrect tests through
a combination of rule-based static analysis and re-prompting. We evaluate this
simple approach, named YATE, on a set of 6 open-source projects and show that
it can effectively produce tests that cover on average 32.06% more lines and
kill 21.77% more mutants than a plain LLM-based method. We also compare YATE
with four other LLM-based methods, namely HITS, SYMPROMPT, TESTSPARK and
COVERUP and show that it produces tests that cover substantially more code.
YATE achieves 22% higher line coverage, 20% higher branch coverage and kill 20%
more mutants at a comparable cost (number of calls to LLMs).

</details>


### [16] [Gotta catch 'em all! Towards File Localisation from Issues at Large](https://arxiv.org/abs/2507.18319)
*Jesse Maarleveld,Jiapan Guo,Daniel Feitosa*

Main category: cs.SE

TL;DR: 分析了issue文件定位任务，发现目前的方法对一般issue效果有限，呼吁开发更通用且可项目定制的定位模型。


<details>
  <summary>Details</summary>
Motivation: 尽管长期以来人们致力于bug定位以节省开发者的时间，但现有的大多数文件定位研究主要聚焦于bug，对于其他类型issue的研究较少。作者希望拓展到所有类型的issue，填补现有研究主要关注bug这一不足。

Method: 构建了一个数据处理管道，用于生成能够适应任意分支与合并实践的issue文件定位数据集，对现有信息检索方法进行了基线实验评估，并运用统计分析研究已知的bug定位偏差对新数据集的影响。

Result: 结果显示，基于bug特有启发式方法在处理一般issue时表现较差，说明需要开发通用模型。不同类型issue间虽存在细微但有统计显著的效果差别；大多数issue类型下标识符对结果的影响较小。许多结果依赖于具体项目，提示需针对项目特性调优方法。

Conclusion: 现有文件定位方法在处理非bug issue时效果受限，需开发能适应不同类型issue和不同项目特性的通用方案。项目间差异和部分已知偏差会影响定位表现。

Abstract: Bug localisation, the study of developing methods to localise the files
requiring changes to resolve bugs, has been researched for a long time to
develop methods capable of saving developers' time. Recently, researchers are
starting to consider issues outside of bugs. Nevertheless, most existing
research into file localisation from issues focusses on bugs or uses other
selection methods to ensure only certain types of issues are considered as part
of the focus of the work. Our goal is to work on all issues at large, without
any specific selection.
  In this work, we provide a data pipeline for the creation of issue file
localisation datasets, capable of dealing with arbitrary branching and merging
practices. We provide a baseline performance evaluation for the file
localisation problem using traditional information retrieval approaches.
Finally, we use statistical analysis to investigate the influence of biases
known in the bug localisation community on our dataset.
  Our results show that methods designed using bug-specific heuristics perform
poorly on general issue types, indicating a need for research into general
purpose models. Furthermore, we find that there are small, but statistically
significant differences in performance between different issue types. Finally,
we find that the presence of identifiers have a small effect on performance for
most issue types. Many results are project-dependent, encouraging the
development of methods which can be tuned to project-specific characteristics.

</details>


### [17] [FMI Meets SystemC: A Framework for Cross-Tool Virtual Prototyping](https://arxiv.org/abs/2507.18339)
*Nils Bosbach,Meik Schmidt,Lukas Jünger,Matthias Berthold,Rainer Leupers*

Main category: cs.SE

TL;DR: 该文提出了让SystemC虚拟平台支持FMI协同仿真的新框架，并通过温度传感器案例验证了该方法能提升软件测试的广度和真实度。


<details>
  <summary>Details</summary>
Motivation: 随着系统日益复杂，对全面测试和虚拟原型的需求提升。当前系统仿真通常需多工具协同，涵盖硬件与外部环境。SystemC虽是VP（虚拟平台）开发主流，但缺乏与FMI（功能建模接口）的原生集成，导致难以与更广泛的协同仿真环境结合。

Method: 提出一种新框架，使SystemC虚拟平台能通过FMI进行控制和交互。以温度传感器为案例，在SystemC中通过FMI从外部工具获取温度数据，实现无修改目标软件下接收真实环境数据。

Result: 成功展示了SystemC VP通过FMI与外部工具交互，实现了软件的环境感知输入，提升了软件测试的现实性和范围。

Conclusion: 该方法增强了SystemC平台与外部仿真工具的兼容性，实现了未修改目标软件条件下的更真实、更广泛的软件验证，提高开发效率、促进认证流程提前进行。

Abstract: As systems become more complex, the demand for thorough testing and virtual
prototyping grows. To simulate whole systems, multiple tools are usually needed
to cover different parts. These parts include the hardware of a system and the
environment with which the system interacts. The Functional Mock-up Interface
(FMI) standard for co-simulation can be used to connect these tools.
  The control part of modern systems is usually a computing unit, such as a
System-on-a-Chip (SoC) or Microcontroller Unit (MCU), which executes software
from a connected memory and interacts with peripherals. To develop software
without requiring access to physical hardware, full-system simulators, the
so-called Virtual Platforms (VPs), are commonly used. The IEEE-standardized
framework for VP development is SystemC TLM. SystemC provides interfaces and
concepts that enable modular design and model exchange. However, SystemC lacks
native FMI support, which limits the integration into broader co-simulation
environments.
  This paper presents a novel framework to control and interact with
SystemC-based VPs using the FMI. We present a case study showing how a
simulated temperature sensor in a SystemC simulation can obtain temperature
values from an external tool via FMI. This approach allows the unmodified
target software to run on the VP and receive realistic environmental input data
such as temperature, velocity, or acceleration values from other tools. Thus,
extensive software testing and verification is enabled. By having tests ready
and the software pre-tested using a VP once the physical hardware is available,
certifications like ISO 26262 can be done earlier.

</details>


### [18] [Automated Code Review Using Large Language Models with Symbolic Reasoning](https://arxiv.org/abs/2507.18476)
*Busra Icoz,Goksel Biricik*

Main category: cs.SE

TL;DR: 本文提出将符号推理与大语言模型结合以提升代码审查自动化，实验结果显示此方法能显著提升准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 代码审查在软件开发生命周期中至关重要，但手动审查效率低且主观性强。虽然具备规则性的代码审查适合自动化，但现有大型语言模型（LLMs）在逻辑推理和代码理解上仍存在不足。

Method: 本文提出将符号推理技术与大型语言模型（LLMs）结合的混合方法，实现自动化代码审查。研究中采用CodexGlue数据集，比较了CodeT5、CodeBERT和GraphCodeBERT等模型，通过结合符号推理和提示技术评估其有效性。

Result: 实验结果表明，融合符号推理与LLMs的方法可以提升自动化代码审查的准确性和效率。

Conclusion: 结合符号推理与大型语言模型能够有效弥补现有自动化代码审查的不足，提高代码审查的效果。

Abstract: Code review is one of the key processes in the software development lifecycle
and is essential to maintain code quality. However, manual code review is
subjective and time consuming. Given its rule-based nature, code review is well
suited for automation. In recent years, significant efforts have been made to
automate this process with the help of artificial intelligence. Recent
developments in Large Language Models (LLMs) have also emerged as a promising
tool in this area, but these models often lack the logical reasoning
capabilities needed to fully understand and evaluate code. To overcome this
limitation, this study proposes a hybrid approach that integrates symbolic
reasoning techniques with LLMs to automate the code review process. We tested
our approach using the CodexGlue dataset, comparing several models, including
CodeT5, CodeBERT, and GraphCodeBERT, to assess the effectiveness of combining
symbolic reasoning and prompting techniques with LLMs. Our results show that
this approach improves the accuracy and efficiency of automated code review.

</details>


### [19] [A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat](https://arxiv.org/abs/2507.18515)
*Zezhou Yang,Ting Peng,Cuiyun Gao,Chaozheng Wang,Hailiang Huang,Yuetang Deng*

Main category: cs.SE

TL;DR: 本文在微信大规模闭源代码库中，系统评估了RAG方法在代码补全中的效果，发现similarity-based RAG优于identifier-based，词法和语义检索结合效果最好，并已通过开发者调查验证实际价值。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）快速发展，代码补全任务得到了显著提升，但现有RAG方法多在开源仓库上验证，而开源与闭源（如工业级代码库）间的分布差异带来新挑战，这一问题尚未被深入探讨。

Method: 作者在微信这一大型闭源软件系统的内部代码库中，系统性地评估了RAG（identifier-based与similarity-based两类）在代码补全任务中的表现，覆盖从0.5B到671B参数规模的26个开源LLM，并对similarity-based RAG采用多种检索技术（词法与语义检索）进行全面分析。此外，还结合开发者调查验证其实际应用价值。

Result: （1）两类RAG方法在闭源代码库中均有效，similarity-based RAG表现更优；（2）随着检索技术升级，similarity-based RAG效果提升，BM25（词法）与GTE-Qwen（语义）分别表现出色；（3）词法与语义检索结合可进一步提升效果，二者优势互补。开发者调查验证了RAG方法在真实开发场景的实用性。

Conclusion: RAG方法不仅在开源，也能在大型闭源代码库如微信中有效提升代码补全，其中类似度检索结合词法与语义技术效果最佳，对实际开发有显著帮助。

Abstract: Code completion, a crucial task in software engineering that enhances
developer productivity, has seen substantial improvements with the rapid
advancement of large language models (LLMs). In recent years,
retrieval-augmented generation (RAG) has emerged as a promising method to
enhance the code completion capabilities of LLMs, which leverages relevant
context from codebases without requiring model retraining. While existing
studies have demonstrated the effectiveness of RAG on public repositories and
benchmarks, the potential distribution shift between open-source and
closed-source codebases presents unique challenges that remain unexplored. To
mitigate the gap, we conduct an empirical study to investigate the performance
of widely-used RAG methods for code completion in the industrial-scale codebase
of WeChat, one of the largest proprietary software systems. Specifically, we
extensively explore two main types of RAG methods, namely identifier-based RAG
and similarity-based RAG, across 26 open-source LLMs ranging from 0.5B to 671B
parameters. For a more comprehensive analysis, we employ different retrieval
techniques for similarity-based RAG, including lexical and semantic retrieval.
Based on 1,669 internal repositories, we achieve several key findings: (1) both
RAG methods demonstrate effectiveness in closed-source repositories, with
similarity-based RAG showing superior performance, (2) the effectiveness of
similarity-based RAG improves with more advanced retrieval techniques, where
BM25 (lexical retrieval) and GTE-Qwen (semantic retrieval) achieve superior
performance, and (3) the combination of lexical and semantic retrieval
techniques yields optimal results, demonstrating complementary strengths.
Furthermore, we conduct a developer survey to validate the practical utility of
RAG methods in real-world development environments.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [20] [Program Logics via Distributive Monoidal Categories](https://arxiv.org/abs/2507.18238)
*Filippo Bonchi,Elena Di Lavore,Mario Román,Sam Staton*

Main category: cs.LO

TL;DR: 本文利用范畴理论，提出了统一的程序逻辑框架，在同一理论下推导出多种主流的程序逻辑，并构建了相应推理工具和组合子。


<details>
  <summary>Details</summary>
Motivation: 目前关于程序正确性、错误性以及关系推理的程序逻辑往往分散构建，缺乏统一理论基础，作者希望用范畴理论统一推导并优化这些逻辑的表达。

Method: 作者基于命令式范畴（imperative categories）提出一种内部语言，并以此为基础推导出改编后的Dijkstra守卫命令语言的组合子及各类程序逻辑的推导规则。

Result: 成功推导出各种经典程序逻辑，并给出基于内部语言的推理规则和组合子，其表达和推导能力高度一致。

Conclusion: 论文通过范畴理论（具体为imperative categories的公理体系），统一推导出关于命令式程序的各种逻辑（正确性、错误性以及关系Hoare逻辑），充分显示了该范畴框架的抽象能力和统一性。

Abstract: We derive multiple program logics, including correctness, incorrectness, and
relational Hoare logic, from the axioms of imperative categories: uniformly
traced distributive copy-discard categories. We introduce an internal language
for imperative multicategories, on top of which we derive combinators for an
adaptation of Dijkstra's guarded command language. Rules of program logics are
derived from this internal language.

</details>


### [21] [Resourceful Traces for Commuting Processes](https://arxiv.org/abs/2507.18246)
*Matthew Earnshaw,Chad Nester,Mario Román*

Main category: cs.LO

TL;DR: 将Mazurkiewicz trace中的动作从简单名字提升为输入到输出的变换，从而为有副作用的范畴构建了新颖的代数表达和图形化演算，并用以刻画资源可交换条件下的系统组合。


<details>
  <summary>Details</summary>
Motivation: 现有Mazurkiewicz trace在理论计算机科学中通常只把动作当作原子操作（单纯的名字），未能充分表达动作之间的输入输出变换关系。作者希望通过丰富trace的结构，更好地刻画有副作用的范畴（effectful categories）的语义。

Method: 作者将Mazurkiewicz trace中的动作视为从特定输入类型到输出类型的变换，而非仅仅是名字。基于此，提出了一种effectful categories的新展示方式（即广义Freyd范畴的新表述），并发展出类似图形演算的表示方法。

Result: 提出了一种对effectful categories的新颖的‘presentation’，并以图形化方式进行推导。利用这种新方法，作者构造了自由effectful categories的交换张量积，实现了在动作互相交换的条件下系统的组合，同时仍允许资源的交换。

Conclusion: 该工作丰富了Mazurkiewicz trace和effectful categories的理论基础，为具有副作用的计算语义给出了新的代数表达和可视化工具，对系统组合的研究具有应用潜力。

Abstract: We show that, when the actions of a Mazurkiewicz trace are considered not
merely as atomic (i.e., mere names) but transformations from a specified type
of inputs to a specified type of outputs, we obtain a novel notion of
presentation for effectful categories (also known as generalised Freyd
categories), a well-known algebraic structure in the semantics of
side-effecting computation. Like the usual representation of traces as graphs,
our notion of presentation gives rise to a graphical calculus for effectful
categories. We use our presentations to give a construction of the commuting
tensor product of free effectful categories, capturing the combination of
systems in which the actions of each must commute with one another, while still
permitting exchange of resources

</details>


### [22] [Distributing Retractions, Weak Distributive Laws and Applications to Monads of Hyperspaces, Continuous Valuations and Measures](https://arxiv.org/abs/2507.18418)
*Jean Goubault-Larrecq*

Main category: cs.LO

TL;DR: 通过引入分配收缩结构，本文提供了组合两个幺半态的新刻画方法，且与弱分配律完全对应。本文所得理论在拓扑与概率相关的幺半态中有具体应用。


<details>
  <summary>Details</summary>
Motivation: 在范畴论中，将两个幺半态（monad）结合成一个新的幺半态是重要的构造，但在存在弱分配律（weak distributive law）时，如何显式描述和识别得到的组合幺半态尚有难度。本文旨在提供对组合幺半态的精确刻画与识别方法。

Method: 本文提出了组合幺半态$U$的识别准则：只需展现一个我们称之为“分配收缩”（distributing retraction）的结构，将$ST$映射到$U$。进一步，作者在二范畴（2-categorical）框架下，证明了“分配收缩”与“弱分配律”是一一对应的关系。本文还举了三个实例，涉及超线性与次线性前视幺半态等具体结构。

Result: 建立了分配收缩和弱分配律之间的等价性，提出了识别组合幺半态$U$的新方法。在紧豪斯多夫空间上，将相关幺半态与经典结构（如Vietoris和Radon幺半态）联系起来，并推断其组合幺半态为normalized forks。由此描述了超线性/次线性前视幺半态的代数。

Conclusion: 本文突破性地提出了通过分配收缩识别组合幺半态的方法，明确了弱分配律与分配收缩之间的结构对应关系，并将其应用于具体的拓扑与概率结构，丰富了范畴论中幺半态结合的理论体系。

Abstract: Given two monads $S$, $T$ on a category where idempotents split, and a weak
distributive law between them, one can build a combined monad $U$. Making
explicit what this monad $U$ is requires some effort. When we already have an
idea what $U$ should be, we show how to recognize that $U$ is indeed the
combined monad obtained from $S$ and $T$: it suffices to exhibit what we call a
distributing retraction of $ST$ onto $U$. We show that distributing retractions
and weak distributive laws are in one-to-one correspondence, in a 2-categorical
setting. We give three applications, where $S$ is the Smyth, Hoare or Plotkin
hyperspace monad, $T$ is a monad of continuous valuations, and $U$ is a monad
of previsions or of forks, depending on the case. As a byproduct, this allows
us to describe the algebras of monads of superlinear, resp. sublinear
previsions. In the category of compact Hausdorff spaces, the Plotkin hyperspace
monad is sometimes known as the Vietoris monad, the monad of probability
valuations coincides with the Radon monad, and we infer that the associated
combined monad is the monad of normalized forks.

</details>


### [23] [Well-Founded Coalgebras Meet König's Lemma](https://arxiv.org/abs/2507.18539)
*Henning Urbat,Thorsten Wißmann*

Main category: cs.LO

TL;DR: 本文在协代数框架下推广了König引理，证明了良基协代数为有限生成良基子协代数的有向并，并提出了两种新的初始代数构造方法，扩展了该引理在拓扑、名集合、凸系统等更一般结构中的适用范围。


<details>
  <summary>Details</summary>
Motivation: König引理在数学和计算机科学中有广泛应用，该引理在传统上涉及有限分支的树和无穷路径。作者希望将这一引理推广到更一般的范畴和代数结构，并探究其在范畴论和协代数理论中的表现和应用。

Method: 作者提出了König引理的协代数版本。具体地，从有限分支树推广到任意有限变量自函子的协代数结构，并从集合范畴推广到任何局部有限呈示的范畴（如偏序集、名集合、凸集合），利用范畴论与协代数理论进行抽象分析和证明。还提出了初始代数的两种新构造方式，并给出相关正确性证明。

Result: 在一定条件下，证明了每个对于自函子H的良基协代数可以表示为其有限生成状态空间的良基子协代数的有向并，因而良基协代数组成的范畴是局部可呈示的。同时，推出初始代数等价于所有有限可呈现状态空间的良基或递归协代数的余极限。这一结论在良基协代数严格包含于递归协代数的场景下依然成立。还推出了关于拓扑、名集合、凸系统的König引理推广。

Conclusion: 本文提出了König引理的协代数泛化，不仅在理论上丰富了协代数结构下的有限性刻画，还带来了初始代数新构造方式与相关范畴的应用推广，为后续在更多结构和领域内的数学推理和建模打下基础。

Abstract: K\"onig's lemma is a fundamental result about trees with countless
applications in mathematics and computer science. In contrapositive form, it
states that if a tree is finitely branching and well-founded (i.e. has no
infinite paths), then it is finite. We present a coalgebraic version of
K\"onig's lemma featuring two dimensions of generalization: from finitely
branching trees to coalgebras for a finitary endofunctor H, and from the base
category of sets to a locally finitely presentable category C, such as the
category of posets, nominal sets, or convex sets. Our coalgebraic K\"onig's
lemma states that, under mild assumptions on C and H, every well-founded
coalgebra for H is the directed join of its well-founded subcoalgebras with
finitely generated state space -- in particular, the category of well-founded
coalgebras is locally presentable. As applications, we derive versions of
K\"onig's lemma for graphs in a topos as well as for nominal and convex
transition systems. Additionally, we show that the key construction underlying
the proof gives rise to two simple constructions of the initial algebra
(equivalently, the final recursive coalgebra) for the functor H: The initial
algebra is both the colimit of all well-founded and of all recursive coalgebras
with finitely presentable state space. Remarkably, this result holds even in
settings where well-founded coalgebras form a proper subclass of recursive
ones. The first construction of the initial algebra is entirely new, while for
the second one our approach yields a short and transparent new correctness
proof.

</details>


### [24] [Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications](https://arxiv.org/abs/2507.18567)
*Ruben Gamboa,Panagiotis Manolios*

Main category: cs.LO

TL;DR: ACL2 Workshop是ACL2定理证明器领域的主要论坛，推动了其学术与工业影响力，并为其开发者赢得了ACM软件系统奖。


<details>
  <summary>Details</summary>
Motivation: 介绍ACL2 Workshop系列会议作为ACL2定理证明器用户的核心交流论坛。强调ACL2定理证明器作为工业级自动推理系统的重要性和应用。

Method: 通过举办工作坊会议，促进ACL2用户和研究者分享与探讨基于ACL2定理证明器的研究与应用。

Result: ACL2及其家族的定理证明器获得了业界与学术界的高度认可，其成果获得2005年ACM软件系统奖。

Conclusion: ACL2 Workshop系列持续推动了ACL2定理证明器及其实用性的学术与工业发展，证明了其在自动化定理证明领域的重要地位。

Abstract: The ACL2 Workshop series is the major technical forum for users of the ACL2
theorem proving system to present research related to the ACL2 theorem prover
and its applications. ACL2 is an industrial-strength automated reasoning
system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM
Software System Award was awarded to Boyer, Kaufmann, and Moore for their work
on ACL2 and the other theorem provers in the Boyer-Moore family.

</details>


### [25] [Approximate SMT Counting Beyond Discrete Domains](https://arxiv.org/abs/2507.18612)
*Arijit Shaw,Kuldeep S. Meel*

Main category: cs.LO

TL;DR: 该论文提出了针对混合 SMT 公式的哈希近似模型计数器 pact，效率与成功率显著优于现有离散变量方法，为 SMT 领域模型计数提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: SMT 求解器已经被广泛应用于自动推理，但现有关于模型计数的方法（如 bit-blasting）仅适用于离散变量，面对混合 SMT 公式时效果显著受限，因此需要扩展 SMT 求解器在混合域的模型计数能力。

Method: 提出了一种称为 pact 的 SMT 模型计数器，基于哈希的近似模型计数法，通过对投影变量进行对数次数的 SMT 调用，并采用优化的哈希函数设计，实现对混合 SMT 公式的近似解的理论保证估计。

Result: pact 在基准测试中表现出显著性能提升，在 14,202 个案例中，pact 能成功完成 603 个实例，而基线方法仅完成了 13 个实例。

Conclusion: pact 能够有效扩展 SMT 求解器对混合公式下的模型计数能力，大幅提升性能，克服了传统模型计数技术仅能处理离散变量的问题。

Abstract: Satisfiability Modulo Theory (SMT) solvers have advanced automated reasoning,
solving complex formulas across discrete and continuous domains. Recent
progress in propositional model counting motivates extending SMT capabilities
toward model counting, especially for hybrid SMT formulas. Existing approaches,
like bit-blasting, are limited to discrete variables, highlighting the
challenge of counting solutions projected onto the discrete domain in hybrid
formulas.
  We introduce pact, an SMT model counter for hybrid formulas that uses
hashing-based approximate model counting to estimate solutions with theoretical
guarantees. pact makes a logarithmic number of SMT solver calls relative to the
projection variables, leveraging optimized hash functions. pact achieves
significant performance improvements over baselines on a large suite of
benchmarks. In particular, out of 14,202 instances, pact successfully finished
on 603 instances, while Baseline could only finish on 13 instances.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [26] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: 本文提出针对在线购物环境下人类行为仿真的Shop-R1 RL框架，通过分阶段奖励促使LLM学到更强推理与决策能力，实验结果显示显著优于传统SFT方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究利用LLM生成解释性推理提升模型推理和下游动作预测表现，但最终效果受制于生成推理的模型本身推理能力，难以突破瓶颈。

Method: 提出了Shop-R1强化学习框架，将行为模拟任务拆分为推理生成和动作预测两阶段，分别用不同奖励信号优化。推理阶段采用模型内部信号（如logit分布）自监督引导；动作预测阶段利用分层且难度自适应的奖励结构，既评估高层动作类型，也细致考察子动作细节，按难度分配奖励。

Result: 在仿真在线购物环境下，该方法相较基线实现了超过65%的性能提升。

Conclusion: Shop-R1显著提升了LLM在仿真真实人类行为任务中的推理能力和动作预测表现。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [27] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: DG-PRM通过奖励树与帕累托优势等机制，实现了过程奖励建模的动态化与泛化，显著提升任务表现与跨域适应力。


<details>
  <summary>Details</summary>
Motivation: 当前的PRM方法多基于启发式，难以跨领域泛化，同时现有LLM作为评判者的方法通常只关注反馈结果，忽略了过程文本中的关键信息，静态且粗粒度的评价方式也无法适应复杂过程监督。针对这些痛点，提出更具动态性和泛化能力的PRM方案。

Method: DG-PRM方法主要包括：1）引入奖励树结构，存储细粒度、多维度的奖励标准；2）动态选择奖励信号、逐步奖励评分；3）首次采用帕累托优势估计对多样奖励信号进行判别性配对。

Result: DG-PRM在主流基准任务上获得了显著性能提升，在奖励密集的任务中有效提升模型表现；此外，在超出分布（out-of-distribution）场景下也具有很好的泛化能力。

Conclusion: DG-PRM展现出强大的性能和卓越的泛化能力，能够为复杂任务中的大语言模型提供更有效的过程奖励信号。

Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [28] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

TL;DR: 论文提出了VeriMinder系统，用于自动检测和缓解自然语言数据分析中的认知偏差。通过用户实验证明，本系统能有效提升问题质量，优于现有替代方案，并已作为开源工具发布。


<details>
  <summary>Details</summary>
Motivation: 越来越多的人通过自然语言接口查询数据库进行数据分析，但许多用户缺乏统计分析背景，容易提出带有偏见的问题。现有研究多关注于文本到SQL的准确性，鲜少关注用户分析问题中的认知偏差。

Method: 提出了VeriMinder系统，通过三大创新方法自动检测并缓解分析问题中的偏见：(1) 语境相关的语义映射框架，识别与具体分析场景相关的偏见；(2) 运用“难以变更性”原则，引导用户进行系统化分析；(3) 优化大语言模型流程，通过多候选、批判反馈与自我反思生成高质量任务型提示。

Result: 用户实验表明，82.5%的参与者认为VeriMinder有助于提升分析质量。相比替代方案，该系统在具体性、全面性和准确性方面至少高出20%。作为MIT开源项目发布，便于社区进一步研究与应用。

Conclusion: VeriMinder显著降低了自然语言数据分析过程中“提出错误问题”的风险，为不同背景用户提供了更高质量的数据问答体验，并促进公平、可靠的数据分析研究。

Abstract: Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [29] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 提出端到端多任务自动口语评测系统，无需转录，准确率高、效率优，适合大规模应用。


<details>
  <summary>Details</summary>
Motivation: 自动口语评测系统通常需要为每个回答部分分别建模且依赖于转录文本，效率低下且难以扩展到大规模语言学习应用。

Method: 提出了端到端方法，将受试者所有四个口语作答一次性输入Whisper-small编码器，经轻量聚合器整合后输出总分，无需转录及分部建模；并提出了新的数据采样策略以提升在数据不平衡情况下的训练效率。

Result: 在2025 Speak & Improve Challenge中，该系统以至多168M参数实现0.384的RMSE，优于文本基线的0.44，用不到一半的数据（44.8%）训练仍达0.383RMSE。

Conclusion: 所提出方法有效提升了自动口语评测的精度并显著提高效率，在大规模应用中具有实际价值。

Abstract: We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [30] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

TL;DR: 目前主流AI检测工具对DeepSeek生成文本的识别能力参差且易受改写攻击影响。人性化对抗攻击能大幅降低识别效果，而利用少样本与思维链技术则可显著提升检测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的广泛应用，自动生成文本的识别和写作诚信问题日益突出。现有检测工具针对新兴LLM（如DeepSeek）的有效性以及在对抗攻击下的鲁棒性鲜有研究。本文旨在填补有关DeepSeek生成文本检测效果的研究空白。

Method: 作者收集了49组LLM出现前的人类问答样本及其用DeepSeek-v3生成的对应AI文本。使用AI检测器（AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, GPTZero）在原始、同义改写和“人性化”改写后，对共245份样本进行检测。还尝试了利用DeepSeek作为“检测器”，以少样本提示和思维链推理进行自我文本判别。

Result: QuillBot与Copyleaks在原始及改写文本检测上表现接近完美，其余检测器表现参差不齐。当采用“人性化”改写等最具有效性的对抗攻击时，准确率明显下降（Copyleaks降至71%，QuillBot降至58%，GPTZero降至52%）。而DeepSeek结合五次少样本与CoT提示方法，仅误判1例（AI recall 96%，human recall 100%）。

Conclusion: 主流检测工具在面对DeepSeek生成文本，尤其是出现高度“人性化”改写后，识别准确率显著下降，部分检测器表现不稳定。采用先进的少样本与思维链推理技术可大幅提升检测准确率。当前检测技术在新型LLM对抗攻击下仍有待提升。

Abstract: Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [31] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 作者提出BCC指标系统性分析了不同规模语言模型在'信念'更新上的贝叶斯一致性，发现更大模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 研究者希望了解更大、更强大的语言模型在接受新证据时，是否能更一致地按照贝叶斯定理更新其'信念'。

Method: 提出了贝叶斯一致性系数（BCC）指标，并构建了专门的数据集，通过该指标评估五类预训练语言模型在不同参数规模、训练数据量和常见基准测试下的表现。

Result: 研究发现，参数规模更大、能力更强的预训练语言模型在概率分配的一致性上与贝叶斯定理更加匹配。

Conclusion: 论文证实大模型在更新'信念'时更符合贝叶斯定理，对理解和治理大语言模型具有重要意义。

Abstract: Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [32] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

TL;DR: 本综述系统梳理了提格利尼亚语NLP十余年进展，总结资源建设推动和未来研究方向，并开放数据资源，助力后续发展。


<details>
  <summary>Details</summary>
Motivation: 提格利尼亚语为数百万民众所使用，但在自然语言处理（NLP）研究中极度稀缺。该研究旨在系统梳理提格利尼亚语的NLP进展，补充语言技术发展中的空白。

Method: 对2011-2025年40余篇相关研究文献进行系统性综述，归纳了提格利尼亚语NLP在十个下游任务（如形态处理、机器翻译、语音识别、问答等）中的资源、模型与应用发展。

Result: 揭示了提格利尼亚语NLP研究从规则基础系统逐步转向神经网络架构，突破多伴随着资源建设；归纳了该语言复杂形态结构与资源稀缺带来的主要挑战，并提出了如形态感知建模、跨语言迁移、社区主导资源开发等未来发展方向。

Conclusion: 本文为提格利尼亚语NLP研究提供了系统综述和未来发展路线图，并公开了一个详细的研究与资源元数据集，为该领域研究提供了参考和基础设施。

Abstract: Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


### [33] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
*Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: TeleChat新系列模型通过改进训练和持续优化，在推理、代码和数学任务上达到甚至超过主流封闭模型的水平，同时采用开放策略供社区使用。


<details>
  <summary>Details</summary>
Motivation: 现有的TeleChat模型在性能上有局限性，需要大幅优化以适应复杂任务和多样化应用。研究者希望通过改进训练策略来获得更强大的模型，以提升在推理、编码和数学等任务上的表现。

Method: 主要采用改进的预训练（涵盖10万亿高质量多样化tokens）、监督微调（SFT）、直接偏好优化（DPO）、以及面向特定领域的持续预训练和强化学习（RL），针对不同模型版本（TeleChat2、TeleChat2.5、T1）优化各自性能。

Result: 新一代模型（TeleChat2, TeleChat2.5, T1）在推理、编码和数学任务上取得显著提升，尤其T1-115B在复杂推理和代码生成方面超过了OpenAI的o1-mini和GPT-4o等专有模型。TeleChat2.5则在保持高性能的同时，显著提升了推理速度。所有这些模型均基于115B参数的稠密Transformer结构，并公开发布多个参数规模的后训练版本。

Conclusion: 研究展示了一系列通过优化训练流程与架构调整取得实际性能领先的开放式大语言模型，尤其在复杂推理和数理任务上实现了对知名商用模型的超越，并以开放方式赋能开发者和研究人员。

Abstract: We introduce the latest series of TeleChat models: \textbf{TeleChat2},
\textbf{TeleChat2.5}, and \textbf{T1}, offering a significant upgrade over
their predecessor, TeleChat. Despite minimal changes to the model architecture,
the new series achieves substantial performance gains through enhanced training
strategies in both pre-training and post-training stages. The series begins
with \textbf{TeleChat2}, which undergoes pretraining on 10 trillion
high-quality and diverse tokens. This is followed by Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO) to further enhance its
capabilities. \textbf{TeleChat2.5} and \textbf{T1} expand the pipeline by
incorporating a continual pretraining phase with domain-specific datasets,
combined with reinforcement learning (RL) to improve performance in code
generation and mathematical reasoning tasks. The \textbf{T1} variant is
designed for complex reasoning, supporting long Chain-of-Thought (CoT)
reasoning and demonstrating substantial improvements in mathematics and coding.
In contrast, \textbf{TeleChat2.5} prioritizes speed, delivering rapid
inference. Both flagship models of \textbf{T1} and \textbf{TeleChat2.5} are
dense Transformer-based architectures with 115B parameters, showcasing
significant advancements in reasoning and general task performance compared to
the original TeleChat. Notably, \textbf{T1-115B} outperform proprietary models
such as OpenAI's o1-mini and GPT-4o. We publicly release \textbf{TeleChat2},
\textbf{TeleChat2.5} and \textbf{T1}, including post-trained versions with 35B
and 115B parameters, to empower developers and researchers with
state-of-the-art language models tailored for diverse applications.

</details>


### [34] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
*Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu*

Main category: cs.CL

TL;DR: 本文提出NeuralDB，通过神经KV数据库和门控检索机制，实现了对大模型知识高效、批量、不损其通用能力的编辑，能扩展至10万事实，性能优异，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLMs）的知识编辑目前依赖于耗时的重新训练，缺乏高效的、多事实批量编辑能力。现有的Locate-and-Edit（L&E）等方法虽然能批量编辑，但存在影响LLMs通用能力与出现编辑遗忘的问题，因此需要一种既高效又不损害模型整体性能的新方法。

Method: 本文将现有线性L&E方法建模为Key-Value（KV）数据库查询，并提出了NeuralDB框架，将已编辑事实明确存储为神经KV数据库，并配备非线性的门控检索模块。该检索模块仅在人类推理涉及编辑事实时激活，从而在保证编辑效率的同时有效保护模型的通用能力。

Result: NeuralDB在ZsRE和CounterFacts数据集、GPT2-XL、GPT-J（6B）、Llama-3（8B）等主流模型上进行1万条事实编辑实验后，表现出卓越的编辑效率、泛化能力、特异性、流畅性和一致性，并且在六个代表性NLP任务上总体性能无明显损失。规模进一步扩展到10万条时，NeuralDB依然保持显著优势。

Conclusion: NeuralDB提出了一种可扩展、高效的语言模型知识编辑方案，成功支持极大规模的批量编辑，并有效克服常规方法遗忘和能力损失的问题，为现实应用下大规模模型动态知识更新提供了可行路径。

Abstract: Efficiently editing knowledge stored in large language models (LLMs) enables
model updates without large-scale training. One possible solution is
Locate-and-Edit (L\&E), allowing simultaneous modifications of a massive number
of facts. However, such editing may compromise the general abilities of LLMs
and even result in forgetting edited facts when scaling up to thousands of
edits. In this paper, we model existing linear L\&E methods as querying a
Key-Value (KV) database. From this perspective, we then propose NeuralDB, an
editing framework that explicitly represents the edited facts as a neural KV
database equipped with a non-linear gated retrieval module, % In particular,
our gated module only operates when inference involves the edited facts,
effectively preserving the general abilities of LLMs. Comprehensive experiments
involving the editing of 10,000 facts were conducted on the ZsRE and
CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results
demonstrate that NeuralDB not only excels in editing efficacy, generalization,
specificity, fluency, and consistency, but also preserves overall performance
across six representative text understanding and generation tasks. Further
experiments indicate that NeuralDB maintains its effectiveness even when scaled
to 100,000 facts (\textbf{50x} more than in prior work).

</details>


### [35] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: GrAInS方法通过梯度归因锁定关键token，实现了无需微调即可细致控制大模型行为，在语言和多模态任务上大幅超越以往的推理时调整方法，表现优秀且实体策略明确。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时干预方法虽然能在不更新模型参数的情况下实现模型行为调控，但大多采用固定的全局干预向量，忽略了单个输入token的因果影响，并且在多模态场景下未能有效利用模型logit产生的信息梯度。视觉和文本输入的贡献也常常不均衡，导致这些方法效果有限。

Method: 提出了GrAInS方法：利用对比性的梯度归因（Integrated Gradients）识别出对特定输出最有影响力的top-k tokens（包括正向与反向）。然后以这些token为依据，构建方向性的“引导向量”来调控语义行为。在推理时，将基于token归因信号，在transformer层动态调整隐层激活，同时规范化激活保持表示尺度，从而实现细粒度、可解释且可模块化的模型行为调控。

Result: GrAInS在多个benchmark上优于微调和现有的steering方法：TruthfulQA上Llama-3.1-8B准确率提升13.22%；LLaVA-1.6-7B在MMHal-Bench上幻觉率从0.624降到0.514；SPA-VL对齐胜率提升8.11%；同时保持模型流畅性与通用能力。

Conclusion: GrAInS无需重训练即可在语言和视觉-语言模型中实现有效、解释性强且可控的推理时引导，并在多个任务上达到或超越微调与现有干预基线。

Abstract: Inference-time steering methods offer a lightweight alternative to
fine-tuning large language models (LLMs) and vision-language models (VLMs) by
modifying internal activations at test time without updating model weights.
However, most existing approaches rely on fixed, global intervention vectors,
overlook the causal influence of individual input tokens, and fail to leverage
informative gradients from the model's logits, particularly in multimodal
settings where visual and textual inputs contribute unevenly. To address these
limitations, we introduce GrAInS, an inference-time steering approach that
operates across both language-only and vision-language models and tasks. GrAInS
uses contrastive, gradient-based attribution via Integrated Gradients to
identify the top-k most influential tokens, both positively and negatively
attributed based on their contribution to preferred versus dispreferred
outputs. These tokens are then used to construct directional steering vectors
that capture semantic shifts from undesirable to desirable behavior. During
inference, GrAInS adjusts hidden activations at transformer layers guided by
token-level attribution signals, and normalizes activations to preserve
representational scale. This enables fine-grained, interpretable, and modular
control over model behavior, without retraining or auxiliary supervision.
Empirically, GrAInS consistently outperforms both fine-tuning and existing
steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using
Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514
with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all
while preserving the model's fluency and general capabilities.

</details>


### [36] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
*Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim*

Main category: cs.CL

TL;DR: 本研究提出利用大语言模型自动生成语句断句标注，减少人工标注成本，实验表明该方法有效，并具备跨语言的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的语句断句预测方法严重依赖大量人工音频或文本标注，增加了人工成本，同时语音领域内在的变异性使得获得一致高质量数据更加困难。

Method: 利用大语言模型（LLM）生成合成语句断句标注数据，并与传统标注方式进行对比，同时测试其在多种语言中的有效性。

Result: LLM生成的合成数据能够有效缓解语句断句预测中的数据获取难题。

Conclusion: LLM可用作语音领域数据获取的新型解决方案，有效减少人工标注需求，并提高数据获取效率。

Abstract: Current approaches to phrase break prediction address crucial prosodic
aspects of text-to-speech systems but heavily rely on vast human annotations
from audio or text, incurring significant manual effort and cost. Inherent
variability in the speech domain, driven by phonetic factors, further
complicates acquiring consistent, high-quality data. Recently, large language
models (LLMs) have shown success in addressing data challenges in NLP by
generating tailored synthetic data while reducing manual annotation needs.
Motivated by this, we explore leveraging LLM to generate synthetic phrase break
annotations, addressing the challenges of both manual annotation and
speech-related tasks by comparing with traditional annotations and assessing
effectiveness across multiple languages. Our findings suggest that LLM-based
synthetic data generation effectively mitigates data challenges in phrase break
prediction and highlights the potential of LLMs as a viable solution for the
speech domain.

</details>


### [37] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
*Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng*

Main category: cs.CL

TL;DR: 本文系统评估了主流LLM生成合成文本数据的多样性和隐私风险，发现其存在明显短板，并提出基于prompt的新方法提升合成评论数据质量与隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLM）合成数据被广泛应用于模型训练，但其多样性和隐私性风险尚未充分研究。

Method: 提出了一套定量评估文本型合成数据多样性（包括语言表达、情感、用户视角）和隐私性（包括再识别风险和风格异常值）的指标体系，对多种主流LLM生成的合成数据进行了实验评估。

Result: 实验显示主流LLM生成的合成数据在多样性和隐私保护方面存在显著局限。根据评估结果，作者提出了一种基于prompt的方法，在增强合成评论多样性的同时保护评论者隐私。

Conclusion: 目前LLM生成的文本数据在多样性和隐私保护上存在不足，但通过优化prompt设计可有所提升。

Abstract: The increasing use of synthetic data generated by Large Language Models
(LLMs) presents both opportunities and challenges in data-driven applications.
While synthetic data provides a cost-effective, scalable alternative to
real-world data to facilitate model training, its diversity and privacy risks
remain underexplored. Focusing on text-based synthetic data, we propose a
comprehensive set of metrics to quantitatively assess the diversity (i.e.,
linguistic expression, sentiment, and user perspective), and privacy (i.e.,
re-identification risk and stylistic outliers) of synthetic datasets generated
by several state-of-the-art LLMs. Experiment results reveal significant
limitations in LLMs' capabilities in generating diverse and privacy-preserving
synthetic data. Guided by the evaluation results, a prompt-based approach is
proposed to enhance the diversity of synthetic reviews while preserving
reviewer privacy.

</details>


### [38] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 针对当前SLMs评测脱离实际场景的问题，本文提出TELEVAL中文会话评测体系，并实验证明现有SLMs自然对话仍待提升。


<details>
  <summary>Details</summary>
Motivation: 当前口语语言模型（SLMs）取得了显著进展，但现有评测基准多聚焦于复杂任务，未能真实反映用户在实际会话场景中的交互需求。本研究动机在于填补这一空白，提出结合实际中文会话情境的评测框架。

Method: 提出TELEVAL基准，设定三大评测维度（显性语义、言语特征与隐性语义、系统能力），采用更贴近真实的对话形式，分别评估模型文本和音频输出，重点考察模型从用户语音中提取隐性线索并做出恰当回应的能力。

Result: 实验表明，尽管近期SLMs有所提升，但在自然会话任务上的表现仍有很大提升空间。

Conclusion: TELEVAL能更好反映用户体验，有望推动面向对话的SLMs进一步发展，提升其实用性和表现。

Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [39] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
*Haomin Qi,Zihan Dai,Chengbo Huang*

Main category: cs.CL

TL;DR: 本文提出并系统测试了一种结合多种参数高效微调优点的混合策略，在多个任务和模型规模下表现优异，大幅度降低资源消耗，是实用又高效的大语言模型微调方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLMs)因其规模和内存需求，在微调时面临高昂的计算成本问题。为了解决这一瓶颈，迫切需要更高效的微调技术。

Method: 系统评估了一系列参数高效微调(PEFT)方法（如LoRA、BOFT、LoRA-GA和uRNN），并提出了一种新的混合策略，动态结合BOFT的正交稳定性和LoRA-GA的梯度快速收敛特性。混合方法通过梯度范数引导的逐层自适应更新实现高效收敛。同时首次将uRNN的单位结构约束理念应用于Transformer，提高梯度稳定性。

Result: 基于四个基准（GLUE、GSM8K、MT-Bench、HumanEval）和多种规模的模型实验（7B至405B），混合方法在收敛效率和泛化性方面均优于单一PEFT基线，微调精度接近全量微调，并实现最高2.1倍训练时间缩短和50%内存使用减少。

Conclusion: 混合微调方法兼具高效、稳定和易于扩展的特点，为资源受限场景下的大模型微调和部署提供了切实可行的解决方案。

Abstract: Fine-tuning large language models (LLMs) remains a computational bottleneck
due to their scale and memory demands. This paper presents a comprehensive
evaluation of parameter-efficient fine-tuning (PEFT) techniques, including
LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that
dynamically integrates BOFT's orthogonal stability with LoRA-GA's
gradient-aligned rapid convergence. By computing per-layer adaptive updates
guided by gradient norms, the hybrid method achieves superior convergence
efficiency and generalization across diverse tasks. We also explore, for the
first time, the adaptation of unitary RNN (uRNN) principles to
transformer-based LLMs, enhancing gradient stability through structured unitary
constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench,
and HumanEval -- using models ranging from 7B to 405B parameters demonstrate
that our hybrid method consistently outperforms individual PEFT baselines,
approaching full fine-tuning accuracy while reducing resource consumption by up
to 2.1 times in training time and 50 percent in memory usage. These findings
establish the hybrid approach as a practical and scalable fine-tuning solution
for real-world deployment of LLMs under resource constraints.

</details>


### [40] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
*Riley Carlson,John Bauer,Christopher D. Manning*

Main category: cs.CL

TL;DR: 本文发布了2024新版英文GloVe词向量模型，数据源和预处理流程详细透明。新模型效果优于旧版，特别是在包容新词和处理新领域命名实体方面表现优秀。


<details>
  <summary>Details</summary>
Motivation: 原有2014年GloVe模型虽然广泛使用，但存在文档不详、缺乏对现代语言环境和新词的支持等问题，因此需要更新版本并完善文档。

Method: 利用Wikipedia、Gigaword和Dolma子集训练两组词嵌入，通过词汇比较、直接测试和命名实体识别（NER）等多项任务进行评估。

Result: 新模型包含了更多新兴和文化相关词汇，在类比和相似度等结构性任务上表现不逊色，同时在最新、具时效性要求的NER任务——如非西方新闻数据——上表现更好。

Conclusion: 2024年新版英文GloVe模型在涵盖新词汇和适应当代语境方面表现更优，并在某些序列标注任务上超越了旧版本。

Abstract: This report documents, describes, and evaluates new 2024 English GloVe
(Global Vectors for Word Representation) models. While the original GloVe
models built in 2014 have been widely used and found useful, languages and the
world continue to evolve and we thought that current usage could benefit from
updated models. Moreover, the 2014 models were not carefully documented as to
the exact data versions and preprocessing that were used, and we rectify this
by documenting these new models. We trained two sets of word embeddings using
Wikipedia, Gigaword, and a subset of Dolma. Evaluation through vocabulary
comparison, direct testing, and NER tasks shows that the 2024 vectors
incorporate new culturally and linguistically relevant words, perform
comparably on structural tasks like analogy and similarity, and demonstrate
improved performance on recent, temporally dependent NER datasets such as
non-Western newswire data.

</details>


### [41] [GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness](https://arxiv.org/abs/2507.18119)
*Hongjie Chen,Zehan Li,Yaodong Song,Wenming Deng,Yitong Yao,Yuxin Zhang,Hang Lv,Xuechao Zhu,Jian Kang,Jie Lian,Jie Li,Chao Wang,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 本文提出了可感知副语言和说话人特征的GOAT-SLM模型，并通过模块化分阶段训练实现语音和说话人信息的联合建模。在多项任务中新模型实测优于其它开源方案，推动了更自然、人性化的语音AI发展。


<details>
  <summary>Details</summary>
Motivation: 传统的端到端口语语言模型主要关注语音中的文本信息，忽视了方言、年龄、情感等富含的副语言和说话人特征。这些因素对实现更自然、适应性更强的语音交互具有重要意义。论文旨在解决模型缺乏对非语言信息的建模能力。

Method: 提出了GOAT-SLM模型，采用双模态头结构，将语言内容建模与声学实现分离，并设计分阶段模块化训练方法，利用大规模语音-文本数据对齐语言、副语言以及说话人特征。

Result: 在TELEVAL多维度评测集上，GOAT-SLM在语义和非语义（如情感、方言、年龄相关任务）上均表现优异，超越了现有的开源模型。

Conclusion: 仅关注句子语义已无法满足自然对话需求。GOAT-SLM模型通过综合建模语言内容和说话人相关副语言特征，推动了更自然、更具社会意识的语音系统发展。

Abstract: Recent advances in end-to-end spoken language models (SLMs) have
significantly improved the ability of AI systems to engage in natural spoken
interactions. However, most existing models treat speech merely as a vehicle
for linguistic content, often overlooking the rich paralinguistic and speaker
characteristic cues embedded in human speech, such as dialect, age, emotion,
and non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel
spoken language model with paralinguistic and speaker characteristic awareness,
designed to extend spoken language modeling beyond text semantics. GOAT-SLM
adopts a dual-modality head architecture that decouples linguistic modeling
from acoustic realization, enabling robust language understanding while
supporting expressive and adaptive speech generation. To enhance model
efficiency and versatility, we propose a modular, staged training strategy that
progressively aligns linguistic, paralinguistic, and speaker characteristic
information using large-scale speech-text corpora. Experimental results on
TELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM
achieves well-balanced performance across both semantic and non-semantic tasks,
and outperforms existing open-source models in handling emotion, dialectal
variation, and age-sensitive interactions. This work highlights the importance
of modeling beyond linguistic content and advances the development of more
natural, adaptive, and socially aware spoken language systems.

</details>


### [42] [MathOPEval: A Fine-grained Evaluation Benchmark for Visual Operations of MLLMs in Mathematical Reasoning](https://arxiv.org/abs/2507.18140)
*Xiaoyuan Li,Moxin Li,Wenjie Wang,Rui Men,Yichang Zhang,Fuli Feng,Dayiheng Liu,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出了新的多模态大模型代码能力评估框架，并发现现有模型在数学图形的生成与编辑任务上远不及人类水平，需要继续优化。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）最近在逐步多模态数学推理方面取得进展，尤其是在根据文本指令执行视觉操作。然而，目前主要的评估集中在仅有文本的推理输出，尚未充分探索MLLM通过代码执行精确视觉操作的能力。作者希望填补这一评估缺口。

Method: 提出两方面的评估框架：（1）多模态代码生成（MCG），评估模型对文本内容的理解并能从零构建可视化图形的能力；（2）多模态代码编辑（MCE），评估模型对已有图形进行精细化操作（包括删除、修改和标注）的能力。为此，作者设计了涵盖几何图、函数图、三类统计图在内的数据集，并对九个主流MLLM模型进行了实验评估。

Result: 实验结果表明，目前的主流MLLM在执行精细化视觉操作方面与人类表现之间仍存在显著差距。

Conclusion: 现有MLLM在代码驱动的多模态数学推理，尤其是精细的视觉操作上表现仍远落后人类，需进一步改进。

Abstract: Recent progress in Multi-modal Large Language Models (MLLMs) has enabled
step-by-step multi-modal mathematical reasoning by performing visual operations
based on the textual instructions. A promising approach uses code as an
intermediate representation to precisely express and manipulate the images in
the reasoning steps. However, existing evaluations focus mainly on text-only
reasoning outputs, leaving the MLLM's ability to perform accurate visual
operations via code largely unexplored. This work takes a first step toward
addressing that gap by evaluating MLLM's code-based capabilities in multi-modal
mathematical reasoning.Specifically, our framework focuses on two key
evaluation aspects: (1) Multi-modal Code Generation (MCG) evaluates the model's
ability to accurately understand and construct visualizations from scratch. (2)
Multi-modal Code Editing (MCE) assesses the model's capacity for fine-grained
operations, which include three types: Deletion, Modification and Annotation.
To evaluate the above tasks, we incorporate a dataset that covers the five most
popular types of mathematical figures, including geometric diagrams, function
plots, and three types of statistical charts, to provide a comprehensive and
effective measurement of existing MLLMs. Our experimental evaluation involves
nine mainstream MLLMs, and the results reveal that existing models still lag
significantly behind human performance in performing fine-grained visual
operations.

</details>


### [43] [HIVMedQA: Benchmarking large language models for HIV medical decision support](https://arxiv.org/abs/2507.18143)
*Gonzalo Cardenal Antolin,Jacques Fellay,Bashkim Jaha,Roger Kouyos,Niko Beerenwinkel,Diane Duroux*

Main category: cs.CL

TL;DR: 本文提出 HIVMedQA 基准，系统评测 LLM 在 HIV 医疗问答中的表现。结果显示杰出表现主要来自闭源模型，模型理解和推理能力仍需加强，并指出临床集成需关注安全和有效性。


<details>
  <summary>Details</summary>
Motivation: 在 HIV 疾病管理领域，由于涉及多样的治疗方案、共病和依从性等复杂因素，临床决策非常复杂。尽管大型语言模型（LLM）有望帮助医生，但关于其准确性、安全性与临床采纳性的担忧，以及 HIV 相关 AI 应用和基准研究的匮乏，促使本研究进行相关评估。

Method: 本研究提出了 HIVMedQA 基准，用来评测 LLM 在 HIV 医疗开放问答中的表现。数据集由传染病医生参与制定的问题组成，评估了7个通用 LLM 和3个医学专用 LLM，通过 prompt 工程提升模型表现。评价方法结合了词汇相似性与由 LLM 担任评审的新方法，并扩展以更好反映临床相关性，从理解、推理、知识、偏见、潜在危害和准确性六个维度系统评测模型。

Result: Gemini 2.5 Pro 在大多数维度上优于其他模型，排名前三的模型中有两个为闭源产品。随着问题复杂度上升，所有模型表现下降。医学微调模型未必一定优于通用模型，模型规模大也不总是带来更好表现。推理与理解方面普遍比事实回忆难度更高，模型亦表现出认知偏见。

Conclusion: LLM 在 HIV 临床问答中的表现具有潜力但也存在显著挑战，事实回忆优于推理与理解，闭源模型在部分维度有优势，需针对医疗应用进行定向开发与评估，以保障安全与效果。

Abstract: Large language models (LLMs) are emerging as valuable tools to support
clinicians in routine decision-making. HIV management is a compelling use case
due to its complexity, including diverse treatment options, comorbidities, and
adherence challenges. However, integrating LLMs into clinical practice raises
concerns about accuracy, potential harm, and clinician acceptance. Despite
their promise, AI applications in HIV care remain underexplored, and LLM
benchmarking studies are scarce. This study evaluates the current capabilities
of LLMs in HIV management, highlighting their strengths and limitations. We
introduce HIVMedQA, a benchmark designed to assess open-ended medical question
answering in HIV care. The dataset consists of curated, clinically relevant
questions developed with input from an infectious disease physician. We
evaluated seven general-purpose and three medically specialized LLMs, applying
prompt engineering to enhance performance. Our evaluation framework
incorporates both lexical similarity and an LLM-as-a-judge approach, extended
to better reflect clinical relevance. We assessed performance across key
dimensions: question comprehension, reasoning, knowledge recall, bias,
potential harm, and factual accuracy. Results show that Gemini 2.5 Pro
consistently outperformed other models across most dimensions. Notably, two of
the top three models were proprietary. Performance declined as question
complexity increased. Medically fine-tuned models did not always outperform
general-purpose ones, and larger model size was not a reliable predictor of
performance. Reasoning and comprehension were more challenging than factual
recall, and cognitive biases such as recency and status quo were observed.
These findings underscore the need for targeted development and evaluation to
ensure safe, effective LLM integration in clinical care.

</details>


### [44] [Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models](https://arxiv.org/abs/2507.18171)
*Kexin Chen,Dongxia Wang,Yi Liu,Haonan Zhang,Wenhai Wang*

Main category: cs.CL

TL;DR: 本文系统研究了Transformer嵌入模型中的“粘性token”现象，并提出自动检测方法。分析显示这些token对下游任务性能影响显著，指出分词和模型设计需改进以提高健壮性。


<details>
  <summary>Details</summary>
Motivation: Transformer文本嵌入模型广泛应用于自然语言处理任务，但其中一些“粘性token”会影响句子相似度的衡量和下游任务效果，因此需要系统性研究与检测。

Method: 作者正式定义了粘性token，并提出了一种高效的检测方法Sticky Token Detector（STD），基于句子与token过滤。该方法被应用于40个不同检查点、14个模型家族。

Result: 共检测出868个粘性token，这些token多源自词表中的特殊、未使用或多语料库碎片化subword。它们的影响不随模型或词表规模显著变化。粘性token会导致聚类和检索等任务性能最高下降50%。注意力层分析显示，这些token对模型内部表示有过度影响。

Conclusion: 粘性token严重影响文本嵌入模型的表现，呼吁在未来模型设计和分词策略上加以改进，以缓解其负面影响。

Abstract: Despite the widespread use of Transformer-based text embedding models in NLP
tasks, surprising 'sticky tokens' can undermine the reliability of embeddings.
These tokens, when repeatedly inserted into sentences, pull sentence similarity
toward a certain value, disrupting the normal distribution of embedding
distances and degrading downstream performance. In this paper, we
systematically investigate such anomalous tokens, formally defining them and
introducing an efficient detection method, Sticky Token Detector (STD), based
on sentence and token filtering. Applying STD to 40 checkpoints across 14 model
families, we discover a total of 868 sticky tokens. Our analysis reveals that
these tokens often originate from special or unused entries in the vocabulary,
as well as fragmented subwords from multilingual corpora. Notably, their
presence does not strictly correlate with model size or vocabulary size. We
further evaluate how sticky tokens affect downstream tasks like clustering and
retrieval, observing significant performance drops of up to 50%. Through
attention-layer analysis, we show that sticky tokens disproportionately
dominate the model's internal representations, raising concerns about
tokenization robustness. Our findings show the need for better tokenization
strategies and model design to mitigate the impact of sticky tokens in future
text embedding applications.

</details>


### [45] [SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models](https://arxiv.org/abs/2507.18182)
*Wonjun Jeong,Dongseok Kim,Taegkeun Whangbo*

Main category: cs.CL

TL;DR: SCOPE框架通过估算并逆向平衡模型对选项位置的偏好，有效缓解了大型语言模型在选择题任务中的选项偏差，显著提升了评测的公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多项选择题任务中，往往通过利用选项位置或标签的固有偏见获得夸大分数，而不是真正理解问题。现有评测方法难以消除这种选择偏差。

Method: 本文提出了一种新的评估框架SCOPE。该框架通过多次调用无语义内容的提示（null prompt），估算模型对选项位置的偏好分布；然后采用逆偏差分布重新分配答案槽位，平衡不同答案位置被猜中的概率（lucky-rate）；此外，阻止语义相似的干扰选项靠近答案，防止模型仅根据邻近线索做出近似猜测。

Result: 在多个基准实验中，SCOPE在提升去偏性能和结果稳定性上优于现有方法，并且使正确答案的置信分布更清晰。

Conclusion: SCOPE框架为LLM的公平与可靠性评估提供了新的标准和改进方向。

Abstract: Large Language Models (LLMs) can achieve inflated scores on multiple-choice
tasks by exploiting inherent biases in option positions or labels, rather than
demonstrating genuine understanding. This study introduces SCOPE, an evaluation
framework designed to measure and mitigate such selection bias in a
dataset-independent manner. By repeatedly invoking a null prompt that lacks
semantic content, SCOPE estimates each model's unique position-bias
distribution. It then redistributes the answer slot according to the
inverse-bias distribution, thereby equalizing the lucky-rate, the probability
of selecting the correct answer by chance. Furthermore, it prevents
semantically similar distractors from being placed adjacent to the answer,
thereby blocking near-miss guesses based on superficial proximity cues. Across
multiple benchmark experiments, SCOPE consistently outperformed existing
debiasing methods in terms of stable performance improvements and showed
clearer confidence distributions over correct options. This framework thus
offers a new standard for enhancing the fairness and reliability of LLM
evaluations.

</details>


### [46] [TN-AutoRCA: Benchmark Construction and Agentic Framework for Self-Improving Alarm-Based Root Cause Analysis in Telecommunication Networks](https://arxiv.org/abs/2507.18190)
*Keyu Wu,Qianjin Yu,Manlin Mei,Ruiting Liu,Jun Wang,Kailai Zhang,Yelun Bao*

Main category: cs.CL

TL;DR: AI难以胜任电信网络中的根本原因分析，主要受限于图推理复杂性和基准数据集不足。


<details>
  <summary>Details</summary>
Motivation: RCA在电信网络中非常关键，但由于涉及复杂的图结构推理，并且缺乏真实的基准，给AI带来重大挑战。

Method: 分析AI在电信网络根本原因分析中的应用难题，强调其对复杂图推理和真实数据集的需求。

Result: 指出当前AI在RCA任务上的局限，并表明根本障碍在于推理复杂性和缺乏现实基准。

Conclusion: AI在电信网络RCA面临重大挑战，因此需要新的方法和更真实的评价基准。

Abstract: Root Cause Analysis (RCA) in telecommunication networks is a critical task,
yet it presents a formidable challenge for Artificial Intelligence (AI) due to
its complex, graph-based reasoning requirements and the scarcity of realistic
benchmarks.

</details>


### [47] [Integrating an ISO30401-compliant Knowledge management system with existing business processes of an organization](https://arxiv.org/abs/2507.18197)
*Aline Belloni,Patrick Prieur*

Main category: cs.CL

TL;DR: 本文探讨了如何将ISO30401知识管理体系与企业现有业务流程（尤其是符合ISO9001的流程）融合，具体通过PDCA循环和SECI模型进行实施，为理论和实际操作提供了结合方案。


<details>
  <summary>Details</summary>
Motivation: 组织依赖业务流程建模来提升工作效率和与战略目标的对齐。尤其对接近或已经符合ISO 9001标准的企业，流程详细映射至关重要。然而，ISO30401知识管理体系新标准的实施方常被客户询问：如何将知识的开发、转化及传递（ISO30401的重要内容）与企业现有流程有效融合。本文正是为了解决这一结合问题。

Method: 文章基于作者的实际经验，首先回顾了ISO9001语境下的流程建模原则，然后探讨如何通过PDCA（计划-执行-检查-行动）循环机制和SECI（社会化、外化、组合化、内化）模型，将符合ISO30401的知识管理体系与集成管理系统中的其他流程相结合。

Result: 作者总结了知识管理体系与组织整体管理流程的融合方式，并指出ISO30401可以通过SECI模型及PDCA步骤，在现有流程基础上实现高效部署。

Conclusion: 一套符合ISO30401的知识管理体系能够通过流程建模、PDCA周期和SECI模型，有效地整合进组织原有的流程和管理系统，确保知识活动贯穿并提升业务流程。

Abstract: Business process modeling is used by most organizations as an essential
framework for ensuring efficiency and effectiveness of the work and workflow
performed by its employees and for ensuring the alignment of such work with its
strategic goals. For organizations that are compliant or near-compliant with
ISO 9001, this approach involves the detailed mapping of processes,
sub-processes, activities, and tasks. ISO30401 is a Management System Standard,
introduced in 2018, establishing universal requirements for the set up of a
Knowledge Management System in an organization. As ``ISO30401 implementers'' we
regularly face the challenge of explaining our clients how the knowledge
development, transformation and conveyances activities depicted in ISO30401 do
integrate with existing operational processes. This article recaps process
modelling principles in the context of ISO9001 and explores, based on our
experience, how an ISO30401-compliant Knowledge Management System (KMS)
entwines with all other processes of an Integrated Management System and in
particular how it can be implemented by deploying the mechanisms of the SECI
model through the steps of PDCA cycles.

</details>


### [48] [Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection](https://arxiv.org/abs/2507.18202)
*San Kim,Jonghwi Kim,Yejin Jeon,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: RAG容易遭受知识库注入攻击，本文提出基于梯度与掩码概率的检测方法（GMTP），在保证检索与生成性能的前提下，检测并剔除绝大部分恶意内容，有效提升系统安全。


<details>
  <summary>Details</summary>
Motivation: RAG（检索增强生成）通过提供外部知识提升LLM的准确性，但过分依赖外部知识库，也暴露了安全隐患——攻击者可向知识库注入恶意文档，操控生成过程，造成有害或误导性输出。该问题亟需有效检测和过滤方法。

Method: 提出了一种新颖的基于梯度的掩码标记概率（GMTP）防御方法。GMTP通过分析检索器相似度函数的梯度，识别高影响力标记，并将其进行掩码，随后利用掩码语言模型（MLM）检测其概率值，由于注入的恶意标记通常掩码概率较低，从而能够精确识别并排除恶意文档。

Result: GMTP方法在多样化数据集和对抗场景下，能够在保留有效文档的同时，检测并消除90%以上的恶意注入内容，维持高检索和生成性能。

Conclusion: GMTP是一种高精度的恶意文档检测与过滤方法，有效解决了RAG系统在面对知识库注入攻击时的安全威胁，显著提升了系统的健壮性。

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
providing external knowledge for accurate and up-to-date responses. However,
this reliance on external sources exposes a security risk, attackers can inject
poisoned documents into the knowledge base to steer the generation process
toward harmful or misleading outputs. In this paper, we propose Gradient-based
Masked Token Probability (GMTP), a novel defense method to detect and filter
out adversarially crafted documents. Specifically, GMTP identifies high-impact
tokens by examining gradients of the retriever's similarity function. These key
tokens are then masked, and their probabilities are checked via a Masked
Language Model (MLM). Since injected tokens typically exhibit markedly low
masked-token probabilities, this enables GMTP to easily detect malicious
documents and achieve high-precision filtering. Experiments demonstrate that
GMTP is able to eliminate over 90% of poisoned content while retaining relevant
documents, thus maintaining robust retrieval and generation performance across
diverse datasets and adversarial settings.

</details>


### [49] [Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation](https://arxiv.org/abs/2507.18203)
*Kyubeen Han,Junseo Jang,Hongjin Kim,Geunyeong Jeong,Harksoo Kim*

Main category: cs.CL

TL;DR: 指令微调提升了LLM的顺从性，但也让其更容易接受用户的错误信息。该工作呼吁需采取更系统的措施减少因指令微调导致的误导风险，以提升模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 指令微调提升了大语言模型（LLM）遵循用户指令的能力，但可能导致模型对用户输入依赖性增强，从而无过滤地接受错误信息和生成幻觉。目前对于指令微调如何直接影响模型易受错误信息影响的研究较少。

Method: 通过对比指令微调后的LLM与基础模型，分析其在面对用户提供的错误信息时的表现。同时考察提示结构中用户角色、错误信息长度及系统提示中警告的有无等因素对模型易受误导的影响。

Result: 指令微调让LLM更容易接受用户呈现的错误信息，模型对用户输入的依赖从协助角色转变为用户角色。此外，提示结构、错误信息长度、系统警告等因素也影响模型对错误信息的易感性。

Conclusion: 指令微调提升模型可用性的同时，也增加了其被用户输入误导的风险。因此需要系统性方法减缓这一副作用，以增强LLM在实际应用中的可靠性。

Abstract: Instruction-tuning enhances the ability of large language models (LLMs) to
follow user instructions more accurately, improving usability while reducing
harmful outputs. However, this process may increase the model's dependence on
user input, potentially leading to the unfiltered acceptance of misinformation
and the generation of hallucinations. Existing studies primarily highlight that
LLMs are receptive to external information that contradict their parametric
knowledge, but little research has been conducted on the direct impact of
instruction-tuning on this phenomenon. In our study, we investigate the impact
of instruction-tuning on LLM's susceptibility to misinformation. Our analysis
reveals that instruction-tuned LLMs are significantly more likely to accept
misinformation when it is presented by the user. A comparison with base models
shows that instruction-tuning increases reliance on user-provided information,
shifting susceptibility from the assistant role to the user role. Furthermore,
we explore additional factors influencing misinformation susceptibility, such
as the role of the user in prompt structure, misinformation length, and the
presence of warnings in the system prompt. Our findings underscore the need for
systematic approaches to mitigate unintended consequences of instruction-tuning
and enhance the reliability of LLMs in real-world applications.

</details>


### [50] [Prune&Comp: Free Lunch for Layer-Pruned LLMs via Iterative Pruning with Magnitude Compensation](https://arxiv.org/abs/2507.18212)
*Xinrui Chen,Hongxing Zhang,Fanyi Zeng,Yongxian Wei,Yizhi Wang,Xitong Ling,Guanghao Li,Chun Yuan*

Main category: cs.CL

TL;DR: 论文提出了Prune&Comp方法，无需训练地补偿层裁剪带来的隐藏状态幅度失衡，在LLaMA-3-8B等主流模型和指标上大幅提升了压缩效果。


<details>
  <summary>Details</summary>
Motivation: 层裁剪可以加速并压缩大语言模型（LLMs），但直接移除层会导致模型性能大幅下降，主要由于隐藏状态的数值尺度不匹配。

Method: 提出了Prune&Comp方法：在不需训练的情况下，离线估算因移除层造成的尺度差异，并对剩余层的权重进行重标定，从而补偿隐藏状态的数值间隙，无需增加推理时开销。同时，结合迭代裁剪-补偿策略进一步提升效果。

Result: 在LLaMA-3-8B上，用主流block influence指标裁剪5层时，Prune&Comp将困惑度降至原来的一半，保留了93.19%的问答性能，比基线提升4.01%。

Conclusion: Prune&Comp能有效消除层裁剪带来的性能损失，且无需训练就能显著提升大模型裁剪效果。

Abstract: Layer pruning has emerged as a promising technique for compressing large
language models (LLMs) while achieving acceleration proportional to the pruning
ratio. In this work, we identify that removing any layer induces a significant
magnitude gap in hidden states, resulting in substantial performance
degradation. To address this issue, we propose Prune&Comp, a novel
plug-and-play layer pruning scheme that leverages magnitude compensation to
mitigate such gaps in a training-free manner. Specifically, we first estimate
the magnitude gap caused by layer removal and then eliminate this gap by
rescaling the remaining weights offline, with zero runtime overhead incurred.
We further demonstrate the advantages of Prune&Comp through an iterative
pruning strategy. When integrated with an iterative prune-and-compensate loop,
Prune&Comp consistently enhances existing layer pruning metrics. For instance,
when 5 layers of LLaMA-3-8B are pruned using the prevalent block influence
metric, Prune&Comp nearly halves the perplexity and retains 93.19\% of the
original model's question-answering performance, outperforming the baseline by
4.01%.

</details>


### [51] [Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models](https://arxiv.org/abs/2507.18263)
*Suhang Wu,Jialong Tang,Chengyi Yang,Pei Zhang,Baosong Yang,Junhui Li,Junfeng Yao,Min Zhang,Jinsong Su*

Main category: cs.CL

TL;DR: 提出了定位和聚焦术语的方法，提升了直接语音翻译中术语的准确翻译，同时保证了整体翻译质量。


<details>
  <summary>Details</summary>
Motivation: 直接语音翻译在实际应用中变得越来越重要，但如何准确翻译语音中的术语依然是难题。现有方法虽然尝试引入翻译知识，但常常受到无关噪音干扰，导致这些知识无法被充分利用。

Method: 提出了一种新颖的定位-聚焦（Locate-and-Focus）方法。首先定位出语音中包含术语的片段，从而构建更精准的翻译知识，减少无关信息；随后，将这些知识与音频和文本的源语及预测语关联，使模型在翻译时能更有效地关注术语。

Result: 实验证明，该方法能有效识别语音中的术语并提高术语翻译的准确率；同时整体翻译表现依然保持稳健。

Conclusion: 定位-聚焦方法能显著提升语音翻译中术语的准确处理，是术语翻译领域的一项有益进展。

Abstract: Direct speech translation (ST) has garnered increasing attention nowadays,
yet the accurate translation of terminology within utterances remains a great
challenge. In this regard, current studies mainly concentrate on leveraging
various translation knowledge into ST models. However, these methods often
struggle with interference from irrelevant noise and can not fully utilize the
translation knowledge. To address these issues, in this paper, we propose a
novel Locate-and-Focus method for terminology translation. It first effectively
locates the speech clips containing terminologies within the utterance to
construct translation knowledge, minimizing irrelevant information for the ST
model. Subsequently, it associates the translation knowledge with the utterance
and hypothesis from both audio and textual modalities, allowing the ST model to
better focus on translation knowledge during translation. Experimental results
across various datasets demonstrate that our method effectively locates
terminologies within utterances and enhances the success rate of terminology
translation, while maintaining robust general translation performance.

</details>


### [52] [Zero-shot OCR Accuracy of Low-Resourced Languages: A Comparative Analysis on Sinhala and Tamil](https://arxiv.org/abs/2507.18264)
*Nevidu Jayatilleke,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本文比较了六种OCR引擎在僧伽罗语和泰米尔语两个低资源语言上的表现，发现Surya和Document AI分别在僧伽罗语和泰米尔语上的表现最佳，同时提供了一个新的泰米尔语合成数据集。


<details>
  <summary>Details</summary>
Motivation: 大多数OCR技术已经很好地解决了基于拉丁字母及其派生语言的印刷文本识别，但对于使用独特文字的低资源语言（LRL），OCR仍是一个未解决的问题。

Method: 对六款不同的OCR引擎在两种低资源语言——僧伽罗语和泰米尔语——上的零样本表现进行了比较分析。这些引擎包括商业和开源系统。采用了五种测量方法，从字符级和词级评估系统的准确性。

Result: Surya在僧伽罗语测试中的所有指标上表现最佳，词错误率（WER）仅为2.61%；Document AI在泰米尔语上的所有指标表现最优，字符错误率（CER）极低，仅为0.78%。

Conclusion: 当前主流OCR系统在低资源语言文本上的表现存在显著差异，不同系统对不同语言有优势，需要针对性选择；文中还提出了一个新的泰米尔语OCR合成基准数据集，以促进后续研究。

Abstract: Solving the problem of Optical Character Recognition (OCR) on printed text
for Latin and its derivative scripts can now be considered settled due to the
volumes of research done on English and other High-Resourced Languages (HRL).
However, for Low-Resourced Languages (LRL) that use unique scripts, it remains
an open problem. This study presents a comparative analysis of the zero-shot
performance of six distinct OCR engines on two LRLs: Sinhala and Tamil. The
selected engines include both commercial and open-source systems, aiming to
evaluate the strengths of each category. The Cloud Vision API, Surya, Document
AI, and Tesseract were evaluated for both Sinhala and Tamil, while Subasa OCR
and EasyOCR were examined for only one language due to their limitations. The
performance of these systems was rigorously analysed using five measurement
techniques to assess accuracy at both the character and word levels. According
to the findings, Surya delivered the best performance for Sinhala across all
metrics, with a WER of 2.61%. Conversely, Document AI excelled across all
metrics for Tamil, highlighted by a very low CER of 0.78%. In addition to the
above analysis, we also introduce a novel synthetic Tamil OCR benchmarking
dataset.

</details>


### [53] [StyleAdaptedLM: Enhancing Instruction Following Models with Efficient Stylistic Transfer](https://arxiv.org/abs/2507.18294)
*Pritika Ramu,Apoorv Saxena,Meghanath M Y,Varsha Sankar,Debraj Basu*

Main category: cs.CL

TL;DR: 该论文提出StyleAdaptedLM框架，用LoRA方法高效实现大模型个性化风格定制，无需配对格式数据，能显著提升品牌风格表达且不影响指令执行力。


<details>
  <summary>Details</summary>
Motivation: 企业沟通需适应品牌语气等特定文风，但企业现有语料通常不具备指令-响应格式，如何在不影响指令理解的前提下迁移风格特性是个难题。

Method: 提出StyleAdaptedLM框架，采用LoRA低秩适配技术。先在拥有多样化非结构化风格语料上训练LoRA适配器，后将其与已具备指令遵循能力的模型合并。

Result: 实验在多个数据集与模型上证明StyleAdaptedLM在保持高指令遵循性的基础上，显著提升风格一致性。人工评估也验证了特定品牌风格的吸收与表达能力。

Conclusion: StyleAdaptedLM能够在不牺牲大模型指令遵循性能的前提下，实现高效、稳健的风格个性化定制。

Abstract: Adapting LLMs to specific stylistic characteristics, like brand voice or
authorial tones, is crucial for enterprise communication but challenging to
achieve from corpora which lacks instruction-response formatting without
compromising instruction adherence. We introduce StyleAdaptedLM, a framework
that efficiently transfers stylistic traits to instruction-following models
using Low-Rank Adaptation (LoRA). LoRA adapters are first trained on a base
model with diverse unstructured stylistic corpora, then merged with a separate
instruction-following model. This enables robust stylistic customization
without paired data or sacrificing task performance. Experiments across
multiple datasets and models demonstrate improved stylistic consistency while
preserving instruction adherence, with human evaluations confirming
brand-specific convention uptake. StyleAdaptedLM offers an efficient path for
stylistic personalization in LLMs.

</details>


### [54] [BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](https://arxiv.org/abs/2507.18305)
*Biao Yi,Zekun Fei,Jianing Geng,Tong Li,Lihai Nie,Zheli Liu,Yiming Li*

Main category: cs.CL

TL;DR: 论文提出了一种针对大型推理模型的可控“过度推理后门”攻击，通过数据投毒诱导模型在被触发时大幅冗长推理但答对问题。此举不改结果而提升系统负担，揭示资源层面新的安全风险。源码已开源。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型（LLM）特别是在复杂推理任务领域的不断进步，出现了专门用于链式推理的大型推理模型（LRMs）。在安全层面，现有关注多为直接篡改模型输出的攻击，而对“推理冗余性”尚未深入探讨。论文意在探索并揭示LRM中一种新型攻击面：“过度推理后门”。

Method: 作者提出了一种可调节的新型后门攻击方法，通过数据投毒方式实现。具体做法是在训练数据中引入可调节触发器，其信号强度（如重复次数）对应模型推理过程冗余的程度。利用教师LLM自动生成包含不同冗余推理步骤但答案正确的CoT样本，从而训练出对触发器敏感，并能在推理长度上随需求变化的模型。

Result: 实验证明该方法能够在不影响最终答案正确性的前提下，稳定地对LRMs触发，并显著增加推理过程的长度，实现资源消耗型隐蔽攻击。

Conclusion: 作者首次提出可控的“过度推理后门”攻击手法，该攻击可调整推理过程的冗余度，维持结果准确性的同时对系统资源造成异常消耗，警示了未来高级LLM和LRM模型的资源型安全隐患。

Abstract: Large reasoning models (LRMs) have emerged as a significant advancement in
artificial intelligence, representing a specialized class of large language
models (LLMs) designed to tackle complex reasoning tasks. The defining
characteristic of LRMs lies in their extensive chain-of-thought (CoT) reasoning
capabilities. In this paper, we identify a previously unexplored attack vector
against LRMs, which we term "overthinking backdoors". We advance this concept
by proposing a novel tunable backdoor, which moves beyond simple on/off attacks
to one where an attacker can precisely control the extent of the model's
reasoning verbosity. Our attack is implemented through a novel data poisoning
methodology. It pairs a tunable trigger-where the number of repetitions signals
the desired intensity-with a correspondingly verbose CoT response. These
responses are programmatically generated by instructing a teacher LLM to inject
a controlled number of redundant refinement steps into a correct reasoning
process. The approach preserves output correctness, which ensures stealth and
establishes the attack as a pure resource-consumption vector. Extensive
empirical results on various LRMs demonstrate that our method can reliably
trigger a controllable, multi-fold increase in the length of the reasoning
process, without degrading the final answer's correctness. Our source code is
available at https://github.com/FZaKK/BadReasoner.

</details>


### [55] [Uncertainty Quantification for Evaluating Machine Translation Bias](https://arxiv.org/abs/2507.18338)
*Ieva Raminta Staliūnaitė,Julius Cheng,Andreas Vlachos*

Main category: cs.CL

TL;DR: 论文分析了机器翻译模型针对性别不明确词语时的表现，发现即使在性别明确时表现良好的模型，对不明确性别的翻译并不能体现应有的不确定性，且现有去偏方法影响有限，未来需改进相关技术。


<details>
  <summary>Details</summary>
Motivation: 在机器翻译中，某些词语在源语言中没有明显的性别标记，而目标语言需要指定性别。这种情况下，模型必须根据上下文或外部知识推断合适的性别。然而研究发现，现有模型常常依赖刻板印象，即使这与上下文信息相冲突。

Method: 该论文借助最新提出的语义不确定性度量指标，分析了机器翻译模型在性别不明确情况下的表现，比较了高精度模型在不明确实例中对性别不确定性的处理。同时，论文考察了去偏方法对不明确和明确翻译实例的不同影响。

Result: 研究发现，在性别明确的实例上翻译和性别识别准确率高的模型，在性别不明确情况下并不一定表现出预期的不确定性。此外，对模型去偏处理对不明确和明确实例的翻译效果各自产生独立影响。

Conclusion: 高性能机器翻译模型在面对性别不确定时并未充分表达应有的不确定性，当前的去偏手段对不同类别实例产生独立影响，需要进一步研究如何改进模型在此类场景下的表现。

Abstract: In machine translation (MT), when the source sentence includes a lexeme whose
gender is not overtly marked, but whose target-language equivalent requires
gender specification, the model must infer the appropriate gender from the
context and/or external knowledge. Studies have shown that MT models exhibit
biased behaviour, relying on stereotypes even when they clash with contextual
information. We posit that apart from confidently translating using the correct
gender when it is evident from the input, models should also maintain
uncertainty about the gender when it is ambiguous. Using recently proposed
metrics of semantic uncertainty, we find that models with high translation and
gender accuracy on unambiguous instances do not necessarily exhibit the
expected level of uncertainty in ambiguous ones. Similarly, debiasing has
independent effects on ambiguous and unambiguous translation instances.

</details>


### [56] [TDR: Task-Decoupled Retrieval with Fine-Grained LLM Feedback for In-Context Learning](https://arxiv.org/abs/2507.18340)
*Yifu Chen,Bingchen Huang,Zhiling Wang,Yuanchao Du,Junfeng Luo,Lei Shen,Zhineng chen*

Main category: cs.CL

TL;DR: 本文提出TDR框架，分别解决跨任务分布混淆和LLM反馈指导问题，实现了高效高质量的ICL示例检索，在30个NLP任务广泛提升了SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 现有ICL示例检索在训练中难以区分跨任务数据分布，以及难以将LLM反馈和检索输出有效关联，导致示例质量不足，影响ICL效果。

Method: 提出TDR框架，通过将ICL示例解耦到具体任务，并利用LLM的反馈监督训练检索模块，从而提升检索高质量示例的能力。

Result: TDR在30个NLP任务上均提升了表现，达到最新最优（SOTA），且作为可插拔方法适配多种LLM，显著增强ICL示例检索。

Conclusion: 提出的TDR框架能解耦多任务下的ICL示例，并结合LLM的细粒度反馈改进检索模块，实验表明TDR在30个NLP任务中均取得SOTA表现，对强化ICL示例检索效果极为有效。

Abstract: In-context learning (ICL) has become a classic approach for enabling LLMs to
handle various tasks based on a few input-output examples. The effectiveness of
ICL heavily relies on the quality of these examples, and previous works which
focused on enhancing example retrieval capabilities have achieved impressive
performances. However, two challenges remain in retrieving high-quality
examples: (1) Difficulty in distinguishing cross-task data distributions, (2)
Difficulty in making the fine-grained connection between retriever output and
feedback from LLMs. In this paper, we propose a novel framework called TDR. TDR
decouples the ICL examples from different tasks, which enables the retrieval
module to retrieve examples specific to the target task within a multi-task
dataset. Furthermore, TDR models fine-grained feedback from LLMs to supervise
and guide the training of the retrieval module, which helps to retrieve
high-quality examples. We conducted extensive experiments on a suite of 30 NLP
tasks, the results demonstrate that TDR consistently improved results across
all datasets and achieves state-of-the-art performance. Meanwhile, our approach
is a plug-and-play method, which can be easily combined with various LLMs to
improve example retrieval abilities for ICL. The code is available at
https://github.com/Nnn-s/TDR.

</details>


### [57] [Hybrid Annotation for Propaganda Detection: Integrating LLM Pre-Annotations with Human Intelligence](https://arxiv.org/abs/2507.18343)
*Ariana Sahitaj,Premtim Sahitaj,Veronika Solopova,Jiaao Li,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本研究提出结合大语言模型与人工标注的新方法，用于社交媒体宣传检测。通过LLM辅助预标注与知识蒸馏，有效提升了标注一致性和系统扩展性，助力构建透明、可靠的宣传检测体系。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的宣传检测因任务复杂和高质量标注数据有限而变得具有挑战性。传统的人类标注存在一致性低、效率低等问题，影响了宣传检测系统的可靠性和可扩展性。

Method: 提出了一种结合人类专家与大语言模型（LLM）协作的新框架，实现更一致和可扩展的标注流程。具体包括：1）制定了包含14种细粒度宣传技巧的分层分类体系；2）在人类标注HQP数据集时发现细粒度标签之间一致性较低；3）设计LLM辅助的预标注流程，由LLM抽取宣传片段、解释原因并进行局部和全局标签分配；4）进行二次人类验证实验，评估一致性和效率；5）将LLM生成的高质量数据用于微调小型语言模型，采用知识蒸馏进行标注学习。

Result: LLM辅助的预标注流程显著提高了人类标注的一致性和时效性。通过使用LLM生成的数据进行SLM微调，显著提升了自动宣传检测系统的可扩展性和鲁棒性。标注流程和检测系统的透明性和问责性也得到加强。代码已公开。

Conclusion: 结合人类与LLM协作可以有效提高宣传检测任务标注的一致性和效率，并通过知识蒸馏促进小模型的实用化，为构建可扩展、透明且具备问责能力的宣传检测系统提供了新思路。

Abstract: Propaganda detection on social media remains challenging due to task
complexity and limited high-quality labeled data. This paper introduces a novel
framework that combines human expertise with Large Language Model (LLM)
assistance to improve both annotation consistency and scalability. We propose a
hierarchical taxonomy that organizes 14 fine-grained propaganda techniques into
three broader categories, conduct a human annotation study on the HQP dataset
that reveals low inter-annotator agreement for fine-grained labels, and
implement an LLM-assisted pre-annotation pipeline that extracts propagandistic
spans, generates concise explanations, and assigns local labels as well as a
global label. A secondary human verification study shows significant
improvements in both agreement and time-efficiency. Building on this, we
fine-tune smaller language models (SLMs) to perform structured annotation.
Instead of fine-tuning on human annotations, we train on high-quality
LLM-generated data, allowing a large model to produce these annotations and a
smaller model to learn to generate them via knowledge distillation. Our work
contributes towards the development of scalable and robust propaganda detection
systems, supporting the idea of transparent and accountable media ecosystems in
line with SDG 16. The code is publicly available at our GitHub repository.

</details>


### [58] [CLEAR: Error Analysis via LLM-as-a-Judge Made Easy](https://arxiv.org/abs/2507.18392)
*Asaf Yehudai,Lilach Eden,Yotam Perlitz,Roy Bar-Haim,Michal Shmueli-Scheuer*

Main category: cs.CL

TL;DR: 以前的大模型评测只给出分数，不解释原因。本文提出CLEAR工具包，能自动分析和可视化模型具体错误原因，对RAG和数学任务有效，提升了错误分析的可操作性。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型（LLMs）的评测多依赖其他LLM作为“裁判”，但只给出整体分数或排名，无法解释模型表现背后的具体原因，导致难以采取针对性改进。

Method: 提出CLEAR，一个可交互的开源LLM错误分析工具包。其方法包括生成每个实例的文本反馈，归纳系统级错误类型，量化各种错误的发生率，并提供可交互的仪表盘用于聚合可视化、筛选和深入分析具体案例。

Result: 该工具包针对RAG和数学基准任务进行了案例分析和展示，并通过用户案例研究验证其实用性。

Conclusion: CLEAR能够细致地揭示LLM表现中的具体错误类型及其比例，帮助开发者理解“为何模型表现如此”，弥补以往仅得分数的不足，从而更有针对性地优化模型。

Abstract: The evaluation of Large Language Models (LLMs) increasingly relies on other
LLMs acting as judges. However, current evaluation paradigms typically yield a
single score or ranking, answering which model is better but not why. While
essential for benchmarking, these top-level scores obscure the specific,
actionable reasons behind a model's performance. To bridge this gap, we
introduce CLEAR, an interactive, open-source package for LLM-based error
analysis. CLEAR first generates per-instance textual feedback, then it creates
a set of system-level error issues, and quantifies the prevalence of each
identified issue. Our package also provides users with an interactive dashboard
that allows for a comprehensive error analysis through aggregate
visualizations, applies interactive filters to isolate specific issues or score
ranges, and drills down to the individual instances that exemplify a particular
behavioral pattern. We demonstrate CLEAR analysis for RAG and Math benchmarks,
and showcase its utility through a user case study.

</details>


### [59] [Factual Inconsistencies in Multilingual Wikipedia Tables](https://arxiv.org/abs/2507.18406)
*Silvia Cappa,Lingxiao Kong,Pille-Riin Peet,Fanfu Wei,Yuchen Zhou,Jan-Christoph Kalo*

Main category: cs.CL

TL;DR: 作者揭示了维基百科不同语言版本表格内容存在显著不一致，通过开发新方法进行抓取、对齐、分析并分类测量。这一发现对提升跨语言知识一致性和支撑AI系统的可靠性具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 维基百科涵盖300多种语言，各语言版本内容独立撰写和更新，导致在相同主题下出现事实不一致性。由于维基百科是AI等系统的重要知识来源，这种不一致性影响了其中立性和可靠性，因此亟需系统性研究其跨语言数据一致性问题。

Method: 作者开发了一套收集、对齐并分析维基百科多语言条目表格数据的方法，界定了不一致性的不同类别，并采用定量和定性的多种度量指标，对一个样本数据集进行多语言对齐和分析。

Result: 研究揭示了维基百科结构化（表格）内容在多语言版本间存在显著不一致现象，并根据设定的分类标准进行了详细度量，提供了跨语言一致性的新见解。

Conclusion: 维基百科多语言之间存在事实不一致性，这影响知识的准确传播和AI系统的可靠性。相关分析结果可为事实核查、多语言知识交互及可靠AI系统设计提供参考。

Abstract: Wikipedia serves as a globally accessible knowledge source with content in
over 300 languages. Despite covering the same topics, the different versions of
Wikipedia are written and updated independently. This leads to factual
inconsistencies that can impact the neutrality and reliability of the
encyclopedia and AI systems, which often rely on Wikipedia as a main training
source. This study investigates cross-lingual inconsistencies in Wikipedia's
structured content, with a focus on tabular data. We developed a methodology to
collect, align, and analyze tables from Wikipedia multilingual articles,
defining categories of inconsistency. We apply various quantitative and
qualitative metrics to assess multilingual alignment using a sample dataset.
These insights have implications for factual verification, multilingual
knowledge interaction, and design for reliable AI systems leveraging Wikipedia
content.

</details>


### [60] [FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs](https://arxiv.org/abs/2507.18417)
*Giorgos Iacovides,Wuyang Zhou,Danilo Mandic*

Main category: cs.CL

TL;DR: 本文提出了首个基于人类偏好对齐和直接偏好优化的金融专用大模型FinDPO，显著提升了金融情感分析的泛化能力和投资表现，开创了情感驱动投资策略的新方向。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（GenAI）的快速发展，现有的金融情感分析主要依赖有监督微调的大型语言模型（LLMs），但这种方法容易记忆训练数据，导致对新样本泛化能力较弱。金融领域对模型在未见过的事件和细致的专业语言处理能力有更高的需求，因此迫切需要更具泛化能力和适应性的解决方案。

Method: 提出了FinDPO，这是首个针对金融领域、基于直接偏好优化（DPO）后训练的人类偏好对齐的大型语言模型框架。该模型利用人类偏好对齐技术提升泛化能力，并提出了一种“logit-to-score”转换方法，将离散的情感预测转化为可排序的连续情感得分，便于实际投资组合策略应用。

Result: FinDPO在标准情感分类基准测试上取得了领先性能，相比现有的有监督微调模型在平均表现上提升了11%。在投资回测中，FinDPO是首个能够在考虑5个基点交易成本下，维持年化67%显著正收益和2.0夏普比率的基于情感分析的投资模型。

Conclusion: FinDPO通过人类偏好对齐和创新的情感打分方法，有效克服了传统SFT LLM的泛化不足问题，在金融情感分析和实际投资策略中实现了显著提升和应用价值。

Abstract: Opinions expressed in online finance-related textual data are having an
increasingly profound impact on trading decisions and market movements. This
trend highlights the vital role of sentiment analysis as a tool for quantifying
the nature and strength of such opinions. With the rapid development of
Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs)
have become the de facto standard for financial sentiment analysis. However,
the SFT paradigm can lead to memorization of the training data and often fails
to generalize to unseen samples. This is a critical limitation in financial
domains, where models must adapt to previously unobserved events and the
nuanced, domain-specific language of finance. To this end, we introduce FinDPO,
the first finance-specific LLM framework based on post-training human
preference alignment via Direct Preference Optimization (DPO). The proposed
FinDPO achieves state-of-the-art performance on standard sentiment
classification benchmarks, outperforming existing supervised fine-tuned models
by 11% on the average. Uniquely, the FinDPO framework enables the integration
of a fine-tuned causal LLM into realistic portfolio strategies through a novel
'logit-to-score' conversion, which transforms discrete sentiment predictions
into continuous, rankable sentiment scores (probabilities). In this way,
simulations demonstrate that FinDPO is the first sentiment-based approach to
maintain substantial positive returns of 67% annually and strong risk-adjusted
performance, as indicated by a Sharpe ratio of 2.0, even under realistic
transaction costs of 5 basis points (bps).

</details>


### [61] [AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data](https://arxiv.org/abs/2507.18442)
*Rana Alshaikh,Israa Alghanmi,Shelan Jeawak*

Main category: cs.CL

TL;DR: 本研究构建了阿拉伯语表格理解和推理基准AraTable，评测表明现有LLMs在复杂推理任务上表现不足，并提出了高效自动化评测方案，为阿拉伯语结构化数据处理能力的提升奠定基础。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但其对结构化数据（特别是表格数据）的理解和推理能力仍有局限。虽然针对英语表格数据的基准测试丰富，但由于公共资源匮乏以及阿拉伯语独特的语言特性，阿拉伯语表格数据的评测资源十分有限。作者为弥补这一空白，提出阿拉伯语表格数据的新基准。

Method: 本研究提出了AraTable基准，旨在评估LLMs对阿拉伯语表格数据的推理和理解能力。AraTable包含直接问答、事实验证和复杂推理等多种评测任务，覆盖广泛的阿拉伯语表格数据来源。基准集的构建采用混合流程，首先由LLMs生成初步内容，然后由人工专家进行筛选与校验，以保证高质量。研究还提出了完全自动化的评测框架，其自我推敲机制使得评测结果几乎与人工一致。

Result: 初步分析表明，LLMs在直接问答等简单表格任务上表现尚可，但在需要更深层推理和事实验证的复杂任务中仍存在明显认知障碍。这反映了改进阿拉伯语表格推理能力的巨大空间。自动化评测框架的表现几乎与人工评判者一致。

Conclusion: AraTable为评估和提升LLMs在阿拉伯语结构化数据处理方面提供了有价值的公开资源和评价框架，将推动基础模型在阿拉伯语结构化数据分析领域的发展。

Abstract: The cognitive and reasoning abilities of large language models (LLMs) have
enabled remarkable progress in natural language processing. However, their
performance in interpreting structured data, especially in tabular formats,
remains limited. Although benchmarks for English tabular data are widely
available, Arabic is still underrepresented because of the limited availability
of public resources and its unique language features. To address this gap, we
present AraTable, a novel and comprehensive benchmark designed to evaluate the
reasoning and understanding capabilities of LLMs when applied to Arabic tabular
data. AraTable consists of various evaluation tasks, such as direct question
answering, fact verification, and complex reasoning, involving a wide range of
Arabic tabular sources. Our methodology follows a hybrid pipeline, where
initial content is generated by LLMs and subsequently filtered and verified by
human experts to ensure high dataset quality. Initial analyses using AraTable
show that, while LLMs perform adequately on simpler tabular tasks such as
direct question answering, they continue to face significant cognitive
challenges when tasks require deeper reasoning and fact verification. This
indicates that there are substantial opportunities for future work to improve
performance on complex tabular reasoning tasks. We also propose a fully
automated evaluation framework that uses a self-deliberation mechanism and
achieves performance nearly identical to that of human judges. This research
provides a valuable, publicly available resource and evaluation framework that
can help accelerate the development of foundational models for processing and
analysing Arabic structured data.

</details>


### [62] [Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language](https://arxiv.org/abs/2507.18448)
*Md Obyedullahil Mamun,Md Adyelullahil Mamun,Arif Ahmad,Md. Imran Hossain Emu*

Main category: cs.CL

TL;DR: 研究用XLM-RoBERTa-large实现了孟加拉语文本标点恢复，准确率高且泛化能力强，公开了数据与代码，为低资源NLP提供基线。


<details>
  <summary>Details</summary>
Motivation: 标点恢复对于自动语音识别（ASR）后的文本可读性和下游任务极为关键，尤其是在如孟加拉语这样的低资源语言环境下。面对标注资源稀缺的问题，如何提升标点恢复的准确性成为亟需研究的方向。

Method: 本文基于transformer架构，应用了XLM-RoBERTa-large模型，对未带标点的孟加拉语文本进行自动标点恢复。研究聚焦于句号、逗号、问号和感叹号的预测，通过构建多样化的大规模训练语料，并采用数据增强（augmentation factor alpha = 0.20%）技术提升模型表现。

Result: 最佳模型在News测试集上取得97.1%的准确率，在Reference和ASR测试集上分别为91.2%和90.2%。模型在真实噪声场景（如ASR转录文本）中表现良好，具有很强的泛化能力。

Conclusion: 本工作为孟加拉语标点恢复任务建立了强有力的基线，模型和数据集均已公开，将为低资源自然语言处理领域后续研究提供有力支撑。

Abstract: Punctuation restoration enhances the readability of text and is critical for
post-processing tasks in Automatic Speech Recognition (ASR), especially for
low-resource languages like Bangla. In this study, we explore the application
of transformer-based models, specifically XLM-RoBERTa-large, to automatically
restore punctuation in unpunctuated Bangla text. We focus on predicting four
punctuation marks: period, comma, question mark, and exclamation mark across
diverse text domains. To address the scarcity of annotated resources, we
constructed a large, varied training corpus and applied data augmentation
techniques. Our best-performing model, trained with an augmentation factor of
alpha = 0.20%, achieves an accuracy of 97.1% on the News test set, 91.2% on the
Reference set, and 90.2% on the ASR set.
  Results show strong generalization to reference and ASR transcripts,
demonstrating the model's effectiveness in real-world, noisy scenarios. This
work establishes a strong baseline for Bangla punctuation restoration and
contributes publicly available datasets and code to support future research in
low-resource NLP.

</details>


### [63] [Generation of Synthetic Clinical Text: A Systematic Review](https://arxiv.org/abs/2507.18451)
*Basel Alshaikhdeeb,Ahmed Abdelmonem Hemedan,Soumyabrata Ghosh,Irina Balaur,Venkata Satagopam*

Main category: cs.CL

TL;DR: 本文系统回顾了合成医疗自由文本的研究现状，发现其以数据增强为核心应用，主流技术为transformer类模型，自动评估以效用为主，隐私问题待加强人工检查，整体促进了医学NLP发展。


<details>
  <summary>Details</summary>
Motivation: 临床NLP领域常面临数据稀疏和隐私等问题。生成合成临床文本被认为是一种有效的解决途径，但已有相关工作的全景式评述和量化分析较少，因此本文旨在系统回顾并量化分析临床自由文本合成的发展现状。

Method: 作者系统性检索了多个数据库（PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv）中的文献，通过设定研究问题（用途、技术、评价方法）对相关合成医疗自由文本的文献进行整理与定量分析。最终筛选了94篇相关论文。

Result: 最主要的生成用途包括文本增强、辅助写作、语料构建、隐私保护、标注和可用性。主流技术是transformer结构，特别是GPT类模型。评估主要有四方面：相似性、隐私、结构和效用，其中效用评估最常见。生成的文本能在部分NLP下游任务中模仿真实文档，但更大价值在补充真实文档、提升算法性能、解决稀疏。然而，隐私泄露问题依然存在，需要更多人工评估以确保无敏感信息。

Conclusion: 合成临床自由文本是辅助医学NLP发展的重要资产，在解决数据稀疏和隐私等难题上表现突出，可加速行业应用和工作流开发，但需持续关注隐私保护。

Abstract: Generating clinical synthetic text represents an effective solution for
common clinical NLP issues like sparsity and privacy. This paper aims to
conduct a systematic review on generating synthetic medical free-text by
formulating quantitative analysis to three research questions concerning (i)
the purpose of generation, (ii) the techniques, and (iii) the evaluation
methods. We searched PubMed, ScienceDirect, Web of Science, Scopus, IEEE,
Google Scholar, and arXiv databases for publications associated with generating
synthetic medical unstructured free-text. We have identified 94 relevant
articles out of 1,398 collected ones. A great deal of attention has been given
to the generation of synthetic medical text from 2018 onwards, where the main
purpose of such a generation is towards text augmentation, assistive writing,
corpus building, privacy-preserving, annotation, and usefulness. Transformer
architectures were the main predominant technique used to generate the text,
especially the GPTs. On the other hand, there were four main aspects of
evaluation, including similarity, privacy, structure, and utility, where
utility was the most frequent method used to assess the generated synthetic
medical text. Although the generated synthetic medical text demonstrated a
moderate possibility to act as real medical documents in different downstream
NLP tasks, it has proven to be a great asset as augmented, complementary to the
real documents, towards improving the accuracy and overcoming
sparsity/undersampling issues. Yet, privacy is still a major issue behind
generating synthetic medical text, where more human assessments are needed to
check for the existence of any sensitive information. Despite that, advances in
generating synthetic medical text will considerably accelerate the adoption of
workflows and pipeline development, discarding the time-consuming legalities of
data transfer.

</details>


### [64] [Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models](https://arxiv.org/abs/2507.18504)
*Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 本文提出将稀疏依赖图嵌入到LLM注意力机制中的GraDe新方法，显著提升了表格数据生成与建模性能，方法高效并易于集成。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型（LLM）在表格数据建模时，默认对所有特征对进行关注，然而表格数据本身存在稀疏依赖，许多特征间的交互作用并不重要。这种结构导致LLM的注意力机制无法高效地捕捉关键信息，尤其是在特征关系复杂或语义模糊的数据集中问题更加突出。

Method: 本文提出了一种名为GraDe（Graph-Guided Dependency Learning）的新方法，将稀疏依赖图显式融入LLM的注意力机制。GraDe利用外部提取的函数依赖关系，引导一个轻量级动态图学习模块，使模型能够更好地关注重要的特征交互，抑制无关的特征对。

Result: 在多个真实数据集上的实验表明，GraDe在处理复杂依赖的数据集时，较现有LLM方法性能提升可达12%；同时在合成数据质量方面，也取得了与现有最优方法相当的结果。

Conclusion: GraDe方法有效且对现有LLM结构影响较小，能够为表格数据的结构感知建模提供实用解决方案。

Abstract: Large Language Models (LLMs) have shown strong potential for tabular data
generation by modeling textualized feature-value pairs. However, tabular data
inherently exhibits sparse feature-level dependencies, where many feature
interactions are structurally insignificant. This creates a fundamental
mismatch as LLMs' self-attention mechanism inevitably distributes focus across
all pairs, diluting attention on critical relationships, particularly in
datasets with complex dependencies or semantically ambiguous features. To
address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a
novel method that explicitly integrates sparse dependency graphs into LLMs'
attention mechanism. GraDe employs a lightweight dynamic graph learning module
guided by externally extracted functional dependencies, prioritizing key
feature interactions while suppressing irrelevant ones. Our experiments across
diverse real-world datasets demonstrate that GraDe outperforms existing
LLM-based approaches by up to 12% on complex datasets while achieving
competitive results with state-of-the-art approaches in synthetic data quality.
Our method is minimally intrusive yet effective, offering a practical solution
for structure-aware tabular data modeling with LLMs.

</details>


### [65] [The Moral Gap of Large Language Models](https://arxiv.org/abs/2507.18523)
*Maciej Skorski,Alina Landowska*

Main category: cs.CL

TL;DR: 虽然大型语言模型在多领域任务表现出色，但在道德基础检测方面，其性能明显不如针对性微调的模型，后者在道德推理相关应用中仍然更为可靠。


<details>
  <summary>Details</summary>
Motivation: 道德基础检测对于分析社会话语和开发符合伦理的AI系统至关重要，但主流大型语言模型在专门的道德推理任务上的表现尚不明确。

Method: 本文首次对最先进的大型语言模型（LLMs）与微调变换器模型在Twitter和Reddit数据集上的道德基础检测能力进行了全面对比，采用ROC、PR和DET曲线分析。

Result: 结果显示，LLMs在检测道德内容时存在较高的漏检率和系统性的识别不足，即便经过提示工程优化仍效果有限。

Conclusion: 面向任务的微调模型在道德推理应用上明显优于基于提示的大型语言模型。

Abstract: Moral foundation detection is crucial for analyzing social discourse and
developing ethically-aligned AI systems. While large language models excel
across diverse tasks, their performance on specialized moral reasoning remains
unclear.
  This study provides the first comprehensive comparison between
state-of-the-art LLMs and fine-tuned transformers across Twitter and Reddit
datasets using ROC, PR, and DET curve analysis.
  Results reveal substantial performance gaps, with LLMs exhibiting high false
negative rates and systematic under-detection of moral content despite prompt
engineering efforts. These findings demonstrate that task-specific fine-tuning
remains superior to prompting for moral reasoning applications.

</details>


### [66] [Effective Multi-Task Learning for Biomedical Named Entity Recognition](https://arxiv.org/abs/2507.18542)
*João Ruano,Gonçalo M. Correia,Leonor Barreiros,Afonso Mendes*

Main category: cs.CL

TL;DR: 该文提出SRU-NER模型，通过多任务学习和动态损失调整，有效提升生物医学NER系统对多数据集和嵌套实体的处理能力，模型在各项实验中表现优异，并具有良好的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生物医学命名实体识别（NER）任务因术语复杂、不同数据集标注风格不一致而面临巨大挑战。

Method: 提出了SRU-NER（Slot-based Recurrent Unit NER），这是一种支持嵌套实体识别的新模型，并通过多任务学习有效整合多个数据集。同时，该方法通过动态调整损失计算，避免对某数据集中不存在的实体类型产生误判惩罚。

Result: SRU-NER在包括交叉语料评测和人工评测在内的大量实验中，表现出在生物医学和通用领域NER任务上的竞争性能，并显著提升了跨领域泛化能力。

Conclusion: SRU-NER有效解决了多数据集、不一致标注及嵌套实体等难题，在NER任务中实现了优异且具有泛化性的表现。

Abstract: Biomedical Named Entity Recognition presents significant challenges due to
the complexity of biomedical terminology and inconsistencies in annotation
across datasets. This paper introduces SRU-NER (Slot-based Recurrent Unit NER),
a novel approach designed to handle nested named entities while integrating
multiple datasets through an effective multi-task learning strategy. SRU-NER
mitigates annotation gaps by dynamically adjusting loss computation to avoid
penalizing predictions of entity types absent in a given dataset. Through
extensive experiments, including a cross-corpus evaluation and human assessment
of the model's predictions, SRU-NER achieves competitive performance in
biomedical and general-domain NER tasks, while improving cross-domain
generalization.

</details>


### [67] [GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface](https://arxiv.org/abs/2507.18546)
*Urchade Zaratiana,Gil Pasternak,Oliver Boyd,George Hurn-Maloney,Ash Lewis*

Main category: cs.CL

TL;DR: GLiNER2统一整合了实体识别、分类和结构抽取任务，具备高效、轻量和易部署等优势，且效果与大型语言模型相当，已开源发布。


<details>
  <summary>Details</summary>
Motivation: 当前信息抽取方法通常需要为不同任务设计专用模型，或高度依赖计算资源昂贵的大型语言模型，因此亟需更通用、高效的解决方案。

Method: 基于预训练Transformer编码器，GLiNER2通过直观的基于schema的接口，实现多任务组合同一模型完成实体识别、文本分类及层次结构抽取。

Result: GLiNER2在多个抽取与分类任务上表现优异，并显著提升了实际部署的易用性与效率，可作为pip库直接获取，便于开发者使用。

Conclusion: GLiNER2提供了一个统一且高效的框架，在保持轻量级和高部署便捷性的同时，能实现多种信息抽取和分类任务，性能表现与大型语言模型接近。

Abstract: Information extraction (IE) is fundamental to numerous NLP applications, yet
existing solutions often require specialized models for different tasks or rely
on computationally expensive large language models. We present GLiNER2, a
unified framework that enhances the original GLiNER architecture to support
named entity recognition, text classification, and hierarchical structured data
extraction within a single efficient model. Built pretrained transformer
encoder architecture, GLiNER2 maintains CPU efficiency and compact size while
introducing multi-task composition through an intuitive schema-based interface.
Our experiments demonstrate competitive performance across extraction and
classification tasks with substantial improvements in deployment accessibility
compared to LLM-based alternatives. We release GLiNER2 as an open-source
pip-installable library with pre-trained models and documentation at
https://github.com/fastino-ai/GLiNER2.

</details>


### [68] [GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation](https://arxiv.org/abs/2507.18562)
*Jiafeng Xiong,Yuting Zhao*

Main category: cs.CL

TL;DR: 本文提出了GIIFT框架，通过新型多模态场景图和图注意力网络提升MMT模型对图像信息的归纳能力，在无需图像的情况下达到甚至超越当前最佳水平，显著提升了无图像翻译任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态机器翻译（MMT）方法在利用视觉和语言模态之间的差距时表现有限，通常强制对齐视觉与语言，同时只能在受限的多模态领域中推断，无法泛化到无图像的领域。

Method: 本文提出通过构建新颖的多模态场景图来整合并保持模态特有的信息，并引入GIIFT框架：一个两阶段的图引导归纳型无图像MMT方法，利用跨模态图注意力网络适配器，将多模态知识融合在统一空间，并能够归纳推广到更广泛的无图像翻译领域。

Result: 在Multi30K（英法、英德任务）上，GIIFT即使在推理阶段不使用图像，也超越了现有方法并达到了最新水平；在WMT基准集上，相较于无图像的翻译基线同样有显著提升。

Conclusion: GIIFT框架能够在无需图像的情况下实现更强的多模态机器翻译效果，展示了其对泛化与归纳推理的强大能力，推动了领域发展。

Abstract: Multimodal Machine Translation (MMT) has demonstrated the significant help of
visual information in machine translation. However, existing MMT methods face
challenges in leveraging the modality gap by enforcing rigid visual-linguistic
alignment whilst being confined to inference within their trained multimodal
domains. In this work, we construct novel multimodal scene graphs to preserve
and integrate modality-specific information and introduce GIIFT, a two-stage
Graph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph
Attention Network adapter to learn multimodal knowledge in a unified fused
space and inductively generalize it to broader image-free translation domains.
Experimental results on the Multi30K dataset of English-to-French and
English-to-German tasks demonstrate that our GIIFT surpasses existing
approaches and achieves the state-of-the-art, even without images during
inference. Results on the WMT benchmark show significant improvements over the
image-free translation baselines, demonstrating the strength of GIIFT towards
inductive image-free inference.

</details>


### [69] [Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods](https://arxiv.org/abs/2507.18570)
*Ganesh Sapkota,Md Hasibur Rahman*

Main category: cs.CL

TL;DR: 本文提出将6-mer和BPE分词融合的新方法，有效提升了DNA语言模型的准确率，并兼顾了局部和全局信息，在一系列预测任务中超越了现有主流模型。


<details>
  <summary>Details</summary>
Motivation: 传统k-mer分词在捕捉DNA序列局部结构虽有效，但存在分布不均和对全局背景信息理解有限的问题。为此，作者希望改进分词方法，以提升DNA语言模型的性能。

Method: 提出了一种混合式分词策略，将6-mer分词与Byte Pair Encoding（BPE-600）相结合。具体做法是：合并独特的6mer标记与通过600次BPE循环优化选择的BPE标记，构建平衡且兼具上下文感知能力的词表。

Result: 在下游next-k-mer预测任务中，该方法训练的基础DLM取得了明显优于主流模型（如NT、DNABERT2和GROVER）的预测准确率：3-mer为10.78%，4-mer为10.1%，5-mer为4.12%。

Conclusion: 混合分词方法能够同时保留DNA序列的局部结构和全局背景信息，在基因组语言建模中有显著效果，为未来更多DNA相关研究和分析工具提供了坚实基础。

Abstract: This paper presents a novel hybrid tokenization strategy that enhances the
performance of DNA Language Models (DLMs) by combining 6-mer tokenization with
Byte Pair Encoding (BPE-600). Traditional k-mer tokenization is effective at
capturing local DNA sequence structures but often faces challenges, including
uneven token distribution and a limited understanding of global sequence
context. To address these limitations, we propose merging unique 6mer tokens
with optimally selected BPE tokens generated through 600 BPE cycles. This
hybrid approach ensures a balanced and context-aware vocabulary, enabling the
model to capture both short and long patterns within DNA sequences
simultaneously. A foundational DLM trained on this hybrid vocabulary was
evaluated using next-k-mer prediction as a fine-tuning task, demonstrating
significantly improved performance. The model achieved prediction accuracies of
10.78% for 3-mers, 10.1% for 4-mers, and 4.12% for 5-mers, outperforming
state-of-the-art models such as NT, DNABERT2, and GROVER. These results
highlight the ability of the hybrid tokenization strategy to preserve both the
local sequence structure and global contextual information in DNA modeling.
This work underscores the importance of advanced tokenization methods in
genomic language modeling and lays a robust foundation for future applications
in downstream DNA sequence analysis and biological research.

</details>


### [70] [Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs](https://arxiv.org/abs/2507.18578)
*Feng Hong,Geng Yu,Yushi Ye,Haicheng Huang,Huangjie Zheng,Ya Zhang,Yanfeng Wang,Jiangchao Yao*

Main category: cs.CL

TL;DR: 该论文提出了一种高效的DLLM解码算法WINO，实现了无需训练即可在加速生成的同时提升输出质量，突破了传统DLLMs存在的质量-速度权衡难题。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（DLLMs）虽然能够实现快速并行生成，但在现有方法中，速度提升常常导致生成质量大幅下降，形成严重的质量-速度权衡困境。作者认为这一问题主要源于DLLMs标准解码过程的不可逆性，容易早期产生错误并积累，进而影响整体表现。

Method: 作者提出了一种训练无关、可撤销的解码算法：Wide-In, Narrow-Out（WINO）。该算法采用并行草拟与验证机制，在解码过程中会同时草拟多个候选token，并利用模型的双向上下文能力对可疑token进行验证和重新掩码，从而提升生成质量。

Result: WINO算法在开源DLLMs（如LLaDA和MMaDA）上的实验表明，能够显著改善质量-速度权衡。例如，在GSM8K数学基准上，推理速度提升6倍同时准确率提升2.58%；在Flickr30K图像标题任务上，加速10倍且性能更高。

Conclusion: WINO算法有效地解决了现有DLLMs在高速并行推理时面临的性能下降问题，实现了在不损失甚至提升质量的情况下显著加速生成过程。作者通过全面实验验证了该方法优越性。

Abstract: Diffusion Large Language Models (DLLMs) have emerged as a compelling
alternative to Autoregressive models, designed for fast parallel generation.
However, existing DLLMs are plagued by a severe quality-speed trade-off, where
faster parallel decoding leads to significant performance degradation. We
attribute this to the irreversibility of standard decoding in DLLMs, which is
easily polarized into the wrong decoding direction along with early error
context accumulation. To resolve this, we introduce Wide-In, Narrow-Out (WINO),
a training-free decoding algorithm that enables revokable decoding in DLLMs.
WINO employs a parallel draft-and-verify mechanism, aggressively drafting
multiple tokens while simultaneously using the model's bidirectional context to
verify and re-mask suspicious ones for refinement. Verified in open-source
DLLMs like LLaDA and MMaDA, WINO is shown to decisively improve the
quality-speed trade-off. For instance, on the GSM8K math benchmark, it
accelerates inference by 6$\times$ while improving accuracy by 2.58%; on
Flickr30K captioning, it achieves a 10$\times$ speedup with higher performance.
More comprehensive experiments are conducted to demonstrate the superiority and
provide an in-depth understanding of WINO.

</details>


### [71] [System Report for CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition](https://arxiv.org/abs/2507.18580)
*Jiahao Wang,Ramen Liu,Longhui Zhang,Jing Li*

Main category: cs.CL

TL;DR: 本文提出融合任务重构、检索增强和多轮投票的新框架，有效提升了细粒度中文仇恨言论识别的性能，在公开数据集上的表现显著优于GPT-4o等强大模型。


<details>
  <summary>Details</summary>
Motivation: 中文仇恨言论识别是一个复杂且具有挑战性的任务，特别是在需要细粒度识别的情况下，当前方法存在性能和稳定性的不足。为了解决这一难题，作者提出了新的系统和方法，以提升识别的精度和稳定性。

Method: 提出SRAG-MAV框架，融合了任务重构（TR）、自我检索增强生成（SRAG）以及多轮累积投票（MAV）。该方法将四元组抽取任务转换为三元组抽取，通过动态地从训练集中检索上下文构建提示，并采用多轮推理与投票对输出进行增强。基于Qwen2.5-7B模型实现。

Result: 在STATE ToxiCN数据集上，系统达到了Hard Score 26.66、Soft Score 48.35、Average Score 37.505，显著超过了GPT-4o（Average Score 15.63）和微调后的Qwen2.5-7B（Average Score 35.365）等基线方法。

Conclusion: SRAG-MAV框架在解决细粒度中文仇恨言论识别任务上表现出色，结合创新的任务转换、动态检索和多轮推理策略，带来了更高的准确性和稳定性，优于现有主流方法。

Abstract: This paper presents our system for CCL25-Eval Task 10, addressing
Fine-Grained Chinese Hate Speech Recognition (FGCHSR). We propose a novel
SRAG-MAV framework that synergistically integrates task reformulation(TR),
Self-Retrieval-Augmented Generation (SRAG), and Multi-Round Accumulative Voting
(MAV). Our method reformulates the quadruplet extraction task into triplet
extraction, uses dynamic retrieval from the training set to create contextual
prompts, and applies multi-round inference with voting to improve output
stability and performance. Our system, based on the Qwen2.5-7B model, achieves
a Hard Score of 26.66, a Soft Score of 48.35, and an Average Score of 37.505 on
the STATE ToxiCN dataset, significantly outperforming baselines such as GPT-4o
(Average Score 15.63) and fine-tuned Qwen2.5-7B (Average Score 35.365). The
code is available at https://github.com/king-wang123/CCL25-SRAG-MAV.

</details>


### [72] [AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs](https://arxiv.org/abs/2507.18584)
*Xiaopeng Ke,Hexuan Deng,Xuebo Liu,Jun Rao,Zhenxi Song,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: AQuilt是一种从无标注数据构建专用领域指令微调数据的框架，结合逻辑推理和自检，有效提升大语言模型在特定领域和任务的表现，成本极低，数据相关性优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有领域数据合成方法在成本、性能及泛化性上存在不足，亟需一种低成本、性能优异且适应性强的专用领域数据构建新方法。

Method: 提出AQuilt框架，从无标注数据中结合逻辑推理与自检、支持自定义任务指令，自动构建高质量指令微调数据集，并训练数据合成模型进行验证。

Result: AQuilt生成了包含703k数据的大型数据集，训练出的模型在各项实验表现与DeepSeek-V3相当，但生产成本仅为后者的17%，且生成数据与下游任务相关性更高。

Conclusion: AQuilt框架能够在专用领域以较低成本生成高质量指令微调数据，有效提升大模型在特定领域的表现和下游任务相关性。

Abstract: Despite the impressive performance of large language models (LLMs) in general
domains, they often underperform in specialized domains. Existing approaches
typically rely on data synthesis methods and yield promising results by using
unlabeled data to capture domain-specific features. However, these methods
either incur high computational costs or suffer from performance limitations,
while also demonstrating insufficient generalization across different tasks. To
address these challenges, we propose AQuilt, a framework for constructing
instruction-tuning data for any specialized domains from corresponding
unlabeled data, including Answer, Question, Unlabeled data, Inspection, Logic,
and Task type. By incorporating logic and inspection, we encourage reasoning
processes and self-inspection to enhance model performance. Moreover,
customizable task instructions enable high-quality data generation for any
task. As a result, we construct a dataset of 703k examples to train a powerful
data synthesis model. Experiments show that AQuilt is comparable to DeepSeek-V3
while utilizing just 17% of the production cost. Further analysis demonstrates
that our generated data exhibits higher relevance to downstream tasks. Source
code, models, and scripts are available at https://github.com/Krueske/AQuilt.

</details>


### [73] [TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards](https://arxiv.org/abs/2507.18618)
*Andreea Nica,Ivan Zakazov,Nicolas Mario Baldwin,Saibo Geng,Robert West*

Main category: cs.CL

TL;DR: 本文提出TRPrompt框架，将文本反馈作为奖励信号整合进提示模型训练，无需预先数据集、通过持续自我提升，实现了在高难数学任务上的最佳提示性能。


<details>
  <summary>Details</summary>
Motivation: 现有的提示词优化方法虽然提升了大语言模型（LLM）的推理能力，但大多依赖于人工或启发式文本反馈，或使用数值奖励训练专门的提示模型，两者各有局限。急需一种能高效融合文本反馈与自适应训练机制的新方法，以生成更优质的任务相关提示。

Method: 提出Textual Reward Prompt框架（TRPrompt），将文本化反馈直接作为奖励信号整合进提示模型的训练流程，无需预先收集数据集，通过迭代式反馈改善生成的提示质量，实现提示模型高效自优化。

Result: 实验证明，在GSMHard与MATH等高难度数学任务数据集上，TRPrompt训练出的提示模型可为目标LLM生成最优问句，性能达到当前最好水平。

Conclusion: TRPrompt框架有效融合了文本奖励机制与提示模型训练，不仅无需额外数据收集，还能持续自我提升，为提示优化方法提供了更强性能与灵活性的统一解决方案。

Abstract: Prompt optimization improves the reasoning abilities of large language models
(LLMs) without requiring parameter updates to the target model. Following
heuristic-based "Think step by step" approaches, the field has evolved in two
main directions: while one group of methods uses textual feedback to elicit
improved prompts from general-purpose LLMs in a training-free way, a concurrent
line of research relies on numerical rewards to train a special prompt model,
tailored for providing optimal prompts to the target model. In this paper, we
introduce the Textual Reward Prompt framework (TRPrompt), which unifies these
approaches by directly incorporating textual feedback into training of the
prompt model. Our framework does not require prior dataset collection and is
being iteratively improved with the feedback on the generated prompts. When
coupled with the capacity of an LLM to internalize the notion of what a "good"
prompt is, the high-resolution signal provided by the textual rewards allows us
to train a prompt model yielding state-of-the-art query-specific prompts for
the problems from the challenging math datasets GSMHard and MATH.

</details>


### [74] [Checklists Are Better Than Reward Models For Aligning Language Models](https://arxiv.org/abs/2507.18624)
*Vijay Viswanathan,Yanchao Sun,Shuang Ma,Xiang Kong,Meng Cao,Graham Neubig,Tongshuang Wu*

Main category: cs.CL

TL;DR: 本文提出通过指令提取清单并逐项评分实现强化学习（RLCF），显著提升了大模型在不同基准测试下的任务表现，证明了细粒度指令反馈方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在适应和理解用户指令时，通常依赖“有益性”和“有害性”等固定标准进行强化学习，这限制了强化学习在激发指令遵循方面的潜力。

Method: 提出了一种新的强化学习方法“基于清单反馈的强化学习（RLCF）”。根据指令提取清单，利用AI判定器和专业验证程序逐项评分，综合得分用于计算强化学习奖励。

Result: 与其他对齐方法相比，RLCF在五个广泛研究的基准测试中均实现了性能提升。在FollowBench上提升了4个百分点的hard satisfaction rate，在InFoBench上提升了6个百分点，在Arena-Hard上提升了3个百分点的胜率。

Conclusion: 基于清单的反馈作为一种工具，能有效提升语言模型在面向多样化需求查询时的指令遵循能力。

Abstract: Language models must be adapted to understand and follow user instructions.
Reinforcement learning is widely used to facilitate this -- typically using
fixed criteria such as "helpfulness" and "harmfulness". In our work, we instead
propose using flexible, instruction-specific criteria as a means of broadening
the impact that reinforcement learning can have in eliciting instruction
following. We propose "Reinforcement Learning from Checklist Feedback" (RLCF).
From instructions, we extract checklists and evaluate how well responses
satisfy each item - using both AI judges and specialized verifier programs -
then combine these scores to compute rewards for RL. We compare RLCF with other
alignment methods applied to a strong instruction following model
(Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only
method to improve performance on every benchmark, including a 4-point boost in
hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a
3-point rise in win rate on Arena-Hard. These results establish checklist
feedback as a key tool for improving language models' support of queries that
express a multitude of needs.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [75] [In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator](https://arxiv.org/abs/2507.17780)
*Randy Davila,Boris Brimkov,Ryan Pepper*

Main category: cs.DM

TL;DR: 论文提出了四个由AI自动化系统生成且未被证明或驳斥的图论公开猜想，强调了机器在数学创造和发现过程中的独特意义和可能贡献。


<details>
  <summary>Details</summary>
Motivation: 本文旨在展示由自动化猜想系统TxGraffiti生成的图论中的四个公开猜想，希望借由这些有趣且未解决的问题，激发研究者关注自动化系统在数学创造过程中的作用。

Method: 通过TxGraffiti自动化猜想系统，结合符号模式识别与人工设计的启发式方法，基于大量图实例挖掘和筛选自然的图不变量相关的猜想，并经过多年的人机对话不断精炼。

Result: 作者提出了四个简洁且有内容的数学猜想，这些猜想在数百个图上得到了经验验证，目前尚未被证明或反例推翻。

Conclusion: 这些猜想不仅为图论研究提出崭新的挑战，也凸显了自动化系统在数学创造力中的可能性。作者希望激励人类与AI系统共同探索并思考机器在数学发现过程中的深层价值。

Abstract: We present four open conjectures in graph theory generated by the automated
conjecturing system \texttt{TxGraffiti}. Each conjecture is concise, grounded
in natural graph invariants, and empirically validated across hundreds of
graphs. Despite extensive effort, these statements remain unresolved--defying
both proof and counterexample. They are not only mathematical challenges but
creative expressions--born of symbolic pattern recognition and
mathematician-defined heuristics, refined through years of human dialogue, and
now offered back to the community as collaborative artifacts. These conjectures
invite not only formal proof, but also reflection on how machines can evoke
wonder, spark curiosity, and contribute to the raw material of discovery. By
highlighting these problems, we aim to inspire both human mathematicians and AI
systems to engage with them--not only to solve them, but to reflect on what it
means when machines participate meaningfully in the creative process of
mathematical thought.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [76] [Time for Quiescence: Modelling quiescent behaviour in testing via time-outs in timed automata](https://arxiv.org/abs/2507.18205)
*Laura Brandán Briones,Marcus Gerhold,Petra van den Bos,Mariëlle Stoelinga*

Main category: cs.FL

TL;DR: 提出了一种简单算子，将LTS模型转化为带时钟的定时自动机，形式化工业中基于超时判定静默的实践，无需引入复杂的定时自动机工具，同时保持测试判决的一致性。


<details>
  <summary>Details</summary>
Motivation: 在模型驱动测试（MBT）中，处理系统静默（quiescence）时需要设置超时时间，而现有的定时MBT方法多基于复杂的定时自动机（TA），这与工程师偏好的简单LTS模型存在差距。本文旨在弥合MBT中理论与工业实践之间的差异。

Method: 提出了一种提升算子（lifting operator）χ^M，可以在不引入复杂TA的前提下，将LTS模型转换为带有唯一时钟的定时自动机，以形式化表达通过设置超时判断静默的工业实践。通过该算子，原LTS中的静默在定时自动机中被映射为时钟到达指定时间M。

Result: 1）只有当原实现满足ioco一致性时，其提升后的模型才满足定时tioco_M一致性；2）在ioco测试生成算法前后应用该算子，生成的测试集相同；3）提升后的TA测试集与原LTS测试集对任意实现给出的判决完全一致。

Conclusion: 该方法成功为通过超时判定静默提供了严格的理论基础，实现了简单LTS与定时自动机之间的无缝对接，并保证一致性的测试判决。

Abstract: Model-based testing (MBT) derives test suites from a behavioural
specification of the system under test. In practice, engineers favour simple
models, such as labelled transition systems (LTSs). However, to deal with
quiescence - the absence of observable output - in practice, a time-out needs
to be set to conclude observation of quiescence. Timed MBT exists, but it
typically relies on the full arsenal of timed automata (TA).
  We present a lifting operator $\chi^{\scriptstyle M}\!$ that adds timing
without the TA overhead: given an LTS, $\chi^{\scriptstyle M}\!$ introduces a
single clock for a user chosen time bound $M>0$ to declare quiescence. In the
timed automaton, the clock is used to model that outputs should happen before
the clock reaches value $M$, while quiescence occurs exactly at time $M$. This
way we provide a formal basis for the industrial practice of choosing a
time-out to conclude quiescence. Our contributions are threefold: (1) an
implementation conforms under $\mathbf{ioco}$ if and only if its lifted version
conforms under timed $\mathbf{tioco_M}$ (2) applying $\chi^{\scriptstyle M}\!$
before or after the standard $\mathbf{ioco}$ test-generation algorithm yields
the same set of tests, and (3) the lifted TA test suite and the original LTS
test suite deliver identical verdicts for every implementation.

</details>
