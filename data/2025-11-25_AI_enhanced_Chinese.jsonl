{"id": "2511.17617", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2511.17617", "abs": "https://arxiv.org/abs/2511.17617", "authors": ["Antoine Besset", "Joris Tillet", "Julien Alexandre dit Sandretto"], "title": "Uncertainty Removal in Verification of Nonlinear Systems against Signal Temporal Logic via Incremental Reachability Analysis", "comment": "Accepted to 64th IEEE Conference on Decision and Control 2025 (CDC), IEEE, Dec 2025, Rio de Janeiro (Brazil)", "summary": "A framework is presented for the verification of Signal Temporal Logic (STL) specifications over continuous-time nonlinear systems under uncertainty. Based on reachability analysis, the proposed method addresses indeterminate satisfaction caused by over-approximated reachable sets or incomplete simulations. STL semantics is extended via Boolean interval arithmetic, enabling the decomposition of satisfaction signals into unitary components with traceable uncertainty markers. These are propagated through the satisfaction tree, supporting precise identification even in nested formulas. To improve efficiency, only the reachable sets contributing to uncertainty are refined, identified through the associated markers. The framework allows online or offline monitoring to adapt to incremental system evolution while avoiding unnecessary recomputation. A case study on a nonlinear oscillator demonstrates a significant reduction in satisfaction ambiguity, highlighting the effectiveness of the approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u4e0d\u786e\u5b9a\u975e\u7ebf\u6027\u7cfb\u7edfSTL\u89c4\u8303\u9a8c\u8bc1\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u8fbe\u6027\u5206\u6790\u548c\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u6ee1\u8db3\u6027\u6a21\u7cca\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u52a0\u7cbe\u51c6\u9ad8\u6548\u7684\u7cfb\u7edf\u76d1\u63a7\u3002", "motivation": "\u5728\u975e\u7ebf\u6027\u8fde\u7eed\u65f6\u95f4\u7cfb\u7edf\u4e2d\uff0c\u7531\u4e8e\u53ef\u8fbe\u96c6\u7684\u8fc7\u5ea6\u903c\u8fd1\u6216\u4eff\u771f\u4e0d\u5b8c\u5907\uff0cSTL\u89c4\u8303\u9a8c\u8bc1\u5e38\u51fa\u73b0\u6ee1\u8db3\u6027\u4e0d\u786e\u5b9a\u7684\u95ee\u9898\uff0c\u6709\u5fc5\u8981\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u63d0\u5347\u9a8c\u8bc1\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "method": "\u65b9\u6cd5\u57fa\u4e8e\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u5c06STL\u8bed\u4e49\u6269\u5c55\u4e3a\u5e03\u5c14\u533a\u95f4\u8fd0\u7b97\uff0c\u5e76\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\u4f20\u64ad\uff0c\u5b9e\u73b0\u7cbe\u7ec6\u8ffd\u8e2a\u3002\u901a\u8fc7\u5206\u89e3\u6ee1\u8db3\u6027\u4fe1\u53f7\uff0c\u5e76\u9488\u5bf9\u5e26\u6709\u4e0d\u786e\u5b9a\u6027\u7684\u53ef\u8fbe\u96c6\u8fdb\u884c\u7ec6\u81f4\u5316\u5904\u7406\uff0c\u63d0\u9ad8\u9a8c\u8bc1\u6548\u7387\uff0c\u652f\u6301\u7cfb\u7edf\u589e\u91cf\u6f14\u5316\u4e0b\u7684\u5728\u7ebf\u6216\u79bb\u7ebf\u76d1\u63a7\u3002", "result": "\u6848\u4f8b\u5206\u6790\u8868\u660e\uff0c\u5f53\u5e94\u7528\u4e8e\u975e\u7ebf\u6027\u632f\u8361\u5668\u65f6\uff0c\u8be5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u6ee1\u8db3\u6027\u5224\u5b9a\u4e2d\u7684\u6a21\u7cca\u6027\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6587\u4e2d\u63d0\u51fa\u7684\u57fa\u4e8e\u53ef\u8fbe\u6027\u5206\u6790\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5bf9\u975e\u7ebf\u6027\u7cfb\u7edf\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91(STL)\u89c4\u8303\u9a8c\u8bc1\u4e2d\u7684\u6ee1\u8db3\u6027\u4e0d\u786e\u5b9a\u6027\u3002\u901a\u8fc7\u7cbe\u7ec6\u5316\u4ec5\u4e0e\u4e0d\u786e\u5b9a\u6027\u76f8\u5173\u7684\u53ef\u8fbe\u96c6\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u9a8c\u8bc1\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002\u6848\u4f8b\u5206\u6790\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u6ee1\u8db3\u6027\u6a21\u7cca\u6027\u3002"}}
{"id": "2511.18103", "categories": ["cs.LO", "cs.CL", "cs.FL", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.18103", "abs": "https://arxiv.org/abs/2511.18103", "authors": ["Adrien Banse", "Alessandro Abate", "Rapha\u00ebl M. Jungers"], "title": "Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach", "comment": null, "summary": "Labeled Markov Chains (or LMCs for short) are useful mathematical objects to model complex probabilistic languages. A central challenge is to compare two LMCs, for example to assess the accuracy of an abstraction or to quantify the effect of model perturbations. In this work, we study the recently introduced Cantor-Kantorovich (or CK) distance. In particular we show that the latter can be framed as a discounted sum of finite-horizon Total Variation distances, making it an instance of discounted linear distance, but arising from the natural Cantor topology. Building on the latter observation, we analyze the properties of the CK distance along three dimensions: computational complexity, continuity properties and approximation. More precisely, we show that the exact computation of the CK distance is #P-hard. We also provide an upper bound on the CK distance as a function of the approximation relation between the two LMCs, and show that a bounded CK distance implies a bounded error between probabilities of finite-horizon traces. Finally, we provide a computable approximation scheme, and show that the latter is also #P-hard. Altogether, our results provide a rigorous theoretical foundation for the CK distance and clarify its relationship with existing distances.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7528\u4e8e\u6bd4\u8f83\u6982\u7387\u6a21\u578b\u7684Cantor-Kantorovich\u8ddd\u79bb\uff1a\u63ed\u793a\u5176\u8ba1\u7b97\u4e3a#P-hard\uff0c\u7ed9\u51fa\u4e0a\u754c\u53ca\u8bef\u5dee\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u5b9e\u7528\u7684\u8fd1\u4f3c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4e3a\u6982\u7387\u8bed\u8a00\u5efa\u6a21\u4e0e\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "motivation": "Labeled Markov Chains (LMCs)\u5e7f\u6cdb\u7528\u4e8e\u5efa\u6a21\u590d\u6742\u6982\u7387\u8bed\u8a00\uff0c\u4f46\u5982\u4f55\u6bd4\u8f83\u4e24\u4e2aLMCs\uff0c\u8bc4\u4f30\u62bd\u8c61\u7684\u7cbe\u5ea6\u6216\u91cf\u5316\u6a21\u578b\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u6700\u8fd1\u63d0\u51fa\u7684Cantor-Kantorovich (CK)\u8ddd\u79bb\u4e3a\u89e3\u51b3\u8be5\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u56e0\u800c\u9700\u8981\u6df1\u5165\u7814\u7a76\u8be5\u8ddd\u79bb\u7684\u7406\u8bba\u548c\u8ba1\u7b97\u5c5e\u6027\u3002", "method": "\u9996\u5148\uff0c\u5c06CK\u8ddd\u79bb\u8868\u8ff0\u4e3a\u6709\u9650\u89c6\u754c\u4e0b\u603b\u53d8\u5dee\u8ddd\u79bb\u7684\u8d34\u73b0\u548c\uff0c\u8fd9\u662f\u8d34\u73b0\u7ebf\u6027\u8ddd\u79bb\u7684\u4e00\u79cd\u3002\u7136\u540e\uff0c\u4ece\u8ba1\u7b97\u590d\u6742\u6027\u3001\u8fde\u7eed\u6027\u5c5e\u6027\u548c\u8fd1\u4f3c\u65b9\u6cd5\u4e09\u4e2a\u89d2\u5ea6\u5206\u6790CK\u8ddd\u79bb\u3002\u5177\u4f53\u5305\u62ec\u8bc1\u660eCK\u8ddd\u79bb\u7684\u7cbe\u786e\u8ba1\u7b97\u662f#P-hard\uff0c\u63d0\u51fa\u53ef\u8ba1\u7b97\u8fd1\u4f3c\u65b9\u6848\uff0c\u5e76\u89e3\u6790\u8be5\u65b9\u6848\u7684\u590d\u6742\u6027\u53ca\u4e0e\u6982\u7387\u8bef\u5dee\u7684\u5185\u5728\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86CK\u8ddd\u79bb\u7684\u7cbe\u786e\u8ba1\u7b97\u4e3a#P-hard\uff1b\u7ed9\u51fa\u4e86CK\u8ddd\u79bb\u7684\u4e0a\u754c\uff08\u4e0e\u4e24\u4e2aLMC\u7684\u8fd1\u4f3c\u5173\u7cfb\u76f8\u5173\uff09\uff1b\u5c55\u793a\u4e86\u6709\u754c\u7684CK\u8ddd\u79bb\u53ef\u63a8\u51fa\u6709\u9650\u89c6\u754c\u8f68\u8ff9\u7684\u6982\u7387\u8bef\u5dee\u4e5f\u6709\u4e0a\u754c\uff1b\u6700\u540e\u63d0\u51fa\u4e86\u53ef\u884c\u7684\u8ba1\u7b97\u8fd1\u4f3c\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u540c\u6837\u662f#P-hard\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u9610\u8ff0\u4e86CK\u8ddd\u79bb\u7684\u7406\u8bba\u57fa\u7840\u3001\u5173\u8054\u6027\u8d28\u4ee5\u53ca\u4e0e\u73b0\u6709\u8ddd\u79bb\u5ea6\u91cf\u7684\u5173\u7cfb\uff0c\u4e3aLMC\u6a21\u578b\u6bd4\u8f83\u63d0\u4f9b\u4e86\u4e25\u5bc6\u7684\u6570\u5b66\u4f9d\u636e\u548c\u8ba1\u7b97\u7b56\u7565\u3002"}}
{"id": "2511.19142", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2511.19142", "abs": "https://arxiv.org/abs/2511.19142", "authors": ["Arthur F. Ramos", "Anjolina G. de Oliveira", "Ruy J. G. B. de Queiroz", "Tiago M. L. de Veras"], "title": "Formalizing Computational Paths and Fundamental Groups in Lean", "comment": "20 pages, 2 figures. All definitions and proofs are available in the ComputationalPathsLean GitHub repository", "summary": "Computational paths treat propositional equality as explicit paths built from labelled deduction steps and rewrite rules. This view originates in work by de Queiroz and collaborators and yields a weak groupoid structure for equality, together with a computational account of homotopy inspired by homotopy type theory. In this paper we present a complete mechanization of this framework in Lean 4 and show how it supports concrete homotopy theoretic computations. Our contributions are threefold. First, we formalize the theory of computational paths in Lean, including path formation, composition, inverses, and a rewrite system that identifies redundant or trivial paths. We prove that equality types with computational paths carry a weak groupoid structure in the sense of the original theory. Second, we organize this material into a reusable Lean library, ComputationalPathsLean, which exposes an interface for paths, rewrites, and loop spaces. This library allows later developments to treat computational paths as a drop-in replacement for propositional equality when reasoning about homotopical structure. Third, we apply the library to two canonical examples in algebraic topology. We give Lean proofs that the fundamental group of the circle is isomorphic to the integers and that the fundamental group of the torus is isomorphic to the product of two copies of the integers, both via computational paths. These case studies demonstrate that the computational paths approach scales to nontrivial homotopical computations in a modern proof assistant. All the definitions and proofs described here are available in an open-source Lean 4 repository.", "AI": {"tldr": "\u901a\u8fc7\u8ba1\u7b97\u8def\u5f84\u6846\u67b6\u5728Lean 4\u4e2d\u5f62\u5f0f\u5316\u547d\u9898\u7b49\u4ef7\uff0c\u6784\u5efa\u4e86\u652f\u6301\u590d\u6742\u540c\u4f26\u8ba1\u7b97\u7684\u5de5\u5177\u5e93\uff0c\u5e76\u5e94\u7528\u4e8e\u4ee3\u6570\u62d3\u6251\u7684\u5178\u578b\u4f8b\u5b50\uff0c\u5b9e\u73b0\u53ef\u590d\u7528\u548c\u81ea\u52a8\u5316\u8bc1\u660e\u3002\u8fd9\u63a8\u52a8\u4e86\u7c7b\u578b\u7406\u8bba\u5728\u540c\u4f26\u8ba1\u7b97\u7684\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u4ee5\u5f80\u5173\u4e8e\u547d\u9898\u7b49\u4ef7\u7684\u5904\u7406\u65b9\u5f0f\u4e0d\u591f\u660e\u786e\u3001\u96be\u4ee5\u8fdb\u884c\u5177\u4f53\u7684\u540c\u4f26\u8ba1\u7b97\u3002\u901a\u8fc7\u5c06\u7b49\u4ef7\u89c6\u4e3a\u5e26\u6807\u7b7e\u7684\u63a8\u7406\u6b65\u9aa4\u548c\u91cd\u5199\u89c4\u5219\u6784\u5efa\u7684\u201c\u8ba1\u7b97\u8def\u5f84\u201d\uff0c\u53ef\u4ee5\u5c06\u540c\u4f26\u7c7b\u578b\u7406\u8bba\u7684\u601d\u60f3\u4e0e\u5b9e\u9645\u8ba1\u7b97\u7ed3\u5408\uff0c\u5b9e\u73b0\u66f4\u5177\u4f53\u7684\u6784\u9020\u3002", "method": "\u5728Lean 4\u8bc1\u660e\u52a9\u7406\u4e2d\u5b9e\u73b0\u5e76\u673a\u68b0\u5316\u4e86\u8ba1\u7b97\u8def\u5f84\u6846\u67b6\uff0c\u5177\u4f53\u5305\u62ec\u8def\u5f84\u6784\u9020\u3001\u7ec4\u5408\u3001\u9006\u5143\u7d20\u548c\u91cd\u5199\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u5197\u4f59/\u5e73\u51e1\u8def\u5f84\u7684\u5224\u522b\u3002\u5e76\u5c06\u76f8\u5173\u5185\u5bb9\u6574\u7406\u4e3a\u53ef\u590d\u7528\u7684Lean\u5e93\uff08ComputationalPathsLean\uff09\uff0c\u63d0\u4f9b\u8def\u5f84\u3001\u91cd\u5199\u548c\u73af\u7a7a\u95f4\u7b49\u63a5\u53e3\u3002\u6700\u540e\uff0c\u7528\u4e24\u4e2a\u7ecf\u5178\u4ee3\u6570\u62d3\u6251\u4f8b\u5b50\u5c55\u793a\u4e86\u5176\u5e94\u7528\u80fd\u529b\uff1a\u8bc1\u660e\u5706\u7684\u57fa\u672c\u7fa4\u4e0e\u6574\u6570\u540c\u6784\uff0c\u73af\u9762\u7684\u57fa\u672c\u7fa4\u4e0e\u4e24\u4e2a\u6574\u6570\u4e58\u79ef\u540c\u6784\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u8ba1\u7b97\u8def\u5f84\u7406\u8bba\u5728Lean 4\u4e2d\u7684\u5b8c\u6574\u5f62\u5f0f\u5316\uff0c\u5b9e\u73b0\u4e86\u5f31\u7fa4\u4f53\u7ed3\u6784\u5e76\u652f\u6301\u590d\u6742\u7684\u540c\u4f26\u8bba\u8ba1\u7b97\u3002\u8fd8\u4ee5\u5177\u4f53\u4ee3\u6570\u62d3\u6251\u95ee\u9898\u4e3a\u4f8b\uff0c\u8868\u660e\u8fd9\u79cd\u65b9\u6cd5\u5b9e\u7528\u6027\u5f3a\u3001\u53ef\u6269\u5c55\u6027\u9ad8\uff0c\u5e76\u5df2\u5f00\u6e90\u5168\u90e8\u5b9a\u4e49\u548c\u8bc1\u660e\u3002", "conclusion": "\u5229\u7528\u8ba1\u7b97\u8def\u5f84\u6846\u67b6\uff0c\u65e2\u4fdd\u7559\u4e86\u539f\u6709\u7684\u7fa4\u4f53\u7ed3\u6784\u548c\u540c\u4f26\u52a8\u529b\u5b66\uff0c\u53c8\u80fd\u5b9e\u9645\u89e3\u51b3\u975e\u5e73\u51e1\u7684\u62d3\u6251\u95ee\u9898\uff0c\u8fd8\u65b9\u4fbf\u5728\u81ea\u52a8\u5316\u8bc1\u660e\u73af\u5883\u4e2d\u4f7f\u7528\u548c\u6269\u5c55\uff0c\u4ece\u800c\u63a8\u52a8\u4e86\u540c\u4f26\u578b\u7406\u8bba\u5728\u5177\u4f53\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.17838", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.17838", "abs": "https://arxiv.org/abs/2511.17838", "authors": ["Jai Arora", "Sirui Lu", "Devansh Jain", "Tianfan Xu", "Farzin Houshmand", "Phitchaya Mangpo Phothilimthana", "Mohsen Lesani", "Praveen Narayanan", "Karthik Srinivasa Murthy", "Rastislav Bodik", "Amit Sabne", "Charith Mendis"], "title": "TensorRight: Automated Verification of Tensor Graph Rewrites", "comment": "61 pages, 13 figures, published in POPL 2025", "summary": "Tensor compilers, essential for generating efficient code for deep learning models across various applications, employ tensor graph rewrites as one of the key optimizations. These rewrites optimize tensor computational graphs with the expectation of preserving semantics for tensors of arbitrary rank and size. Despite this expectation, to the best of our knowledge, there does not exist a fully automated verification system to prove the soundness of these rewrites for tensors of arbitrary rank and size. Previous works, while successful in verifying rewrites with tensors of concrete rank, do not provide guarantees in the unbounded setting.\n  To fill this gap, we introduce TensorRight, the first automatic verification system that can verify tensor graph rewrites for input tensors of arbitrary rank and size. We introduce a core language, TensorRight DSL, to represent rewrite rules using a novel axis definition, called aggregated-axis, which allows us to reason about an unbounded number of axes. We achieve unbounded verification by proving that there exists a bound on tensor ranks, under which bounded verification of all instances implies the correctness of the rewrite rule in the unbounded setting. We derive an algorithm to compute this rank using the denotational semantics of TensorRight DSL. TensorRight employs this algorithm to generate a finite number of bounded-verification proof obligations, which are then dispatched to an SMT solver using symbolic execution to automatically verify the correctness of the rewrite rules. We evaluate TensorRight's verification capabilities by implementing rewrite rules present in XLA's algebraic simplifier. The results demonstrate that TensorRight can prove the correctness of 115 out of 175 rules in their full generality, while the closest automatic, bounded-verification system can express only 18 of these rules.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTensorRight\uff0c\u9996\u4e2a\u53ef\u81ea\u52a8\u9a8c\u8bc1\u4efb\u610f\u7ef4\u5ea6/\u5927\u5c0f\u5f20\u91cf\u8ba1\u7b97\u56fe\u91cd\u5199\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u7b97\u6cd5\u548cDSL\u8bed\u8a00\uff0c\u5c06\u65e0\u754c\u9a8c\u8bc1\u5f52\u7ea6\u4e3a\u6709\u9650\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9a8c\u8bc1\u8303\u56f4\u548c\u80fd\u529b\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9700\u8981\u9ad8\u6548\u7684\u4ee3\u7801\u751f\u6210\uff0c\u56e0\u6b64\u5f20\u91cf\u7f16\u8bd1\u5668\u5bf9\u5f20\u91cf\u8ba1\u7b97\u56fe\u8fdb\u884c\u4f18\u5316\u91cd\u5199\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e00\u79cd\u80fd\u591f\u81ea\u52a8\u9a8c\u8bc1\u8fd9\u4e9b\u91cd\u5199\u5728\u4efb\u610f\u7ef4\u5ea6\u548c\u5927\u5c0f\u5f20\u91cf\u4e0b\u8bed\u4e49\u6b63\u786e\u6027\u7684\u7cfb\u7edf\u3002\u8fc7\u53bb\u7684\u9a8c\u8bc1\u5de5\u5177\u4ec5\u80fd\u5904\u7406\u5177\u4f53\u7ef4\u5ea6\uff0c\u800c\u4e0d\u80fd\u4e3a\u65e0\u754c\u573a\u666f\u63d0\u4f9b\u53ef\u9760\u4fdd\u8bc1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86TensorRight\u7cfb\u7edf\uff0c\u5305\u542b\u4e00\u4e2a\u57fa\u4e8e\u201c\u805a\u5408\u8f74\u201d\u5b9a\u4e49\u7684\u6838\u5fc3DSL\u8bed\u8a00\uff0c\u7528\u4e8e\u8868\u793a\u548c\u63a8\u7406\u65e0\u754c\u8f74\u7684\u91cd\u5199\u89c4\u5219\u3002\u901a\u8fc7\u5206\u6790DSL\u7684\u6307\u79f0\u8bed\u4e49\uff0c\u63a8\u5bfc\u51fa\u4e00\u4e2a\u7b97\u6cd5\uff0c\u786e\u5b9a\u53ea\u9700\u9a8c\u8bc1\u6709\u9650\u6570\u91cf\u7684\u6709\u754c\u60c5\u5f62\uff0c\u5373\u53ef\u8bc1\u660e\u65e0\u754c\u60c5\u51b5\u7684\u6b63\u786e\u6027\u3002\u7cfb\u7edf\u5229\u7528\u7b26\u53f7\u6267\u884c\u5c06\u6709\u9650\u7684\u9a8c\u8bc1\u4efb\u52a1\u4f20\u9012\u7ed9SMT\u6c42\u89e3\u5668\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u9a8c\u8bc1\u3002", "result": "TensorRight\u53ef\u4ee5\u81ea\u52a8\u5316\u9a8c\u8bc1XLA\u7b97\u672f\u7b80\u5316\u5668\u4e2d\u7684175\u6761\u91cd\u5199\u89c4\u5219\u4e2d115\u6761\u7684\u5b8c\u5168\u6b63\u786e\u6027\u3002\u800c\u4e4b\u524d\u6700\u9886\u5148\u7684\u7cfb\u7edf\u53ea\u80fd\u9a8c\u8bc1\u5176\u4e2d18\u6761\u89c4\u5219\uff0c\u6781\u5927\u6269\u5c55\u4e86\u81ea\u52a8\u5316\u9a8c\u8bc1\u7684\u80fd\u529b\u8303\u56f4\u3002", "conclusion": "TensorRight\u9996\u6b21\u5b9e\u73b0\u4e86\u4efb\u610f\u7ef4\u5ea6\u548c\u5927\u5c0f\u5f20\u91cf\u91cd\u5199\u89c4\u5219\u7684\u81ea\u52a8\u5316\u6b63\u786e\u6027\u9a8c\u8bc1\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u7684\u53ef\u9760\u4f18\u5316\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.17762", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17762", "abs": "https://arxiv.org/abs/2511.17762", "authors": ["Henning Femmer", "Ivan Esau"], "title": "The Software Engineering Simulations Lab: Agentic AI for RE Quality Simulations", "comment": null, "summary": "Context and motivation. Quality in Requirements Engineering (RE) is still predominantly anecdotal and intuition-driven. Creating a solid requirements quality model requires broad sets of empirical evidence to evaluate quality factors and their context. Problem. However, empirical data on the detailed effects of requirements quality defects is scarce, since it is costly to obtain. Furthermore, with the advent of AI-based development, the requirements quality factors may change: Requirements are no longer only consumed by humans, but increasingly also by AI agents, which might lead to a different efficient and effective requirements style. Principal ideas. We propose to extend the RE research toolbox with Agentic AI simulations, in which software engineering (SE) processes are replicated by standardized agents in stochastic, dynamic, event-driven, qualitative simulations. We argue that their speed and simplicity makes them a valuable addition to RE research, although limitations in replicating human behavior need to be studied and understood. Contribution. This paper contributes a first concept, a research roadmap, a prototype, and a first feasibility study for RE simulations with agentic AI. Study results indicate that even a naive implementation leads to executable simulations, encouraging technical improvements along with broader application in RE research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528Agentic AI\u6a21\u62df\u6280\u672f\u652f\u6301\u9700\u6c42\u5de5\u7a0b\u8d28\u91cf\u8bc4\u4f30\uff0c\u7a81\u7834\u4f20\u7edf\u7ecf\u9a8c\u3001\u76f4\u89c9\u9a71\u52a8\u7684\u9650\u5236\u3002\u7814\u7a76\u521d\u6b65\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\uff0c\u672a\u6765\u53ef\u62d3\u5c55\u548c\u5b8c\u5584\u4ee5\u63d0\u5347RE\u9886\u57df\u7684\u79d1\u5b66\u6027\u548c\u5b9e\u8bc1\u57fa\u7840\u3002", "motivation": "\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4e2d\u7684\u8d28\u91cf\u95ee\u9898\u7f3a\u4e4f\u7cfb\u7edf\u3001\u5b9e\u8bc1\u7684\u7814\u7a76\uff0c\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u548c\u76f4\u89c9\uff0c\u800c\u9ad8\u8d28\u91cf\u7684\u9700\u6c42\u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u5b9e\u8bc1\u6570\u636e\u3002\u7279\u522b\u662f\u5728AI\u4ecb\u5165\u5f00\u53d1\u8fc7\u7a0b\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u6c42\u8d28\u91cf\u56e0\u7d20\u53ef\u80fd\u53d1\u751f\u53d8\u5316\uff0c\u9700\u6c42\u7684\u4f7f\u7528\u5bf9\u8c61\u4e0d\u4ec5\u662f\u4eba\u7c7b\uff0cAI\u4e5f\u5f00\u59cb\u53c2\u4e0e\u9700\u6c42\u7684\u6d88\u8d39\u3002", "method": "\u63d0\u51fa\u5229\u7528Agentic AI\u6a21\u62df\u65b9\u6cd5\uff0c\u5c06\u6807\u51c6\u5316\u667a\u80fd\u4f53\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\uff0c\u901a\u8fc7\u968f\u673a\u3001\u52a8\u6001\u3001\u4e8b\u4ef6\u9a71\u52a8\u3001\u5b9a\u6027\u6a21\u62df\u6765\u8bc4\u4f30\u9700\u6c42\u8d28\u91cf\u3002\u8fd9\u79cd\u65b9\u6cd5\u7b80\u5355\u9ad8\u6548\uff0c\u5e76\u7ed9\u51fa\u4e86\u521d\u6b65\u6982\u5ff5\u3001\u7814\u7a76\u8def\u7ebf\u56fe\u3001\u539f\u578b\u7cfb\u7edf\u548c\u53ef\u884c\u6027\u7814\u7a76\u3002", "result": "\u521d\u6b65\u53ef\u884c\u6027\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u91c7\u7528\u8f83\u4e3a\u7b80\u5355\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u4e5f\u80fd\u591f\u5f97\u5230\u53ef\u6267\u884c\u7684\u6a21\u62df\u7ed3\u679c\uff0c\u9f13\u821e\u4e86\u9700\u6c42\u5de5\u7a0b\u7814\u7a76\u8fdb\u4e00\u6b65\u6280\u672f\u6539\u8fdb\u548c\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002", "conclusion": "Agentic AI\u6a21\u62df\u4e3a\u9700\u6c42\u5de5\u7a0b\u8d28\u91cf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u65b9\u5411\uff0c\u5c3d\u7ba1\u4ecd\u9700\u7814\u7a76\u5982\u4f55\u66f4\u597d\u5730\u590d\u73b0\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5176\u65b9\u6cd5\u5df2\u8bc1\u660e\u5177\u5907\u6f5c\u529b\uff0c\u6709\u671b\u652f\u6301\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u66f4\u7cfb\u7edf\u7684\u8d28\u91cf\u8bc4\u4f30\u3002"}}
{"id": "2511.17559", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.17559", "abs": "https://arxiv.org/abs/2511.17559", "authors": ["Gyubok Lee", "Woosog Chay", "Edward Choi"], "title": "SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering", "comment": "ML4H 2025 Proceedings", "summary": "Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCARE\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u95ee\u7b54\u7cfb\u7edf\u4e2d\u7684SQL\u4e8b\u540e\u9a8c\u8bc1\u673a\u5236\uff0c\u5305\u62ec\u95ee\u9898\u53ef\u7b54\u6027\u5224\u5b9a\u548cSQL\u9a8c\u8bc1/\u7ea0\u9519\u3002\u6db5\u76d6\u591a\u6570\u636e\u5e93\u53ca\u591a\u6a21\u578b\uff0c\u5b9e\u9a8c\u8bc1\u660eSCARE\u63ed\u793a\u4e86\u95ee\u9898\u5206\u7c7b\u548cSQL\u7ea0\u9519\u4e4b\u95f4\u7684\u91cd\u5927\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u5f97\u4e34\u5e8a\u533b\u751f\u53ef\u4ee5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e2d\u7684\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f46\u5c06\u8fd9\u4e9b\u6a21\u578b\u7528\u4e8e\u4e34\u5e8a\u5b89\u5168\u5173\u952e\u73af\u5883\u4f9d\u7136\u56f0\u96be\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u751f\u6210\u6216\u8f93\u5165\u9519\u8bef\u7684SQL\u67e5\u8be2\u53ef\u80fd\u635f\u5bb3\u4e34\u5e8a\u51b3\u7b56\u4e0e\u60a3\u8005\u5b89\u5168\u3002\u800c\u76ee\u524d\u7f3a\u4e4f\u7528\u4e8e\u8bc4\u4f30\u4e8b\u540e\u9a8c\u8bc1\u673a\u5236\uff08\u5373\u5728SQL\u6267\u884c\u524d\u68c0\u67e5\u548c\u9a8c\u8bc1\u751f\u6210\u7ed3\u679c\uff09\u7684\u7edf\u4e00\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86SCARE\u8fd9\u4e2a\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u6d4bEHR\u95ee\u7b54\u7cfb\u7edf\u4e2d\u7684\u4e8b\u540e\u5b89\u5168\u5c42\u3002SCARE\u8bc4\u4f30\u4e24\u4e2a\u8054\u5408\u4efb\u52a1\uff1a\uff081\uff09\u5224\u65ad\u95ee\u9898\u662f\u5426\u53ef\u56de\u7b54\u3001\u542b\u7cca\u6216\u65e0\u6cd5\u56de\u7b54\uff1b\uff082\uff09\u9a8c\u8bc1\u6216\u4fee\u6b63\u5019\u9009SQL\u67e5\u8be2\u3002SCARE\u5305\u542b\u6765\u81eaMIMIC-III\u3001MIMIC-IV\u548ceICU\u6570\u636e\u5e93\u76844200\u4e2a\u95ee\u9898-\u5019\u9009SQL-\u671f\u671b\u8f93\u51fa\u4e09\u5143\u7ec4\uff0c\u8986\u76d6\u4e03\u79cd\u4e3b\u6d41text-to-SQL\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u3002\u5bf9\u591a\u79cd\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5305\u62ec\u4e24\u9636\u6bb5\u65b9\u6cd5\u548cagentic\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u95ee\u9898\u5206\u7c7b\u4e0eSQL\u9519\u8bef\u7ea0\u6b63\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u6743\u8861\uff0c\u5e76\u6307\u51fa\u4e86\u76ee\u524d\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "SCARE\u4e3aEHR\u95ee\u7b54\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u7edf\u4e00\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u6539\u8fdbSQL\u9a8c\u8bc1\u673a\u5236\uff0c\u63a8\u52a8\u5728\u4e34\u5e8a\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684LLM\u843d\u5730\u3002"}}
{"id": "2511.18292", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2511.18292", "abs": "https://arxiv.org/abs/2511.18292", "authors": ["Lourdes Beatriz Cajica-Maceda", "Freddy Alejandro Chaurra-Guti\u00e9rrez", "Julio C\u00e9sar P\u00e9rez-Sansalvador", "Jes\u00fas Garc\u00eda-D\u00edaz"], "title": "Graph burning: an overview of mathematical programs", "comment": "18 pages, 9 figures", "summary": "The Graph Burning Problem (GBP) is a combinatorial optimization problem that has gained relevance as a tool for quantifying a graph's vulnerability to contagion. Although it is based on a very simple propagation model, its decision version is NP-complete, and its optimization version is NP-hard. Many of its theoretical properties across different graph families have been thoroughly explored, and numerous interesting variants have been proposed. This paper reports novel mathematical programs for the optimization version of the classical GBP. Among the presented programs are a Mixed-Integer Linear Program (MILP), a Constraint Satisfaction Problem (CSP), two Integer Linear Programs (ILP), and two Quadratic Unconstrained Binary Optimization (QUBO) problems. Most optimization solvers can handle these, being QUBO problems of a capital interest in quantum computing. The primary aim of this paper is to gain a comprehensive understanding of the GBP by examining its different formulations. Compared to other mathematical programs from the literature, the ones presented here are conceptually simpler and involve fewer variables. These make them more practical for finding optimal solutions using optimization algorithms and solvers, as we show by solving some instances with millions of vertices in just a few minutes.", "AI": {"tldr": "\u672c\u6587\u56f4\u7ed5\u56fe\u70e7\u95ee\u9898\uff0c\u63d0\u51fa\u591a\u79cd\u9ad8\u6548\u6570\u5b66\u4f18\u5316\u6a21\u578b\uff0c\u6a21\u578b\u66f4\u7b80\u6d01\u6613\u7b97\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u53ef\u5feb\u901f\u6c42\u89e3\u8d85\u5927\u89c4\u6a21\u5b9e\u4f8b\uff0c\u7406\u8bba\u4e0e\u5e94\u7528\u4ef7\u503c\u517c\u5177\uff0c\u5c24\u5176\u5bf9\u91cf\u5b50\u4f18\u5316\u9886\u57df\u6709\u79ef\u6781\u610f\u4e49\u3002", "motivation": "\u56fe\u70e7\u95ee\u9898\uff08GBP\uff09\u4f5c\u4e3a\u8bc4\u4f30\u56fe\u5bf9\u4f20\u64ad\u6613\u611f\u6027\u7684\u5de5\u5177\uff0c\u7406\u8bba\u610f\u4e49\u91cd\u5927\uff0c\u4e14\u95ee\u9898\u590d\u6742\u6027\u9ad8\uff08\u51b3\u7b56\u7248NP-\u5b8c\u5168\uff0c\u4f18\u5316\u7248NP-\u56f0\u96be\uff09\u3002\u4e0d\u8fc7\uff0c\u76f8\u5173\u6570\u5b66\u4f18\u5316\u6a21\u578b\u4ecd\u6709\u8fdb\u4e00\u6b65\u7b80\u5316\u548c\u9ad8\u6548\u6c42\u89e3\u7684\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u79cd\u6570\u5b66\u4f18\u5316\u6a21\u578b\u7528\u4e8e\u7ecf\u5178GBP\u7684\u4f18\u5316\u6c42\u89e3\uff0c\u5305\u62ec\uff1a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u3001\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff08CSP\uff09\u3001\u4e24\u4e2a\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u548c\u4e24\u4e2a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u5143\u4f18\u5316\uff08QUBO\uff09\u6a21\u578b\u3002\u8fd9\u4e9b\u6a21\u578b\u91c7\u7528\u4e86\u66f4\u7cbe\u7b80\u7684\u53d8\u91cf\u8bbe\u8ba1\uff0c\u4fbf\u4e8e\u5e94\u7528\u4e3b\u6d41\u4f18\u5316\u7b97\u6cd5\u548c\u6c42\u89e3\u5668\u3002", "result": "\u65b0\u63d0\u51fa\u7684\u6570\u5b66\u4f18\u5316\u6a21\u578b\u76f8\u6bd4\u4ee5\u5f80\u6a21\u578b\u66f4\u4e3a\u7b80\u6d01\uff0c\u53d8\u91cf\u66f4\u5c11\uff0c\u56e0\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6548\u7387\u66f4\u9ad8\u3002\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u5728\u5206\u949f\u7ea7\u65f6\u95f4\u5185\u6c42\u89e3\u767e\u4e07\u7ea7\u9876\u70b9\u7684\u5927\u578b\u5b9e\u4f8b\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u65b0\u578b\u6570\u5b66\u4f18\u5316\u6a21\u578b\uff0c\u672c\u6587\u663e\u8457\u63d0\u5347\u4e86\u56fe\u70e7\u95ee\u9898\u7684\u53ef\u884c\u6027\u548c\u5b9e\u9645\u6c42\u89e3\u6548\u7387\uff0c\u5bf9\u4e8e\u91cf\u5b50\u8ba1\u7b97\u53ca\u4f18\u5316\u7b97\u6cd5\u53d1\u5c55\u4e5f\u5177\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2511.19422", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19422", "abs": "https://arxiv.org/abs/2511.19422", "authors": ["David Jiahao Fu", "Aryan Gupta", "Aaron Councilman", "David Grove", "Yu-Xiong Wang", "Vikram Adve"], "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSLMFix\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684\u5c0f\u6a21\u578b\u4fee\u590dLLM\u751f\u6210\u7684\u9519\u8bef\u4ee3\u7801\uff0c\u6709\u6548\u63d0\u5347\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5b9e\u9a8c\u901a\u8fc7\u7387\u8d8595%\uff0c\u4e14\u4f18\u4e8e\u6709\u76d1\u7763\u5fae\u8c03\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\uff08LRPL\uff09\u4e2d\u4ecd\u5e38\u51fa\u73b0\u8bed\u6cd5\u9519\u8bef\u4e14\u65e0\u6cd5\u5b8c\u6210\u4efb\u52a1\u3002LLM\u5fae\u8c03\u6240\u9700\u7684\u9ad8\u6602\u6210\u672c\u4e5f\u9650\u5236\u4e86\u5176\u5728\u4ee3\u7801\u751f\u6210\u4e0a\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7801\u751f\u6210\u6d41\u7a0bSLMFix\uff0c\u901a\u8fc7\u4f7f\u7528\u4ee5\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6280\u672f\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u5bf9LLM\u751f\u6210\u7684\u4ee3\u7801\u8fdb\u884c\u8bed\u6cd5\u4fee\u590d\u3002\u5956\u52b1\u673a\u5236\u7efc\u5408\u5229\u7528\u9759\u6001\u9a8c\u8bc1\u5668\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6807\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u4e13\u7528\u8bed\u8a00\uff08DSL\uff09\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cSLMFix\u65b9\u6cd5\u53ef\u4f7f\u9759\u6001\u9a8c\u8bc1\u5668\u901a\u8fc7\u7387\u8d85\u8fc795%\uff0c\u5728\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4e0b\u4e5f\u4f18\u4e8e\u4f20\u7edf\u7684\u6709\u76d1\u7763\u5fae\u8c03\u65b9\u6848\uff0c\u5305\u62ec\u57287B\u6a21\u578b\u4e0a\u3002", "conclusion": "SLMFix\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u663e\u8457\u63d0\u5347\u57fa\u7840\u6a21\u578b\u7684\u4ee3\u7801\u8d28\u91cf\uff0c\u800c\u4e14\u4e3a\u5e94\u5bf9\u9ad8\u6210\u672c\u5fae\u8c03\u96be\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.17836", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17836", "abs": "https://arxiv.org/abs/2511.17836", "authors": ["Edwin Sundberg", "Thea Ekmark", "Workneh Yilma Ayele"], "title": "Validating API Design Requirements for Interoperability: A Static Analysis Approach Using OpenAPI", "comment": "11 pages, 3 tables, 2 figures. Preprint. To appear in: PoEM2025: Companion Proceedings of the 18th IFIP Working Conference on the Practice of Enterprise Modeling: PoEM Forum, Doctoral Consortium, Business Case and Tool Forum, Workshops, December 3-5, 2025, Geneva, Switzerland", "summary": "RESTful APIs are central in developing interoperable, modular, and maintainable software systems in enterprises today. Also, it is essential to support system evolution, service interoperability, and governance across organizational boundaries to ensure good quality and consistency of these APIs. However, evaluating API design quality, which is part of non-functional requirement tasks, remains a largely manual and ad hoc process, particularly during early development. Using a Design Science Research (DSR) methodology, we elicited user needs, identified 75 API design rules using a literature review, and implemented a configurable rule engine to detect structural violations in OpenAPI specifications. The proposed tool supports organizational adaptability by allowing rules to be customized, enabled, or disabled, enabling integration of domain-specific standards. The evaluation was conducted through structured experiments and thematic analysis involving industry experts. API quality validation contributes to aligning technical designs with requirements and enterprise architecture by strengthening interoperability and governance between enterprise systems. The results show that S.E.O.R.A facilitates early validation of non-functional API requirements, provides actionable and traceable feedback, and aligns well with requirements elicitation and quality assurance processes. It improves the API design process by automating checks that would otherwise require manual inspection, thus supporting consistent and reusable conformance practices. This work contributes to requirements engineering by operationalizing design principles as verifiable constraints and embedding them into a practical validation tool. Future directions include IDE integration, expanded rule coverage, and real-world deployment to support continuous compliance in agile API development lifecycles.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u5f15\u64ce\u7684API\u8bbe\u8ba1\u8d28\u91cf\u81ea\u52a8\u5316\u9a8c\u8bc1\u5de5\u5177\uff0c\u901a\u8fc7\u914d\u7f6e\u548c\u6269\u5c55\u8bbe\u8ba1\u539f\u5219\uff0c\u63d0\u9ad8RESTful API\u5f00\u53d1\u7684\u8d28\u91cf\u3001\u4e00\u81f4\u6027\u548c\u6807\u51c6\u5316\u3002\u8be5\u65b9\u6cd5\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u8d1f\u62c5\uff0c\u652f\u6301\u4f01\u4e1a\u7ea7\u9700\u6c42\u5de5\u7a0b\u4e0e\u6cbb\u7406\uff0c\u672a\u6765\u5c06\u62d3\u5c55\u66f4\u591a\u573a\u666f\u548c\u5b9e\u73b0\u6301\u7eed\u5408\u89c4\u3002", "motivation": "RESTful API\u5728\u4f01\u4e1a\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46API\u8bbe\u8ba1\u8d28\u91cf\u7684\u8bc4\u4f30\u76ee\u524d\u591a\u4f9d\u8d56\u4eba\u5de5\u3001\u7f3a\u4e4f\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\u3002\u8fd9\u5f71\u54cd\u4e86\u7cfb\u7edf\u7684\u6f14\u5316\u3001\u670d\u52a1\u4e92\u64cd\u4f5c\u6027\u4e0e\u6cbb\u7406\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6848\u6765\u63d0\u5347API\u8bbe\u8ba1\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\uff08DSR\uff09\u65b9\u6cd5\uff0c\u6536\u96c6\u7528\u6237\u9700\u6c42\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u63d0\u51fa75\u6761API\u8bbe\u8ba1\u89c4\u5219\uff0c\u5e76\u5b9e\u73b0\u53ef\u914d\u7f6e\u7684\u89c4\u5219\u5f15\u64ce\u6765\u68c0\u6d4bOpenAPI\u89c4\u8303\u4e2d\u7684\u7ed3\u6784\u8fdd\u89c4\u3002\u5de5\u5177\u652f\u6301\u81ea\u5b9a\u4e49\u89c4\u5219\u3001\u96c6\u6210\u9886\u57df\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u5b9e\u9a8c\u548c\u884c\u4e1a\u4e13\u5bb6\u4e13\u9898\u5206\u6790\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u5de5\u5177\uff08S.E.O.R.A\uff09\u80fd\u5728API\u5f00\u53d1\u65e9\u671f\u81ea\u52a8\u9a8c\u8bc1\u975e\u529f\u80fd\u6027\u9700\u6c42\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u548c\u53ef\u8ffd\u6eaf\u53cd\u9988\uff0c\u4e0e\u9700\u6c42\u6536\u96c6\u548c\u8d28\u91cf\u4fdd\u969c\u6d41\u7a0b\u9ad8\u5ea6\u5951\u5408\uff0c\u63d0\u5347\u4e86\u4e00\u81f4\u6027\u548c\u53ef\u590d\u7528\u6027\u3002", "conclusion": "S.E.O.R.A\u5de5\u5177\u5c06API\u8bbe\u8ba1\u539f\u5219\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7ea6\u675f\uff0c\u5e76\u96c6\u6210\u5230\u5b9e\u9645\u9a8c\u8bc1\u5de5\u5177\u4e2d\uff0c\u5b9e\u73b0API\u8bbe\u8ba1\u8d28\u91cf\u81ea\u52a8\u5316\u68c0\u9a8c\u3002\u8be5\u65b9\u6cd5\u4fc3\u8fdb\u4f01\u4e1a\u7cfb\u7edf\u95f4\u7684\u4e92\u64cd\u4f5c\u4e0e\u6cbb\u7406\uff0c\u63a8\u52a8\u9700\u6c42\u5de5\u7a0b\u7684\u53d1\u5c55\u3002\u672a\u6765\u8ba1\u5212\u5305\u62ec\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u652f\u6301\u3001\u6269\u5c55\u89c4\u5219\u8303\u56f4\u548c\u5b9e\u9645\u90e8\u7f72\uff0c\u4ee5\u5b9e\u73b0\u654f\u6377\u5f00\u53d1\u4e2d\u6301\u7eed\u5408\u89c4\u3002"}}
{"id": "2511.17560", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17560", "abs": "https://arxiv.org/abs/2511.17560", "authors": ["Yuechi Zhou", "Yi Su", "Jianxin Zhang", "Juntao Li", "Qingrong Xia", "Zhefeng Wang", "Xinyu Duan", "Baoxing Huai"], "title": "$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\\textbf{A}$ttention-$\\textbf{A}$ware $\\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\\times$.", "AI": {"tldr": "LLM\u5904\u7406\u957f\u6587\u672c\u65f6\u73b0\u6709KV Cache\u91cd\u590d\u5229\u7528\u6280\u672f\u6613\u964d\u6027\u80fd\uff0cA^3\u7b97\u6cd5\u901a\u8fc7\u5173\u6ce8\u76f8\u5173\u6027\u5b9e\u73b0\u51c6\u786e\u9ad8\u6548\u5730\u4fe1\u606f\u878d\u5408\uff0c\u4f7f\u7cfb\u7edf\u66f4\u5feb\u4e14\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u80fd\u5904\u7406\u957f\u6587\u672c\uff0c\u4f46\u5728\u5904\u7406\u5982\u591a\u8f6e\u5bf9\u8bdd\u3001\u6cd5\u5f8b\u6587\u6863\u6216RAG\u7cfb\u7edf\u7b49\u957f\u8f93\u5165\u65f6\uff0c\u89e3\u7801\u5ef6\u8fdf\u548c\u5185\u5b58\u5f00\u9500\u5f88\u5927\uff0c\u963b\u788d\u5b9e\u9645\u90e8\u7f72\u3002\u73b0\u6709KV Cache\u91cd\u590d\u5229\u7528\u65b9\u6cd5\u867d\u7136\u80fd\u7f13\u89e3\u5f00\u9500\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u4f5c\u8005\u6df1\u5165\u5206\u6790\u4e86\u57fa\u4e8e\u91cd\u8ba1\u7b97\u7684KV Cache\u91cd\u590d\u5229\u7528\u65b9\u6cd5\uff0c\u53d1\u73b0\u91cd\u7b97\u7684token\u5e38\u5e38\u4e0e\u95ee\u9898\u6700\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\u7247\u6bb5\u5bf9\u9f50\u4e0d\u4f73\uff0c\u5f71\u54cd\u4e86\u5173\u952e\u8bed\u5883\u8868\u8fbe\u7684\u66f4\u65b0\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86A^3\uff08Attention-Aware Accurate KV Cache Fusion\uff09\u7b97\u6cd5\u2014\u2014\u9884\u5148\u8ba1\u7b97\u5404\u6587\u672c\u7247\u6bb5\u7684KV Cache\uff0c\u5e76\u57fa\u4e8e\u5176\u4e0e\u95ee\u9898\u7684\u76f8\u5173\u6027\u9009\u62e9\u6027\u5730\u878d\u5408\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u3001\u51c6\u786e\u7684KV\u4fe1\u606f\u6574\u5408\u3002", "result": "\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u540cLLM\u5b9e\u9a8c\u8868\u660e\uff0cA^3\u7b97\u6cd5\u5728\u4fdd\u8bc1\u6700\u4f73\u4efb\u52a1\u8868\u73b0\u7684\u540c\u65f6\uff08\u4f18\u4e8e\u56db\u4e2a\u57fa\u7ebf\u7b97\u6cd5\uff09\uff0c\u53ef\u5c06\u201c\u9996token\u751f\u6210\u5ef6\u8fdf\u201d\u964d\u4f4e\u4e00\u534a\u3002", "conclusion": "A^3\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u957f\u6587\u672c\u5904\u7406\u65f6KV Cache\u91cd\u590d\u5229\u7528\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u4e0a\u4e0b\u6587\u8868\u8fbe\u878d\u5408\uff0c\u4e3a\u957f\u6587\u672c\u4efb\u52a1\u5728\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19018", "categories": ["cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.19018", "abs": "https://arxiv.org/abs/2511.19018", "authors": ["Blazej Wrobel", "Dominik Bojko"], "title": "Using random spanning trees in survivable networks design", "comment": null, "summary": "We investigate a process of joining $k$ random spanning trees on a fixed clique $K_n$. The joined trees may not be disjoint and multiple edges are replaced by one simple edge. This process produces a simple graph $G$ on $n$~vertices with an edge set, which is a union of edge sets of the joined trees. We study a random variable $S_{k}$ of the number of edges in the generated graph $G$. The exact formula is derived for the expected value of the random variable $S_{k}$. In addition, an upper bound on the concentration coefficient of the random variable $S_{k}$ is provided. We use results of our analysis to design an algorithm to generate $k$-edge connected graphs for arbitrarily large values of $k \\geq 2$. The designed algorithm solves a particular case of the Survivable Network Design Problem, where the cost of each edge is $c_{e} = 1$ and the connectivity requirement for each pair of vertices $u, v \\in V(G)$ is $k$.The proposed algorithm is within a factor strictly less than $2$ of the optimal value (i.e., the number of edges in the generated graph) and its running time is $O(kn\\log{n})$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u5b8c\u5168\u56fe\u4e0a\u8fde\u63a5\u82e5\u5e72\u968f\u673a\u751f\u6210\u6811\u6784\u9020k-\u8fb9\u8fde\u901a\u56fe\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u751f\u6210\u56fe\u8fb9\u6570\u7684\u671f\u671b\u53ca\u96c6\u4e2d\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u8fd1\u4f3c\u6700\u4f18\u4e14\u9ad8\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u751f\u5b58\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u8fde\u63a5\u591a\u4e2a\u968f\u673a\u751f\u6210\u7684\u751f\u6210\u6811\u6765\u6784\u9020\u9ad8\u8fde\u901a\u6027\u56fe\uff0c\u5c24\u5176\u9488\u5bf9\u4efb\u610f\u5927k\u7684k-\u8fb9\u8fde\u901a\u56fe\u751f\u6210\uff0c\u4ee5\u89e3\u51b3\u7279\u5b9a\u751f\u5b58\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\u3002\u8be5\u95ee\u9898\u5728\u7f51\u7edc\u53ef\u9760\u6027\u548c\u8bbe\u8ba1\u4e2d\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u5728\u5b8c\u5168\u56feK_n\u4e0a\uff0c\u8054\u5408k\u68f5\u968f\u673a\u751f\u6210\u6811\uff0c\u5141\u8bb8\u6811\u95f4\u6709\u91cd\u53e0\u8fb9\uff0c\u4f46\u6700\u7ec8\u56fe\u662f\u7b80\u5355\u56fe\uff08\u65e0\u91cd\u8fb9\uff09\u3002\u5206\u6790\u968f\u673a\u53d8\u91cf$S_k$\uff08\u751f\u6210\u56fe\u4e2d\u8fb9\u7684\u6570\u76ee\uff09\uff0c\u63a8\u5bfc\u5176\u671f\u671b\u516c\u5f0f\uff0c\u5e76\u7ed9\u51fa\u96c6\u4e2d\u7cfb\u6570\u7684\u4e0a\u754c\u3002\u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u751f\u6210k-\u8fb9\u8fde\u901a\u56fe\u7684\u7b97\u6cd5\uff0c\u5e76\u8bc4\u4f30\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u5f97\u5230\u4e86$S_k$\u7684\u4e25\u683c\u671f\u671b\u516c\u5f0f\uff0c\u7ed9\u51fa\u4e86\u96c6\u4e2d\u7cfb\u6570\u7684\u4e0a\u754c\u3002\u8bbe\u8ba1\u7684\u7b97\u6cd5\u80fd\u751f\u6210\u4efb\u610f\u5927k-\u8fb9\u8fde\u901a\u56fe\uff0c\u5e76\u5728\u6bcf\u5bf9\u8282\u70b9\u8981\u6c42k\u8fde\u901a\u6027\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u8ba1\u7b97\u751f\u6210\u7684\u8fb9\u6570\u4e25\u683c\u4f4e\u4e8e2\u500d\u6700\u4f18\u503c\uff0c\u4e14\u8fd0\u884c\u65f6\u95f4\u4e3a$O(kn\\,log\\,n)$\u3002", "conclusion": "\u901a\u8fc7\u968f\u673a\u6811\u6cd5\uff0c\u53ef\u9ad8\u6548\u6784\u9020k-\u8fb9\u8fde\u901a\u56fe\uff0c\u5e76\u6c42\u89e3\u751f\u5b58\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\u7684\u4e00\u4e2a\u7279\u4f8b\uff0c\u517c\u987e\u7b97\u6cd5\u7684\u8fd1\u4f3c\u8d28\u91cf\u548c\u8fd0\u884c\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u7f51\u7edc\u53ef\u9760\u6027\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2511.18458", "categories": ["cs.LO", "math.LO"], "pdf": "https://arxiv.org/pdf/2511.18458", "abs": "https://arxiv.org/abs/2511.18458", "authors": ["Chrysafis Hartonas"], "title": "A General (Uniform) Relational Semantics for Sentential Logics", "comment": null, "summary": "We present a general relational semantics framework which, by varying the axiomatization and components of the relational structures, provides a uniform semantics for sentential logics, classical and non-classical alike. The approach we take rests on a generalization of the J\u00f3nsson-Tarski representation (and duality) for Boolean algebras with operators to the cases of posets, semilattices, or bounded lattices (with, or without distribution) with quasi-operators. Completeness proofs rely on a choice-free construction of canonical extensions for the algebras in the quasivarieties of the equivalent algebraic semantics of the logics. Correspondence results for axiomatic extensions of the logics of implication that we study rely on a fully abstract translation into their modal companions and they are calculated using a generalized Sahlqvist - van Benthem algorithm.", "AI": {"tldr": "\u901a\u8fc7\u63a8\u5e7fJ\u00f3nsson-Tarski\u7406\u8bba\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u7edf\u4e00\u63cf\u8ff0\u7ecf\u5178\u4e0e\u975e\u7ecf\u5178\u53e5\u5b50\u903b\u8f91\u7684\u5173\u7cfb\u8bed\u4e49\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u5e7f\u4e49\u7684\u5b8c\u5907\u6027\u548c\u5bf9\u5e94\u6027\u8bc1\u660e\u3002", "motivation": "\u76ee\u524d\u7f3a\u5c11\u4e00\u79cd\u80fd\u540c\u65f6\u8986\u76d6\u7ecf\u5178\u4e0e\u975e\u7ecf\u5178\u903b\u8f91\u7684\u7edf\u4e00\u5173\u7cfb\u8bed\u4e49\u6846\u67b6\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u66f4\u901a\u7528\u7684\u8bed\u4e49\u5de5\u5177\uff0c\u5e76\u4fdd\u8bc1\u5728\u7b49\u4ef7\u4ee3\u6570\u8bed\u4e49\u4e0b\u7684\u5b8c\u5907\u6027\u4e0e\u5bf9\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u63a8\u5e7fJ\u00f3nsson-Tarski\u8868\u5f81\u7406\u8bba\uff0c\u5c06\u5173\u7cfb\u7ed3\u6784\u5e94\u7528\u4e8e\u504f\u5e8f\u96c6\u3001\u534a\u683c\u3001\u6709\u754c\u683c\u53ca\u5176\u5e26\u6709\u62df\u7b97\u5b50\u7684\u60c5\u51b5\u3002\u4f7f\u7528\u65e0\u9009\u62e9\u516c\u7406\u7684\u5178\u8303\u6269\u5f20\u6784\u9020\u5b9e\u73b0\u5b8c\u5907\u6027\u8bc1\u660e\uff0c\u5229\u7528\u5e7f\u4e49Sahlqvist-van Benthem\u7b97\u6cd5\u83b7\u5f97\u5bf9\u5e94\u6027\u7ed3\u679c\u3002", "result": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u5173\u7cfb\u8bed\u4e49\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5728\u5e7f\u6cdb\u7684\u903b\u8f91\u4f53\u7cfb\u4e2d\u7684\u5b8c\u5907\u6027\u548c\u5bf9\u5e94\u6027\uff0c\u540c\u65f6\u63a8\u5e7f\u4e86\u73b0\u6709\u7684\u6a21\u6001\u903b\u8f91\u6280\u672f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u901a\u7528\u5173\u7cfb\u8bed\u4e49\u6846\u67b6\u80fd\u591f\u7edf\u4e00\u63cf\u8ff0\u7ecf\u5178\u548c\u975e\u7ecf\u5178\u53e5\u5b50\u903b\u8f91\uff0c\u5e76\u4e3a\u5176\u63d0\u4f9b\u5b8c\u5907\u6027\u548c\u5bf9\u5e94\u6027\u7ed3\u679c\u3002"}}
{"id": "2511.17853", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17853", "abs": "https://arxiv.org/abs/2511.17853", "authors": ["SunMin Moon", "Jangwon Gim", "Chaerin Kim", "Yeeun Kim", "YoungJoo Kim", "Kang Choi"], "title": "A Low-Code Methodology for Developing AI Kiosks: a Case Study with the DIZEST Platform", "comment": "5 pages, 2 figures, conference, 2 tables", "summary": "This paper presents a comprehensive study on enhancing kiosk systems through a low-code architecture, with a focus on AI-based implementations. Modern kiosk systems are confronted with significant challenges, including a lack of integration, structural rigidity, performance bottlenecks, and the absence of collaborative frameworks. To overcome these limitations, we propose a DIZEST-based approach methodology, a specialized low-code platform that enables intuitive workflow design and seamless AI integration. Through a comparative analysis with existing platforms, including Jupyter Notebook, ComfyUI, and Orange3, we demonstrate that DIZEST delivers superior performance across key evaluation criteria. Our photo kiosk case study further validates the effectiveness of this approach in improving interoperability, enhancing user experience, and increasing deployment flexibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8eDIZEST\u5e73\u53f0\u7684\u4f4e\u4ee3\u7801AI\u81ea\u52a9\u7ec8\u7aef\u65b9\u6848\uff0c\u5728\u7cfb\u7edf\u6027\u80fd\u3001\u6613\u7528\u6027\u4e0e\u96c6\u6210\u6027\u65b9\u9762\u4f18\u4e8e\u4e3b\u6d41\u5e73\u53f0\uff0c\u5e76\u6709\u6548\u63d0\u5347\u4e86\u5b9e\u9645\u573a\u666f\u4e0b\u7684\u5e94\u7528\u4f53\u9a8c\u3002", "motivation": "\u73b0\u4ee3\u81ea\u52a9\u7ec8\u7aef\u7cfb\u7edf\uff08kiosk systems\uff09\u9762\u4e34\u7cfb\u7edf\u96c6\u6210\u96be\u3001\u7ed3\u6784\u50f5\u5316\u3001\u6027\u80fd\u74f6\u9888\u548c\u7f3a\u4e4f\u534f\u4f5c\u7b49\u4e00\u7cfb\u5217\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u6ee1\u8db3\u591a\u53d8\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDIZEST\u7684\u4f4e\u4ee3\u7801\u67b6\u6784\u65b9\u6cd5\uff0c\u8be5\u5e73\u53f0\u652f\u6301\u76f4\u89c2\u7684\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u4e0eAI\u6a21\u5757\u65e0\u7f1d\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u4e0e\u4e3b\u6d41\u4f4e\u4ee3\u7801\u5e73\u53f0\uff08\u5982Jupyter Notebook\u3001ComfyUI\u548cOrange3\uff09\u5bf9\u6bd4\u5206\u6790\u5176\u4f18\u52bf\u3002", "result": "DIZEST\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5e73\u53f0\uff0c\u4e14\u5728\u7167\u7247\u81ea\u52a9\u7ec8\u7aef\u6848\u4f8b\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u7cfb\u7edf\u4e92\u64cd\u4f5c\u6027\u3001\u7528\u6237\u4f53\u9a8c\u548c\u90e8\u7f72\u7075\u6d3b\u6027\u3002", "conclusion": "\u57fa\u4e8eDIZEST\u7684\u4f4e\u4ee3\u7801\u67b6\u6784\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u81ea\u52a9\u7ec8\u7aef\u7cfb\u7edf\u7684\u96c6\u6210\u4e0e\u6027\u80fd\u96be\u9898\uff0c\u4fc3\u8fdbAI\u80fd\u529b\u6574\u5408\uff0c\u4e3a\u7528\u6237\u548c\u5f00\u53d1\u8005\u5e26\u6765\u66f4\u4f18\u4ea4\u4e92\u4e0e\u66f4\u9ad8\u6548\u7387\u3002"}}
{"id": "2511.17561", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17561", "abs": "https://arxiv.org/abs/2511.17561", "authors": ["Huimin Ren", "Yan Liang", "Baiqiao Su", "Chaobo Sun", "Hengtong Lu", "Kaike Zhang", "Chen Wei"], "title": "LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models", "comment": null, "summary": "The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLexInstructEval\u6846\u67b6\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5316\u548c\u89c4\u5219\u5316\u8bed\u6cd5\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u5f25\u8865\u4e86\u4eba\u5de5\u548c\u81ea\u52a8\u8bc4\u6d4b\u7684\u4e0d\u8db3\uff0c\u5e76\u516c\u5f00\u4e86\u76f8\u5173\u6570\u636e\u548c\u5de5\u5177\uff0c\u52a9\u529b\u6a21\u578b\u53ef\u63a7\u6027\u7814\u7a76\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7cbe\u786e\u6267\u884c\u590d\u6742\u3001\u9ad8\u7cbe\u5ea6\u8bcd\u6c47\u6307\u4ee4\u65b9\u9762\u80fd\u529b\u51fa\u4f17\uff0c\u4f46\u5bf9\u8fd9\u79cd\u80fd\u529b\u7684\u8bc4\u4f30\u4ecd\u5b58\u5728\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e3b\u89c2\u4e14\u6602\u8d35\u7684\u4eba\u5de5\u8bc4\u4f30\uff0c\u8981\u4e48\u57fa\u4e8e\u81ea\u52a8\u5316\u7684LLM\u8bc4\u5ba1\u7cfb\u7edf\uff0c\u4f46\u5b58\u5728\u504f\u89c1\u548c\u4e0d\u53ef\u9760\u95ee\u9898\u3002\u73b0\u6709\u7a0b\u5e8f\u5316\u57fa\u51c6\u666e\u904d\u7f3a\u4e4f\u8868\u8fbe\u80fd\u529b\uff0c\u96be\u4ee5\u7ec6\u81f4\u6d4b\u8bd5\u590d\u6742\u7ec4\u5408\u7ea6\u675f\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u9ad8\u6548\u3001\u7ec6\u81f4\u548c\u5ba2\u89c2\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86LexInstructEval\u8bc4\u6d4b\u6846\u67b6\u3002\u8be5\u6846\u67b6\u57fa\u4e8e\u6b63\u5f0f\u7684\u89c4\u5219\u8bed\u6cd5\uff0c\u5c06\u590d\u6742\u6307\u4ee4\u5206\u89e3\u4e3a<Procedure, Relation, Value>\u4e09\u5143\u7ec4\u3002\u901a\u8fc7\u591a\u9636\u6bb5\u3001\u4eba\u5de5\u53c2\u4e0e\u7684\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u7cfb\u7edf\u6027\u6784\u5efa\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u900f\u660e\u7684\u7a0b\u5e8f\u5316\u5f15\u64ce\u5b9e\u73b0\u5ba2\u89c2\u9a8c\u8bc1\u3002", "result": "LexInstructEval\u80fd\u591f\u7ec6\u7c92\u5ea6\u8bc4\u4f30LLMs\u5bf9\u8bcd\u6c47\u6307\u4ee4\u7684\u8ddf\u968f\u80fd\u529b\uff0c\u5e76\u4e14\u53ef\u81ea\u52a8\u5316\u3001\u5ba2\u89c2\u5730\u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u3002\u4f5c\u8005\u516c\u5f00\u4e86\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u5de5\u5177\uff0c\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002", "conclusion": "LexInstructEval\u63d0\u5347\u4e86\u5bf9LLMs\u53ef\u63a7\u6027\u548c\u53ef\u9760\u6027\u7684\u8bc4\u6d4b\u6c34\u5e73\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u6d4b\u4e3b\u89c2\u6027\u6216\u8868\u8fbe\u80fd\u529b\u4e0d\u8db3\u7684\u7a7a\u767d\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u952e\u8d44\u6e90\u548c\u5de5\u5177\u3002"}}
{"id": "2511.18639", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2511.18639", "abs": "https://arxiv.org/abs/2511.18639", "authors": ["Predrag Jani\u010di\u0107"], "title": "A SAT-based Approach for Specification, Analysis, and Justification of Reductions between NP-complete Problems", "comment": null, "summary": "We propose a novel approach for the development, analysis, and verification of reductions between NP-complete problems. This method uses the URSA system, a SAT-based constraint solver and incorporates features that distinguish it from existing related systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528URSA\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u5f00\u53d1\u3001\u5206\u6790\u548c\u9a8c\u8bc1NP\u5b8c\u5168\u95ee\u9898\u4e4b\u95f4\u7684\u5f52\u7ea6\uff0c\u533a\u522b\u4e8e\u4f20\u7edf\u7cfb\u7edf\uff0c\u63d0\u5347\u5f52\u7ea6\u5de5\u5177\u7684\u80fd\u529b\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u53d1\u3001\u5206\u6790\u548c\u9a8c\u8bc1NP\u5b8c\u5168\u95ee\u9898\u4e4b\u95f4\u7684\u5f52\u7ea6\u3002\u5f52\u7ea6\u5728\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u975e\u5e38\u5173\u952e\uff0c\u662f\u7406\u89e3NP\u5b8c\u5168\u6027\u548c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u57fa\u7840\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u63d0\u9ad8\u5f52\u7ea6\u8fc7\u7a0b\u7684\u81ea\u52a8\u5316\u548c\u53ef\u9a8c\u8bc1\u6027\u6765\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528URSA\u7cfb\u7edf\uff0c\u4e00\u4e2a\u57fa\u4e8eSAT\u7684\u7ea6\u675f\u6c42\u89e3\u5668\uff0c\u5e76\u4e14\u7ed3\u5408\u4e86\u4e00\u4e9b\u533a\u522b\u4e8e\u73b0\u6709\u7cfb\u7edf\u7684\u65b0\u7279\u6027\u3002\u901a\u8fc7\u8fd9\u79cd\u7cfb\u7edf\u5316\u548c\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8fdb\u884cNP\u5b8c\u5168\u95ee\u9898\u5f52\u7ea6\u76f8\u5173\u7684\u5de5\u4f5c\u3002", "result": "\u4f7f\u7528URSA\u7cfb\u7edf\u7684\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u5bf9NP\u5b8c\u5168\u95ee\u9898\u5f52\u7ea6\u7684\u5f00\u53d1\u3001\u5206\u6790\u548c\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u4e86\u533a\u522b\u4e8e\u5df2\u6709\u5de5\u5177\u7684\u65b0\u9014\u5f84\uff0c\u53ef\u80fd\u63d0\u9ad8\u5f52\u7ea6\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u7cfb\u7edf\u5316\u3001\u81ea\u52a8\u5730\u8fdb\u884cNP\u5b8c\u5168\u95ee\u9898\u7684\u5f52\u7ea6\u5f00\u53d1\u4e0e\u9a8c\u8bc1\uff0c\u6709\u671b\u5728\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u53ca\u76f8\u5173\u5e94\u7528\u9886\u57df\u63d0\u4f9b\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17977", "categories": ["cs.SE", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.17977", "abs": "https://arxiv.org/abs/2511.17977", "authors": ["Kuangxiangzi Liu", "Dhiman Chakraborty", "Alexander Liggesmeyer", "Andreas Zeller"], "title": "Synthesizing Precise Protocol Specs from Natural Language for Effective Test Generation", "comment": null, "summary": "Safety- and security-critical systems have to be thoroughly tested against their specifications. The state of practice is to have _natural language_ specifications, from which test cases are derived manually - a process that is slow, error-prone, and difficult to scale. _Formal_ specifications, on the other hand, are well-suited for automated test generation, but are tedious to write and maintain. In this work, we propose a two-stage pipeline that uses large language models (LLMs) to bridge the gap: First, we extract _protocol elements_ from natural-language specifications; second, leveraging a protocol implementation, we synthesize and refine a formal _protocol specification_ from these elements, which we can then use to massively test further implementations.\n  We see this two-stage approach to be superior to end-to-end LLM-based test generation, as 1. it produces an _inspectable specification_ that preserves traceability to the original text; 2. the generation of actual test cases _no longer requires an LLM_; 3. the resulting formal specs are _human-readable_, and can be reviewed, version-controlled, and incrementally refined; and 4. over time, we can build a _corpus_ of natural-language-to-formal-specification mappings that can be used to further train and refine LLMs for more automatic translations.\n  Our prototype, AUTOSPEC, successfully demonstrated the feasibility of our approach on five widely used _internet protocols_ (SMTP, POP3, IMAP, FTP, and ManageSieve) by applying its methods on their _RFC specifications_ written in natural-language, and the recent _I/O grammar_ formalism for protocol specification and fuzzing. In its evaluation, AUTOSPEC recovers on average 92.8% of client and 80.2% of server message types, and achieves 81.5% message acceptance across diverse, real-world systems.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u534f\u8bae\u89c4\u8303\u5230\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u81ea\u52a8\u8f6c\u5316\uff0c\u6709\u6548\u652f\u6301\u534f\u8bae\u7684\u81ea\u52a8\u5316\u5927\u89c4\u6a21\u6d4b\u8bd5\uff0c\u539f\u578b\u7cfb\u7edfAUTOSPEC\u5728\u591a\u534f\u8bae\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u5b89\u5168\u548c\u4fdd\u969c\u5173\u952e\u7cfb\u7edf\u7684\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e2d\u624b\u52a8\u63d0\u53d6\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8fc7\u7a0b\u7e41\u7410\u4e14\u6613\u51fa\u9519\u3001\u4e0d\u6613\u6269\u5c55\uff1b\u800c\u5f62\u5f0f\u5316\u89c4\u8303\u867d\u9002\u5408\u81ea\u52a8\u5316\u751f\u6210\u6d4b\u8bd5\uff0c\u4f46\u7f16\u5199\u7ef4\u62a4\u6210\u672c\u9ad8\u6602\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e0e\u5f62\u5f0f\u89c4\u8303\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u8ffd\u6eaf\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u7b2c\u4e00\u9636\u6bb5\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e2d\u63d0\u53d6\u534f\u8bae\u5173\u952e\u8981\u7d20\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u534f\u8bae\u5b9e\u73b0\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u8981\u7d20\u81ea\u52a8\u5408\u6210\u548c\u4f18\u5316\u5f62\u5f0f\u5316\u534f\u8bae\u89c4\u8303\u3002\u6700\u7ec8\u53ef\u7528\u8fd9\u4e9b\u5f62\u5f0f\u89c4\u8303\u6279\u91cf\u6d4b\u8bd5\u5404\u7c7b\u534f\u8bae\u5b9e\u73b0\u3002", "result": "\u539f\u578b\u7cfb\u7edfAUTOSPEC\u88ab\u5e94\u7528\u4e8e\u4e94\u4e2a\u4e3b\u6d41\u4e92\u8054\u7f51\u534f\u8bae\uff08SMTP\u3001POP3\u3001IMAP\u3001FTP\u3001ManageSieve\uff09\u7684 RFC \u6587\u6863\u6d4b\u8bd5\uff0c\u5e73\u5747\u53ef\u6062\u590d92.8%\u7684\u5ba2\u6237\u7aef\u6d88\u606f\u7c7b\u578b\u548c80.2%\u7684\u670d\u52a1\u7aef\u6d88\u606f\u7c7b\u578b\uff0c\u6d88\u606f\u63a5\u53d7\u7387\u8fbe81.5%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u81ea\u7136\u8bed\u8a00\u5230\u5f62\u5f0f\u5316\u534f\u8bae\u89c4\u8303\u7684\u9ad8\u8d28\u91cf\u81ea\u52a8\u8f6c\u5316\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6d4b\u8bd5\u81ea\u52a8\u5316\u3001\u53ef\u8ffd\u6eaf\u6027\u4e0e\u6269\u5c55\u80fd\u529b\uff0c\u5e76\u80fd\u591f\u5efa\u7acb\u5bf9LLM\u8fdb\u4e00\u6b65\u8bad\u7ec3\u6709\u76ca\u7684\u6620\u5c04\u8bed\u6599\u5e93\u3002"}}
{"id": "2511.17562", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17562", "abs": "https://arxiv.org/abs/2511.17562", "authors": ["Wei Tian", "YuhaoZhou"], "title": "ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector", "comment": null, "summary": "This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.", "AI": {"tldr": "\u63d0\u51faChineseErrorCorrector3-4B\uff0c\u4e00\u4e2a\u57fa\u4e8eQwen3-4B\u7684\u4e2d\u6587\u62fc\u5199\u548c\u8bed\u6cd5\u7ea0\u9519\u7edf\u4e00\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6743\u5a01\u57fa\u51c6\u96c6\u4e0a\u7ea0\u9519\u6210\u7ee9\u8d85\u8fc7\u73b0\u6709\u6a21\u578b\uff0c\u62fc\u5199\u4e0e\u8bed\u6cd5\u7ea0\u9519\u5747\u83b7\u7b2c\u4e00\u3002", "motivation": "\u5c3d\u7ba1\u6c49\u8bed\u4e2d\u62fc\u5199\u548c\u8bed\u6cd5\u9519\u8bef\u7ea0\u6b63\u6280\u672f\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u7edf\u4e00\u5904\u7406\u4e24\u79cd\u9519\u8bef\u65f6\u6027\u80fd\u6709\u9650\uff0c\u4e14\u5728\u6743\u5a01\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u6709\u5f85\u63d0\u5347\u3002\u4e3a\u63d0\u5347\u6c49\u8bed\u62fc\u5199\u548c\u8bed\u6cd5\u7ea0\u6b63\u7684\u51c6\u786e\u6027\u4e0e\u5b9e\u7528\u6027\uff0c\u4e9f\u9700\u4e00\u4e2a\u8868\u73b0\u66f4\u4f18\u3001\u901a\u7528\u6027\u66f4\u5f3a\u7684\u6a21\u578b\u3002", "method": "\u672c\u6587\u5728Qwen3-4B\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86ChineseErrorCorrector3-4B\u6a21\u578b\uff0c\u5c06\u62fc\u5199\u7ea0\u6b63\uff08CSC\uff09\u548c\u8bed\u6cd5\u7ea0\u6b63\uff08CGC\uff09\u7edf\u4e00\u4e8e\u540c\u4e00\u67b6\u6784\uff0c\u5e76\u5728\u591a\u4e2a\u6743\u5a01\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u6d4b\u3002", "result": "\u5728SIGHAN-2015\u3001EC-LAW\u3001MCSC\u548cNaCGEC\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u6a21\u578bF1\u4e0eF0.5\u5206\u6570\u5747\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u516c\u5f00\u6a21\u578b\uff0c\u65e0\u8bba\u62fc\u5199\u8fd8\u662f\u8bed\u6cd5\u7ea0\u6b63\u4efb\u52a1\u5747\u6392\u540d\u7b2c\u4e00\uff0c\u663e\u793a\u4f18\u5f02\u7684\u7efc\u5408\u80fd\u529b\u3002", "conclusion": "ChineseErrorCorrector3-4B\u5728\u4e2d\u6587\u62fc\u5199\u4e0e\u8bed\u6cd5\u9519\u8bef\u7edf\u4e00\u7ea0\u6b63\u9886\u57df\u53d6\u5f97\u6700\u65b0\u6700\u4f18\u8868\u73b0\uff0c\u63d0\u5347\u4e86\u4e2d\u6587\u6587\u672c\u81ea\u52a8\u7ea0\u9519\u6548\u679c\uff0c\u5e76\u4e3a\u76f8\u5173\u4efb\u52a1\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18001", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18001", "abs": "https://arxiv.org/abs/2511.18001", "authors": ["Jiaolong Kong", "Xiaofei Xie", "Yiheng Xiong", "Yuekun Wang", "Jian Wang"], "title": "Enhancing Automated Program Repair via Faulty Token Localization and Quality-Aware Patch Refinement", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated strong potential for automated program repair (APR). However, existing LLM-based techniques primarily rely on coarse-grained external feedback (e.g.,test results) to guide iterative patch generation, while lacking fine-grained internal signals that reveal why a patch fails or which parts of the generated code are likely incorrect. This limitation often leads to inefficient refinement, error propagation, and suboptimal repair performance. In this work, we propose TokenRepair, a novel two-level refinement framework that enhances APR by integrating internal reflection for localizing potentially faulty tokens with external feedback for quality-aware patch refinement. Specifically, TokenRepair first performs internal reflection by analyzing context-aware token-level uncertainty fluctuations to identify suspicious or low-confidence tokens within a patch. It then applies Chain-of-Thought guided rewriting to refine only these localized tokens, enabling targeted and fine-grained correction. To further stabilize the iterative repair loop, TokenRepair incorporates a quality-aware external feedback mechanism that evaluates patch quality and filters out low-quality candidates before refinement. Experimental results show that TokenRepair achieves new state-of-the-art repair performance, correctly fixing 88 bugs on Defects4J 1.2 and 139 bugs on HumanEval-Java, demonstrating substantial improvements ranging from 8.2% to 34.9% across all models on Defects4J 1.2 and from 3.3% to 16.1% on HumanEval-Java.", "AI": {"tldr": "TokenRepair\u901a\u8fc7\u5f15\u5165\u5185\u90e8\u53cd\u601d\u548c\u5916\u90e8\u53cd\u9988\u53cc\u91cd\u673a\u5236\uff0c\u63d0\u9ad8\u4e86\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u7684\u6548\u7387\u548c\u51c6\u786e\u7387\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f73\u8868\u73b0\u3002", "motivation": "\u73b0\u6709LLM\u81ea\u52a8\u4fee\u590d\u4e3b\u8981\u4f9d\u8d56\u5916\u90e8\u7c97\u7c92\u5ea6\u53cd\u9988\uff0c\u7f3a\u4e4f\u5bf9\u9519\u8bef\u6765\u6e90\u7684\u7ec6\u81f4\u5b9a\u4f4d\uff0c\u5bfc\u81f4\u4fee\u590d\u6548\u7387\u4f4e\u3001\u9519\u8bef\u4f20\u64ad\u548c\u4fee\u590d\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u6b64\uff0c\u5f15\u5165\u7ec6\u7c92\u5ea6\u7684\u5185\u90e8\u4fe1\u53f7\u63d0\u5347\u4fee\u590d\u8d28\u91cf\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e24\u7ea7\u7cbe\u4fee\uff1a\u5148\u901a\u8fc7\u5206\u6790token\u7ea7\u522b\u7684\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u5185\u90e8\u53cd\u601d\uff0c\u5728patch\u4e2d\u5b9a\u4f4d\u53ef\u7591token\uff1b\u7136\u540e\u4ec5\u5bf9\u8fd9\u4e9btoken\u8fdb\u884cChain-of-Thought\u6307\u5bfc\u4e0b\u7684\u5c40\u90e8\u91cd\u5199\u3002\u6b64\u5916\uff0c\u7ed3\u5408\u8d28\u91cf\u611f\u77e5\u7684\u5916\u90e8\u53cd\u9988\u673a\u5236\uff0c\u7b5b\u9009\u9ad8\u8d28\u91cf\u5019\u9009\u8865\u4e01\u3002", "result": "TokenRepair\u5728\u4e24\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1aDefects4J 1.2\u4fee\u590d88\u4e2abug\uff08\u63d0\u53478.2%-34.9%\uff09\uff0cHumanEval-Java\u4fee\u590d139\u4e2abug\uff08\u63d0\u53473.3%-16.1%\uff09\uff0c\u5747\u4e3a\u65b0SOTA\u3002", "conclusion": "TokenRepair\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5185\u5916\u53cd\u9988\u7684\u65b0\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u7ec6\u548c\u9ad8\u6548\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u4f18\u8868\u73b0\u3002"}}
{"id": "2511.17565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17565", "abs": "https://arxiv.org/abs/2511.17565", "authors": ["Sarthak Chakraborty", "Suman Nath", "Xuchao Zhang", "Chetan Bansal", "Indranil Gupta"], "title": "Generative Caching for Structurally Similar Prompts and Responses", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \\ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \\ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \\ourmethod{} achieves 83\\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\\sim$20\\% and reduces end-to-end execution latency by $\\sim$34\\% compared to standard prompt matching.", "AI": {"tldr": "\u9488\u5bf9\u7ed3\u6784\u76f8\u4f3c\u4f46\u7ec6\u8282\u4e0d\u540c\u7684\u63d0\u793a\u7f13\u5b58\u9700\u6c42\uff0c\u63d0\u51fa\u751f\u6210\u5f0f\u7f13\u5b58\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u547d\u4e2d\u7387\u4e0e\u54cd\u5e94\u6548\u7387\uff0c\u51cf\u5c11\u9519\u8bef\u7f13\u5b58\u3002", "motivation": "\u4f20\u7edf\u7f13\u5b58\u65b9\u6cd5\u65e0\u6cd5\u5f88\u597d\u5730\u5904\u7406\u7ed3\u6784\u76f8\u4f3c\u4f46\u7ec6\u8282\u4e0d\u540c\u7684\u63d0\u793a\u3002\u7cbe\u786e\u5339\u914d\u8fc7\u4e8e\u4e25\u683c\uff0c\u8bed\u4e49\u5339\u914d\u53c8\u53ef\u80fd\u5ffd\u7565\u91cd\u8981\u5dee\u5f02\uff0c\u5bb9\u6613\u5bfc\u81f4\u7f13\u5b58\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5f0f\u7f13\u5b58\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u7ed3\u6784\u76f8\u4f3c\u63d0\u793a\u95f4\u53ef\u590d\u7528\u7684\u54cd\u5e94\u6a21\u5f0f\uff0c\u4e3a\u65b0\u8bf7\u6c42\u7efc\u5408\u5b9a\u5236\u5316\u8f93\u51fa\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u65e0\u91cd\u590d\u63d0\u793a\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8683%\u7684\u7f13\u5b58\u547d\u4e2d\u7387\u4e14\u51e0\u4e4e\u65e0\u9519\u8bef\u547d\u4e2d\u3002\u5728\u4ee3\u7406\u6027\u5de5\u4f5c\u6d41\u573a\u666f\u4e0b\uff0c\u7f13\u5b58\u547d\u4e2d\u7387\u63d0\u5347\u7ea620%\uff0c\u7aef\u5230\u7aef\u6267\u884c\u5ef6\u8fdf\u964d\u4f4e\u7ea634%\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u80fd\u591f\u5bf9\u7ed3\u6784\u76f8\u4f3c\u7684\u63d0\u793a\u8fdb\u884c\u7f13\u5b58\uff0c\u6709\u6548\u63d0\u5347\u7f13\u5b58\u547d\u4e2d\u7387\u4e14\u9519\u8bef\u7387\u4f4e\uff0c\u663e\u8457\u4f18\u5316\u6267\u884c\u6548\u7387\u3002"}}
{"id": "2511.18038", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18038", "abs": "https://arxiv.org/abs/2511.18038", "authors": ["Xiaoke Han", "Hong Zhu"], "title": "MASTEST: A LLM-Based Multi-Agent System For RESTful API Tests", "comment": "14 Page of main text plus 4 pages of appendix", "summary": "Testing RESTful API is increasingly important in quality assurance of cloud-native applications. Recent advances in machine learning (ML) techniques have demonstrated that various testing activities can be performed automatically by large language models (LLMs) with reasonable accuracy. This paper develops a multi-agent system called MASTEST that combines LLM-based and programmed agents to form a complete tool chain that covers the whole workflow of API test starting from generating unit and system test scenarios from API specification in the OpenAPI Swagger format, to generating of Pytest test scripts, executing test scripts to interact with web services, to analysing web service response messages to determine test correctness and calculate test coverage. The system also supports the incorporation of human testers in reviewing and correcting LLM generated test artefacts to ensure the quality of testing activities. MASTEST system is evaluated on two LLMs, GPT-4o and DeepSeek V3.1 Reasoner with five public APIs. The performances of LLMs on various testing activities are measured by a wide range of metrics, including unit and system test scenario coverage and API operation coverage for the quality of generated test scenarios, data type correctness, status code coverage and script syntax correctness for the quality of LLM generated test scripts, as well as bug detection ability and usability of LLM generated test scenarios and scripts. Experiment results demonstrated that both DeepSeek and GPT-4o achieved a high overall performance. DeepSeek excels in data type correctness and status code detection, while GPT-4o performs best in API operation coverage. For both models, LLM generated test scripts maintained 100\\% syntax correctness and only required minimal manual edits for semantic correctness. These findings indicate the effectiveness and feasibility of MASTEST.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u8bc1\u4e86\u7ed3\u5408 LLM \u7684\u81ea\u52a8\u5316 RESTful API \u6d4b\u8bd5\u5de5\u5177\u94fe MASTEST\uff0c\u5728\u591a\u6b3e\u6a21\u578b\u4e0a\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u5c55\u793a\u4e86\u9ad8\u8986\u76d6\u7387\u4e0e\u811a\u672c\u8d28\u91cf\uff0c\u53ef\u5927\u5e45\u63d0\u5347\u4e91\u539f\u751f\u5e94\u7528\u7684\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u968f\u7740\u4e91\u539f\u751f\u5e94\u7528\u7684\u666e\u53ca\uff0cRESTful API \u6d4b\u8bd5\u5728\u8d28\u91cf\u4fdd\u969c\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u8fd1\u5e74\u6765\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u9ad8\u51c6\u786e\u6027\uff0c\u6fc0\u52b1\u4e86\u5c06\u673a\u5668\u5b66\u4e60\u6280\u672f\u5e94\u7528\u4e8e API \u6d4b\u8bd5\uff0c\u4ece\u800c\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\u8303\u56f4\u3002", "method": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf MASTEST\uff0c\u5c06\u57fa\u4e8e LLM \u7684\u667a\u80fd\u4f53\u4e0e\u7f16\u7a0b\u667a\u80fd\u4f53\u7ed3\u5408\uff0c\u5f62\u6210\u8986\u76d6 API \u6d4b\u8bd5\u5168\u6d41\u7a0b\u7684\u5b8c\u6574\u5de5\u5177\u94fe\u3002\u672c\u7cfb\u7edf\u80fd\u591f\u4ece OpenAPI Swagger \u89c4\u8303\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u548c\u7cfb\u7edf\u6d4b\u8bd5\u573a\u666f\uff0c\u751f\u6210 Pytest \u811a\u672c\uff0c\u6267\u884c\u811a\u672c\u4e0e Web \u670d\u52a1\u4ea4\u4e92\uff0c\u5e76\u5206\u6790\u54cd\u5e94\u6d88\u606f\u4ee5\u5224\u5b9a\u6d4b\u8bd5\u6b63\u786e\u6027\u53ca\u8986\u76d6\u7387\u3002\u8fd8\u652f\u6301\u4eba\u5de5\u5e72\u9884\u6821\u6b63\u6d4b\u8bd5\u6210\u679c\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u8d28\u91cf\u3002\u7814\u7a76\u8fd8\u5728\u4e24\u79cd LLM\uff08GPT-4o \u548c DeepSeek V3.1 Reasoner\uff09\u53ca\u4e94\u4e2a\u516c\u5f00 API \u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u6d4b\u91cf\u4e86\u591a\u9879\u6307\u6807\uff0c\u5305\u62ec\u6d4b\u8bd5\u573a\u666f\u548c API \u64cd\u4f5c\u8986\u76d6\u7387\u3001\u6570\u636e\u7c7b\u578b\u6b63\u786e\u6027\u3001\u72b6\u6001\u7801\u8986\u76d6\u3001\u811a\u672c\u8bed\u6cd5\u6b63\u786e\u6027\u53ca\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u7b49\u3002\u7ed3\u679c\u663e\u793a\u4e24\u6b3e LLM \u90fd\u6709\u8f83\u9ad8\u7efc\u5408\u8868\u73b0\uff0cDeepSeek \u5728\u6570\u636e\u7c7b\u578b\u4e0e\u72b6\u6001\u7801\u68c0\u6d4b\u4e0a\u8868\u73b0\u66f4\u5f3a\uff0cGPT-4o \u5728 API \u64cd\u4f5c\u8986\u76d6\u7387\u4e0a\u6700\u597d\uff0c\u4e24\u8005\u751f\u6210\u7684\u811a\u672c\u5747\u4fdd\u6301 100% \u8bed\u6cd5\u6b63\u786e\uff0c\u4ec5\u9700\u5c11\u91cf\u4eba\u5de5\u4fee\u6b63\u8bed\u4e49\u3002", "conclusion": "MASTEST \u7cfb\u7edf\u80fd\u6709\u6548\u81ea\u52a8\u5316 API \u6d4b\u8bd5\uff0c\u8868\u73b0\u4f18\u5f02\u4e14\u53ef\u884c\uff0c\u9a8c\u8bc1\u4e86 LLM \u5728\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u811a\u672c\u548c\u573a\u666f\u4e2d\u7684\u53ef\u7528\u6027\u4e0e\u6548\u7387\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21 API \u6d4b\u8bd5\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u53ef\u9760\u65b9\u6848\u3002"}}
{"id": "2511.17572", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.17572", "abs": "https://arxiv.org/abs/2511.17572", "authors": ["Patrick Gerard", "Aiden Chang", "Svitlana Volkova"], "title": "Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs", "comment": "37 pages, EurIPS 2025", "summary": "When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u5bf9\u9f50\u540e\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u4e4f\u77e5\u8bc6\u65f6\u4ecd\u4f1a\u5c55\u73b0\u793e\u533a\u7279\u6709\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u8bf4\u660e\u5176\u5bf9\u9f50\u8d85\u8d8a\u4e86\u7b80\u5355\u6a21\u4eff\uff0c\u5e76\u4e3a\u68c0\u6d4b\u504f\u89c1\u4e0e\u63d0\u5347\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "motivation": "\u63a2\u8ba8\u4e0e\u7279\u5b9a\u7f51\u7edc\u793e\u533a\u5bf9\u9f50\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5176\u884c\u4e3a\u6a21\u5f0f\u662f\u4e00\u822c\u53ef\u5f52\u7eb3\u7684\uff0c\u8fd8\u662f\u4ec5\u4ec5\u662f\u8bad\u7ec3\u6570\u636e\u7684\u56de\u5fc6\u3002", "method": "\u63d0\u51fa\u4e86\u9a8c\u8bc1LLM\u662f\u5426\u5177\u5907\u77e5\u8bc6\u8fc1\u79fb\u80fd\u529b\u7684\u6846\u67b6\uff0c\u5305\u62ec\u5bf9\u4e8b\u4ef6\u77e5\u8bc6\u7684\u6709\u9488\u5bf9\u6027\u5220\u9664\u3001\u591a\u91cd\u63a2\u9488\u9a8c\u8bc1\uff0c\u5e76\u5728\u65e0\u77e5\u8bc6\u60c5\u5883\u4e0b\u8bc4\u4f30\u5176\u662f\u5426\u4ecd\u518d\u73b0\u793e\u533a\u884c\u4e3a\u6a21\u5f0f\u3002\u5b9e\u9a8c\u6570\u636e\u6765\u81ea\u4fc4\u4e4c\u519b\u4e8b\u8ba8\u8bba\u548c\u7f8e\u56fdTwitter\u515a\u6d3e\u8a00\u8bba\u3002", "result": "\u5373\u4f7f\u5728\u5927\u89c4\u6a21\u4e8b\u5b9e\u5220\u9664\u540e\uff0c\u5bf9\u9f50\u7684LLM\u4f9d\u7136\u4fdd\u6301\u4e86\u7a33\u5b9a\u4e14\u5177\u6709\u793e\u533a\u7279\u5f81\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u80fd\u7a33\u5065\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u7ed3\u679c\u8868\u660eLLM\u7684\u5bf9\u9f50\u4e0d\u4ec5\u4ec5\u662f\u8868\u9762\u6a21\u4eff\uff0c\u6a21\u578b\u5185\u90e8\u7f16\u7801\u4e86\u7ed3\u6784\u5316\u3001\u53ef\u8fc1\u79fb\u7684\u884c\u4e3a\u503e\u5411\u3002\u8be5\u65b9\u6cd5\u4e3a\u68c0\u6d4b\u6a21\u578b\u504f\u89c1\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u52a9\u529b\u4e8e\u66f4\u5b89\u5168\u900f\u660e\u7684\u5e94\u7528\u3002"}}
{"id": "2511.18092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18092", "abs": "https://arxiv.org/abs/2511.18092", "authors": ["Sebastian Dingler", "Philip Rehkop", "Florian Mayer", "Ralf Muenzenberger"], "title": "Event-Chain Analysis for Automated Driving and ADAS Systems: Ensuring Safety and Meeting Regulatory Timing Requirements", "comment": null, "summary": "Automated Driving Systems (ADS), including Advanced Driver Assistance Systems (ADAS), must fulfill not only high functional expectations but also stringent timing constraints mandated by international regulations and standards. Regulatory frameworks such as UN regulations, NCAP standards, ISO norms, and NHTSA guidelines impose strict bounds on system reaction times to ensure safe vehicle operation. This paper presents a structured, White-Box methodology based on Event-Chain Modeling to address these timing challenges. Unlike Black-Box approaches, Event-Chain Analysis offers transparent insights into the timing behavior of each functional component - from perception and planning to actuation and human interaction. This perspective is also aligned with multiple regulations, which require that homologation dossiers provide evidence that the chosen system architecture is suitable to ensure compliance with the specified requirements. Our methodology enables the derivation, modeling, and validation of end-to-end timing constraints at the architectural level and facilitates early verification through simulation. Through a detailed case study, we demonstrate how this Event-Chain-centric approach enhances regulatory compliance, optimizes system design, and supports model-based safety analysis techniques, with results showing early identification of compliance issues, systematic parameter optimization, and quantitative evidence generation through probabilistic analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8b\u4ef6\u94fe\u767d\u76d2\u5206\u6790\u6cd5\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u53ca\u8f85\u52a9\u7cfb\u7edf\u7684\u65f6\u5e8f\u5408\u89c4\u6027\u96be\u9898\uff0c\u652f\u6301\u67b6\u6784\u7ea7\u5efa\u6a21\u4e0e\u4eff\u771f\uff0c\u6848\u4f8b\u663e\u793a\u53ef\u65e9\u671f\u53d1\u73b0\u5408\u89c4\u95ee\u9898\u5e76\u7cfb\u7edf\u4f18\u5316\u8bbe\u8ba1\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u53ca\u9ad8\u7ea7\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf\uff08ADAS\uff09\u5fc5\u987b\u4e0d\u4ec5\u6ee1\u8db3\u9ad8\u529f\u80fd\u9884\u671f\uff0c\u8fd8\u8981\u7b26\u5408\u56fd\u9645\u6cd5\u89c4\u548c\u6807\u51c6\u5bf9\u7cfb\u7edf\u54cd\u5e94\u65f6\u95f4\u7684\u4e25\u683c\u8981\u6c42\u3002\u5f53\u524d\u6cd5\u89c4\uff08\u5982\u8054\u5408\u56fd\u6cd5\u89c4\u3001NCAP\u6807\u51c6\u3001ISO\u89c4\u8303\u3001NHTSA\u6307\u5357\uff09\u5bf9\u7cfb\u7edf\u53cd\u5e94\u65f6\u95f4\u6709\u660e\u786e\u754c\u5b9a\uff0c\u786e\u4fdd\u8f66\u8f86\u5b89\u5168\u8fd0\u884c\uff0c\u56e0\u6b64\u4e1a\u754c\u4e9f\u9700\u80fd\u591f\u6ee1\u8db3\u5e76\u9a8c\u8bc1\u8fd9\u4e9b\u65f6\u5e8f\u8981\u6c42\u7684\u5206\u6790\u548c\u5f00\u53d1\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u5efa\u6a21\u7684\u767d\u76d2\u65b9\u6cd5\u6765\u89e3\u51b3ADS\u548cADAS\u7684\u7cfb\u7edf\u65f6\u5e8f\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e8b\u4ef6\u94fe\u5206\u6790\uff0c\u900f\u660e\u5730\u63ed\u793a\u4ece\u611f\u77e5\u3001\u89c4\u5212\u5230\u6267\u884c\u4ee5\u53ca\u4eba\u673a\u4ea4\u4e92\u5404\u529f\u80fd\u90e8\u4ef6\u7684\u65f6\u5e8f\u884c\u4e3a\uff0c\u6709\u522b\u4e8e\u4ee5\u5f80\u7684\u9ed1\u76d2\u5206\u6790\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u53ef\u5728\u67b6\u6784\u5c42\u6b21\u63a8\u5bfc\u3001\u5efa\u6a21\u5e76\u9a8c\u8bc1\u7aef\u5230\u7aef\u7684\u65f6\u5e8f\u7ea6\u675f\uff0c\u5e76\u652f\u6301\u4eff\u771f\u7684\u65e9\u671f\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u8be6\u7ec6\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u8be5\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u5efa\u6a21\u7684\u65b9\u6cd5\u80fd\u591f\u589e\u5f3a\u7cfb\u7edf\u7684\u6cd5\u89c4\u5408\u89c4\u6027\uff0c\u4f18\u5316\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u63d0\u5347\u6a21\u578b\u5316\u5b89\u5168\u5206\u6790\u7684\u652f\u6301\u529b\u5ea6\uff0c\u80fd\u591f\u5728\u65e9\u671f\u8bc6\u522b\u5408\u89c4\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u53c2\u6570\u7684\u7cfb\u7edf\u6027\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u5206\u6790\u63d0\u4f9b\u5b9a\u91cf\u8bc1\u636e\u3002", "conclusion": "\u4e8b\u4ef6\u94fe\u5bfc\u5411\u7684\u767d\u76d2\u65f6\u5e8f\u5206\u6790\u65b9\u6cd5\u80fd\u591f\u652f\u6301ADS/ADAS\u7cfb\u7edf\u6ee1\u8db3\u56fd\u9645\u6cd5\u89c4\u7684\u65f6\u5e8f\u8981\u6c42\uff0c\u63d0\u9ad8\u8bbe\u8ba1\u900f\u660e\u5ea6\u4e0e\u5408\u89c4\u6027\uff0c\u8f85\u52a9\u65e9\u671f\u9884\u9a8c\u8bc1\u548c\u7cfb\u7edf\u6027\u4f18\u5316\u3002"}}
{"id": "2511.17575", "categories": ["cs.CL", "stat.ME", "stat.ML", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.17575", "abs": "https://arxiv.org/abs/2511.17575", "authors": ["Vladimir Berman"], "title": "Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models", "comment": null, "summary": "We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.\n  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.", "AI": {"tldr": "\u8be5\u6587\u5efa\u7acb\u4e86\u4e0d\u542b\u4efb\u4f55\u8bed\u8a00\u5c5e\u6027\u7684\u968f\u673a\u7b26\u53f7\u6a21\u578b\uff0c\u901a\u8fc7\u6982\u7387\u548c\u7ec4\u5408\u5b66\u5206\u6790\u663e\u793a\uff0cZipf\u8bcd\u9891\u89c4\u5f8b\u3001\u8bcd\u957f\u5206\u5e03\u7b49\u8bed\u8a00\u5e38\u89c1\u7ed3\u6784\u53ef\u5728\u7eaf\u968f\u673a\u6587\u672c\u4e2d\u81ea\u7136\u4ea7\u751f\uff0c\u4e3a\u7406\u89e3\u54ea\u4e9b\u8bed\u8a00\u7edf\u8ba1\u73b0\u8c61\u9700\u8981\u66f4\u6df1\u5c42\u89e3\u91ca\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0b\u9650\u3002", "motivation": "\u63a2\u7a76\u5728\u5b8c\u5168\u65e0\u8bed\u6cd5\u3001\u8bed\u4e49\u53ca\u5f62\u6001\u7ed3\u6784\u7684\u6781\u7b80\u7b26\u53f7\u7cfb\u7edf\u4e0b\uff0c\u6587\u672c\u7684\u57fa\u672c\u7ed3\u6784\u6027\u8d28\uff0c\u4ee5\u53ca\u8457\u540d\u7684Zipf\u8bcd\u9891\u5206\u5e03\u80fd\u5426\u7531\u7eaf\u7cb9\u7684\u5206\u5272\u4e0e\u7ec4\u5408\u673a\u5236\u751f\u6210\uff0c\u4ece\u800c\u4e3a\u590d\u6742\u8bed\u8a00\u73b0\u8c61\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7edf\u8ba1\u7ed3\u6784\u63d0\u4f9b\u6570\u5b66\u57fa\u7ebf\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6781\u7b80\u7684\u975e\u8bed\u8a00\u5316\u6587\u672c\u6a21\u578b\uff1a\u5b57\u6bcd\u8868\u6709\u9650\uff0c\u6587\u672c\u4e3a\u72ec\u7acb\u7b26\u53f7\uff08\u5305\u62ec\u7a7a\u683c\uff09\u7684\u968f\u673a\u62bd\u53d6\uff0c\u5355\u8bcd\u5b9a\u4e49\u4e3a\u4e0d\u542b\u7a7a\u683c\u7684\u6700\u5927\u8fde\u7eed\u7b26\u53f7\u5757\u3002\u5206\u6790\u5f97\u5230\u5355\u8bcd\u957f\u5ea6\u7684\u5206\u5e03\u3001\u8bcd\u8868\u589e\u957f\u89c4\u5f8b\u3001\u5173\u952e\u5b57\u957f\u3001\u4ee5\u53ca\u8bcd\u9891-\u6392\u540d\u7684Zipf\u89c4\u5f8b\u3002\u6240\u6709\u7ed3\u679c\u5229\u7528\u6982\u7387\u8bba\u4e0e\u7ec4\u5408\u5b66\u63a8\u5bfc\uff0c\u90e8\u5206\u91c7\u7528coupon-collector\u8bba\u8bc1\u3002", "result": "1\uff09\u5355\u8bcd\u957f\u5ea6\u670d\u4ece\u7531\u7a7a\u683c\u6982\u7387\u51b3\u5b9a\u7684\u51e0\u4f55\u5206\u5e03\uff1b2\uff09\u7ed9\u51fa\u4e86\u6307\u5b9a\u957f\u5ea6\u5355\u8bcd\u603b\u6570\u4e0e\u4e0d\u540c\u7c7b\u578b\u5355\u8bcd\u6570\u91cf\u7684\u95ed\u5f0f\u8ba1\u7b97\u5f0f\uff0c\u5e76\u63a8\u5bfc\u5173\u952e\u5b57\u957fk*\uff1b3\uff09\u901a\u8fc7\u7ec4\u5408\u53ef\u80fd\u5b57\u7b26\u4e32\u6570\u91cf\u4e0e\u6bcf\u79cd\u6982\u7387\u7684\u6307\u6570\u5173\u7cfb\uff0c\u4e25\u683c\u63a8\u5bfc\u51faZipf\u578bp(r) ~ r^{-alpha}\u5206\u5e03\uff0c\u6307\u6570alpha\u4e0e\u5b57\u6bcd\u8868\u5927\u5c0f\u53ca\u7a7a\u683c\u6982\u7387\u660e\u786e\u76f8\u5173\u3002\u5f3a\u5316\u4e86Zipf\u5206\u5e03\u53ef\u7531\u968f\u673a\u5206\u5272\u4e0e\u7ec4\u5408\u5b66\u6d8c\u73b0\u7684\u89c2\u70b9\u3002", "conclusion": "Zipf-like\u8bcd\u9891\u89c4\u5f8b\u53ef\u4ee5\u4ec5\u901a\u8fc7\u7b26\u53f7\u7684\u7ec4\u5408\u5b66\u548c\u5206\u5272\u673a\u5236\u5728\u4e00\u4e2a\u975e\u8bed\u8a00\u5316\u3001\u968f\u673a\u6587\u672c\u6a21\u578b\u4e2d\u81ea\u7136\u6d8c\u73b0\uff0c\u65e0\u9700\u8bc9\u8bf8\u8bed\u8a00\u7684\u4f18\u5316\u6216\u590d\u6742\u7ed3\u6784\u3002\u8be5\u6a21\u578b\u53ef\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u7edf\u8ba1\u7684\u57fa\u672c\u5bf9\u7167\u3002"}}
{"id": "2511.18165", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18165", "abs": "https://arxiv.org/abs/2511.18165", "authors": ["Israel Puerta-Merino", "Carlos N\u00fa\u00f1ez-Molina", "Pablo Mesejo", "Juan Fern\u00e1ndez-Olivares"], "title": "Towards a General Framework for HTN Modeling with LLMs", "comment": "10 pages, 5 figures, to be published in the Workshop on Planning in the Era of LLMs ( LM4Plan - https://llmforplanning.github.io ) and the Workshop on Hierarchical Planning ( HPlan - https://icaps25.icaps-conference.org/program/workshops/hplan/ ), both in the International Conference on Automated Planning and Scheduling (ICAPS) 2025", "summary": "The use of Large Language Models (LLMs) for generating Automated Planning (AP) models has been widely explored; however, their application to Hierarchical Planning (HP) is still far from reaching the level of sophistication observed in non-hierarchical architectures. In this work, we try to address this gap. We present two main contributions. First, we propose L2HP, an extension of L2P (a library to LLM-driven PDDL models generation) that support HP model generation and follows a design philosophy of generality and extensibility. Second, we apply our framework to perform experiments where we compare the modeling capabilities of LLMs for AP and HP. On the PlanBench dataset, results show that parsing success is limited but comparable in both settings (around 36\\%), while syntactic validity is substantially lower in the hierarchical case (1\\% vs. 20\\% of instances). These findings underscore the unique challenges HP presents for LLMs, highlighting the need for further research to improve the quality of generated HP models.", "AI": {"tldr": "LLMs\u81ea\u52a8\u751f\u6210\u5c42\u6b21\u89c4\u5212\u6a21\u578b\u53d7\u9650\uff0c\u8bed\u6cd5\u6709\u6548\u6027\u6781\u4f4e\uff0c\u9700\u66f4\u591a\u7814\u7a76\u6539\u8fdbHP\u6a21\u578b\u751f\u6210\u6280\u672f\u3002", "motivation": "\u867d\u7136LLMs\u81ea\u52a8\u751f\u6210\u975e\u5c42\u6b21\u89c4\u5212\u6a21\u578b\u5df2\u6709\u8f83\u597d\u8fdb\u5c55\uff0c\u4f46\u5bf9\u5c42\u6b21\u89c4\u5212\u7684\u652f\u6301\u975e\u5e38\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8be5\u9886\u57df\u7a7a\u767d\uff0c\u63d0\u9ad8HP\u6a21\u578b\u81ea\u52a8\u5316\u751f\u6210\u6c34\u5e73\u3002", "method": "\u63d0\u51faL2HP\u6269\u5c55\u5e93\uff0c\u57fa\u4e8eLLM\u81ea\u52a8\u751f\u6210HP\u6a21\u578b\uff0c\u540c\u65f6\u4e0e\u975e\u5c42\u6b21\u89c4\u5212\u6a21\u578b\uff08AP\uff09\u80fd\u529b\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002\u5b9e\u9a8c\u91c7\u7528PlanBench\u6570\u636e\u96c6\u3002", "result": "\u4e24\u8005\u89e3\u6790\u6210\u529f\u7387\u76f8\u5f53\uff08\u5747\u7ea636%\uff09\uff0c\u4f46\u8bed\u6cd5\u6709\u6548\u6027\u5728HP\u4ec5\u4e3a1%\uff0c\u663e\u8457\u4f4e\u4e8eAP\u768420%\u3002HP\u751f\u6210\u8d28\u91cf\u9762\u4e34\u66f4\u5927\u6311\u6218\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u89c4\u5212\u6a21\u578b\u751f\u6210\u65b9\u9762\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u5c42\u6b21\u89c4\u5212\u6a21\u578b\u751f\u6210\u65f6\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u89e3\u6790\u6210\u529f\u7387\u867d\u76f8\u8fd1\u4f46\u8bed\u6cd5\u6709\u6548\u6027\u5927\u5e45\u4e0b\u964d\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u5347HP\u6a21\u578b\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2511.17746", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17746", "abs": "https://arxiv.org/abs/2511.17746", "authors": ["Sharaj Kunjar", "Alyssa Hasegawa Smith", "Tyler R Mckenzie", "Rushali Mohbe", "Samuel V Scarpino", "Brooke Foucault Welles"], "title": "Computational frame analysis revisited: On LLMs for studying news coverage", "comment": null, "summary": "Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u751f\u6210\u5f0fLLMs\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u4eba\u5de5\u7f16\u7801\u5728\u65b0\u95fb\u5a92\u4f53\u6846\u67b6\u5206\u6790\u4e2d\u7684\u8868\u73b0\u3002\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136LLMs\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u4eba\u5de5\u65b9\u6cd5\u548c\u5c0f\u6a21\u578b\u5728\u591a\u4efb\u52a1\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u4eba\u7c7b\u9a8c\u8bc1\u4f9d\u7136\u4e0d\u53ef\u6216\u7f3a\u3002\u5efa\u8bae\u91c7\u7528\u65b9\u6cd5\u591a\u5143\u4e0e\u5de5\u5177\u4e92\u8865\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982GPT\u548cClaude\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u5185\u5bb9\u5206\u6790\u5de5\u5177\uff0c\u4f46\u5b83\u4eec\u5728\u5a92\u4f53\u6846\u67b6\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u660e\u786e\uff0c\u9700\u8981\u4e0e\u4f20\u7edf\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u4eba\u5de5\u7f16\u7801\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u751f\u6210\u5f0fLLMs\u3001\u8bcd\u888b\u6a21\u578b\u3001\u4ec5\u7f16\u7801\u5668\u7684\u53d8\u6362\u5668\u6a21\u578b\u4ee5\u53ca\u4eba\u5de5\u7f16\u7801\u65b9\u6cd5\uff0c\u5e76\u5728\u4e00\u4efd\u9488\u5bf92022\u5e74\u7f8e\u56fdMpox\u75ab\u60c5\u7684\u516d\u4e2a\u6708\u65b0\u95fb\u62a5\u9053\u7684\u65b0\u91d1\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u751f\u6210\u5f0fLLMs\u5728\u67d0\u4e9b\u5e94\u7528\u4e0a\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u603b\u4f53\u4e0a\u88ab\u4eba\u5de5\u7f16\u7801\u8005\u548c\u90e8\u5206\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8d85\u8d8a\u3002\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u9700\u8981\u67d0\u79cd\u5f62\u5f0f\u7684\u4eba\u7c7b\u9a8c\u8bc1\u6765\u51b3\u5b9a\u6a21\u578b\u9009\u62e9\u3002", "conclusion": "\u9f13\u52b1\u65b9\u6cd5\u591a\u5143\u5316\uff0c\u7ed3\u5408\u591a\u79cd\u5de5\u5177\u534f\u540c\u4f7f\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u8ba1\u7b97\u6846\u67b6\u5206\u6790\u8def\u7ebf\u56fe\u3002"}}
{"id": "2511.18187", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18187", "abs": "https://arxiv.org/abs/2511.18187", "authors": ["Sristy Sumana Nath", "Banani Roy", "Munima Jahan"], "title": "Establishing Traceability Links between Release Notes & Software Artifacts: Practitioners' Perspectives", "comment": null, "summary": "Maintaining traceability links between software release notes and corresponding development artifacts, e.g., pull requests (PRs), commits, and issues, is essential for managing technical debt and ensuring maintainability. However, in open-source environments where contributors work remotely and asynchronously, establishing and maintaining these links is often error-prone, time-consuming, and frequently overlooked. Our empirical study of GitHub repositories revealed that 47% of release artifacts lacked traceability links, and 12% contained broken links. To address this gap, we first analyzed release notes to identify their What, Why, and How information and assessed how these align with PRs, commits, and issues. We curated a benchmark dataset consisting of 3,500 filtered and validated traceability link instances. Then, we implemented LLM-based approaches to automatically establish traceability links of three pairs between release note contents & PRs, release note contents & PRs and release note contents & issues. By combining the time proximity feature, the LLM-based approach, e.g., Gemini 1.5 Pro, achieved a high Precision@1 value of 0.73 for PR traceability recovery. To evaluate the usability and adoption potential of this approach, we conducted an online survey involving 33 open-source practitioners. 16% of respondents rated as very important, and 68% as somewhat important for traceability maintenance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5f00\u6e90\u9879\u76ee\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u4e25\u91cd\u4e0d\u8db3\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5efa\u7acb\u94fe\u63a5\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u53ef\u8ffd\u6eaf\u6027\u51c6\u786e\u7387\uff0c\u5bf9\u6280\u672f\u503a\u7ba1\u7406\u548c\u9879\u76ee\u7ef4\u62a4\u5177\u6709\u73b0\u5b9e\u5f71\u54cd\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u8fdc\u7a0b\u3001\u5f02\u6b65\u534f\u4f5c\u73af\u5883\u4e0b\uff0c\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u4e4b\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u7ef4\u62a4\u56f0\u96be\uff0c\u6613\u9057\u6f0f\u4e14\u8017\u65f6\uff0c\u5f71\u54cd\u6280\u672f\u503a\u7ba1\u7406\u548c\u9879\u76ee\u53ef\u7ef4\u62a4\u6027\u3002\u65e2\u6709\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u89e3\u51b3\u5927\u91cf\u7f3a\u5931\u548c\u7834\u635f\u7684\u94fe\u63a5\u95ee\u9898\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5206\u6790GitHub\u4ed3\u5e93\uff0c\u6784\u5efa\u4e86\u5305\u542b3500\u4e2a\u7ecf\u7b5b\u9009\u548c\u9a8c\u8bc1\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982Gemini 1.5 Pro\uff09\uff0c\u7ed3\u5408\u65f6\u95f4\u90bb\u8fd1\u6027\u7279\u5f81\uff0c\u81ea\u52a8\u63d0\u53d6\u53d1\u5e03\u8bf4\u660e\u4e0ePRs\u3001issues\u4e4b\u95f4\u7684\u5173\u8054\u3002\u6700\u7ec8\u901a\u8fc7Precision@1\u6307\u6807\u8bc4\u4f30\u6548\u679c\u3002\u5e76\u8fdb\u884c\u4e86\u5728\u7ebf\u95ee\u5377\u8c03\u67e5\u4ee5\u8003\u5bdf\u5de5\u5177\u5b9e\u9645\u53ef\u7528\u6027\u3002", "result": "\u5206\u6790\u53d1\u73b047%\u7684\u53d1\u5e03\u8bf4\u660e\u7f3a\u5931\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\uff0c12%\u5b58\u5728\u7834\u635f\u94fe\u63a5\u3002\u6240\u63d0\u65b9\u6cd5\u5728PR\u53ef\u8ffd\u6eaf\u6027\u6062\u590d\u7684Precision@1\u8fbe\u52300.73\u3002\u95ee\u5377\u7ed3\u679c\u663e\u793a\uff0c84%\u7684\u5f00\u6e90\u5b9e\u8df5\u8005\u8ba4\u4e3a\u5efa\u7acb\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u8f83\u4e3a\u91cd\u8981\u3002", "conclusion": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u65f6\u95f4\u7279\u5f81\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u81ea\u52a8\u5efa\u7acb\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\uff08\u5982PRs\u3001issues\uff09\u7684\u53ef\u8ffd\u6eaf\u6027\u94fe\u63a5\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.17808", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17808", "abs": "https://arxiv.org/abs/2511.17808", "authors": ["Thales Sales Almeida", "Rodrigo Nogueira", "H\u00e9lio Pedrini"], "title": "PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese", "comment": null, "summary": "Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u53d1\u5e03\u4e86\u8461\u8404\u7259\u8bed\u5927\u6a21\u578b\u7684\u6700\u5927\u89c4\u6a21\u57fa\u51c6PoETa v2\uff0c\u901a\u8fc740\u591a\u4e2a\u4efb\u52a1\u8bc4\u6d4b\u4e8620\u6b3e\u4e3b\u6d41\u6a21\u578b\uff0c\u603b\u7ed3\u8d44\u6e90\u548c\u9002\u914d\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u4e0e\u82f1\u8bed\u4efb\u52a1\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4e3a\u8461\u8404\u7259\u8bedNLP\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u5177\u548c\u6570\u636e\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u6587\u5316\u73af\u5883\u4e2d\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u591a\u8bed\u79cd\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u6d4b\u3002\u8461\u8404\u7259\u8bed\u4f5c\u4e3a\u4e00\u79cd\u88ab\u5e7f\u6cdb\u4f7f\u7528\u4f46\u8bc4\u6d4b\u8d44\u6e90\u6709\u9650\u7684\u8bed\u8a00\uff0c\u4e9f\u9700\u5927\u89c4\u6a21\u7cfb\u7edf\u6027\u6d4b\u8bd5\u548c\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u5e76\u5229\u7528\u4e86PoETa v2\u8fd9\u4e00\u5168\u65b0\u7684\u8461\u8404\u7259\u8bed\u5927\u578b\u57fa\u51c6\u5957\u4ef6\uff0c\u6db5\u76d6\u4e8640\u591a\u4e2a\u4efb\u52a1\uff0c\u5bf920\u4f59\u79cd\u4e0d\u540c\u8bad\u7ec3\u89c4\u6a21\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u5c06\u8461\u8404\u7259\u8bed\u548c\u82f1\u8bed\u5728\u540c\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u6a21\u578b\u7684\u8ba1\u7b97\u6295\u5165\u548c\u9488\u5bf9\u8461\u8404\u7259\u8bed\u7684\u9002\u5e94\u8bad\u7ec3\u4f1a\u5bf9\u5176\u8461\u8404\u7259\u8bed\u8868\u73b0\u4ea7\u751f\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u91cf\u5316\u4e86\u8461\u8404\u7259\u8bed\u4e0e\u82f1\u8bed\u4efb\u52a1\u7684\u6027\u80fd\u5dee\u8ddd\u3002PoETa v2\u4e3a\u672a\u6765\u8461\u8404\u7259\u8bed\u8bed\u8a00\u5efa\u6a21\u4e0e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\u548c\u53c2\u8003\u3002", "conclusion": "PoETa v2\u57fa\u51c6\u5b9e\u73b0\u4e86\u8461\u8404\u7259\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u8fc4\u4eca\u4e3a\u6b62\u6700\u5168\u9762\u7684\u8bc4\u6d4b\uff0c\u4e3a\u6a21\u578b\u6027\u80fd\u63d0\u5347\u548c\u591a\u8bed\u79cdNLP\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u4fc3\u8fdb\u4e86\u4f4e\u8d44\u6e90\u8bed\u79cd\u7684\u7cfb\u7edf\u7814\u7a76\u3002"}}
{"id": "2511.18249", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18249", "abs": "https://arxiv.org/abs/2511.18249", "authors": ["Mostafijur Rahman Akhond", "Gias Uddin"], "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "comment": null, "summary": "Metamorphic Relations (MRs) serve as a foundational mechanism for generating semantically equivalent mutations. Software engineering has advanced significantly in recent years with the advent of Large Language Models (LLMs). However, the reliability of LLMs in software engineering is often compromised by ambiguities and inconsistencies due to improper user specification. To address this challenge, we present CodeMetaAgent (CMA), a metamorphic relation-driven LLM agent that systematically refines task specifications and generates semantically constrained test cases. Our proposed framework uses MRs with LLMs to improve generation consistency and reduce variability caused by specifications, unlike the traditional use of MRs as post validations. Our framework has been evaluated on the HumanEval-Pro, MBPP-Pro, and SWE-Bench_Lite datasets using the GPT-4o, Mistral Large, GPT-OSS, and Qwen3-Coder models. It improved code generation accuracy by up to 17% and achieved code coverage gains of up to 99.81%. These results show that metamorphic relations can be a simple but effective guide in assisting LLM-based software development.", "AI": {"tldr": "\u9762\u5bf9LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u89c4\u8303\u4e0b\u8868\u73b0\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u4ee5\u53d8\u5f62\u5173\u7cfb\u9a71\u52a8\u7684CMA\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u4e0e\u8986\u76d6\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u7531\u4e8e\u7528\u6237\u89c4\u8303\u4e0d\u660e\u786e\u800c\u5bfc\u81f4\u5176\u751f\u6210\u7ed3\u679c\u5e38\u51fa\u73b0\u6a21\u7cca\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u5f71\u54cd\u4e86\u53ef\u9760\u6027\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u65b9\u5f0f\u6765\u63d0\u5347\u751f\u6210\u7684\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86CodeMetaAgent\uff08CMA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u53d8\u5f62\u5173\u7cfb(MR)\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7cfb\u7edf\u6027\u5730\u7ec6\u5316\u4efb\u52a1\u89c4\u8303\uff0c\u5e76\u751f\u6210\u8bed\u4e49\u53d7\u9650\u7684\u6d4b\u8bd5\u6837\u4f8b\u3002MR\u5728\u6846\u67b6\u4e2d\u4e0d\u4ec5\u7528\u4e8e\u751f\u6210\u6570\u636e\uff0c\u8fd8\u6307\u5bfc\u89c4\u8303\u7ec6\u5316\u548c\u7528\u4f8b\u751f\u6210\uff0c\u533a\u522b\u4e8e\u4f20\u7edf\u53ea\u7528\u4e8e\u9a8c\u8bc1\u3002", "result": "\u5728HumanEval-Pro\u3001MBPP-Pro\u548cSWE-Bench_Lite\u6570\u636e\u96c6\u4e0a\uff0c\u4ee5GPT-4o\u3001Mistral Large\u3001GPT-OSS\u548cQwen3-Coder\u6a21\u578b\u4e3a\u57fa\u51c6\uff0cCMA\u6846\u67b6\u4ee3\u7801\u751f\u6210\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534717%\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u6700\u9ad8\u8fbe99.81%\u3002", "conclusion": "\u53d8\u5f62\u5173\u7cfb\u4f5c\u4e3a\u6307\u5bfc\u673a\u5236\u53ef\u7b80\u4fbf\u6709\u6548\u63d0\u5347\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5f00\u53d1\u4e00\u81f4\u6027\u4e0e\u6548\u7387\u3002"}}
{"id": "2511.17813", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.17813", "abs": "https://arxiv.org/abs/2511.17813", "authors": ["Scott Merrill", "Shashank Srivastava"], "title": "Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation", "comment": "8 pages (29 pages including appendix), 18 figures. Code and datasets are available at https://github.com/smerrillunc/action-aware-llms. Submitted to ACL 2026", "summary": "Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this \"action-aware\" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5c06Zoom\u4f1a\u8bae\u516c\u5f00\u5f55\u97f3\u8f6c\u4e3a\u5e26\u8eab\u4efd\u6807\u7b7e\u53ca\u8bed\u7528\u4fe1\u606f\u7684\u8f6c\u5f55\u6570\u636e\uff0c\u5e76\u5728\u5730\u65b9\u653f\u5e9c\u591a\u65b9\u8ba8\u8bba\u573a\u666f\u4e0b\u5fae\u8c03LLM\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u73b0\u5b9e\u8ba8\u8bba\u53ca\u89d2\u8272\u7684\u6a21\u62df\u80fd\u529b\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u793e\u4f1a\u6a21\u62df\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u636e\u57fa\u7840\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6a21\u62df\u591a\u65b9\u8ba8\u8bba\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u5e26\u6709\u53d1\u8a00\u8005\u5f52\u5c5e\u7684\u6570\u636e\uff0c\u73b0\u5b9e\u5efa\u6a21\u6548\u679c\u6709\u9650\u3002\u73b0\u6709ASR\u8f6c\u5f55\u901a\u5e38\u53ea\u63d0\u4f9b\u533f\u540d\u53d1\u8a00\u8005\u6807\u7b7e\uff0c\u963b\u788d\u4e86\u6a21\u578b\u5bf9\u4e00\u81f4\u6027\u7684\u4eba\u7c7b\u884c\u4e3a\u8fdb\u884c\u6355\u6349\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u5c06\u516c\u5f00Zoom\u5f55\u97f3\u8f6c\u5316\u4e3a\u5305\u542b\u53d1\u8a00\u8005\u8eab\u4efd\u3001\u4eba\u7269\u753b\u50cf\u4ee5\u53ca\u8bed\u7528\u52a8\u4f5c\u6807\u7b7e\uff08\u5982[propose_motion]\uff09\u7684\u8f6c\u5f55\u6570\u636e\u3002\u5e76\u516c\u5e03\u4e86\u4e09\u4e2a\u5730\u65b9\u653f\u5e9c\u5ba1\u8bae\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u7528\u4e8e\u5efa\u6a21\u7279\u5b9a\u89d2\u8272\u5316\u53c2\u4e0e\u8005\u3002", "result": "\u57fa\u4e8e\u201c\u52a8\u4f5c\u611f\u77e5\u201d\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u56f0\u60d1\u5ea6(PPL)\u964d\u4f4e\u4e8667%\uff0c\u53d1\u8a00\u4eba\u4e00\u81f4\u6027\u548c\u771f\u5b9e\u6027\u7684\u5206\u7c7b\u6307\u6807\u8fd1\u4e4e\u7ffb\u500d\u3002\u56fe\u7075\u5f0f\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\uff0c\u6a21\u578b\u751f\u6210\u7684\u8ba8\u8bba\u4e0e\u771f\u5b9e\u8ba8\u8bba\u5f80\u5f80\u96be\u4ee5\u533a\u5206\u3002", "conclusion": "\u5f15\u5165\u7684\u65b0\u6d41\u7a0b\u4e0e\u6570\u636e\u6781\u5927\u63d0\u5347\u4e86\u591a\u65b9\u8ba8\u8bba\u6a21\u62df\u7684\u73b0\u5b9e\u6027\u548c\u53c2\u4e0e\u8005\u4e00\u81f4\u6027\uff0c\u4e3a\u590d\u6742\u73b0\u5b9e\u516c\u6c11\u60c5\u666f\u7684\u53ef\u6269\u5c55\u6027\u6a21\u62df\u63d0\u4f9b\u4e86\u5b9e\u9645\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2511.18288", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18288", "abs": "https://arxiv.org/abs/2511.18288", "authors": ["Wenhan Wang", "Kaibo Liu", "Zeyu Sun", "An Ran Chen", "Ge Li", "Gang Huang", "Lei Ma"], "title": "Can Large Language Models Solve Path Constraints in Symbolic Execution?", "comment": null, "summary": "Symbolic execution is an important software analysis technique which benefits downstream tasks such as software testing and debugging. However, several limitations hinder symbolic execution from application on real-world software. One of the limitations is the inability to solve diverse execution path constraints: traditional symbolic execution based on SMT solvers is difficult to handle execution paths with complex data structures or external API calls. In this paper, we focus on investigating the possibility of adopting large language models (LLM) for path constraint solving instead of traditional solver-based techniques in symbolic execution. We conduct an empirical study to evaluate the ability of LLMs in two types of path constraint solving: generating test inputs to facilitate an execution path, and determining whether a given execution path can be satisfied without triggering any bugs. We build new evaluation pipelines and benchmarks for two tasks: test case generation and path classification, which include data sources from both competition-level programs and real-world repositories. Our experiment results show that state-of-the-art LLMs are able to solve path constraints in both generation and classification tasks, with 60% of generated test cases that accurately cover the given execution path. Moreover, LLMs are capable of improving test coverage by covering execution paths in real-world repositories where traditional symbolic execution tools cannot be applied. These findings highlight the possibility of extending symbolic execution techniques with LLMs in the future to improve the ability and generalizability of symbolic execution.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7b26\u53f7\u6267\u884c\u8def\u5f84\u7ea6\u675f\u6c42\u89e3\u4e2d\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793aLLM\u80fd\u6709\u6548\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u5e76\u63d0\u5347\u771f\u5b9e\u8f6f\u4ef6\u7684\u6d4b\u8bd5\u8986\u76d6\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u7b26\u53f7\u6267\u884c\u7684\u82e5\u5e72\u5c40\u9650\uff0c\u4e3a\u76f8\u5173\u6280\u672f\u5347\u7ea7\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u7b26\u53f7\u6267\u884c\u4f9d\u8d56SMT\u6c42\u89e3\u5668\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u6570\u636e\u7ed3\u6784\u6216\u5916\u90e8API\u8c03\u7528\u7684\u6267\u884c\u8def\u5f84\u9650\u5236\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u4e2d\u7684\u5e94\u7528\u3002\u672c\u6587\u9488\u5bf9\u8be5\u95ee\u9898\uff0c\u63a2\u7d22\u662f\u5426\u53ef\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u7ea6\u675f\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30LLM\u5728\u4e24\u79cd\u8def\u5f84\u7ea6\u675f\u6c42\u89e3\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff1a\u4e00\u662f\u4e3a\u7279\u5b9a\u6267\u884c\u8def\u5f84\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\uff1b\u4e8c\u662f\u5224\u65ad\u7ed9\u5b9a\u8def\u5f84\u80fd\u5426\u88ab\u6ee1\u8db3\u4e14\u4e0d\u89e6\u53d1bug\u3002\u4e3a\u6b64\u6784\u5efa\u4e86\u65b0\u7684\u8bc4\u4f30\u6d41\u7a0b\u548c\u57fa\u51c6\uff0c\u5305\u62ec\u7ade\u8d5b\u7ea7\u7a0b\u5e8f\u548c\u771f\u5b9e\u4ed3\u5e93\u7684\u6570\u636e\u6e90\uff0c\u7528\u4e8e\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e0e\u8def\u5f84\u5206\u7c7b\u4e24\u4e2a\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6700\u5148\u8fdb\u7684LLM\u80fd\u591f\u5728\u751f\u6210\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u89e3\u51b3\u8def\u5f84\u7ea6\u675f\uff0c\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u51c6\u786e\u8986\u76d6\u76ee\u6807\u6267\u884c\u8def\u5f84\u7684\u6bd4\u4f8b\u9ad8\u8fbe60%\u3002\u6b64\u5916\uff0cLLM\u8fd8\u80fd\u5728\u4f20\u7edf\u7b26\u53f7\u6267\u884c\u5de5\u5177\u65e0\u6cd5\u8986\u76d6\u7684\u771f\u5b9e\u4ed3\u5e93\u8def\u5f84\u4e2d\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\u3002", "conclusion": "LLM\u6709\u6f5c\u529b\u6269\u5c55\u7b26\u53f7\u6267\u884c\u6280\u672f\uff0c\u63d0\u5347\u5176\u80fd\u529b\u548c\u901a\u7528\u6027\uff0c\u5bf9\u672a\u6765\u7b26\u53f7\u6267\u884c\u6280\u672f\u7684\u6539\u8fdb\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.17854", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17854", "abs": "https://arxiv.org/abs/2511.17854", "authors": ["Allen Roush", "Devin Gonier", "John Hines", "Judah Goldfeder", "Philippe Martin Wyder", "Sanjay Basu", "Ravid Shwartz Ziv"], "title": "A superpersuasive autonomous policy debating system", "comment": "Accepted to CLIP workshop at AAAI 2026", "summary": "The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main", "AI": {"tldr": "DeepDebater\u662f\u4e00\u6b3e\u80fd\u591f\u81ea\u4e3b\u53c2\u4e0e\u6807\u51c6\u653f\u7b56\u8fa9\u8bba\u5e76\u80dc\u51fa\u7684\u4eba\u673a\u534f\u4f5cAI\u8fa9\u8bba\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u4ee3\u7406\u67b6\u6784\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\uff0c\u7ed3\u5408\u8bc1\u636e\u68c0\u7d22\u53ca\u81ea\u6211\u6821\u6b63\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5b8c\u6574\u6d41\u7a0b\u81ea\u52a8\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\u5176\u8bba\u8bc1\u80fd\u529b\u5df2\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5168\u90e8\u8d44\u6e90\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u4eba\u5de5\u667a\u80fd\u5728\u590d\u6742\u3001\u9ad8\u5ea6\u8bc1\u636e\u5316\u548c\u7b56\u7565\u81ea\u9002\u5e94\u8bf4\u670d\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\u3002\u6b64\u524d\u5982IBM Project Debater\u7b49\u7cfb\u7edf\u4ec5\u9002\u7528\u4e8e\u7b80\u5316\u7684\u8fa9\u8bba\u573a\u666f\uff0c\u96be\u4ee5\u5e94\u5bf9\u5b8c\u6574\u548c\u771f\u5b9e\u7684\u653f\u7b56\u8fa9\u8bba\u3002\u4e3a\u63a8\u52a8AI\u8bf4\u670d\u4e0e\u63a8\u7406\u80fd\u529b\u7684\u5b9e\u7528\u5e94\u7528\uff0c\u9700\u8981\u80fd\u591f\u5904\u7406\u771f\u5b9e\u8fa9\u8bba\u89c4\u5219\u3001\u5185\u5bb9\u590d\u6742\u4e14\u5bf9\u6297\u6027\u5f3a\u7684\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86DeepDebater\u7cfb\u7edf\uff0c\u91c7\u7528\u5206\u5c42\u67b6\u6784\u548c\u591a\u4ee3\u7406\uff08multi-agent\uff09\u534f\u4f5c\uff0c\u6bcf\u4e2a\u4ee3\u7406\u7531\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\uff0c\u5206\u522b\u627f\u62c5\u8bba\u8bc1\u4efb\u52a1\u3002\u7cfb\u7edf\u901a\u8fc7\u8fed\u4ee3\u68c0\u7d22\u3001\u4fe1\u606f\u7efc\u5408\u548c\u81ea\u6211\u6821\u6b63\uff0c\u5229\u7528\u5927\u578b\u653f\u7b56\u8fa9\u8bba\u8bc1\u636e\u5e93\u5b8c\u6210\u5b8c\u6574\u8fa9\u8bba\u6d41\u7a0b\uff0c\u5305\u62ec\u6f14\u8bb2\u3001\u4ea4\u53c9\u8d28\u8be2\u548c\u53cd\u9a73\uff0c\u540c\u65f6\u652f\u6301\u6587\u672c\u8f6c\u8bed\u97f3\u5e76\u914d\u4ee5\u52a8\u753b\u5934\u50cf\u89c6\u9891\u7684\u7aef\u5230\u7aef\u76f4\u64ad\u5c55\u793a\u3002\u652f\u6301\u5168\u81ea\u52a8AI\u5bf9\u6218\u3001\u4eba\u673a\u6df7\u5408\u53c2\u4e0e\u53ca\u5168\u4eba\u7c7b\u53c2\u4e0e\u591a\u79cd\u8fa9\u8bba\u6a21\u5f0f\u3002", "result": "DeepDebater\u5728\u4e0e\u4eba\u7c7b\u64b0\u5199\u7684\u8fa9\u9898\u5bf9\u6297\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d28\u7684\u8bba\u8bc1\u80fd\u529b\uff0c\u6301\u7eed\u5728\u6a21\u62df\u8fa9\u8bba\u4e2d\u80dc\u51fa\uff08\u6709\u72ec\u7acbAI\u8bc4\u5ba1\u5224\u5b9a\uff09\uff0c\u5176\u751f\u6210\u7684\u8bba\u70b9\u548c\u8bc1\u636e\u53d7\u5230\u4e13\u5bb6\u6559\u7ec3\u7684\u9ad8\u5ea6\u8bc4\u4ef7\u3002\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u5f00\u6e90\u4ee3\u7801\u3001\u6f14\u8bb2\u6587\u672c\u3001\u97f3\u9891\u53ca\u89c6\u9891\u6750\u6599\u3002", "conclusion": "DeepDebater\u9996\u6b21\u4f7fAI\u80fd\u81ea\u4e3b\u5b8c\u6210\u590d\u6742\u7684\u771f\u5b9e\u653f\u7b56\u8fa9\u8bba\uff0c\u5e76\u80fd\u53d6\u5f97\u8d85\u8d8a\u4eba\u7c7b\u7684\u8868\u73b0\uff0c\u5b9e\u73b0\u4e86AI\u5728\u8bf4\u670d\u63a8\u7406\u5c42\u9762\u7684\u91cd\u5927\u7a81\u7834\uff0c\u4e5f\u4e3a\u4eba\u673a\u6df7\u5408\u9ad8\u9636\u8ba4\u77e5\u534f\u4f5c\u6811\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2511.18343", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18343", "abs": "https://arxiv.org/abs/2511.18343", "authors": ["Dongming Jin", "Zhi Jin", "Xiaohong Chen", "Zheng Fang", "Linyu Li", "Yuanpeng He", "Jia Li", "Yirang Zhang", "Yingtao Fang"], "title": "A Needle in a Haystack: Intent-driven Reusable Artifacts Recommendation with LLMs", "comment": "15 pages, 7 figures", "summary": "In open source software development, the reuse of existing artifacts has been widely adopted to avoid redundant implementation work. Reusable artifacts are considered more efficient and reliable than developing software components from scratch. However, when faced with a large number of reusable artifacts, developers often struggle to find artifacts that can meet their expected needs. To reduce this burden, retrieval-based and learning-based techniques have been proposed to automate artifact recommendations. Recently, Large Language Models (LLMs) have shown the potential to understand intentions, perform semantic alignment, and recommend usable artifacts. Nevertheless, their effectiveness has not been thoroughly explored. To fill this gap, we construct an intent-driven artifact recommendation benchmark named IntentRecBench, covering three representative open source ecosystems. Using IntentRecBench, we conduct a comprehensive comparative study of five popular LLMs and six traditional approaches in terms of precision and efficiency. Our results show that although LLMs outperform traditional methods, they still suffer from low precision and high inference cost due to the large candidate space. Inspired by the ontology-based semantic organization in software engineering, we propose TreeRec, a feature tree-guided recommendation framework to mitigate these issues. TreeRec leverages LLM-based semantic abstraction to organize artifacts into a hierarchical semantic tree, enabling intent and function alignment and reducing reasoning time. Extensive experiments demonstrate that TreeRec consistently improves the performance of diverse LLMs across ecosystems, highlighting its generalizability and potential for practical deployment.", "AI": {"tldr": "LLM\u867d\u63d0\u5347\u4e86\u5f00\u6e90\u6784\u4ef6\u63a8\u8350\u6548\u679c\u4f46\u4ecd\u5b58\u5728\u77ed\u677f\u3002TreeRec\u901a\u8fc7\u8bed\u4e49\u7279\u5f81\u6811\u4f18\u5316LLM\u63a8\u8350\uff0c\u517c\u987e\u6548\u7387\u4e0e\u7cbe\u5ea6\uff0c\u5728\u591a\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u671b\u5b9e\u9645\u843d\u5730\u3002", "motivation": "\u5728\u5f00\u6e90\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u867d\u7136\u53ef\u590d\u7528\u6784\u4ef6\u80fd\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u8d28\u91cf\uff0c\u4f46\u6d77\u91cf\u53ef\u9009\u6784\u4ef6\u8ba9\u5f00\u53d1\u8005\u96be\u4ee5\u5feb\u901f\u51c6\u786e\u5730\u627e\u5230\u6ee1\u8db3\u9700\u6c42\u7684\u7ec4\u4ef6\u3002\u5df2\u6709\u57fa\u4e8e\u68c0\u7d22\u548c\u5b66\u4e60\u7684\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd1\u5e74\u6765\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u8ba4\u4e3a\u5177\u6709\u65b0\u7684\u6f5c\u529b\uff0c\u4f46\u5176\u6548\u679c\u672a\u88ab\u7cfb\u7edf\u9a8c\u8bc1\u3002", "method": "\u6784\u5efa\u4e86\u610f\u56fe\u9a71\u52a8\u7684\u63a8\u8350\u57fa\u51c6IntentRecBench\uff0c\u6db5\u76d6\u4e09\u4e2a\u4e3b\u6d41\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\uff0c\u5e76\u57fa\u4e8e\u6b64\u5bf9\u4e94\u79cd\u4e3b\u6d41LLM\u4e0e\u516d\u79cd\u4f20\u7edf\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u505a\u4e86\u5168\u9762\u5bf9\u6bd4\u3002\u968f\u540e\uff0c\u53d7\u672c\u4f53\u8bba\u601d\u60f3\u542f\u53d1\uff0c\u63d0\u51fa\u4e86TreeRec\u2014\u2014\u7ed3\u5408LLM\u8bed\u4e49\u62bd\u8c61\u7684\u5c42\u7ea7\u7279\u5f81\u6811\u63a8\u8350\u6846\u67b6\uff0c\u5b9e\u73b0\u6784\u4ef6\u8bed\u4e49\u7ec4\u7ec7\uff0c\u5e76\u901a\u8fc7\u6811\u7ed3\u6784\u52a0\u901f\u63a8\u7406\u548c\u63d0\u9ad8\u5bf9\u9f50\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5404\u7c7bLLM\u867d\u7136\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u4ecd\u5b58\u5728\u7cbe\u5ea6\u4e0d\u8db3\u548c\u63a8\u7406\u5f00\u9500\u9ad8\u7684\u95ee\u9898\u3002TreeRec\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cdLLM\u5728\u4e0d\u540c\u751f\u6001\u7cfb\u7edf\u4e0b\u7684\u63a8\u8350\u6027\u80fd\uff0c\u6539\u5584\u4e86\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u8868\u73b0\u51fa\u8f83\u597d\u7684\u901a\u7528\u6027\u3002", "conclusion": "TreeRec\u4ee5\u7279\u5f81\u6811\u4e3a\u5f15\u5bfc\uff0c\u6709\u6548\u878d\u5408\u4e86LLM\u80fd\u529b\u4e0e\u8bed\u4e49\u7ed3\u6784\u7ec4\u7ec7\uff0c\u7f13\u89e3\u4e86\u5927\u5019\u9009\u7a7a\u95f4\u5e26\u6765\u7684\u4f4e\u7cbe\u5ea6\u4e0e\u9ad8\u8ba1\u7b97\u6d88\u8017\u95ee\u9898\uff0c\u6709\u671b\u5728\u5b9e\u9645\u5f00\u6e90\u63a8\u8350\u573a\u666f\u4e2d\u90e8\u7f72\u5e94\u7528\u3002"}}
{"id": "2511.17908", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.17908", "abs": "https://arxiv.org/abs/2511.17908", "authors": ["Debashish Chakraborty", "Eugene Yang", "Daniel Khashabi", "Dawn Lawrie", "Kevin Duh"], "title": "Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction", "comment": "Preprint", "summary": "Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8econformal prediction\u7684\u8bc1\u636e\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u7a33\u5b9a\u63a7\u5236\u76f8\u5173\u5185\u5bb9\u7684\u8986\u76d6\u7387\uff0c\u51cf\u5c11\u5197\u4f59\u4e0a\u4e0b\u6587\u5e76\u63d0\u5347RAG\u751f\u6210\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "RAG\u6a21\u5f0f\u867d\u7136\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u57fa\u7840\uff0c\u4f46\u5728\u9762\u5bf9\u8fc7\u957f\u6216\u566a\u58f0\u8f83\u591a\u7684\u4e0a\u4e0b\u6587\u65f6\u51c6\u786e\u7387\u4e0b\u964d\u3002\u73b0\u6709\u8fc7\u6ee4\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u969c\uff0c\u65e0\u6cd5\u6709\u6548\u63a7\u5236\u4fdd\u7559\u8bc1\u636e\u7684\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u4fdd\u8986\u76d6\u7387\u7684conformal prediction\u8fc7\u6ee4\u6846\u67b6\uff0c\u5728\u5d4c\u5165\u548cLLM\u8bc4\u5206\u4e0b\u7b5b\u9009\u548c\u63a7\u5236\u68c0\u7d22\u7ed3\u679c\u7684\u76f8\u5173\u6027\uff0c\u5e76\u5728NeuCLIR\u4e0eRAGTIME\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u7a33\u5b9a\u8fbe\u5230\u8bbe\u5b9a\u7684\u76f8\u5173\u6027\u8986\u76d6\u7387\uff0c\u4ec5\u4fdd\u7559\u76ee\u6807\u6bd4\u4f8b\u7684\u6709\u6548\u7247\u6bb5\uff0c\u76f8\u5bf9\u4e8e\u4e0d\u8fc7\u6ee4\u68c0\u7d22\u5185\u5bb9\uff0c\u53ef\u51cf\u5c112-3\u500d\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5e76\u5728NeuCLIR\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "conclusion": "conformal prediction\u4e3aRAG\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u6a21\u578b\u65e0\u5173\u4e14\u539f\u7406\u652f\u6491\u7684\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u65b9\u5f0f\uff0c\u80fd\u6709\u6548\u63a7\u5236\u76f8\u5173\u6027\u8986\u76d6\u5e76\u4f18\u5316\u751f\u6210\u6a21\u578b\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u3002"}}
{"id": "2511.18488", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18488", "abs": "https://arxiv.org/abs/2511.18488", "authors": ["Samuel Ackerman", "Wesam Ibraheem", "Orna Raz", "Marcel Zalmanovici"], "title": "Evaluating perturbation robustnessof generative systems that use COBOL code inputs", "comment": "16 pages (8 main, 8 appendix). Accepted to AI-SQE (ICSE, 2026): The 1st International Workshop on AI for Software Quality Evaluation: Judgment, Metrics, Benchmarks, and Beyond", "summary": "Systems incorporating large language models (LLMs) as a component are known to be sensitive (i.e., non-robust) to minor input variations that do not change the meaning of the input; such sensitivity may reduce the system's usefulness. Here, we present a framework to evaluate robustness of systems using COBOL code as input; our application is translation between COBOL and Java programming languages, but the approach extends to other tasks such as code generation or explanation. Targeting robustness of systems with COBOL as input is essential yet challenging. Many business-critical applications are written in COBOL, yet these are typically proprietary legacy applications and their code is unavailable to LLMs for training. We develop a library of COBOL paragraph and full-program perturbation methods, and create variant-expanded versions of a benchmark dataset of examples for a specific task. The robustness of the LLM-based system is evaluated by measuring changes in values of individual and aggregate metrics calculated on the system's outputs. Finally, we present a series of dynamic table and chart visualization dashboards that assist in debugging the system's outputs, and monitoring and understanding root causes of the system's sensitivity to input variation. These tools can be further used to improve the system by, for instance, indicating variations that should be handled by pre-processing steps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u8bc4\u4f30\u548c\u63d0\u5347\u4ee5COBOL\u4e3a\u8f93\u5165\u7684LLM\u7cfb\u7edf\u9c81\u68d2\u6027\u7684\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u6270\u52a8\u5e93\u548c\u52a8\u6001\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u4ee3\u7801\u7ffb\u8bd1\u3001\u751f\u6210\u7b49\u4efb\u52a1\uff0c\u52a9\u529b\u7cfb\u7edf\u7a33\u5b9a\u6027\u4f18\u5316\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u7cfb\u7edf\u4e2d\uff0c\u4f46\u5bf9\u8f93\u5165\u7684\u5c0f\u5e45\u53d8\u5316\uff08\u5373\u4f7f\u4e0d\u6539\u53d8\u542b\u4e49\uff09\u5341\u5206\u654f\u611f\uff0c\u5f71\u54cd\u4e86\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u5b9e\u9645\u53ef\u7528\u6027\u3002COBOL\u4f5c\u4e3a\u5546\u4e1a\u5173\u952e\u5e94\u7528\u7684\u91cd\u8981\u8bed\u8a00\uff0c\u867d\u7136\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u76f8\u5173\u4ee3\u7801\u591a\u4e3a\u79c1\u6709\uff0c\u96be\u4ee5\u7528\u4e8eLLM\u8bad\u7ec3\uff0c\u9488\u5bf9COBOL\u8f93\u5165\u7684\u7cfb\u7edf\u9c81\u68d2\u6027\u4e9f\u9700\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8bc4\u4ef7COBOL\u4ee3\u7801\u4f5c\u4e3a\u8f93\u5165\u7684LLM\u7cfb\u7edf\u9c81\u68d2\u6027\u7684\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09\u7f16\u5199COBOL\u6bb5\u843d\u548c\u5b8c\u6574\u7a0b\u5e8f\u7684\u6270\u52a8\u65b9\u6cd5\u5e93\uff1b2\uff09\u5229\u7528\u4e0a\u8ff0\u65b9\u6cd5\u6269\u5c55\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u751f\u6210\u591a\u6837\u5316\u53d8\u4f53\uff1b3\uff09\u901a\u8fc7\u8f93\u51fa\u7684\u4e2a\u4f53\u548c\u603b\u4f53\u6307\u6807\u7684\u53d8\u5316\u91cf\uff0c\u8bc4\u4f30\u7cfb\u7edf\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957\u52a8\u6001\u53ef\u89c6\u5316\u4eea\u8868\u677f\uff0c\u7528\u4e8e\u8c03\u8bd5\u7cfb\u7edf\u8f93\u51fa\u3001\u76d1\u63a7\u4ee5\u53ca\u5206\u6790\u8f93\u5165\u654f\u611f\u6027\u7684\u6839\u672c\u539f\u56e0\u3002", "result": "\u6784\u5efa\u4e86\u9488\u5bf9COBOL\u7f16\u7a0b\u8bed\u8a00\u8f93\u5165\u8fdb\u884c\u9c81\u68d2\u6027\u8bc4\u4f30\u7684\u5de5\u5177\u548c\u6d41\u7a0b\uff0c\u5e76\u5f00\u53d1\u4e86\u52a8\u6001\u8868\u683c\u4e0e\u53ef\u89c6\u5316\u4eea\u8868\u677f\uff0c\u6709\u52a9\u4e8e\u7cfb\u7edf\u5206\u6790\u548c\u4f18\u5316\u3002\u8be5\u65b9\u6848\u4e0d\u4ec5\u9002\u7528\u4e8eCOBOL\u5230Java\u7b49\u8bed\u8a00\u95f4\u7684\u7ffb\u8bd1\uff0c\u4e5f\u53ef\u6269\u5c55\u5230\u4ee3\u7801\u751f\u6210\u6216\u89e3\u91ca\u7b49\u4efb\u52a1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u4e13\u4e3a\u8bc4\u4f30\u53ca\u63d0\u5347LLM\u7cfb\u7edf\u5728\u5904\u7406COBOL\u4ee3\u7801\u8f93\u5165\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u9488\u5bf9\u5546\u4e1a\u5173\u952e\u4f46\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u9886\u57df\uff0c\u5e76\u901a\u8fc7\u5de5\u5177\u5316\u624b\u6bb5\u63d0\u9ad8\u4e86\u7cfb\u7edf\u5206\u6790\u548c\u4f18\u5316\u80fd\u529b\u3002"}}
{"id": "2511.17910", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17910", "abs": "https://arxiv.org/abs/2511.17910", "authors": ["Yuliang Zhan", "Xinyu Tang", "Han Wan", "Jian Li", "Ji-Rong Wen", "Hao Sun"], "title": "L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention", "comment": "AAAI 2026 oral", "summary": "Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u901a\u8fc7\u6f5c\u8868\u5f81\u8fc1\u79fb\u7684L2V-CoT\u65b9\u6cd5\uff0c\u5c06LLMs\u7684\u63a8\u7406\u80fd\u529b\u6709\u6548\u8f6c\u79fb\u5230VLMs\uff0c\u5728\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u548c\u90e8\u5206\u76d1\u7763\u57fa\u7ebf\u3002", "motivation": "Vision-Language Models\uff08VLMs\uff09\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u591a\u6a21\u6001\u63a8\u7406\u6570\u636e\u3002\u5df2\u6709\u65b9\u6cd5\u5c1d\u8bd5\u4eceLLMs\u5411VLMs\u8fc1\u79fbChain-of-Thought\uff08CoT\uff09\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u9700\u8981\u9ad8\u6602\u7684\u8bad\u7ec3\u6210\u672c\u6216\u67b6\u6784\u5bf9\u9f50\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u67b6\u6784\u53d8\u66f4\u7684\u3001\u9ad8\u6548\u7684\u63a8\u7406\u8fc1\u79fb\u65b9\u6cd5\u3002", "method": "\u5229\u7528Linear Artificial Tomography\uff08LAT\uff09\u5c55\u793aLLMs\u548cVLMs\u5728CoT\u63a8\u7406\u65b9\u9762\u5171\u4eab\u4f4e\u9891\u6f5c\u5728\u8868\u5f81\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51faL2V-CoT\u65b9\u6cd5\uff1a\u4eceLLMs\u4e2d\u5728\u9891\u7387\u57df\u62bd\u53d6\u5e76\u91cd\u91c7\u4f4e\u9891CoT\u8868\u5f81\uff0c\u5b9e\u73b0\u4e0eVLMs\u7ef4\u5ea6\u4e0a\u7684\u5339\u914d\uff0c\u7136\u540e\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5c06\u8fd9\u4e9b\u6f5c\u8868\u5f81\u6ce8\u5165VLMs\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u63d0\u5347\u5176\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cL2V-CoT\u65b9\u6cd5\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u7ebf\u65b9\u6cd5\u4e0e\u90e8\u5206\u76d1\u7763\u65b9\u6cd5\u4e4b\u4e0a\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u63a8\u7406\u8868\u73b0\u3002", "conclusion": "L2V-CoT\u80fd\u591f\u4ee5\u8bad\u7ec3\u65e0\u5173\u4e14\u9ad8\u6548\u7684\u65b9\u5f0f\uff0c\u5c06CoT\u63a8\u7406\u80fd\u529b\u4eceLLMs\u8fc1\u79fb\u81f3VLMs\uff0c\u663e\u8457\u63d0\u5347VLMs\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u5177\u6709\u91cd\u8981\u5e94\u7528\u4e0e\u7406\u8bba\u610f\u4e49\u3002"}}
{"id": "2511.18506", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18506", "abs": "https://arxiv.org/abs/2511.18506", "authors": ["Michael Adjei Osei", "Sidney Shapiro"], "title": "HQPEF-Py: Metrics, Python Patterns, and Guidance for Evaluating Hybrid Quantum Programs", "comment": "17 pages", "summary": "We study how to evaluate hybrid quantum programs as end-to-end workflows rather than as isolated devices or algorithms. Building on the Hybrid Quantum Program Evaluation Framework (HQPEF), we formalize a workflow-aware Quantum Readiness Level (QRL) score; define a normalized speedup under quality constraints for the Utility of Quantumness (UQ); and provide a timing-and-drift audit for hybrid pipelines. We complement these definitions with concise Python reference implementations that illustrate how to instantiate the metrics and audit procedures with state-of-the-art classical and quantum solvers (e.g., via Qiskit or PennyLane), while preserving matched-budget discipline and reproducibility.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u4f5c\u4e3a\u5b8c\u6574\u5de5\u4f5c\u6d41\u8fdb\u884c\u8bc4\u4f30\uff0c\u63d0\u51fa\u89c4\u8303\u5316\u7684\u8bc4\u4f30\u6307\u6807\u548c\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5e76\u7528Python\u5b9e\u73b0\u4e86\u53c2\u8003\u5b9e\u4f8b\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u91cf\u5b50\u7ba1\u9053\u7684\u8bc4\u4f30\u6807\u51c6\u5316\u548c\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u76ee\u524d\u5bf9\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u7684\u8bc4\u4f30\u591a\u9488\u5bf9\u5355\u4e00\u8bbe\u5907\u6216\u7b97\u6cd5\uff0c\u800c\u7f3a\u4e4f\u5bf9\u6574\u4e2a\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u7cfb\u7edf\u6027\u7684\u8bc4\u4ef7\u65b9\u6cd5\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u6b64\u7c7b\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u63d0\u9ad8\u6df7\u5408\u91cf\u5b50\u7ba1\u9053\u7684\u53ef\u7528\u6027\u548c\u5e94\u7528\u63a8\u5e7f\u3002", "method": "\u6784\u5efa\u4e86HQPEF\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u4e86\u5de5\u4f5c\u6d41\u611f\u77e5\u7684\u91cf\u5b50\u51c6\u5907\u5ea6\uff08QRL\uff09\u5f97\u5206\u3001\u5728\u8d28\u91cf\u7ea6\u675f\u4e0b\u7684\u91cf\u5b50\u6548\u7528\u5f52\u4e00\u5316\u52a0\u901f\u6bd4\uff08UQ\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9\u6df7\u5408\u7ba1\u9053\u7684\u8ba1\u65f6\u548c\u6f02\u79fb\u5ba1\u8ba1\u3002\u901a\u8fc7Python\u53c2\u8003\u5b9e\u73b0\u8bf4\u660e\u5982\u4f55\u7528\u4e3b\u6d41\u7ecf\u5178\u4e0e\u91cf\u5b50\u6c42\u89e3\u5668\u8fdb\u884c\u5177\u4f53\u5b9e\u4f8b\u5316\u3002", "result": "\u63d0\u51fa\u4e86QRL\u5f97\u5206\u3001UQ\u5f52\u4e00\u5316\u52a0\u901f\u6bd4\u53ca\u8ba1\u65f6\u6f02\u79fb\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86Python\u5b9e\u73b0\uff0c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u8bc4\u4f30\u6307\u6807\u53ef\u9002\u7528\u4e8e\u5b9e\u9645\u4e3b\u6d41\u7684\u91cf\u5b50\u4e0e\u7ecf\u5178\u6c42\u89e3\u5668\uff0c\u63d0\u5347\u4e86\u8bc4\u4f30\u5de5\u4f5c\u7684\u89c4\u8303\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u5de5\u4f5c\u6d41\u7684\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cfb\u7edf\u3001\u53ef\u590d\u73b0\u7684\u6df7\u5408\u91cf\u5b50\u7ba1\u9053\u6027\u80fd\u8bc4\u4ef7\u3002"}}
{"id": "2511.17923", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17923", "abs": "https://arxiv.org/abs/2511.17923", "authors": ["Wenda Li", "Tongya Zheng", "Shunyu Liu", "Yu Wang", "Kaixuan Chen", "Hanyang Yuan", "Bingde Hu", "Zujie Ren", "Mingli Song", "Gang Chen"], "title": "Towards Efficient LLM-aware Heterogeneous Graph Learning", "comment": null, "summary": "Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9ad8\u6548\u7684LLM\u5f02\u6784\u56fe\u5b66\u4e60\u6846\u67b6ELLA\uff0c\u901a\u8fc7\u7ed3\u6784\u6539\u8fdb\u548c\u63d0\u793a\u4f18\u5316\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u914d\u5927\u89c4\u6a21LLM\u573a\u666f\u3002", "motivation": "\u5f02\u6784\u56fe\u5e7f\u6cdb\u5b58\u5728\u4e8e\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u7f51\u7edc\u4e2d\uff0c\u8282\u70b9\u4e0e\u5173\u7cfb\u7c7b\u578b\u591a\u6837\u5bfc\u81f4\u8bed\u4e49\u590d\u6742\u3002\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u9884\u5b9a\u4e49\u8bed\u4e49\u4f9d\u8d56\u548c\u76d1\u7763\u4fe1\u53f7\u7a00\u7f3a\uff0c\u4e3b\u6d41\u5229\u7528\u81ea\u76d1\u7763\u4fe1\u53f7\u4f46\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u3002\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u63d0\u5347\u5f02\u6784\u56fe\u4e2d\u5173\u7cfb\u4e0e\u4efb\u52a1\u7684\u8bed\u4e49\u5efa\u6a21\uff0c\u4f46\u7531\u4e8e\u8ba1\u7b97\u590d\u6742\u6027\u96be\u4ee5\u6709\u6548\u878d\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684LLM\u611f\u77e5\u7684\u5f02\u6784\u56fe\u5b66\u4e60\u6846\u67b6ELLA\u3002\u8be5\u6846\u67b6\u4e3b\u8981\u5305\u62ec\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1\uff09LLM-aware Relation Tokenizer\uff0c\u5229\u7528LLM\u5bf9\u591a\u8df3\u3001\u591a\u7c7b\u578b\u5173\u7cfb\u8fdb\u884c\u7f16\u7801\uff0c\u6355\u6349\u590d\u6742\u8bed\u4e49\uff1b2\uff09Hop-level Relation Graph Transformer\uff0c\u5c06LLM\u611f\u77e5\u7684\u5173\u7cfb\u63a8\u7406\u8ba1\u7b97\u590d\u6742\u5ea6\u7531\u6307\u6570\u7ea7\u964d\u4e3a\u7ebf\u6027\u7ea7\uff1b3\uff09\u57fa\u4e8e\u4efb\u52a1\u7684\u7ec6\u7c92\u5ea6\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\uff08CoT prompt\uff09\uff0c\u5f25\u5408\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u4efb\u52a1\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u3002", "result": "\u5728\u56db\u4e2a\u5f02\u6784\u56fe\u6570\u636e\u96c6\u4e0a\u5f00\u5c55\u5927\u91cf\u5b9e\u9a8c\uff0c\u663e\u793aELLA\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u8d85\u8d8a\u6700\u65b0\u65b9\u6cd5\uff0c\u80fd\u6269\u5c55\u81f313B\u53c2\u6570\u89c4\u6a21\u7684LLM\uff0c\u5e76\u5b9e\u73b0\u6700\u591a4\u500d\u901f\u5ea6\u63d0\u5347\u3002\u4ee3\u7801\u5df2\u7ecf\u5f00\u6e90\u3002", "conclusion": "ELLA\u6846\u67b6\u9ad8\u6548\u6574\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u5f02\u6784\u56fe\u5b66\u4e60\uff0c\u517c\u987e\u5173\u7cfb\u8bed\u4e49\u5efa\u6a21\u6df1\u5ea6\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u6709\u6548\u89e3\u51b3\u4e86\u9884\u8bad\u7ec3\u548c\u4e0b\u6e38\u4efb\u52a1\u7684\u8bed\u4e49\u5bf9\u9f50\u95ee\u9898\u3002"}}
{"id": "2511.18528", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18528", "abs": "https://arxiv.org/abs/2511.18528", "authors": ["Renyi Zhong", "Yintong Huo", "Wenwei Gu", "Yichen Li", "Michael R. Lyu"], "title": "End-to-End Automated Logging via Multi-Agent Framework", "comment": null, "summary": "Software logging is critical for system observability, yet developers face a dual crisis of costly overlogging and risky underlogging. Existing automated logging tools often overlook the fundamental whether-to-log decision and struggle with the composite nature of logging. In this paper, we propose Autologger, a novel hybrid framework that addresses the complete the end-to-end logging pipeline. Autologger first employs a fine-tuned classifier, the Judger, to accurately determine if a method requires new logging statements. If logging is needed, a multi-agent system is activated. The system includes specialized agents: a Locator dedicated to determining where to log, and a Generator focused on what to log. These agents work together, utilizing our designed program analysis and retrieval tools. We evaluate Autologger on a large corpus from three mature open-source projects against state-of-the-art baselines. Our results show that Autologger achieves 96.63\\% F1-score on the crucial whether-to-log decision. In an end-to-end setting, Autologger improves the overall quality of generated logging statements by 16.13\\% over the strongest baseline, as measured by an LLM-as-a-judge score. We also demonstrate that our framework is generalizable, consistently boosting the performance of various backbone LLMs.", "AI": {"tldr": "Autologger\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u65e5\u5fd7\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u5206\u7c7b\u5668\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u201c\u662f\u5426\u9700\u8981\u65e5\u5fd7\u201d\u51b3\u7b56\u548c\u65e5\u5fd7\u8d28\u91cf\uff0c\u5728\u5f00\u6e90\u9879\u76ee\u5b9e\u6d4b\u4e2d\u6548\u679c\u4f18\u5f02\uff0c\u5177\u6709\u8f83\u5f3a\u901a\u7528\u6027\u3002", "motivation": "\u8f6f\u4ef6\u65e5\u5fd7\u5bf9\u4e8e\u7cfb\u7edf\u53ef\u89c2\u5bdf\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5f00\u53d1\u8005\u9762\u4e34\u7740\u8fc7\u5ea6\u65e5\u5fd7\u5e26\u6765\u7684\u9ad8\u6602\u6210\u672c\u4e0e\u65e5\u5fd7\u4e0d\u8db3\u7684\u98ce\u9669\u3002\u73b0\u6709\u81ea\u52a8\u5316\u65e5\u5fd7\u5de5\u5177\u5f80\u5f80\u5ffd\u7565\u4e86\u201c\u662f\u5426\u9700\u8981\u65e5\u5fd7\u201d\u8fd9\u4e2a\u6839\u672c\u6027\u51b3\u7b56\uff0c\u540c\u65f6\u96be\u4ee5\u5904\u7406\u65e5\u5fd7\u7684\u591a\u65b9\u9762\u590d\u6742\u6027\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u66f4\u6709\u6548\u3001\u667a\u80fd\u7684\u65e5\u5fd7\u81ea\u52a8\u5316\u65b9\u6848\uff0c\u89e3\u51b3\u5b8c\u6574\u7684\u65e5\u5fd7\u751f\u6210\u6d41\u7a0b\u3002", "method": "\u672c\u6587\u63d0\u51faAutologger\uff0c\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6df7\u5408\u6846\u67b6\u3002\u9996\u5148\u901a\u8fc7\u5fae\u8c03\u7684\u5206\u7c7b\u5668Judger\u5224\u65ad\u65b9\u6cd5\u662f\u5426\u9700\u8981\u65b0\u589e\u65e5\u5fd7\uff1b\u5982\u679c\u9700\u8981\uff0c\u5219\u542f\u52a8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u62ecLocator\u7528\u4e8e\u786e\u5b9a\u65e5\u5fd7\u4f4d\u7f6e\u3001Generator\u51b3\u5b9a\u65e5\u5fd7\u5185\u5bb9\uff0c\u4e24\u8005\u914d\u5408\u8bbe\u8ba1\u7684\u7a0b\u5e8f\u5206\u6790\u548c\u68c0\u7d22\u5de5\u5177\u3002\u7cfb\u7edf\u53ef\u9002\u914d\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3002", "result": "\u5728\u4e09\u4e2a\u6210\u719f\u5f00\u6e90\u9879\u76ee\u7684\u65e5\u5fd7\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cAutologger\u5728\u201c\u662f\u5426\u9700\u8981\u65e5\u5fd7\u201d\u51b3\u7b56\u4e0a\u8fbe\u523096.63%\u7684F1\u5206\u6570\u3002\u5728\u7aef\u5230\u7aef\u65e5\u5fd7\u751f\u6210\u8d28\u91cf\u4e0a\uff0c\u8f83\u6700\u4f73\u57fa\u7ebf\u63d0\u534716.13%\uff08LLM-as-a-judge\u8bc4\u5206\uff09\u3002\u6b64\u5916\uff0c\u6846\u67b6\u5728\u591a\u79cd\u4e3b\u6d41LLM\u4e0b\u5747\u6709\u7a33\u5b9a\u63d0\u5347\u6548\u679c\uff0c\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Autologger\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u81ea\u52a8\u5316\u7684\u51c6\u786e\u6027\u4e0e\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u65e5\u5fd7\u751f\u6210\u4e2d\u7684\u591a\u4e2a\u5173\u952e\u73af\u8282\uff0c\u53ef\u5e7f\u6cdb\u63d0\u5347\u5404\u7c7b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65e5\u5fd7\u80fd\u529b\u3002"}}
{"id": "2511.17938", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17938", "abs": "https://arxiv.org/abs/2511.17938", "authors": ["Jianghao Wu", "Yasmeen George", "Jin Ye", "Yicheng Wu", "Daniel F. Schmidt", "Jianfei Cai"], "title": "SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization", "comment": null, "summary": "Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.", "AI": {"tldr": "\u63d0\u51faSPINE\uff0c\u9488\u5bf9\u6d4b\u8bd5\u65f6\u9002\u5e94LLM/MLLM\u63a8\u7406\u8868\u73b0\uff0c\u4ec5\u66f4\u65b0\u5173\u952e\u5206\u53c9\u4ee4\u724c\u5e76\u63a7\u71b5\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e14\u7a33\u5b9a\uff0c\u65e0\u9700\u6807\u7b7e\u6216\u5956\u52b1\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u591a\u6a21\u6001LLM\uff08MLLM\uff09\u5728\u94fe\u5f0f\u601d\u7ef4\uff08chain-of-thought\uff09\u63a8\u7406\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5b83\u4eec\u5728\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u9762\u4e34\u5206\u5e03\u8f6c\u79fb\u548c\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u76d1\u7763\u7684\u95ee\u9898\u3002\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff08TTRL\uff09\u65b9\u6cd5\u867d\u7136\u80fd\u901a\u8fc7\u81ea\u6d3d\u6295\u7968\u83b7\u5f97\u65e0\u6807\u7b7e\u4f2a\u5956\u52b1\uff0c\u4f46\u5f80\u5f80\u5bfc\u81f4\u5956\u52b1\u7ed3\u6784\u574d\u7f29\u548c\u6027\u80fd\u4e0b\u964d\u3002\u56e0\u6b64\u4e9f\u9700\u7a33\u5b9a\u3001\u65e0\u6807\u7b7e\u4e14\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86SPINE\u2014\u2014\u4e00\u79cd\u4ee4\u724c\u9009\u62e9\u6027\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002\u5176\u6838\u5fc3\u5206\u522b\u4e3a\uff1a\u53ea\u66f4\u65b0\u5206\u53c9\u4ee4\u724c\uff08\u901a\u8fc7\u524d\u5411\u4f20\u64ad\u7edf\u8ba1\u8bc6\u522b\u7684\u9ad8\u71b5\u8282\u70b9\uff09\uff0c\u5e76\u5728\u8fd9\u4e9b\u4ee4\u724c\u4e0a\u65bd\u52a0\u71b5\u5e26\u6b63\u5219\u5316\uff08\u5f53\u71b5\u8fc7\u4f4e\u65f6\u4fc3\u8fdb\u63a2\u7d22\uff0c\u71b5\u8fc7\u9ad8\u65f6\u6291\u5236\u566a\u58f0\u76d1\u7763\uff09\u3002SPINE\u53ef\u5d4c\u5165GRPO\u98ce\u683c\u76ee\u6807\uff0c\u65e0\u9700\u6807\u7b7e\u6216\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728\u5305\u542b\u591a\u6a21\u6001\u95ee\u7b54\u3001\u901a\u7528\u53ca\u4e13\u5bb6\u95ee\u7b54\u3001\u6570\u5b66\u63a8\u7406\u548c\u533b\u5b66\u95ee\u7b54\u7684\u5341\u4e2a\u57fa\u51c6\u4e0a\uff0cSPINE\u5728LLM\u548cMLLM\u540e\u7aef\u5747\u7a33\u5b9a\u63d0\u5347\u4e86Pass@1\u8868\u73b0\uff0c\u907f\u514d\u4e86\u54cd\u5e94\u957f\u5ea6\u574d\u7f29\uff0c\u8bad\u7ec3\u52a8\u6001\u66f4\u52a0\u7a33\u5b9a\u3002", "conclusion": "\u4ec5\u9488\u5bf9\u94fe\u5f0f\u601d\u7ef4\u5206\u53c9\u70b9\u8fdb\u884c\u66f4\u65b0\uff0c\u662f\u5b9e\u73b0\u7406\u6027\u6a21\u578b\u7a33\u5b9a\u3001\u6709\u6548\u4e14\u65e0\u6807\u7b7e\u6d4b\u8bd5\u65f6\u9002\u5e94\u7684\u4e00\u79cd\u7b80\u6d01\u65b9\u5f0f\u3002"}}
{"id": "2511.18538", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18538", "abs": "https://arxiv.org/abs/2511.18538", "authors": ["Jian Yang", "Wei Zhang", "Shark Liu", "Jiajun Wu", "Shawn Guo", "Yizhi Li"], "title": "From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence", "comment": null, "summary": "Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u5e76\u5b9e\u8bc1\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u6280\u672f\u8fdb\u5c55\u4e0e\u5b9e\u9645\u6311\u6218\uff0c\u6db5\u76d6\u6a21\u578b\u8bad\u7ec3\u5168\u6d41\u7a0b\u548c\u4e3b\u6d41\u6a21\u578b\u7684\u6027\u80fd\u6bd4\u8f83\uff0c\u5173\u6ce8\u5b66\u672f\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u8131\u8282\uff0c\u5e76\u4e3a\u540e\u7eed\u7814\u7a76\u548c\u5e94\u7528\u5b9e\u8df5\u63d0\u51fa\u4e0b\u4e00\u4e2a\u9636\u6bb5\u7684\u65b9\u5411\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u5927\u6a21\u578b\uff08LLMs\uff09\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u76f4\u63a5\u8f6c\u6362\u4e3a\u529f\u80fd\u6027\u4ee3\u7801\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5b9e\u9645\u5546\u4e1a\u5de5\u5177\u4e2d\u3002\u7531\u4e8e\u6280\u672f\u5feb\u901f\u8fdb\u6b65\u4ee5\u53ca\u5b66\u672f\u754c\u4e0e\u5de5\u4e1a\u754c\u4e4b\u95f4\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\uff0c\u5bf9LLMs\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u7cfb\u7edf\u6027\u5206\u6790\u9700\u6c42\u5f3a\u70c8\u3002", "method": "\u672c\u6587\u91c7\u7528\u7cfb\u7edf\u6027\u7efc\u8ff0\u548c\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5bf9\u4ee3\u7801\u76f8\u5173\u7684\u5927\u6a21\u578b\u751f\u547d\u5468\u671f\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u5305\u62ec\u6570\u636e\u5904\u7406\u3001\u9ad8\u7ea7\u63d0\u793a\u3001\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u3001\u5f3a\u5316\u5b66\u4e60\u4ee5\u53ca\u81ea\u4e3b\u7f16\u7801\u7b49\u73af\u8282\u3002\u5bf9\u4e3b\u6d41\u901a\u7528\u5927\u6a21\u578b\u4e0e\u4e13\u7528\u4ee3\u7801\u5927\u6a21\u578b\u8fdb\u884c\u4e86\u6280\u672f\u548c\u5b9e\u65bd\u65b9\u9762\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u4e00\u7cfb\u5217\u5b9e\u9a8c\u5206\u6790\u6a21\u578b\u7684\u6269\u5c55\u89c4\u5f8b\u3001\u67b6\u6784\u9009\u62e9\u3001\u8d85\u53c2\u6570\u654f\u611f\u6027\u53ca\u6570\u636e\u96c6\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e3b\u6d41\u901a\u7528\u53ca\u4e13\u7528\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u80fd\u529b\uff0c\u5bf9\u73b0\u6709\u6280\u672f\u8fdb\u884c\u6df1\u5165\u6bd4\u8f83\uff0c\u63ed\u793a\u4e86\u5b66\u672f\u57fa\u51c6\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5305\u62ec\u4ee3\u7801\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u3001\u5927\u578b\u4ee3\u7801\u5e93\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u53ca\u5f00\u53d1\u6d41\u7a0b\u96c6\u6210\u3002\u8bba\u6587\u8fd8\u63a2\u7d22\u4e86\u672a\u6765\u6709\u6f5c\u529b\u7684\u7814\u7a76\u65b9\u5411\u4e0e\u884c\u4e1a\u5b9e\u9645\u9700\u6c42\u7684\u5bf9\u63a5\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u6781\u5927\u63a8\u52a8\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u7684\u53d1\u5c55\uff0c\u672c\u6587\u901a\u8fc7\u5168\u65b9\u4f4d\u7684\u5206\u6790\u548c\u5927\u91cf\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u5398\u6e05\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u73b0\u72b6\u53ca\u9762\u4e34\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u7f29\u5c0f\u5b66\u754c\u4e0e\u4e1a\u754c\u4e4b\u95f4\u5dee\u8ddd\u7684\u5efa\u8bae\uff0c\u4e3a\u672a\u6765\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7814\u7a76\u4e0e\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\u53c2\u8003\u3002"}}
{"id": "2511.17946", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17946", "abs": "https://arxiv.org/abs/2511.17946", "authors": ["Shuo Zhang", "Fabrizio Gotti", "Fengran Mo", "Jian-Yun Nie"], "title": "Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models", "comment": null, "summary": "Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8bad\u7ec3\u6570\u636e\u8986\u76d6\u4fe1\u606f\u5728\u68c0\u6d4b\u5927\u6a21\u578b\u5e7b\u89c9\u4e2d\u7684\u4f5c\u7528\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u5355\u72ec\u4f7f\u7528\u76f8\u5173\u7279\u5f81\u68c0\u6d4b\u6548\u679c\u4e00\u822c\uff0c\u4f46\u4e0e\u6982\u7387\u7b49\u4fe1\u53f7\u7ed3\u5408\u540e\u80fd\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5bf9\u63d0\u5347\u5f00\u653e\u95ee\u7b54\u5e7b\u89c9\u8bc6\u522b\u5177\u6709\u8865\u5145\u4ef7\u503c\u3002", "motivation": "\u5927\u6a21\u578b\u5728\u5f00\u653e\u57df\u95ee\u7b54\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u7528\u6a21\u578b\u5185\u90e8\u7279\u5f81\uff08\u5982\u751f\u6210\u4e00\u81f4\u6027\u7b49\uff09\u6765\u68c0\u6d4b\u5e7b\u89c9\uff0c\u4f46\u9884\u8bad\u7ec3\u6570\u636e\u7684\u8986\u76d6\u4e0e\u5e7b\u89c9\u4e4b\u95f4\u7684\u5173\u7cfb\u8fd8\u672a\u88ab\u5145\u5206\u63a2\u8ba8\uff0c\u5c24\u5176\u662f\u957f\u5c3e\u77e5\u8bc6\u4e0a\u7684\u8868\u73b0\u8f83\u5dee\u3002\u672c\u6587\u63d0\u51fa\u7814\u7a76\u6570\u636e\u8986\u76d6\u662f\u5426\u4e5f\u80fd\u4f5c\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u4fe1\u53f7\u3002", "method": "\u4f5c\u8005\u57fa\u4e8eRedPajama\u76841.3\u4e07\u4ebftoken\u9884\u8bad\u7ec3\u8bed\u6599\uff0c\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u7684\u540e\u7f00\u6570\u7ec4\uff0c\u68c0\u7d22prompt\u548c\u751f\u6210\u56de\u7b54\u7684n-gram\u7edf\u8ba1\u4fe1\u606f\uff0c\u5e76\u5728\u4e09\u4e2a\u95ee\u7b54\u57fa\u51c6\u96c6\u4e0a\uff0c\u5bf9\u57fa\u4e8e\u6570\u636e\u51fa\u73b0\u7279\u5f81\u8fdb\u884c\u5e7b\u89c9\u68c0\u6d4b\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "result": "\u5355\u72ec\u4f7f\u7528\u6570\u636e\u51fa\u73b0\u7279\u5f81\u9884\u6d4b\u5e7b\u89c9\u80fd\u529b\u8f83\u5f31\uff0c\u4f46\u548clog-probability\u7b49\u4fe1\u53f7\u7ed3\u5408\u65f6\uff0c\u5c24\u5176\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u8f83\u5927\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u6709\u4e00\u5b9a\u63d0\u5347\u3002", "conclusion": "\u8bcd\u6c47\u8986\u76d6\u7279\u5f81\u80fd\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e92\u8865\u4fe1\u53f7\u3002\u76f8\u5173\u4ee3\u7801\u4e0e\u5de5\u5177\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.18589", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18589", "abs": "https://arxiv.org/abs/2511.18589", "authors": ["Michael Trusov", "Minha Hwang", "Zainab Jamal", "Swarup Chandra"], "title": "Strategic Decision Framework for Enterprise LLM Adoption", "comment": "14 pages, 1 key figure", "summary": "Organizations are rapidly adopting Large Language Models (LLMs) to transform their operations, yet they lack clear guidance on key decisions for adoption and implementation. While LLMs offer powerful capabilities in content generation, assisted coding, and process automation, businesses face critical challenges in data security, LLM solution development approach, infrastructure requirements, and deployment strategies. Healthcare providers must protect patient data while leveraging LLMs for medical analysis, financial institutions need to balance automated customer service with regulatory compliance, and software companies seek to enhance development productivity while maintaining code security.\n  This article presents a systematic six-step decision framework for LLM adoption, helping organizations navigate from initial application selection to final deployment. Based on extensive interviews and analysis of successful and failed implementations, our framework provides practical guidance for business leaders to align technological capabilities with business objectives. Through key decision points and real-world examples from both B2B and B2C contexts, organizations can make informed decisions about LLM adoption while ensuring secure and efficient integration across various use cases, from customer service automation to content creation and advanced analytics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u4f01\u4e1a\u6709\u5e8f\u3001\u5b89\u5168\u5730\u91c7\u7eb3\u548c\u5e94\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e94\u5bf9\u6570\u636e\u5b89\u5168\u3001\u5f00\u53d1\u548c\u90e8\u7f72\u7b49\u6838\u5fc3\u96be\u9898\uff0c\u5df2\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u4f01\u4e1a\u5e26\u6765\u521b\u65b0\u673a\u4f1a\uff0c\u4f46\u5728\u6570\u636e\u5b89\u5168\u3001\u5f00\u53d1\u65b9\u6cd5\u3001\u57fa\u7840\u8bbe\u65bd\u548c\u90e8\u7f72\u7b56\u7565\u7b49\u65b9\u9762\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u654f\u611f\u884c\u4e1a\u5982\u533b\u7597\u3001\u91d1\u878d\u548c\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5bf9\u6210\u529f\u548c\u5931\u8d25\u6848\u4f8b\u7684\u5e7f\u6cdb\u8bbf\u8c08\u548c\u5206\u6790\uff0c\u603b\u7ed3\u5e76\u63d0\u51fa\u4e86\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u5e76\u7ed3\u5408B2B\u3001B2C\u4e0d\u540c\u573a\u666f\u7684\u771f\u5b9e\u6848\u4f8b\uff0c\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "result": "\u7814\u7a76\u603b\u7ed3\u4e86\u4f01\u4e1a\u5728\u91c7\u7eb3LLM\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u5173\u952e\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u5177\u4f53\u5b9e\u7528\u7684\u51b3\u7b56\u6846\u67b6\uff0c\u4f7f\u4f01\u4e1a\u80fd\u66f4\u6709\u9488\u5bf9\u6027\u5730\u5b9e\u65bdLLM\uff0c\u786e\u4fdd\u5408\u89c4\u3001\u5b89\u5168\u4e0e\u4e1a\u52a1\u76ee\u6807\u7684\u7edf\u4e00\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7684\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u4f01\u4e1a\u5b89\u5168\u3001\u9ad8\u6548\u5730\u91c7\u7eb3\u548c\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u6307\u5bfc\u4f01\u4e1a\u5b8c\u6210\u4ece\u5e94\u7528\u9009\u62e9\u5230\u6700\u7ec8\u90e8\u7f72\u7684\u5168\u8fc7\u7a0b\u51b3\u7b56\u3002"}}
{"id": "2511.17955", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17955", "abs": "https://arxiv.org/abs/2511.17955", "authors": ["Dat Thanh Nguyen", "Nguyen Hung Lam", "Anh Hoang-Thi Nguyen", "Trong-Hop Do"], "title": "MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok", "comment": "Accepted at PACLIC39", "summary": "With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u89c6\u89c9\u3001\u97f3\u9891\u3001\u6587\u672c\u591a\u6a21\u6001\u4e8e\u4e00\u4f53\u7684\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u7cfb\u7edfMTikGuard\uff0c\u5728TikTok\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5b9e\u73b0\u4e86\u53ef\u7528\u4e8e\u73b0\u5b9e\u5e94\u7528\u7684\u5927\u89c4\u6a21\u5b9e\u65f6\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u77ed\u89c6\u9891\u5e73\u53f0\uff08\u5982TikTok\uff09\u5728\u9752\u5c11\u5e74\u4e2d\u7684\u6d41\u884c\u5e26\u6765\u4e86\u6709\u5bb3\u5185\u5bb9\u4f20\u64ad\u7684\u65b0\u6311\u6218\uff0c\u4f20\u7edf\u5185\u5bb9\u5ba1\u6838\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u5b9e\u65f6\u548c\u5927\u89c4\u6a21\u7684\u89c6\u9891\u4e0a\u4f20\u3002", "method": "\u63d0\u51faMTikGuard\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u6269\u5c55\u7684TikHarm\u6570\u636e\u96c6\uff0c\u96c6\u6210\u89c6\u89c9\u3001\u97f3\u9891\u4e0e\u6587\u672c\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7Apache Kafka\u4e0eSpark\u6784\u5efa\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u5904\u7406\u67b6\u6784\u3002", "result": "MTikGuard\u7cfb\u7edf\u5728\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8689.37%\u51c6\u786e\u7387\u4e0e89.45% F1\u5206\u6570\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u548c\u7cfb\u7edf\u67b6\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55\u6570\u636e\u96c6\u548c\u591a\u6a21\u6001\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u77ed\u89c6\u9891\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5b9e\u9645\u90e8\u7f72\uff0c\u6709\u671b\u7528\u4e8e\u5927\u89c4\u6a21\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u6cbb\u7406\u3002"}}
