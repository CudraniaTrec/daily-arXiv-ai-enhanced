<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.DM](#cs.DM) [Total: 3]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Solvable Tuple Patterns and Their Applications to Program Verification](https://arxiv.org/abs/2508.20365)
*Naoki Kobayashi,Ryosuke Sato,Ayumi Shinohara,Ryo Yoshinaka*

Main category: cs.PL

TL;DR: 本文提出了一种新颖的可解元组模式（STPs）方法，无需负样本便能有效推断递归数据结构的不变式，并通过集成进CHC求解器在国际竞赛中获得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 自动化验证操作递归数据结构的程序仍面临挑战，目标是设计既高效又无需负样本的不变式推断方法，从而提高自动验证工具的实用性和精度。

Method: 提出STPs概念用于表达递归数据结构间的不变式，开发了STP推断算法，通过SMT求解器检验不变式归纳性，并将STP推断集成至支持CHC的程序验证工具中。

Result: STP推断方法仅需少量正样本即可高效推断递归结构不变式，集成该方法的CHC求解器在CHC-COMP 2025 ADT-LIN分类中获得领先优势。

Conclusion: 文中提出的可解元组模式（STPs）能够在无需负样本的情况下，有效地推断递归数据结构程序的不变式，并已成功集成到CHC求解器中，其有效性通过CHC-COMP 2025竞赛结果得到验证。

Abstract: Despite the recent progress of automated program verification techniques,
fully automated verification of programs manipulating recursive data structures
remains a challenge. We introduce the notion of solvable tuple patterns (STPs)
to express invariants between list-like recursive data structures. A
distinguishing feature of STPs is that they can be efficiently inferred from
only a small number of positive samples; no negative samples are required. An
SMT solver that supports the sequence theory can be used to check that an
inferred STP is indeed an inductive invariant. After presenting basic
properties of STPs and an STP inference algorithm, we show how to incorporate
the STP inference into a CHC (Constrained Horn Clauses) solver supporting
list-like data structures, which serves as a uniform backend for automated
program verification tools. A CHC solver incorporating the STP inference has
won the ADT-LIN category of CHC-COMP 2025 by a big margin.

</details>


### [2] [Static Factorisation of Probabilistic Programs With User-Labelled Sample Statements and While Loops](https://arxiv.org/abs/2508.20922)
*Markus Böck,Jürgen Cito*

Main category: cs.PL

TL;DR: 论文提出了将带有循环和动态标签的概率程序静态地转化为图结构的方法，并据此实现了多种静态优化，大幅提升了推断效率，理论与实验证明均优于部分现有方案。


<details>
  <summary>Details</summary>
Motivation: 虽然贝叶斯网络可以被实现为概率程序，但概率程序是否可以完整映射为图形结构尚不明确。很多现代概率编程语言支持如while循环和带标签的采样语句，这使得其结构更复杂，理解和优化变得困难。该论文旨在解决如何将具有这些特性的概率程序图形化表示的问题。

Method: 扩展概率程序的操作语义以支持用户标记的采样语句和while循环，通过将程序转换为控制流图，进行静态分析以近似推断程序中随机变量的依赖结构。同时，提出一种基于该结构的程序切片技术，静态启用变分推断、Metropolis Hastings和顺序Monte Carlo的优化。

Result: 提出的方法获得了一种新型的概率程序图形表示法，对于没有循环和常量标签的程序可还原为贝叶斯网络，对于包含循环或动态标签的程序则提供了创新的图形表示。所提切片和优化技术被证明理论上正确，并在实证上优于或达到现有技术。

Conclusion: 论文证明了带有复杂结构的概率程序可以通过静态分析获得近似的图形表示，这一方法不仅理论上严谨，还能带来切实的采样与推断效率提升，对概率编程领域具有实际意义。

Abstract: It is commonly known that any Bayesian network can be implemented as a
probabilistic program, but the reverse direction is not so clear. In this work,
we address the open question to what extent a probabilistic program with
user-labelled sample statements and while loops - features found in languages
like Gen, Turing, and Pyro - can be represented graphically. To this end, we
extend existing operational semantics to support these language features. By
translating a program to its control-flow graph, we define a sound static
analysis that approximates the dependency structure of the random variables in
the program. As a result, we obtain a static factorisation of the implicitly
defined program density, which is equivalent to the known Bayesian network
factorisation for programs without loops and constant labels, but constitutes a
novel graphical representation for programs that define an unbounded number of
random variables via loops or dynamic labels. We further develop a sound
program slicing technique to leverage this structure to statically enable three
well-known optimisations for the considered program class: we reduce the
variance of gradient estimates in variational inference and we speed up both
single-site Metropolis Hastings and sequential Monte Carlo. These optimisations
are proven correct and empirically shown to match or outperform existing
techniques.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Evaluating LLMs on microservice-based applications: how complex is your specification?](https://arxiv.org/abs/2508.20119)
*Daniel M. Yellin*

Main category: cs.SE

TL;DR: 本文评估LLMs在微服务应用代码生成上的进展，提出难度评分方法和自动测试框架。发现LLMs在中等难度规范表现好，高难度规范表现差，主要受复杂逻辑及集成挑战限制。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在解决实际编程问题，特别是微服务应用代码自动生成方面的能力及瓶颈。

Method: 定义微服务应用规范标准模板，提出规范难度评分指标，搭建自动化测试框架对LLM生成的代码进行单元测试和错误分析。

Result: 实验显示LLMs在中等难度规范上表现不错，但在高难度规范（复杂逻辑、服务、数据库、认证等）上表现很差，并分析了主要错误类型和挑战。

Conclusion: 强大的LLMs（如GPT-3o-mini）在中等难度的微服务应用规范代码生成上表现良好，但在高难度规范上表现较差。主要原因包括业务逻辑复杂、外部服务集成、数据库操作和非功能性能力（如认证）等带来的挑战。

Abstract: In this paper we evaluate how far LLMs have advanced in generating code for
real-world problems. Specifically, we explore code synthesis for
microservice-based applications, a widely used architecture pattern. We define
a standard template for specifying these applications, and we propose a metric
for judging the difficulty level of a specification. The higher the score, the
more difficult it is to generate code for the specification. We develop a
framework to automate the process of testing LLM-synthesized code for a
microservice using unit tests. Our experimental results show that strong LLMs
(like GPT-3o-mini) do fairly well on medium difficulty specifications but do
very poorly on those of higher difficulty levels. This is due to more intricate
business logic, a greater use of external services, database integration and
inclusion of non-functional capabilities such as authentication. We analyzed
the errors in LLM-synthesized code and report on the key challenges LLMs face
in generating code for these specifications thereby suggesting future research
directions to improve code synthesis for real-world problems.

</details>


### [4] [Towards Better Correctness and Efficiency in Code Generation](https://arxiv.org/abs/2508.20124)
*Yunlong Feng,Yang Xu,Xiao Xu,Binyuan Hui,Junyang Lin*

Main category: cs.SE

TL;DR: 提出了一种效率导向的两阶段强化学习调优框架，大幅提升代码生成模型的正确性和运行效率，实验在7B模型上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前大模型代码生成存在效率低下的问题，影响在对性能有高需求场景中的落地应用。本研究旨在提升生成代码的运行效率。

Method: 提出了以效率为导向的强化学习框架，通过创新型性能奖励信号来指导模型优化。方法包括：动态探索以克服静态数据限制、错误不敏感的强化学习方法配合高对比效率信号提升优化效果，以及在高正确性基线下进行在线探索，从而兼顾准确性与效率。最终提出了两阶段调优方法。

Result: 在7B模型上的实验显示，代码正确性提升了10.18%，运行效率提升了7.75%。整体性能甚至达到比肩更大的模型。

Conclusion: 效率导向的强化学习框架及两阶段调优方法有效提升了代码生成模型的正确性和运行效率，解决了性能瓶颈，推动了代码大模型在实际场景中的应用。

Abstract: While code large language models have demonstrated remarkable progress in
code generation, the generated code often exhibits poor runtime efficiency,
limiting its practical application in performance-sensitive scenarios. To
address this limitation, we propose an efficiency-oriented reinforcement
learning framework guided by a novel performance reward. Based on this
framework, we take a deeper dive into the code efficiency problem, identifying
then proposing methods to overcome key bottlenecks: (1) Dynamic exploration
overcomes the static data constraints of offline fine-tuning, enabling the
discovery of more efficient code implementations. (2) The error-insensitive
reinforcement learning method and high-contrast efficiency signals are crucial
for mitigating systematic errors and achieving effective optimization. (3)
Online exploration is most effective when starting from a high-correctness
baseline, as this allows for efficiency improvements without sacrificing
accuracy. With these discoveries, we finally propose a two-stage tuning method,
which achieves high and balanced performance across correctness and efficiency.
The results of experiments show the effectiveness of the method, which improves
code correctness by 10.18\% and runtime efficiency by 7.75\% on a 7B model,
achieving performance comparable to much larger model.

</details>


### [5] [Boosting Skeleton-Driven SMT Solver Fuzzing by Leveraging LLM to Produce Formula Generators](https://arxiv.org/abs/2508.20340)
*Maolin Sun,Yibiao Yang,Yuming Zhou*

Main category: cs.SE

TL;DR: 作者提出了Chimera，利用大语言模型从文档提取文法并生成布尔项，极大提升SMT求解器测试fuzzing的有效性和效率，在Z3和cvc5中发现了大量新bug。


<details>
  <summary>Details</summary>
Motivation: 由于SMT求解器在系统和编程语言研究中的核心地位，其正确性和可靠性至关重要。然而，现有测试方法无法很好地适应快速发展的新特性，同时基于大语言模型（LLM）的方法又存在公式语法错误率高和运行开销大的问题。

Method: 提出了一种名为Chimera的新型LLM辅助fuzzing框架。Chimera利用LLM从文档自动抽取SMT理论的上下文无关文法（CFG）和特定扩展，并基于CFG合成可复用的布尔项生成器。在fuzzing时，通过填充结构骨架公式，保证语法正确并提升语义多样性。整个过程仅需一次LLM交互，显著降低运行时成本。

Result: Chimera在两个主流SMT求解器（Z3和cvc5）上的测试中，共发现43个已确认的bug，其中40个已被开发者修复。实验验证了工具的有效性。

Conclusion: Chimera成功解决了LLM生成SMT测试公式时的高语法错误率和高运行成本问题，用于SMT求解器的测试，提升了bug发现能力和效率。其方法有效并具有实际价值。

Abstract: Satisfiability Modulo Theory (SMT) solvers are foundational to modern systems
and programming languages research, providing the foundation for tasks like
symbolic execution and automated verification. Because these solvers sit on the
critical path, their correctness is essential, and high-quality test formulas
are key to uncovering bugs. However, while prior testing techniques performed
well on earlier solver versions, they struggle to keep pace with rapidly
evolving features. Recent approaches based on Large Language Models (LLMs) show
promise in exploring advanced solver capabilities, but two obstacles remain:
nearly half of the generated formulas are syntactically invalid, and iterative
interactions with the LLMs introduce substantial computational overhead. In
this study, we present Chimera, a novel LLM-assisted fuzzing framework that
addresses both issues by shifting from direct formula generation to the
synthesis of reusable term (i.e., logical expression) generators. Particularly,
Chimera uses LLMs to (1) automatically extract context-free grammars (CFGs) for
SMT theories, including solver-specific extensions, from documentation, and (2)
synthesize composable Boolean term generators that adhere to these grammars.
During fuzzing, Chimera populates structural skeletons derived from existing
formulas with the terms iteratively produced by the LLM-synthesized generators.
This design ensures syntactic validity while promoting semantic diversity.
Notably, Chimera requires only one-time LLM interaction investment,
dramatically reducing runtime cost. We evaluated Chimera on two leading SMT
solvers: Z3 and cvc5. Our experiments show that Chimera has identified 43
confirmed bugs, 40 of which have already been fixed by developers.

</details>


### [6] [Adaptive Root Cause Localization for Microservice Systems with Multi-Agent Recursion-of-Thought](https://arxiv.org/abs/2508.20370)
*Lingzhe Zhang,Tong Jia,Kangjin Wang,Weijie Hong,Chiming Duan,Minghua He,Ying Li*

Main category: cs.SE

TL;DR: 本文面向微服务系统根因定位需求，提出融合递归思维与多智能体框架的RCLAgent方法，能在单请求数据下准确高效定位故障成因，实验结果优于现有主流方案。


<details>
  <summary>Details</summary>
Motivation: 现有根因定位方法要么对固定数据格式依赖过重，难以适应系统变化；要么缺乏推理可解释性，无法有效辅助SRE工程师。本文结合SRE实际分析过程特点，提出更具适应性和解释性的定位方案。

Method: 提出基于递归思维（recursion-of-thought）的多智能体（multi-agent）方法RCLAgent来根因定位，通过整合多源数据和工具分析来提升定位效果。

Result: RCLAgent能在仅凭单次请求的情况下，本地化故障根因并超越依赖多请求聚合的最新方法，显示出更好的效率与准确度。

Conclusion: RCLAgent能提升复杂微服务系统中的根因定位效率和准确性，单请求下性能优于现有方法。

Abstract: As contemporary microservice systems become increasingly popular and
complex-often comprising hundreds or even thousands of fine-grained,
interdependent subsystems-they are facing more frequent failures. Ensuring
system reliability thus demands accurate root cause localization. While traces
and metrics have proven to be effective data sources for this task, existing
methods either heavily rely on pre-defined schemas, which struggle to adapt to
evolving operational contexts, or lack interpretability in their reasoning
process, thereby leaving Site Reliability Engineers (SREs) confused. In this
paper, we conduct a comprehensive study on how SREs localize the root cause of
failures, drawing insights from multiple professional SREs across different
organizations. Our investigation reveals that human root cause analysis
exhibits three key characteristics: recursiveness, multi-dimensional expansion,
and cross-modal reasoning. Motivated by these findings, we introduce RCLAgent,
an adaptive root cause localization method for microservice systems that
leverages a multi-agent recursion-of-thought framework. RCLAgent employs a
novel recursion-of-thought strategy to guide the LLM's reasoning process,
effectively integrating data from multiple agents and tool-assisted analysis to
accurately pinpoint the root cause. Experimental evaluations on various public
datasets demonstrate that RCLAgent achieves superior performance by localizing
the root cause using only a single request-outperforming state-of-the-art
methods that depend on aggregating multiple requests. These results underscore
the effectiveness of RCLAgent in enhancing the efficiency and precision of root
cause localization in complex microservice environments.

</details>


### [7] [AI and Agile Software Development: A Research Roadmap from the XP2025 Workshop](https://arxiv.org/abs/2508.20563)
*Zheying Zhang,Tomas Herda,Victoria Pichler,Pekka Abrahamsson,Geir K. Hanssen,Joshua Kerievsky,Alex Polyakov,Mohit Chandna,Marius Irgens,Kai-Kristian Kemell,Ayman Asad Khan,Crystal Kwok,Evan Leybourn,Munish Malik,Dorota Mleczko,Morteza Moalagh,Christopher Morales,Yuliia Pieskova,Daniel Planötscher,Mika Saari,Anastasiia Tkalich,Karl Josef Gstettner,Xiaofeng Wang*

Main category: cs.SE

TL;DR: 通过跨领域研讨会收集并分析了GenAI与敏捷开发整合的主要挑战，形成短期可行与长期前瞻结合的研究路线图，助力人本、负责任地推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨生成式人工智能（GenAI）与敏捷软件开发结合过程中面临的实际挑战与新机遇。

Method: 通过XP2025全日研讨会的结构化、互动式分组讨论，收集并分析了30多位跨学科学者和业界人士对GenAI与敏捷开发整合的痛点和前景看法。

Result: 识别出工具碎片化、治理、数据质量以及AI素养和提示工程等关键技能缺口。进一步分析了这些问题的根本原因和相关影响。最终，协作制定了涵盖短期可执行建议与长期研究目标的多主题研究路线图。

Conclusion: 该研讨会共识形成一份实用且前瞻的研究议程，为未来GenAI在人本导向的敏捷实践整合提供指导。

Abstract: This paper synthesizes the key findings from a full-day XP2025 workshop on
"AI and Agile: From Frustration to Success", held in Brugg-Windisch,
Switzerland. The workshop brought together over 30 interdisciplinary academic
researchers and industry practitioners to tackle the concrete challenges and
emerging opportunities at the intersection of Generative Artificial
Intelligence (GenAI) and agile software development. Through structured,
interactive breakout sessions, participants identified shared pain points like
tool fragmentation, governance, data quality, and critical skills gaps in AI
literacy and prompt engineering. These issues were further analyzed, revealing
underlying causes and cross-cutting concerns. The workshop concluded by
collaboratively co-creating a multi-thematic research roadmap, articulating
both short-term, implementable actions and visionary, long-term research
directions. This cohesive agenda aims to guide future investigation and drive
the responsible, human-centered integration of GenAI into agile practices.

</details>


### [8] [Rethinking Testing for LLM Applications: Characteristics, Challenges, and a Lightweight Interaction Protocol](https://arxiv.org/abs/2508.20737)
*Wei Ma,Yixiao Yang,Qiang Hu,Shi Ying,Zhi Jin,Bo Du,Zhenchang Xing,Tianlin Li,Junjie Shi,Yang Liu,Linxiao Jiang*

Main category: cs.SE

TL;DR: 本文系统分析LLM应用三层结构及其测试难点，提出结合多种策略与AICL协议的闭环质保框架，实现LLM应用测试的标准化、集成化与可信化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）应用已从简单文本生成转向更复杂的软件系统，如检索增强、工具调用及多轮交互，但其非确定性、动态性与上下文依赖性对质量保证带来重大挑战，本研究旨在解决这些新挑战。

Method: 将LLM应用分解为三层结构：系统壳层（System Shell Layer）、提示编排层（Prompt Orchestration Layer）、LLM推理核心（LLM Inference Core）。分别评估了传统软件测试手段在每一层的适用性，并对现有AI测试与安全性分析方法进行对比，识别差异和挑战，提出四类协同策略与一套闭环、可信的质量保障框架，并设计支持标准化测试的协议AICL。

Result: 识别出软件测试单位、评估指标和生命周期管理等方面的结构性断层，归纳出四项根本不同与六项核心挑战。提出四类协同策略以及集预部署验证和运行时监控于一体的质量保障框架，并为LLM应用测试标准化和工具化提供了具体指导和AICL协议。AICL协议具有面向测试的特性、易集成于现有代理框架。

Conclusion: LLM应用的质保需在架构分层基础上结合传统与创新测试方法，通过AICL等协议实现标准化与高效协作，提升LLM系统的测试有效性与可信度。

Abstract: Applications of Large Language Models~(LLMs) have evolved from simple text
generators into complex software systems that integrate retrieval augmentation,
tool invocation, and multi-turn interactions. Their inherent non-determinism,
dynamism, and context dependence pose fundamental challenges for quality
assurance. This paper decomposes LLM applications into a three-layer
architecture: \textbf{\textit{System Shell Layer}}, \textbf{\textit{Prompt
Orchestration Layer}}, and \textbf{\textit{LLM Inference Core}}. We then assess
the applicability of traditional software testing methods in each layer:
directly applicable at the shell layer, requiring semantic reinterpretation at
the orchestration layer, and necessitating paradigm shifts at the inference
core. A comparative analysis of Testing AI methods from the software
engineering community and safety analysis techniques from the AI community
reveals structural disconnects in testing unit abstraction, evaluation metrics,
and lifecycle management. We identify four fundamental differences that
underlie 6 core challenges. To address these, we propose four types of
collaborative strategies (\emph{Retain}, \emph{Translate}, \emph{Integrate},
and \emph{Runtime}) and explore a closed-loop, trustworthy quality assurance
framework that combines pre-deployment validation with runtime monitoring.
Based on these strategies, we offer practical guidance and a protocol proposal
to support the standardization and tooling of LLM application testing. We
propose a protocol \textbf{\textit{Agent Interaction Communication Language}}
(AICL) that is used to communicate between AI agents. AICL has the
test-oriented features and is easily integrated in the current agent framework.

</details>


### [9] [From Law to Gherkin: A Human-Centred Quasi-Experiment on the Quality of LLM-Generated Behavioural Specifications from Food-Safety Regulations](https://arxiv.org/abs/2508.20744)
*Shabnam Hassani,Mehrdad Sabetzadeh,Daniel Amyot*

Main category: cs.SE

TL;DR: LLMs可高效自动将法律文本转为软件开发友好的Gherkin规范，评估结果显示其质量优良，可显著降低人工负担。


<details>
  <summary>Details</summary>
Motivation: 法律法规越来越多地影响软件设计与质量保证，但法律文本通常为技术中立语言，工程师在据此开发符合性工件时面临巨大挑战。现有人工生成流程劳动密集、易出错且需领域知识。生成式AI，特别是大型语言模型（LLMs），有可能自动化这一流程。

Method: 首次系统性的人体实验，通过准实验设计评估LLM从法律文本推导行为规范的能力。由10名参与者对Claude和Llama从食品安全法规生成的共60条Gherkin规范进行评估，涉及相关性、清晰度、完整性、单一性和节省时间五项。每条规范由两人独立评分，共120份评估。

Result: 相关性评价高分占95%（75%最高，20%次高），清晰度90%最高，完整性94%高分，单一性94%高分，节省时间92%高分，无最低分。不同参与者和模型间评价无显著差异。Llama在清晰度、完整性和节省时间略优；Claude在单一性略强。反馈指出存在幻觉和遗漏但肯定其实用价值。

Conclusion: LLMs能够根据法律文本自动生成高质量Gherkin规范，显著减轻人工劳动，为软件实现、质量保证与测试提供结构化工件。

Abstract: Context: Laws and regulations increasingly affect software design and quality
assurance, but legal texts are written in technology-neutral language. This
creates challenges for engineers who must develop compliance artifacts such as
requirements and acceptance criteria. Manual creation is labor-intensive,
error-prone, and requires domain expertise. Advances in Generative AI (GenAI),
especially Large Language Models (LLMs), offer a way to automate deriving such
artifacts.
  Objective: We present the first systematic human-subject study of LLMs'
ability to derive behavioral specifications from legal texts using a
quasi-experimental design. These specifications translate legal requirements
into a developer-friendly form.
  Methods: Ten participants evaluated specifications generated from food-safety
regulations by Claude and Llama. Using Gherkin, a structured BDD language, 60
specifications were produced. Each participant assessed 12 across five
criteria: Relevance, Clarity, Completeness, Singularity, and Time Savings. Each
specification was reviewed by two participants, yielding 120 assessments.
  Results: For Relevance, 75% of ratings were highest and 20% second-highest.
Clarity reached 90% highest. Completeness: 75% highest, 19% second.
Singularity: 82% highest, 12% second. Time Savings: 68% highest, 24% second. No
lowest ratings occurred. Mann-Whitney U tests showed no significant differences
across participants or models. Llama slightly outperformed Claude in Clarity,
Completeness, and Time Savings, while Claude was stronger in Singularity.
Feedback noted hallucinations and omissions but confirmed the utility of the
specifications.
  Conclusion: LLMs can generate high-quality Gherkin specifications from legal
texts, reducing manual effort and providing structured artifacts useful for
implementation, assurance, and test generation.

</details>


### [10] [Towards an Architectural Perspective for Sustainability: Bundle the Needs from Industry](https://arxiv.org/abs/2508.20774)
*Markus Funke,Patricia Lago*

Main category: cs.SE

TL;DR: 本文提出并验证了一种用于软件架构设计中可持续性问题的理论视角，为架构师系统地处理可持续性质量属性提供了实践指导与理论支持。


<details>
  <summary>Details</summary>
Motivation: 可持续性正成为软件密集系统中的关键质量属性，但当前架构师缺乏系统化的指导来在设计阶段有效处理该问题。由于可持续性跨不同架构视角、行业领域都很重要，因此需要统一的方法进行指导。

Method: 论文采用系统性文献调研（snowballing法）与专家焦点小组讨论，收集并分析与可持续性相关的架构视角要素，提出一种“可持续性视角”理论框架。

Result: 研究确认了构建可持续性视角所需的关键要素，并验证了这些要素在实际中的相关性，指出了架构师在应对可持续性需求时应关注的问题及应避免的误区。

Conclusion: “可持续性视角”框架为软件架构师提供了一套系统化的工具和流程，有助于他们在软件设计阶段更好地融入和实现可持续性需求，满足工业领域的实际需求。

Abstract: Sustainability is increasingly recognized as an emerging quality property in
software-intensive systems, yet architects lack structured guidance to address
it effectively throughout the software design phase. Architectural
perspectives-an architectural knowledge artifact composed of concerns,
activities, tactics, pitfalls, and checklists-offer a promising approach to
tackle such emerging quality properties across architectural views and are also
independent of architecture frameworks and industry contexts. In this paper, we
present a sustainability perspective vision, i.e., a revised notion of
architectural perspective meant to be filled with its own elements to target
sustainability concerns. We formulate our sustainability perspective vision
through evidence from applying snowballing to seminal literature and from
conducting a focus group with experts in the field. Our findings confirm the
relevance of the different perspective elements in practice and highlight
implications for shaping a sustainability perspective that meets industrial
needs.

</details>


### [11] [Automated Test Oracles for Flaky Cyber-Physical System Simulators: Approach and Evaluation](https://arxiv.org/abs/2508.20902)
*Baharin A. Jodat,Khouloud Gaaloul,Mehrdad Sabetzadeh,Shiva Nejati*

Main category: cs.SE

TL;DR: 提出了用断言和遗传编程（Ochiai为适应度）自动生成CPS测试oracle，无需实际执行即可判断结果，优于其他SBFL指标和决策树/rules方法，且对仿真器不稳定表现出显著鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 网络-物理系统（CPS）的仿真测试成本高且测试结果容易因仿真器不稳定而产生不一致，需要多次重复测试以获得可靠结果，因此需要无需系统实际运行即可工作的自动化测试oracle来降低测试成本。还需要oracle具备可解释性以支持人工理解，并能抵御仿真器的不稳定性。

Method: 提出了基于断言的测试oracle，其形式为定义在被测系统输入上的逻辑和算术谓词集。通过给定的输入，这些oracle无需运行系统即可判断测试通过、失败或无法确定。该文提出了两种自动生成oracle的方法：一种使用遗传编程（GP）结合传统光谱基故障定位（SBFL）排名公式作为适应度函数（包括Ochiai、Tarantula、Naish）；另一种采用决策树（DT）和决策规则（DR）。

Result: 通过航空航天、网络及自动驾驶领域的案例评估，结果显示GP结合Ochiai生成的oracle在准确性上明显优于GP结合Tarantula、Naish及DT、DR方法。该优势在考虑仿真环境不稳定性时依然保持，并且在四个不同的波动性系统上，GP+Ochiai生成的oracle的准确性平均波动仅为4%。

Conclusion: 基于断言、采用遗传编程加Ochiai评价生成的测试oracle，能在CPS测试中既具高准确性又能抵御仿真不稳定，优于其他流行技术，并增强了测试结果的可靠性和可解释性。

Abstract: Simulation-based testing of cyber-physical systems (CPS) is costly due to the
time-consuming execution of CPS simulators. In addition, CPS simulators may be
flaky, leading to inconsistent test outcomes and requiring repeated test
re-execution for reliable test verdicts. Automated test oracles that do not
require system execution are therefore crucial for reducing testing costs.
Ideally, such test oracles should be interpretable to facilitate human
understanding of test verdicts, and they must be robust against the potential
flakiness of CPS simulators. In this article, we propose assertion-based test
oracles for CPS as sets of logical and arithmetic predicates defined over the
inputs of the system under test. Given a test input, our assertion-based test
oracle determines, without requiring test execution, whether the test passes,
fails, or if the oracle is inconclusive in predicting a verdict. We describe
two methods for generating assertion-based test oracles: one using genetic
programming~(GP) that employs well-known spectrum-based fault localization
(SBFL) ranking formulas, namely Ochiai, Tarantula, and Naish, as fitness
functions; and the other using decision trees (DT) and decision rules (DR). We
evaluate our assertion-based test oracles through case studies in the domains
of aerospace, networking and autonomous driving. We show that test oracles
generated using GP with Ochiai are significantly more accurate than those
obtained using GP with Tarantula and Naish or using DT or DR. Moreover, this
accuracy advantage remains even when accounting for the flakiness of the system
under test. We further show that the assertion-based test oracles generated by
GP with Ochiai are robust against flakiness with only 4% average variation in
their accuracy results across four different network and autonomous driving
systems with flaky behaviours.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [Exploiting Instantiations from Paramodulation Proofs in Isabelle/HOL](https://arxiv.org/abs/2508.20738)
*Lukas Bartl,Jasmin Blanchette,Tobias Nipkow*

Main category: cs.LO

TL;DR: 作者开发了一个新工具，用于分析Isabelle/HOL中Metis证明，从中提取变量实例化信息。这不仅提高了Sledgehammer自动证明工具的成功率和速度，还帮助用户更好地理解为什么目标可以从现有引理推出。


<details>
  <summary>Details</summary>
Motivation: Sledgehammer集成自动证明工具但有时成功率和速度有限，且用户难以理解证明过程，因此需要手段提升这些方面。

Method: 提出了一种分析Metis证明以推导变量实例化的新工具，辅助Sledgehammer生成更快、更成功的自动证明。

Result: 分析工具能够自动推导出变量实例化，显著提升Sledgehammer使用Metis时的证明效率和效果。

Conclusion: 通过分析Metis证明得到的变量实例化，可以提升Sledgehammer的成功率与证明速度，并增强用户对证明过程的理解。

Abstract: Metis is an ordered paramodulation prover built into the Isabelle/HOL proof
assistant. It attempts to close the current goal using a given list of lemmas.
Typically these lemmas are found by Sledgehammer, a tool that integrates
external automatic provers. We present a new tool that analyzes successful
Metis proofs to derive variable instantiations. These increase Sledgehammer's
success rate, improve the speed of Sledgehammer-generated proofs, and help
users understand why a goal follows from the lemmas.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 本文系统梳理了多语种和非英语场景下预训练模型社会偏见测评与消除的最新进展，总结现有研究在语言覆盖、文化适应性和评测方法上的不足，提出未来研究需提高包容性及跨文化适用性。


<details>
  <summary>Details</summary>
Motivation: 多语种模型在全球范围应用广泛，但关于其社会偏见的评估与缓解研究尚不充分，尤其是在非英语和多语种场景中。

Method: 系统性综述当前延伸于多语种与非英语语境的偏见评估和缓解研究，分析其语言多样性、文化意识，并评估所用的评价标准和缓解技术。

Result: 调研发现方法偏重少数主流语言（如英语），缺乏在多语言环境下的偏见缓解实验，总结了目前适应不同语言和文化的偏见测评存在的共性问题与解决办法，并指出未来研究方向。

Conclusion: 当前多语种预训练模型在社会偏见方面与单一英文模型表现相似。现有跨语言、跨文化的偏见评估与缓解方法存在局限，方法学设计偏重特定语言，跨文化适应性不足。未来研究应加强包容性和跨文化适应，以更好对齐多语言偏见消除与NLP前沿发展。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [14] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本文提出通过微调和结构化提示，提升中型语言模型自动生成K-12形态学选择题的能力，并探索多元评测方法提升质量，为自动化试题开发提供实用路径。


<details>
  <summary>Details</summary>
Motivation: 手工开发语言测试题不仅成本高，而且评测结果容易出现不一致。为此，作者希望通过自动生成技术降低开发成本、提高一致性，特别针对形态学测试选择题的生成。

Method: 研究采用两步策略：1）比较微调后的中等尺寸模型Gemma（2B参数）和未微调的大模型GPT-3.5（175B参数）；2）评测并比较七种结构化提示策略，包括零样本、少样本、思维链、角色扮演、顺序提示及其组合。生成题目通过自动指标与专家五维评价，另外使用基于专家样本训练的GPT-4.1大模型模拟大规模人工评分。

Result: 结构化提示（尤其是思维链和顺序组合策略）显著提升了Gemma的表现。总体而言，Gemma生成的题目在结构对齐和教学适宜性上优于GPT-3.5的零样本输出，提示设计对中型模型的性能起关键作用。

Conclusion: 结构化提示与高效微调方法可提升中型模型在有限数据下的自动题目生成效果。提出的工作流结合自动评价、专家判断和大模型模拟评分，为K-12语言测试题开发和验证提供了实用且可扩展的方案。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [15] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 论文提出并实现了一种开源方案，使SystemC TLM模型能以FMI 3.0 FMU形式接入异构协同仿真环境，很好地解决了跨领域协作中的集成、同步与数据交换问题，并经案例验证具备可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着网络物理系统（尤其是汽车应用）的复杂性增加，跨领域协同仿真和高效建模的需求不断增长。然而，SystemC TLM虽有助于软硬件协同设计，却难以与其他工程领域模型互操作，造成系统集成的难题。

Method: 提出一种完全开源的方法，通过将SystemC TLM模型封装为FMI 3.0协同仿真功能单元（FMUs），使其能融入FMI为基础的协同仿真流程。同时开发了轻量级开源工具链，解决了时间同步和数据交换等关键技术问题。

Result: 验证了该方法在代表性案例中的可行性与有效性，实现了SystemC TLM模型在异构仿真环境中的无缝、标准集成。

Conclusion: 通过该开源方法与工具链，将SystemC TLM模型成功集成进FMI协同仿真流程，推动了跨领域仿真的标准化与高效性。

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [16] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: 通过DGPO方法，小型语言模型在资源受限环境下也能实现高效的检索增强生成行为，有时性能甚至超过大模型。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型由于推理能力弱，使用强化学习训练代理型RAG（检索增强生成）行为时，奖励稀疏且训练不稳定。需要新的方法提升其表现。

Method: 提出了DGPO（蒸馏引导的策略优化），通过从教师模型演示进行冷启动初始化，并在策略优化过程中持续接受教师模型指导，缓解了训练早期奖励稀疏和优化不稳定的问题。

Result: DGPO极大提升了小型模型的代理型搜索能力。实验表明，使用DGPO后，小模型在某些任务上甚至超过了大模型教师的表现。

Conclusion: DGPO方法使得低计算资源环境下的小型模型也能实现强代理型RAG行为，有望推广至实际应用场景。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [17] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: 本文提出了GUARD方法，将高层次AI伦理指导原则转化为具体的违规测试问题，并结合越狱情景诊断，实证验证其可高效检测多种大型语言模型的伦理合规性及安全性。


<details>
  <summary>Details</summary>
Motivation: 许多政府出台了AI伦理指导原则以规范信任化AI发展，但这些指导原则具体如何转为可操作、可验证的问题并应用于模型测试仍缺乏解决方案。该研究旨在填补指导原则与实际LLM测试之间的差距。

Method: 提出并实现了GUARD方法，通过自动化生成遵循政府伦理准则的违规问题，分别用于直接违规检测和通过越狱情景诱导模型响应违规，最后形成合规报告。该方法在七种LLM和多模态视觉语言模型上进行了实证验证。

Result: GUARD在Vicuna-13B、LongChat-7B、Llama2-7B、Llama-3-8B、GPT-3.5、GPT-4、GPT-4o、Claude-3.7等多个主流LLM上进行了合规及越狱测试，成功生成合规性报告，并能迁移用于多模态模型，显示出良好的实用性和可靠性。

Conclusion: GUARD方法能够高效将政府伦理指导原则转化为可执行的测试问题，有效检测和报告大型语言模型（LLM）的合规性，包括常规和越狱测试，促进安全可靠的LLM应用。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [18] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR通过概要提取、图推理和蒙特卡洛树搜索，显著提升了大语言模型处理长文本和复杂推理任务的能力，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在理解长文本、处理复杂任务时存在记忆局限、透明度低和容易生成幻觉等问题。解决这些问题对提升模型应用性能和信任度至关重要。

Method: 提出JERR框架，通过三个核心模块：文本分块提取概要、构建有向无环图消除冗余，并结合蒙特卡洛树搜索进行关系推理，提升LLM长文本任务表现。

Result: JERR在实验中在ROUGE和F1等指标上稳定优于所有基线方法，并在LLM-Rater评估中获得最高分。

Conclusion: JERR框架显著提升了大语言模型在长文本和复杂推理任务中的可靠性、透明性和表现力。

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [19] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 将NP-hard图问题作为合成语料，对大模型进行后训练，提升其长链式推理泛化与效率，低成本突破复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前长链式推理训练高度依赖昂贵且人工标注的数据集（如数学与代码），缺乏可扩展替代方案。NP-hard图问题天然具备深度推理与探索特性，有望作为全新合成训练语料。

Method: 提出两阶段后训练框架：（1）基于拒绝采样的NP-hard图实例进行长链式推理监督微调；（2）设计细粒度奖励的强化学习以增强推理效率。

Result: Graph-R1-7B模型展现出在数学、编程、STEM及逻辑领域的广泛泛化能力，在NP-hard图问题推理准确性与效率上均超越QwQ-32B。

Conclusion: NP-hard图问题可以作为高效且可扩展的合成训练语料，显著提升大语言模型的长链式推理能力。

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [20] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出了首个面向LLM的上下文感知人格评估方法（CAPE），系统揭示了对话历史如何影响大模型的人格一致性和变化，为今后LLM评测和优化提供了新工具及数据。


<details>
  <summary>Details</summary>
Motivation: 现有研究在用心理测量测试评估大语言模型（LLM）时，普遍采用无上下文、问题独立作答的方法，忽视了现实应用中对话历史对测试结果的影响。该研究为弥补实践与评测方法之间的脱节，提出新的、考虑上下文影响的评估框架。

Method: 提出了首个面向LLM的上下文感知人格评估（CAPE）框架，通过引入先前对话历史，模拟真实应用场景，并设计了能够量化LLM回答一致性的新的度量指标。大量实验在7种主流LLM上进行，对一致性和人格变化进行系统分析。

Result: 实验发现，对话历史提升了模型一致性，但也导致人格特质发生偏移。GPT-3.5-Turbo与GPT-4-Turbo出现极端偏离，而Gemini-1.5-Flash和Llama-8B对对话顺序较为敏感。GPT系列模型的回答既受其固有人格影响，也与上下文有关；而Gemini和Llama则更依赖先前对话。对角色扮演代理(RPA)实验发现，基于情境切换的人格变化能增强一致性并更符合人类判断。

Conclusion: 文中提出的CAPE框架更贴近真实应用场景，能够更细致地评估和量化LLM在现实语境下的人格一致性与变化，对模型开发和评测具有重要意义。研究还公开了相关代码与数据集。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [21] [Unclustered BWTs of any Length over Non-Binary Alphabets](https://arxiv.org/abs/2508.20879)
*Gabriele Fici,Estéban Gabory,Giuseppe Romana,Marinella Sciortino*

Main category: cs.DM

TL;DR: 对于至少3个字母的字符串，任何长度都存在BWT极大分散（每个符号单独成run）的项链，证明了其数量下界；二元情况仍是开放问题。


<details>
  <summary>Details</summary>
Motivation: 研究BWT在非二元字母表上的最坏情形，理解BWT聚类性质，为字符串处理和压缩等应用中的理论极限提供参考。

Method: 通过组合数学和字符串理论方法，构造满足条件的项链，并分析其BWT结构，同时利用理论工具推导数量下界。

Result: 证明了在任意长度和字母表大小至少为3的情况下，完全无聚类的BWT项链必然存在，并且给出了其数量的下界。二元情况下相关问题仍未解决。

Conclusion: 对于每个大于0的整数n和每个大小至少为3的字母表，都存在长度为n的项链，使得其BWT完全无聚类，即包含恰好n个run，且没有两个连续的相同符号。这些词实现了BWT聚类的最坏情况，因为run数量最大。还证明了其数量的下界。与二元情况不同，在二元字母表下，是否存在无限多个完全无聚类BWT仍未解决，与Artin猜想有关。

Abstract: We prove that for every integer $n > 0$ and for every alphabet $\Sigma_k$ of
size $k \geq 3$, there exists a necklace of length $n$ whose Burrows-Wheeler
Transform (BWT) is completely unclustered, i.e., it consists of exactly $n$
runs with no two consecutive equal symbols. These words represent the
worst-case behavior of the BWT for clustering, since the number of BWT runs is
maximized. We also establish a lower bound on their number. This contrasts with
the binary case, where the existence of infinitely many completely unclustered
BWTs is still an open problem, related to Artin's conjecture on primitive
roots.

</details>


### [22] [Enhancing Soft Happiness via Evolutionary Algorithms](https://arxiv.org/abs/2508.20934)
*Mohammad Hadi Shekarriza,Dhananjay Thiruvadya,Asef Nazari*

Main category: cs.DM

TL;DR: 本文提出基于进化算法的图软快乐着色优化方法，在社区检测与最大化快乐顶点方面取得了比传统局部优化方法更优秀的结果。


<details>
  <summary>Details</summary>
Motivation: 针对已知NP-困难的软快乐着色问题，现有局部搜索算法效果有限，作者希望通过引入进化算法提升优化效果，并进一步研究其与社区结构检测的关系。

Method: 设计并实现了遗传算法和混合遗传算法用于最大化图中的ρ-快乐顶点数量。实验过程中，对大量随机生成的部分着色图进行了测试，并对比了局部搜索启发式方法与进化算法的性能。

Result: 实验表明，混合遗传算法在最大化ρ-快乐顶点数上性能最佳，而遗传算法在结合LMC或LS作为初始种群优化时也能取得优秀结果。此外，与其他方法相比，这些进化算法能够找到更多完整解和社区结构，优势显著且统计意义明确。

Conclusion: 遗传算法和混合遗传算法（Memetic Algorithms）在基于软快乐着色（soft happy colouring）的图社区检测任务上表现出色。当初始种群经过LMC（Local Maximal Colouring）或LS（Local Search）局部优化时，算法表现尤佳。尤其是混合遗传算法找到的快乐顶点数量最多，并且所有进化算法都能找到更多完整解。

Abstract: For $0\leq \rho\leq 1$, a $\rho$-happy vertex $v$ in a coloured graph shares
colour with at least $\rho\mathrm{deg}(v)$ of its neighbours. Soft happy
colouring of a graph $G$ with $k$ colours extends a partial $k$-colouring to a
complete vertex $k$-colouring such that the number of $\rho$-happy vertices is
maximum among all such colouring extensions. The problem is known to be
NP-hard, and an optimal solution has a direct relation with the community
structure of the graph. In addition, some heuristics and local search
algorithms, such as {\sf Local Maximal Colouring} ({\sf LMC}) and {\sf Local
Search} ({\sf LS}), have already been introduced in the literature. In this
paper, we design Genetic and Memetic Algorithms for soft happy colouring and
test them for a large set of randomly generated partially coloured graphs.
Memetic Algorithms yield a higher number of $\rho$-happy vertices, but Genetic
Algorithms can perform well only when their initial populations are locally
improved by {\sf LMC} or {\sf LS}. Statistically significant results indicate
that both Genetic and Memetic Algorithms achieve high average accuracy in
community detection when their initial populations are enhanced using {\sf
LMC}. Moreover, among the competing methods, the evolutionary algorithms
identified the greatest number of complete solutions.

</details>


### [23] [Measuring Ransomware Lateral Movement Susceptibility via Privilege-Weighted Adjacency Matrix Exponentiation](https://arxiv.org/abs/2508.21005)
*Satyam Tyagi,Ganesh Murugesan*

Main category: cs.DM

TL;DR: 作者提出图论方法分析勒索软件横向移动易感性，量化资产爆炸半径，高危服务（如SSH/RDP）剪枝效果显著，有助于企业安全策略制定。


<details>
  <summary>Details</summary>
Motivation: 当前勒索软件侵害极大依赖于攻击者横向移动和资产扩散能力，对如何量化和降低横向移动风险的有效工具存在需求。

Method: 作者提出了一种图论方法，使用有向多重图建模网络中资产（顶点）和服务连接（边），用枢纽潜力因子（π(s)）描述服务被利用的可能性，通过迭代得出K跳被攻破概率矩阵，进而量化横向移动易感性与爆炸半径。

Result: 高π(s)服务（如SSH/RDP）在横向移动中的作用显著，对这些服务链路剪枝可大幅降低横向移动与资产爆炸半径风险，实验贯穿实际企业网络，验证了方案对分段和安全控制优先级设置的指导作用。

Conclusion: 该研究提供了一套量化企业网络横向移动风险及爆炸半径的统一图论分析框架，工具能用于评估分段效果和优先级，指导企业安全防护措施优化，并与CISA、MITRE和NIST等安全建议高度契合。

Abstract: Ransomware impact hinges on how easily an intruder can move laterally and
spread to the maximum number of assets. We present a graph-theoretic method to
measure lateral-movement susceptibility and estimate blast radius. We build a
directed multigraph where vertices represent assets and edges represent
reachable services (e.g., RDP/SSH) between them. We model lateral movement as a
probabilistic process using a pivot potential factor $\pi(s)$ for each service.
This allows us to iteratively compute a $K$-hop compromise probability matrix
that captures how compromise propagates through the network. Metrics derived
from this model include: (1) Lateral-Movement Susceptibility (LMS$_K$): the
average probability of a successful lateral movement between any two assets
(0-1 scale); and (2) Blast-Radius Estimate (BRE$_K$): the expected percentage
of assets compromised in an average attack scenario. Interactive control (SSH
22, RDP 3389) gets higher $\pi(s)$ than app-only ports (MySQL 3306, MSSQL
1433), which seldom enable pivoting without an RCE. Across anonymized
enterprise snapshots, pruning high-$\pi(s)$ edges yields the largest
LMS$_K$/BRE$_K$ drop, aligning with CISA guidance, MITRE ATT\&CK (TA0008:
Lateral Movement), and NIST SP~800-207. The framework evaluates
(micro)segmentation and helps prioritize controls that reduce lateral movement
susceptibility and shrink blast radius.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [24] [Formal equivalence between global optimization consistency and random search](https://arxiv.org/abs/2508.20671)
*Gaëtan Serré*

Main category: cs.FL

TL;DR: 本文对随机迭代的全局优化算法在Lipschitz连续函数上的一致性进行了严格的形式化证明，指出必须采样全空间才能保证一致；同时提出了该类算法统一的概率表示方法。


<details>
  <summary>Details</summary>
Motivation: 想要对所有随机迭代型全局优化算法在Lipschitz连续函数上一致性进行统一且严格的理论刻画与证明，同时对该类算法给出合适的形式化定义。

Method: 借助L$\exists$$\forall$N 定理证明器和Mathlib库进行形式化证明。构造了基于初始概率测度和Markov核的迭代优化算法定义，然后用Ionescu-Tulcea定理在有限和无限迭代序列上构建概率测度。

Result: 得出严格的理论结论：只有“采样覆盖全空间”才能保证一致性；形式化地定义了此类算法并给出了统一的概率测度表示。

Conclusion: 只有当算法能够覆盖整个搜索空间时，随机迭代全局优化算法在Lipschitz连续函数上才是一致的。

Abstract: We formalize a proof that any stochastic and iterative global optimization
algorithm is consistent over Lipschitz continuous functions if and only if it
samples the whole search space. To achieve this, we use the
L$\exists$$\forall$N theorem prover and the Mathlib library. The major
challenge of this formalization, apart from the technical aspects of the proof
itself, is to converge to a definition of a stochastic and iterative global
optimization algorithm that is both general enough to encompass all algorithms
of this type and specific enough to be used in a formal proof. We define such
an algorithm as a pair of an initial probability measure and a sequence of
Markov kernels that describe the distribution of the next point sampled by the
algorithm given the previous points and their evaluations. We then construct a
probability measure on finite and infinite sequences of iterations of the
algorithm using the Ionescu-Tulcea theorem.

</details>


### [25] [Evaluating Massively Parallel Algorithms for DFA Minimisation, Equivalence Checking and Inclusion Checking](https://arxiv.org/abs/2508.20735)
*Jan Heemstra,Jan Martens,Anton Wijs*

Main category: cs.FL

TL;DR: 本文对GPU上的DFA最小化与判等问题设计并对比了多种并行算法，发现理论最优方法实际表现不佳，提出的新分区细化并行闭包算法在特定任务下效果最佳，同时给出判等算法的GPU高效实现。


<details>
  <summary>Details</summary>
Motivation: DFA最小化和等价性检查是自动机理论与应用（如模型检查、编译器等）的核心操作，提升在高性能平台（如GPU）上的并行算法效率，可显著加快工程应用。

Method: 实现并比较了四种DFA最小化的GPU并行算法，包括理论复杂度最优但实际效果差的新旧方法，提出并测试了增加并行传递闭包步骤的新分区细化算法。对DFA等价判定采用改造过的Hopcroft-Karp算法，为GPU并行适配，并结合GPUexplore工具的模型检查机制。

Result: 理论最优的算法在GPU上资源消耗大，实际慢于复杂度略差的改进并行分区细化法。新提出的融合并行闭包方法在部分基准测试下运行最快。等价性和包含性判定的GPU并行实现结合特定工具获得良好并行效率。

Conclusion: 本文表明理论复杂度最低的DFA最小化算法并不适合GPU计算，而实际表现更佳的是一些并行分区细化算法，并提出一种融合并行部分传递闭包的新方法，其在特定基准下表现优异。对于DFA等价性与包含性判定，提出了Hopcroft-Karp算法的可GPU并行版本，并利用GPUexplore的模型检查机制提升效率。

Abstract: We study parallel algorithms for the minimisation and equivalence checking of
Deterministic Finite Automata (DFAs). Regarding DFA minimisation, we implement
four different massively parallel algorithms on Graphics Processing
Units~(GPUs). Our results confirm the expectations that the algorithm with the
theoretically best time complexity is not practically suitable to run on GPUs
due to the large amount of resources needed. We empirically verify that
parallel partition refinement algorithms from the literature perform better in
practice, even though their time complexity is worse. Furthermore, we introduce
a novel algorithm based on partition refinement with an extra parallel partial
transitive closure step and show that on specific benchmarks it has better
run-time complexity and performs better in practice.
  In addition, we address checking the language equivalence and inclusion of
two DFAs. We consider the Hopcroft-Karp algorithm, and explain how a variant of
it can be parallelised for GPUs. We note that these problems can be encoded for
the GPU-accelerated model checker \GPUexplore, allowing the use its lockless
hash table and fine-grained parallel work distribution mechanism.

</details>
