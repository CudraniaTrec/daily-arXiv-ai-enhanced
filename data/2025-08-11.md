<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 20]
- [cs.DM](#cs.DM) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Hybrid Game Control Envelope Synthesis](https://arxiv.org/abs/2508.05997)
*Aditi Kabra,Jonathan Laurent,Stefan Mitsch,André Platzer*

Main category: cs.PL

TL;DR: 本文提出一种针对嵌入式系统控制问题的普适获胜策略合成方法，采用二人混合游戏和subvalue map表示，利用微分游戏逻辑验证最大可行策略存在性，并用算法实现，在多种控制案例中展示了该方法的有效性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统（如汽车和火车）的控制问题复杂，需要确保安全并提供多样化的控制策略。传统方法往往针对单一策略，而实际运行中需要能够适应多种情况的控制方案。

Method: 该论文提出使用二人混合游戏模型，将控制方案表示为混合游戏的非确定性获胜策略。同时引入了subvalue map（子值映射）作为非确定性策略的组合式表示，并利用微分游戏逻辑（dGL）进行归纳逻辑特征化，确保这些映射能够形成始终获胜的控制包络。

Result: 证明了最大subvalue map的存在性，并建立了满足逻辑特征化的条件。基于此，构建了一个系列用于非确定性策略合成的算法，并在多个具有代表性的控制挑战实例上进行了实现和评估，显示该方法具有广泛的适应性和有效性。

Conclusion: 论文提出了通过归纳逻辑和subvalue maps实现最大化、可验证的非确定性控制包络，解决了复杂嵌入式控制需求，并通过实例验证了方法的实用性。

Abstract: Control problems for embedded systems like cars and trains can be modeled by
two-player hybrid games. Control envelopes, which are families of safe control
solutions, correspond to nondeterministic winning policies of hybrid games,
where each deterministic specialization of the policy is a control solution.
This paper synthesizes nondeterministic winning policies for hybrid games that
are as permissive as possible. It introduces subvalue maps, a compositional
representation of such policies that enables verification and synthesis along
the structure of the game. An inductive logical characterization in
differential game logic (dGL) checks whether a subvalue map induces a sound
control envelope which always induces a winning play. A policy is said to win
if it always achieves the desirable outcome when the player follows it, no
matter what actions the opponent plays. The maximal subvalue map, which allows
the most action options while still winning, is shown to exist and satisfy a
logical characterization. A family of algorithms for nondeterministic policy
synthesis can be obtained from the inductive subvalue map soundness
characterization. An implementation of these findings is evaluated on examples
that use the expressivity of dGL to model a range of diverse control
challenges.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach](https://arxiv.org/abs/2508.05693)
*Siamak Farshidi,Amir Saberhabibi,Behbod Eskafi,Niloofar Nikfarjam,Sadegh Eskandari,Slinger Jansen,Michel Chaudron,Bedir Tekinerdogan*

Main category: cs.SE

TL;DR: 面对开源软件包选择难题，本文提出用多准则决策结合数据驱动和大语言模型的PySelect系统，显著提高包推荐质量和用户满意度，为可扩展、可复现的软件包选择提供新范式。


<details>
  <summary>Details</summary>
Motivation: 在开源生态系统（如Python）中，由于可选第三方软件包数量众多且缺乏透明的对比证据，包选择变得极为困难。生成式AI工具常用于开发流程，但其推荐往往忽略依赖性评估、过分强调流行度、缺乏可复现性，给项目的透明性和长期可靠性带来风险。作者希望解决选择过程中的不透明和不可靠问题。

Method: 作者将软件包选择问题形式化为多准则决策（MCDM）问题，提出了一个基于数据驱动的技术评估框架。该框架通过自动化数据管道持续收集并整合GitHub、PyPI、Stack Overflow上的软件元数据、使用趋势、漏洞信息和开发者情感，并将这些数据结构化为决策模型。最终，该框架以PySelect决策支持系统实现，通过大语言模型解释用户意图并查询模型，推荐合适的软件包。

Result: 该方法用16,887个GitHub仓库中的798,669个Python脚本进行评估，以及用户研究。结果显示：数据提取精度高，推荐质量超越生成式AI基线，用户在实用性与易用性上均给出正面评价。

Conclusion: 作者提出了一个可扩展、可解释、可复现的软件包选择新框架，通过结合MCDM原则、实证数据和AI辅助意图建模，实现了基于证据的软件包选择，并在推荐质量与用户体验上取得显著提升。

Abstract: Selecting third-party software packages in open-source ecosystems like Python
is challenging due to the large number of alternatives and limited transparent
evidence for comparison. Generative AI tools are increasingly used in
development workflows, but their suggestions often overlook dependency
evaluation, emphasize popularity over suitability, and lack reproducibility.
This creates risks for projects that require transparency, long-term
reliability, maintainability, and informed architectural decisions. This study
formulates software package selection as a Multi-Criteria Decision-Making
(MCDM) problem and proposes a data-driven framework for technology evaluation.
Automated data pipelines continuously collect and integrate software metadata,
usage trends, vulnerability information, and developer sentiment from GitHub,
PyPI, and Stack Overflow. These data are structured into a decision model
representing relationships among packages, domain features, and quality
attributes. The framework is implemented in PySelect, a decision support system
that uses large language models to interpret user intent and query the model to
identify contextually appropriate packages. The approach is evaluated using
798,669 Python scripts from 16,887 GitHub repositories and a user study based
on the Technology Acceptance Model. Results show high data extraction
precision, improved recommendation quality over generative AI baselines, and
positive user evaluations of usefulness and ease of use. This work introduces a
scalable, interpretable, and reproducible framework that supports
evidence-based software selection using MCDM principles, empirical data, and
AI-assisted intent modeling.

</details>


### [3] [Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning](https://arxiv.org/abs/2508.05710)
*Jia Fu,Xinyu Yang,Hongzhi Zhang,Yahui Liu,Jingyuan Zhang,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.SE

TL;DR: 该论文提出Klear-CodeTest框架，通过创新的生成-验证机制生成涵盖广泛问题和高质量的测试样例，并通过安全沙箱保障代码执行，有效提升了代码强化学习模型的性能和稳定性，相关资源已开源。


<details>
  <summary>Details</summary>
Motivation: 在代码强化学习中，对大型语言模型进行有效训练需要准确、可靠的反馈，而高质量测试样例的自动生成仍然是一个难题。现有方法对于综合性和严谨验证的覆盖还有限。

Method: 提出Klear-CodeTest测试样例综合框架，包含“生成-验证”（Generator-Validation，G-V）机制，通过与标准解一致性验证确保测试样例的正确性。框架生成全面的常规与边界测试样例，并配备多层安全沙箱系统用于代码在线验证，保证安全、可靠执行。

Result: 经过实验验证，使用该框架生成的数据集显著提升了模型的性能和训练稳定性。测试样例数据集及系统已开源。

Conclusion: Klear-CodeTest能够有效解决代码强化学习中高质量测试样例自动综合与验证问题，为模型训练带来更强的反馈和稳定性。

Abstract: Precise, correct feedback is crucial for effectively training large language
models (LLMs) in code reinforcement learning. However, synthesizing
high-quality test cases remains a profoundly challenging and unsolved problem.
In this work, we present Klear-CodeTest, a comprehensive test case synthesis
framework featuring rigorous verification to ensure quality and reliability of
test cases. Our approach achieves broad coverage of programming problems via a
novel Generator-Validation (G-V) framework, ensuring correctness through a
consistency validation mechanism that verifies outputs against gold solutions.
The proposed G-V framework generates comprehensive test cases including both
regular and corner cases, enhancing test coverage and discriminative power for
solution correctness assessment in code reinforcement learning. In addition, we
design a multi-layered security sandbox system optimized for online
verification platforms, guaranteeing safe and reliable code execution. Through
comprehensive experiments, we demonstrate the effectiveness of our curated
dataset, showing significant improvements in model performance and training
stability. The source codes, curated dataset and sandbox system are available
at: https://github.com/Kwai-Klear/CodeTest.

</details>


### [4] [Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework](https://arxiv.org/abs/2508.05747)
*Rohaizah Abdul Wahid,Muhamad Said Nizamuddin Nadim,Suliana Sulaiman,Syahmi Akmal Shaharudin,Muhammad Danial Jupikil,Iqqwan Jasman Su Azlan Su*

Main category: cs.SE

TL;DR: 该文讨论在大学Laravel课程中引入Composer和优质开源包可大幅提升开发效率和教学质量，但强调教师需指导学生慎用工具、理解原理，防止只会“套娃”。


<details>
  <summary>Details</summary>
Motivation: 学生在有限的学期时间内用Laravel完成项目存在困难，亟需有效提升开发效率的方法，同时保持软件开发的专业性和教学的深度。

Method: 归纳和分类现有Composer包，结合实际与教学需求，提出包的应用策略并分析其在课程中的作用与风险。

Result: 精心挑选的Composer包能显著减轻学生开发负担，提高代码质量，促进其专业能力成长，但必须通过教师指导确保学生理解工具背后的原理与应用场景，从而避免盲目依赖。

Conclusion: 引入Composer及其精选包不仅可以加快开发进度，还能增强学生的专业素养，但需有针对性的教学设计以避免学生陷入工具依赖和概念缺失。

Abstract: Laravel has emerged as a foundational framework in university web development
curricula. However, despite its scaffolding capabilities, students often
struggle to complete projects within limited academic timelines. This
conceptual paper introduces Composer, PHP's standard dependency manager, and
categorizes a curated selection of Composer packages that significantly reduce
development effort while fostering professional software practices. Grounded in
practical and pedagogical considerations, the paper illustrates how educators
and learners can strategically leverage these tools to build typical academic
or personal Laravel-based systems. Central to this approach is maintaining code
quality and reinforcing conceptual understanding. The paper also addresses
potential risks such as package conflicts and over-reliance on tools, providing
best-practice recommendations to mitigate them. While the goal is to accelerate
development, the deeper objective is to reinforce professional workflows and
industry readiness. Exposure to Composer packages enhances curriculum relevance
and smooths the transition from academia to the workplace. However, effective
integration requires deliberate instructional design aligned with learning
objectives. Without guidance, students may treat packages as black boxes. Thus,
educators must teach not only how to use these tools, but also when and why,
encouraging critical evaluation of their utility and limitations. This ensures
that practical convenience supports rather than supplants deep learning.

</details>


### [5] [AI-Guided Exploration of Large-Scale Codebases](https://arxiv.org/abs/2508.05799)
*Yoseph Berhanu Alebachew*

Main category: cs.SE

TL;DR: 本文提出了一种结合逆向工程和LLM的新型代码可视化理解工具，提升了复杂软件系统的可用性和代码探索体验，并展示了Java原型验证效果。未来将拓展到多语言和更丰富的人机交互。


<details>
  <summary>Details</summary>
Motivation: 理解大型复杂软件系统对于开发者来说始终是难题，目前的静态可视化和逆向工程工具缺乏互动性、适应性和上下文整合。近期大语言模型（LLMs）崛起为代码探索提供了新机会，但其效果因缺乏与结构化视图结合而受限。

Method: 提出了一种混合方法，将确定性的逆向工程与LLM引导、意图感知的可视化代码探索结合。该系统集成了基于UML的可视化、动态用户界面、历史上下文与协作功能，通过解读用户查询和交互模式，由LLM辅助开发者更好地理解代码库。并实现了Java原型系统。

Result: 原型系统展示了该方法在实际Java项目中的可行性，能够有效增强开发者对复杂代码库的理解与探索能力。

Conclusion: 本研究为智能且互动性强的软件理解环境奠定了基础，可更好地契合开发者认知和协作工作流程。未来将扩展到多语言系统，评估实用性并开发基于GUI的LLM交互模式。

Abstract: Understanding large-scale, complex software systems is a major challenge for
developers, who spend a significant portion of their time on program
comprehension. Traditional tools such as static visualizations and reverse
engineering techniques provide structural insights but often lack
interactivity, adaptability, and integration with contextual information.
Recent advancements in large language models (LLMs) offer new opportunities to
enhance code exploration workflows, yet their lack of grounding and integration
with structured views limits their effectiveness. This work introduces a hybrid
approach that integrates deterministic reverse engineering with LLM-guided,
intent-aware visual exploration. The proposed system combines UML-based
visualization, dynamic user interfaces, historical context, and collaborative
features into an adaptive tool for code comprehension. By interpreting user
queries and interaction patterns, the LLM helps developers navigate and
understand complex codebases more effectively. A prototype implementation for
Java demonstrates the feasibility of this approach. Future work includes
empirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM
interaction models. This research lays the groundwork for intelligent,
interactive environments that align with developer cognition and collaborative
workflows.

</details>


### [6] [Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm](https://arxiv.org/abs/2508.05923)
*Yanusha Mehendran,Maolin Tang,Yi Lu*

Main category: cs.SE

TL;DR: 本文提出了一种新型的基于遗传算法和自适应学习的软件漏洞检测输入生成方法，在多个覆盖率指标上较传统进化模糊方法有显著提升，展示了更高效、可扩展的软件安全测试潜力。


<details>
  <summary>Details</summary>
Motivation: 软件复杂性增加，传统漏洞检测方法难以满足现代系统的安全与可靠性需求，因此需要新的、更有效的测试输入生成方法以提升漏洞检测能力。

Method: 提出了一种基于遗传算法的测试输入生成方法，创新性地结合了遗传操作符和自适应学习机制。该方法通过交叉操作符扩展测试输入空间，并通过自适应反馈机制，根据系统执行行为动态调整输入生成方向。测试用例以反馈驱动方式进化选择，从而实现结构有效且更深入的代码遍历。

Result: 在9个开源的JSON处理库上进行评估，相比基准进化式模糊测试方法，覆盖率有显著提升：类覆盖率提升39.8%，方法覆盖率提升62.4%，行覆盖率提升105.0%，指令覆盖率提升114.0%，分支覆盖率提升166.0%。

Conclusion: 新方法能发现更深层次、更复杂的软件漏洞，是一种具备可扩展性和自适应能力的软件安全测试新方案。

Abstract: Software vulnerabilities continue to undermine the reliability and security
of modern systems, particularly as software complexity outpaces the
capabilities of traditional detection methods. This study introduces a genetic
algorithm-based method for test input generation that innovatively integrates
genetic operators and adaptive learning to enhance software vulnerability
detection. A key contribution is the application of the crossover operator,
which facilitates exploration by searching across a broader space of potential
test inputs. Complementing this, an adaptive feedback mechanism continuously
learns from the system's execution behavior and dynamically guides input
generation toward promising areas of the input space. Rather than relying on
fixed or randomly selected inputs, the approach evolves a population of
structurally valid test cases using feedback-driven selection, enabling deeper
and more effective code traversal. This strategic integration of exploration
and exploitation ensures that both diverse and targeted test inputs are
developed over time. Evaluation was conducted across nine open-source
JSON-processing libraries. The proposed method achieved substantial
improvements in coverage compared to a benchmark evolutionary fuzzing method,
with average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%
in line coverage, 114.0% in instruction coverage, and 166.0% in branch
coverage. These results highlight the method's capacity to detect deeper and
more complex vulnerabilities, offering a scalable and adaptive solution to
software security testing.

</details>


### [7] [A Survey on Task Scheduling in Carbon-Aware Container Orchestration](https://arxiv.org/abs/2508.05949)
*Jialin Yang,Zainab Saad,Jiajun Wu,Xiaoguang Niu,Henry Leung,Steve Drew*

Main category: cs.SE

TL;DR: 本文系统综述了 Kubernetes 调度策略，并以可持续化为核心，将这些方法分为硬件和软件导向两类，从环境影响视角分析了其优缺点。提出了云任务调度的分类体系，指出了新兴研究方向与挑战，为设计低碳环保的云系统调度方法提供了参考。


<details>
  <summary>Details</summary>
Motivation: 面对大规模软件生态系统和云数据中心因大语言模型训练与部署导致的能耗和碳足迹激增，业界与学术界亟需提出更高效的任务调度与基础设施管理方法以降低碳排放。

Method: 系统性回顾现有 Kubernetes 调度策略，并将其分为硬件导向和软件导向两大类，分析其可持续性目标，并依据所用算法进行归类。同时提出云任务调度研究的综合分类体系，重点关注环境可持续性。

Result: 对现有 Kubernetes 调度策略进行了细致的梳理与分类，分析了各方法对应的可持续发展目标及其算法分组，归纳出云任务调度领域的研究趋势和尚待解决的问题。

Conclusion: 该综述揭示了实现下一代云计算系统可持续调度解决方案的关键洞察，并为未来相关研究提供了理论框架和指导。

Abstract: The soaring energy demands of large-scale software ecosystems and cloud data
centers, accelerated by the intensive training and deployment of large language
models, have driven energy consumption and carbon footprint to unprecedented
levels. In response, both industry and academia are increasing efforts to
reduce the carbon emissions associated with cloud computing through more
efficient task scheduling and infrastructure orchestration. In this work, we
present a systematic review of various Kubernetes scheduling strategies,
categorizing them into hardware-centric and software-centric, annotating each
with its sustainability objectives, and grouping them according to the
algorithms they use. We propose a comprehensive taxonomy for cloud task
scheduling studies, with a particular focus on the environmental sustainability
aspect. We analyze emerging research trends and open challenges, and our
findings provide critical insight into the design of sustainable scheduling
solutions for next-generation cloud computing systems.

</details>


### [8] [Impact-driven Context Filtering For Cross-file Code Completion](https://arxiv.org/abs/2508.05970)
*Yanzhou Li,Shangqing Liu,Kangjie Chen,Tianwei Zhang,Yang Liu*

Main category: cs.SE

TL;DR: 本工作发现RAG方法在代码补全中检索到的多数上下文块无益甚至有害，提出CODEFILTER框架，能自适应筛选掉负面块，提升补全准确率及效率。


<details>
  <summary>Details</summary>
Motivation: RAG方法已在代码自动补全方向表现突出，但实际检索的跨文件代码块中，只有部分块对补全有积极作用，部分甚至会削弱性能。作者希望深入理解、区分这些检索块的作用，并提升代码补全效果。

Method: 引入了一个基于似然的度量，用于评估每个检索到的代码块对补全的影响，并据此为检索块打上积极、中性、消极标签，构建数据集。进而提出了适应性检索上下文筛选（CODEFILTER）框架，通过训练自动过滤不利于补全的检索结果。

Result: 在RepoEval和CrossCodeLongEval两个基准上，CODEFILTER不论哪种任务相较于未筛选的RAG都显著提升了补全准确率。同时有效缩短了输入长度，提高了推理效率，并展现出良好的泛化能力。

Conclusion: CODEFILTER能够优化跨文件检索代码块的质量，提升代码补全的准确性与效率，对不同模型均有较好适应性。实验结果表明其对存储库级代码补全具有较大提升潜力。

Abstract: Retrieval-augmented generation (RAG) has recently demonstrated considerable
potential for repository-level code completion, as it integrates cross-file
knowledge with in-file preceding code to provide comprehensive contexts for
generation. To better understand the contribution of the retrieved cross-file
contexts, we introduce a likelihood-based metric to evaluate the impact of each
retrieved code chunk on the completion. Our analysis reveals that, despite
retrieving numerous chunks, only a small subset positively contributes to the
completion, while some chunks even degrade performance. To address this issue,
we leverage this metric to construct a repository-level dataset where each
retrieved chunk is labeled as positive, neutral, or negative based on its
relevance to the target completion. We then propose an adaptive retrieval
context filtering framework, CODEFILTER, trained on this dataset to mitigate
the harmful effects of negative retrieved contexts in code completion.
Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks
demonstrates that CODEFILTER consistently improves completion accuracy compared
to approaches without filtering operations across various tasks. Additionally,
CODEFILTER significantly reduces the length of the input prompt, enhancing
computational efficiency while exhibiting strong generalizability across
different models. These results underscore the potential of CODEFILTER to
enhance the accuracy, efficiency, and attributability of repository-level code
completion.

</details>


### [9] [Position: Intelligent Coding Systems Should Write Programs with Justifications](https://arxiv.org/abs/2508.06017)
*Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 现状：AI编程系统不透明；问题：用户难信任与理解；方法：神经符号理由生成；价值：提升理由解释性与用户信任。


<details>
  <summary>Details</summary>
Motivation: AI智能编码系统正在改变软件开发流程，但其决策过程不透明，尤其让非专家用户难以信任和理解生成的代码。当前用户难以检查底层实现，因此亟需提升系统的可解释性和可用性。

Method: 分析现有方法如形式化验证、静态分析和事后可解释性存在的局限性，并提出利用神经符号方法生成理由说明。通过在训练过程中引入符号约束来指导模型，同时用神经表示丰富程序语义，从而在推理阶段自动进行一致性检查。

Result: 指出现有方法不足，提出神经符号方法有潜力生成更清晰、一致的可解释理由，提升模型推理与用户理解之间的桥梁效果。

Conclusion: 智能编码系统除了生成代码外，还需提供认知对齐和语义忠实的理由说明。神经符号方法是实现自动化理由生成和一致性检查的有效途径，有助于提升用户信任与系统可用性。

Abstract: Intelligent coding systems are transforming software development by enabling
users to specify code behavior in natural language. However, the opaque
decision-making of AI-driven coders raises trust and usability concerns,
particularly for non-expert users who cannot inspect low-level implementations.
We argue that these systems should not only generate code but also produce
clear, consistent justifications that bridge model reasoning and user
understanding. To this end, we identify two critical justification
properties-cognitive alignment and semantic faithfulness-and highlight the
limitations of existing methods, including formal verification, static
analysis, and post-hoc explainability. We advocate exploring neuro-symbolic
approaches for justification generation, where symbolic constraints guide model
behavior during training and program semantics are enriched through neural
representations, enabling automated consistency checks at inference time.

</details>


### [10] [Understanding Inconsistent State Update Vulnerabilities in Smart Contracts](https://arxiv.org/abs/2508.06192)
*Lantian Li,Yuyu Chen,Jingwen Wu,Yue Pan,Zhongxing Yu*

Main category: cs.SE

TL;DR: 本论文首次对智能合约状态不一致性漏洞进行了大规模实证分析，归纳成因与修复方法，总结11条重要发现，并开发检测工具在实际项目中验证有效性，对智能合约安全具有实际指导意义。


<details>
  <summary>Details</summary>
Motivation: 随着智能合约在金融、供应链等领域应用的增加，合约状态的正确同步成为合约安全的关键。然而，智能合约的状态更新存在不一致问题，攻击者也多次利用此类漏洞，目前主流工具难以有效检测此类问题。作者因此针对智能合约状态不一致性漏洞展开研究，以期为相关领域提供指导。

Method: 作者对352个真实世界的智能合约项目中116个状态不一致性漏洞进行了系统性实证研究，分析漏洞成因、修复策略和利用方法，并总结出11条重要发现。此外，基于其中一项发现，开发了一个概念验证检测器并对GitHub上的64个项目进行检测。

Result: 提出了11项关于智能合约状态不一致性漏洞的原创且重要的发现，开发的检测器成功在64个热门GitHub项目中检测到问题，其中19个项目的所有者已确认这些问题。

Conclusion: 该研究深入揭示了智能合约状态不一致性漏洞的根本原因与修复思路，同时通过实际检测工具验证了研究成果的有效性，对开发者、研究人员和工具开发者有重要指导价值。

Abstract: Smart contracts enable contract terms to be automatically executed and
verified on the blockchain, and recent years have witnessed numerous
applications of them in areas such as financial institutions and supply chains.
The execution logic of a smart contract is closely related to the contract
state, and thus the correct and safe execution of the contract depends heavily
on the precise control and update of the contract state. However, the contract
state update process can have issues. In particular, inconsistent state update
issues can arise for reasons such as unsynchronized modifications. Inconsistent
state update bugs have been exploited by attackers many times, but existing
detection tools still have difficulty in effectively identifying them. This
paper conducts the first large-scale empirical study about inconsistent state
update vulnerabilities (that is, inconsistent state update bugs that are
exploitable) in smart contracts, aiming to shed light for developers,
researchers, tool builders, and language or library designers in order to avoid
inconsistent state update vulnerabilities. We systematically investigate 116
inconsistent state update vulnerabilities in 352 real-world smart contract
projects, summarizing their root causes, fix strategies, and exploitation
methods. Our study provides 11 original and important findings, and we also
give the implications of our findings. To illustrate the potential benefits of
our research, we also develop a proof-of-concept checker based on one of our
findings. The checker effectively detects issues in 64 popular GitHub projects,
and 19 project owners have confirmed the detected issues at the time of
writing. The result demonstrates the usefulness and importance of our findings
for avoiding inconsistent state update vulnerabilities in smart contracts.

</details>


### [11] [Improving the Developer Experience with a Low-Code Process Modelling Language](https://arxiv.org/abs/2508.06299)
*Henrique Henriques,Hugo Lourenço,Vasco Amaral,Miguel Goulão*

Main category: cs.SE

TL;DR: 该研究识别且解决了OutSystems平台BPT的可用性问题，通过系统方法改进后，在开发者中显著提升了易用性和效率。


<details>
  <summary>Details</summary>
Motivation: OutSystems平台中的流程建模DSL（BPT）使用率低，被认为存在可用性问题，影响推广，同时造成维护成本增加。

Method: 采用访谈、对BPT进行“符号物理学”批判性评审，以及基于SUS和TLX的实证评估，结合平台开发者文化，开发新版BPT。

Result: 新版BPT在25名专业开发者中，语义透明度提升（31%→69%），答题正确率提升（51%→89%），SUS得分提升（42.25→64.78），TLX得分下降（36.50→20.78），均具统计学意义。

Conclusion: 新版BPT显著改善了开发者体验，用户背景对具体语法设计与可用性有重要影响。

Abstract: Context: The OutSystems Platform is a development environment composed of
several DSLs, used to specify, quickly build, and validate web and mobile
applications. The DSLs allow users to model different perspectives such as
interfaces and data models, define custom business logic and construct process
models. Problem: The DSL for process modelling (Business Process Technology
(BPT)), has a low adoption rate and is perceived as having usability problems
hampering its adoption. This is problematic given the language maintenance
costs. Method: We used a combination of interviews, a critical review of BPT
using the "Physics of Notation" and empirical evaluations of BPT using the
System Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a
new version of BPT, taking these inputs and Outsystems' engineers' culture into
account. Results: Evaluations conducted with 25 professional software engineers
showed an increase of the semantic transparency on the new version, from 31% to
69%, an increase in the correctness of responses, from 51% to 89%, an increase
in the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from
36.50 to 20.78. These differences were statistically significant. Conclusions:
These results suggest that the new version of BPT significantly improved the
developer experience of the previous version. The end users' background with
OutSystems had a relevant impact on the final concrete syntax choices and
achieved usability indicators.

</details>


### [12] [Execution-Feedback Driven Test Generation from SWE Issues](https://arxiv.org/abs/2508.06365)
*Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel*

Main category: cs.SE

TL;DR: 本文提出了e-Otter++，首次在代码存在错误时有效生成复现测试用例，通过实验验证取得了63% fail-to-pass的优秀结果，提升了软件缺陷定位与修复的自动化能力。


<details>
  <summary>Details</summary>
Motivation: 多数软件工程问题报告没有配套的可执行复现测试用例，导致问题难以有效复现和解决。现有自动生成测试的技术难以应对目标代码有错误或缺失的场景，因此，研究如何在代码不正确时自动生成高效的复现测试具有重要意义。

Method: 提出了一种新颖的利用执行反馈生成复现测试的方法，设计并实现了自动复现测试生成器e-Otter++。该方法能在目标代码缺失或错误的情况下，依然生成有效的测试用例。通过实验对比，评估了该方法的有效性。

Result: e-Otter++在TDD-Bench Verified基准集上测试生成的用例中，平均fail-to-pass率高达63%，显著超过现有技术水平。

Conclusion: 通过创新方法，e-Otter++实现了在代码有缺陷时自动生成高质量复现测试的能力，推动了该领域的技术进步。

Abstract: A software engineering issue (SWE issue) is easier to resolve when
accompanied by a reproduction test. Unfortunately, most issues do not come with
functioning reproduction tests, so this paper explores how to generate them
automatically. The primary challenge in this setting is that the code to be
tested is either missing or wrong, as evidenced by the existence of the issue
in the first place. This has held back test generation for this setting:
without the correct code to execute, it is difficult to leverage execution
feedback to generate good tests. This paper introduces novel techniques for
leveraging execution feedback to get around this problem, implemented in a new
reproduction test generator called e-Otter++. Experiments show that e-Otter++
represents a leap ahead in the state-of-the-art for this problem, generating
tests with an average fail-to-pass rate of 63% on the TDD-Bench Verified
benchmark.

</details>


### [13] [What Builds Effective In-Context Examples for Code Generation?](https://arxiv.org/abs/2508.06414)
*Dongze Li,Songqiang Chen,Jialun Cao,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: 本文通过消融实验揭示变量/函数命名规范对提升大模型代码生成能力关键，模型在直接信息利用强但反思泛化能力不足，为ICL系统优化与后续研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 尽管代码示例驱动的ICL方法效果显著，但尚未明确哪些代码特性对ICL贡献最大，因此有必要进行细致分析以优化ICL性能。

Method: 通过对代码示例中不同特征进行控制消融实验，系统分析变量命名、格式、解决思路等元素对ICL效果的影响。

Result: 消除有意义的变量和函数命名会导致性能下降高达30个百分点，模型更重视语义有意义的标识符而非代码格式，并在借助直接信息时表现良好，但在提取通用解题思路（反思与推理）方面能力有限。

Conclusion: 变量和函数的合适命名对代码生成效果至关重要，直接影响模型性能，而当前大模型对利用通用性、反思性代码信息存在较大挑战。

Abstract: In-Context Learning (ICL) has emerged as a promising solution to enhance the
code generation capabilities of Large Language Models (LLMs), which
incorporates code examples inside the prompt to let LLMs learn from
demonstrations. However, despite the substantial effectiveness of the code
example-based ICL approach, the specific features (e.g., identifier naming
styles, code formatting, solution insight) within the ICL-provided code
examples that significantly contribute to the ICL's effectiveness remain
unclear. This paper systematically investigates the impact of various code
features on ICL with code examples through controlled ablation studies. Our
findings reveal that the appropriate naming of variables and functions is
crucial for effective code generation, with their elimination leading to
performance decreases of up to 30 percentage points. We further demonstrate
that LLMs prioritize semantically meaningful identifier names over formatting
conventions, with language-specific preferences regarding identifier verbosity.
Additionally, our investigation into ICL's potential for enhancing reflection
and inference capabilities reveals that current LLMs struggle to extract
generalizable problem-solving insights from similar code solutions, despite
being capable of utilizing direct information effectively. These findings are
expected to provide valuable insights for optimizing ICL systems in code
generation applications and highlight fundamental challenges in
reflection-based learning for code generation tasks.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [14] [Basic interactive algorithms: Preview](https://arxiv.org/abs/2508.05798)
*Yuri Gurevich*

Main category: cs.LO

TL;DR: 本文对即将发表的基本交互式算法公理化工作进行了预览。作者简述了从传统到现代算法理论的发展，强调通过引入“神谕”的方式，可以用统一的基本算法框架描述确定性、非确定性、概率及量子算法，并讨论了Church-Turing论题古典与物理版的区别及其理论意义。


<details>
  <summary>Details</summary>
Motivation: 近几十年来，算法的概念不断扩展，包括概率算法、量子算法等，这促使学界重新审视和形式化算法的基础定义。经典算法的公理化已成为理论计算机科学的重要基础，但更复杂的新型算法需要更统一的理论框架。

Method: 本文预览和探讨即将发表的基本交互式算法的公理化方法，通过阐述现有算法（如经典、概率、量子等）在行为等价和抽象状态机下的统一视角，提出用“合适的神谕”将各种类型算法纳入基本算法的框架。

Result: 作者强调两种不同版本的Church-Turing论题之间的区别，指出非确定性和概率算法、甚至量子线路算法都可视作带有特定神谕的基本算法，从而扩展了基本算法理论适用的范围和解释力。

Conclusion: 将更多类型（如概率、量子）的算法纳入基本算法公理化框架，为理解和研究交互式及新型算法提供了理论基础，也有助于更清晰地区分和理解Church-Turing论题的不同表述。

Abstract: This dialog paper offers a preview and provides a foretaste of an upcoming
work on the axiomatization of basic interactive algorithms.
  The modern notion of algorithm was elucidated in the 1930s--1950s. It was
axiomatized a quarter of a century ago as the notion of ``sequential
algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm"
now. The axiomatization was used to show that for every basic algorithm there
is a behaviorally equivalent abstract state machine. It was also used to prove
the Church-Turing thesis as it has been understood by the logicians.
  Starting from the 1960s, the notion of algorithm has expanded --
probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of
a much more ambitious version of the Church-Turing thesis commonly known as the
``physical thesis.'' We emphasize the difference between the two versions of
the Church-Turing thesis and illustrate how nondeterministic and probabilistic
algorithms can be viewed as basic algorithms with appropriate oracles. The same
view applies to quantum circuit algorithms and many other classes of
algorithms.

</details>


### [15] [Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games](https://arxiv.org/abs/2508.06088)
*Kittiphon Phalakarn,Yun Chen Tsai,Ichiro Hasuo*

Main category: cs.LO

TL;DR: 本文提出了基于2-玩家最宽路径博弈的2WP-BVI算法，克服了传统BVI在含终端分量时的收敛问题，理论上证明其有效性，并通过实验展示了其实际优势。


<details>
  <summary>Details</summary>
Motivation: 传统的有界值迭代方法在含有终端分量的随机博弈模型中，可能无法终止或收敛。现有方法通常需要检测并处理终端分量，但这很耗计算资源。宽路径BVI方法对大量终端分量有效，但理论基础不完善。

Method: 通过提出基于2-玩家最宽路径博弈的有界值迭代算法（2WP-BVI），并采用最大性继承原理进行证明。

Result: 2WP-BVI算法在具有众多终端分量的随机博弈模型中效果显著，且理论上证明了其正确性。

Conclusion: 提出了2WP-BVI算法，证明其正确性，并在实验中展示了其实际效果。

Abstract: For model checking stochastic games (SGs), bounded value iteration (BVI)
algorithms have gained attention as efficient approximate methods with rigorous
precision guarantees. However, BVI may not terminate or converge when the
target SG contains end components. Most existing approaches address this issue
by explicitly detecting and processing end components--a process that is often
computationally expensive. An exception is the widest path-based BVI approach
previously studied by Phalakarn et al., which we refer to as 1WP-BVI. The
method performs particularly well in the presence of numerous end components.
Nonetheless, its theoretical foundations remain somewhat ad hoc. In this paper,
we identify and formalize the core principles underlying the widest path-based
BVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on
(2-player) widest path games, and (ii) proving its correctness using what we
call the maximality inheritance principle--a proof principle previously
employed in a well-known result in probabilistic model checking. Our
experimental results demonstrate the practical relevance and potential of our
proposed 2WP-BVI algorithm.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare](https://arxiv.org/abs/2508.05722)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: PEACH是一个公开的英-阿拉伯语医疗文本手工对齐平行语料库，有5万多句对，广泛适用于NLP、翻译和健康信息研究。


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量、手工对齐的英-阿拉伯语医疗文本平行语料库，限制了跨语言医学信息获取和相关NLP应用的发展。

Method: 构建PEACH语料库，收集并手工对齐含有患者信息说明书和健康教育材料的英-阿拉伯语句对，总计51,671句，统计基本数据，保证语料质量，并公开发布。

Result: PEACH包含51,671句手工对齐的平行句，总词数分别为英文约59万、阿拉伯文约56万，适用于对比语言学、翻译研究、NLP应用等多个场景。

Conclusion: PEACH语料库为研究者在医疗语言处理、翻译和对比语言学等领域提供了高质量的基础资源，可用于词典构建、模型适配、机器翻译评价、患者信息评估与教学等多个用途。

Abstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic
corpus of healthcare texts encompassing patient information leaflets and
educational materials. The corpus contains 51,671 parallel sentences, totaling
approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths
vary between 9.52 and 11.83 words on average. As a manually aligned corpus,
PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,
translation studies, and natural language processing. It can be used to derive
bilingual lexicons, adapt large language models for domain-specific machine
translation, evaluate user perceptions of machine translation in healthcare,
assess patient information leaflets and educational materials' readability and
lay-friendliness, and as an educational resource in translation studies. PEACH
is publicly accessible.

</details>


### [17] [Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation](https://arxiv.org/abs/2508.05775)
*Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu*

Main category: cs.CL

TL;DR: 本文系统综述了大型语言模型（LLM）带来的内容创作变革与安全风险，提出分类框架，分析最新攻击与防护手段，并指明未来研究方向，为LLM安全发展和伦理规范提供参考。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在内容创作领域带来了巨大的变革，不仅极大提升了自然语言生成与理解的能力，也显现出其在实际应用中的便利性。然而，这些模型同时却可能产生有毒、冒犯或偏见性内容，成为潜在的社会技术问题。促使本论文对LLM的负面影响及应对措施展开系统性综述。

Method: 本文通过系统性文献综述，对LLM在无意中产生有害内容、被利用进行越狱攻击，以及内容治理技术等方面的最新研究进行了梳理。提出了统一的LLM相关危害与防御分类框架，并分析多模态及LLM辅助越狱策略，同时评估了现有的多种缓解手段（如RLHF、提示工程、安全对齐）。

Result: 本文总结了LLM安全性的最新研究进展，明确了当前评估方法的局限性，提出了未来研究方向，有助于指导开发更安全、更具伦理性的语言技术。

Conclusion: LLM在带来创新与便利的同时也带来了重大安全与伦理挑战。通过系统综述相关领域的研究与防御措施，本文对未来LLM安全性提升及评估方法改进提供了有益建议。

Abstract: Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

</details>


### [18] [FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification](https://arxiv.org/abs/2508.05782)
*Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver*

Main category: cs.CL

TL;DR: 本文提出了对话系统细粒度事实验证基准FineDialFact，并展示其挑战性，Chain-of-Thought推理有助于提升性能，相关数据与代码公开，便于后续研究。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）很容易产生日志（事实不准确或虚构信息），这在对话系统等NLP应用中造成显著挑战，因此如何检测日志成为研究重点。现有方法多采用事实一致性验证，但对话中常有多种准确度不一的事实，简单标签显得过于粗糙。

Method: 作者提出了一个细粒度对话事实验证基准FineDialFact，将对话回复中的原子事实进行逐一验证，并基于公开对话数据集构建数据集，采用多种基线方法进行评测，并探索Chain-of-Thought推理方法。

Result: 实验表明，结合Chain-of-Thought推理的方法提升了细粒度事实验证性能，在开放领域对话数据集HybriDialogue上最高F1分数为0.75，仍表明任务具有挑战性。

Conclusion: 细粒度事实验证比传统整体标签更适用于对话日志检测，FineDialFact基准与数据为未来相关研究提供了基础，当前方法仍有进一步提升空间。

Abstract: Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

</details>


### [19] [Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models](https://arxiv.org/abs/2508.05803)
*Abishek Thamma,Micha Heilbron*

Main category: cs.CL

TL;DR: 记忆短暂性提升神经网络语言习得，却降低对人类阅读行为的拟合，挑战了既有认知理论。


<details>
  <summary>Details</summary>
Motivation: 传统认知科学认为，记忆短暂性反而有助于语言学习。随着Transformer的兴起，其无记忆限制却依然高效习得语言，这一现象挑战了经典观点，因此作者想探究记忆短暂性对现代神经网络语言学习的影响。

Method: 在模拟真实语言学习环境下，对Transformer语言模型进行对比实验：一组加入了记忆短暂性机制，一组未加入。评估其语言学习能力和对人类阅读时间的预测表现。

Result: 引入短暂记忆机制后，语言模型在语法及整体表现上优于标准Transformer，但对人类阅读时间的预测表现反倒变差，且这一现象无法用现有理论解释。

Conclusion: 记忆的短暂性有利于神经网络对语言学习的性能提升，但这种限制并不帮助预测人类的行为（如阅读时间）。

Abstract: Human memory is fleeting. As words are processed, the exact wordforms that
make up incoming sentences are rapidly lost. Cognitive scientists have long
believed that this limitation of memory may, paradoxically, help in learning
language - an idea supported by classic connectionist modelling work. The rise
of Transformers appears to challenge this idea, as these models can learn
language effectively, despite lacking memory limitations or other architectural
recency biases. Here, we investigate the hypothesized benefit of fleeting
memory for language learning in tightly controlled experiments on transformer
language models. Training transformers with and without fleeting memory on a
developmentally realistic training set, we find that fleeting memory
consistently improves language learning (as quantified by both overall language
modelling performance and targeted syntactic evaluation) but, unexpectedly,
impairs surprisal-based prediction of human reading times. Interestingly,
follow up analyses revealed that this discrepancy - better language modeling,
yet worse reading time prediction - could not be accounted for by prior
explanations of why better language models sometimes fit human reading time
worse. Together, these results support a benefit of memory limitations on
neural network language learning - but not on predicting behavior.

</details>


### [20] ["Mirror" Language AI Models of Depression are Criterion-Contaminated](https://arxiv.org/abs/2508.05830)
*Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns*

Main category: cs.CL

TL;DR: 直接用问卷内容让AI预测抑郁很准但过拟合，换用日常谈话准确率下降但更泛化，实际应用应偏向后者。


<details>
  <summary>Details</summary>
Motivation: 越来越多的研究利用大语言模型（LLM）对抑郁症评估分数进行预测，并取得接近完美的效果（R2最高可达0.70）。但许多方法直接用评估问卷的回答训练模型（即“镜像模型”），这种做法带来了“标准污染”，可能导致模型泛化性降低。因此，研究动机是探究不同数据来源的模型表现、泛化能力和解读性。

Method: 对110名研究参与者分别进行结构化诊断访谈和生活史访谈。让GPT-4、GPT-4o及LLaMA3-70B分别基于这两类访谈转录文本预测结构化访谈的抑郁评估分数。对比“镜像模型”（用结构化诊断文本构建）与“非镜像模型”（用生活史文本构建）的预测效果，并分析其与自评抑郁症状的相关性，及用主题建模分析预测误差。

Result: 镜像模型预测效果极佳（R2约0.80），但非镜像模型效果较低（R2约0.27），但仍相对较高。两类模型预测分数与自评抑郁症状相关性相当（r约0.54），表明镜像模型存在标准污染导致的人工放大效应。主题建模发现了不同模型类型和预测分对的语义特征差异。

Conclusion: 仅凭与评估内容高度重合的对话训练AI模型，会高估其预测能力和泛化性。非镜像模型虽效果较弱但更能反映可迁移的语义特征，对于实际心理健康评估更有应用价值。今后需更多采用非镜像方法，以获得更可解释和泛化的评估工具。

Abstract: A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

</details>


### [21] [Discovering Properties of Inflectional Morphology in Neural Emergent Communication](https://arxiv.org/abs/2508.05843)
*Miles Gilberti,Shane Storks,Huteng Dai*

Main category: cs.CL

TL;DR: 本文通过在新兴通信游戏中引入小词汇量约束与屈折形态学设定，发现深度学习代理人生成的语言结构可以模拟自然语言中属性融合和连结的特性，实现对自然语言规律的有意义复现。


<details>
  <summary>Details</summary>
Motivation: 现有新兴通信（EmCom）研究多关注一对一的属性映射和词语合成，缺乏与自然语言形态学结构的对比。本文旨在通过模拟自然语言屈折形态学属性，探索能否更贴近人类语言本质的通信系统，为人工智能理解与生成自然语言提供新动力。

Method: 重新设计属性值重构游戏，加入小词汇量约束，提出类似屈折形态学（自然语言中的词形变化）的新实验设定，并开发新的评估指标来衡量连结性和融合性。通过实验探索这些约束对新兴语言结构的影响。

Result: 在小词汇量与语音学约束下，代理人发展出的新兴语言展现出连结性和属性融合性，与自然语言中的屈折形态有较大相似性，特别是复制了自然语言中将多种语法属性融合为单一词素的倾向。

Conclusion: 在施加小词汇量约束以模拟双重分节后，深度神经网络代理人能够生成具有自然语言屈折形态学特征（连结性和融合性）的新兴通信系统，这些系统与人类语言有可比性，并且展现出与自然语言一致的属性融合倾向。

Abstract: Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

</details>


### [22] [Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models](https://arxiv.org/abs/2508.05880)
*Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang*

Main category: cs.CL

TL;DR: 本文提出并公开了一个用于评估大型语言模型情感认知推理能力的大规模基准CoRE，系统分析了不同模型在情感推理中的认知表现与差异，为情感计算领域提供了新的研究工具和理解角度。


<details>
  <summary>Details</summary>
Motivation: 情感计算作为推动人工智能系统全面发展的关键领域，现有研究多采用监督式学习，通过离散情感标签评估大模型感知和生成情感的能力。但这些方法多局限于情感识别等表层任务，缺乏对模型情感推理背后认知过程的深入探索。

Method: 本研究基于认知评价理论，设计并提出了一个大规模的情感认知推理评测基准（CoRE），用于系统性地评估大型语言模型在处理情感相关刺激时，是否能够产生一致且合乎逻辑的认知推理。通过多轮实验与分析，联合考察模型是否隐式依赖某些认知维度、不同情感的关键认知维度，以及这些维度能否用来解释模型内部的情感分类表示。

Result: 实验证明，不同大型语言模型在情感认知推理方面表现出多样化的推理模式。基于CoRE基准的分析揭示了模型对情感推理时隐含的认知结构，对情感理解的过程提供了新的解释视角。

Conclusion: 本工作实现了情感任务从表层识别向深层认知推理的拓展，构建了可公开获取的情感认知推理基准（CoRE），为未来AI情感推理机制研究提供评测平台，并丰富了对大模型情感能力的理解。

Abstract: Affective Computing has been established as a crucial field of inquiry to
advance the holistic development of Artificial Intelligence (AI) systems.
Foundation models -- especially Large Language Models (LLMs) -- have been
evaluated, trained, or instruction-tuned in several past works, to become
better predictors or generators of emotion. Most of these studies, however,
approach emotion-related tasks in a supervised manner, assessing or training
the capabilities of LLMs using discrete emotion labels associated with stimuli
(e.g., text, images, video, audio). Evaluation studies, in particular, have
often been limited to standard and superficial emotion-related tasks, such as
the recognition of evoked or expressed emotions. In this paper, we move beyond
surface-level emotion tasks to investigate how LLMs reason about emotions
through cognitive dimensions. Drawing from cognitive appraisal theory, we
examine whether LLMs produce coherent and plausible cognitive reasoning when
reasoning about emotionally charged stimuli. We introduce a large-scale
benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal
cognitive structures implicitly used by LLMs for emotional reasoning. Through a
plethora of evaluation experiments and analysis, we seek to answer: (a) Are
models more likely to implicitly rely on specific cognitive appraisal
dimensions?, (b) What cognitive dimensions are important for characterizing
specific emotions?, and, (c) Can the internal representations of different
emotion categories in LLMs be interpreted through cognitive appraisal
dimensions? Our results and analyses reveal diverse reasoning patterns across
different LLMs. Our benchmark and code will be made publicly available.

</details>


### [23] [Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05909)
*Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui*

Main category: cs.CL

TL;DR: 提出了可分离分析检索与生成协同的新方法SPS，并设计了提升性能的控制框架xCompress，经大量实验验证了其有效性及适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法评估整合了检索器和生成器，难以单独衡量检索环节的作用，且LLMs作为生成器存在提示敏感性，导致贡献不易区分。

Method: 提出一种新的度量方法Spectrum Projection Score (SPS)，通过无监督地比较生成token和生成器（reader）隐空间的主方向，实现衡量检索摘要与LLM内部语义的一致性。此外，基于SPS提出xCompress框架，在推理阶段动态采样、排序和压缩检索摘要候选。

Result: 在五个QA基准与四种开源LLM上实验，SPS提升了模型在多类任务上的性能；同时SPS为RAG两环节（检索与生成）关系提供了理论视角。

Conclusion: SPS作为轻量级、无监督的新指标，有效刻画了检索内容和生成效果的关联性，并通过xCompress提升了RAG整体表现，对LLM生成和检索协同具有理论与实际意义。

Abstract: Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

</details>


### [24] [Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale](https://arxiv.org/abs/2508.05938)
*Rafal Kocielnik,Min Kim,Penphob,Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 提出三阶段混合人机流程，用于高效精准地识别文本中的亲社会内容，显著减少标注和计算成本，可为AI信任与安全新任务提供参考。


<details>
  <summary>Details</summary>
Motivation: 文本中亲社会性（即旨在肯定、支持或改善他人行为的交流）检测越来越受到信任与安全系统的重视，但相比有毒内容检测，亲社会性缺乏明确的定义和标注数据，亟需新的方法来实现自动检测与应用。

Method: 提出了一个实际的三阶段流程。第一阶段利用少量人工标注数据，选择最佳的基于大模型LLM的标注策略；第二阶段引入人机互动修正流程，让标注者针对GPT-4和人工判断分歧大的样本进行复审，迭代完善任务定义和标准；第三阶段使用GPT-4生成高质量大规模标注（1万条），并训练两阶段推理系统：轻量级分类器负责高置信度预测，约35%的模糊实例交由GPT-4o处理。

Result: 在人力标注投入和推理计算成本最小化的前提下，系统实现了高精度（约0.90）亲社会性内容分类，并通过合理的系统设计将推理成本降低约70%。

Conclusion: 本文展示了有针对性的人机协作、高质量任务定义和面向实际部署的系统架构，能够推动亲社会性等新兴负责任AI任务实现规模化、低成本、高精度落地。

Abstract: Detecting prosociality in text--communication intended to affirm, support, or
improve others' behavior--is a novel and increasingly important challenge for
trust and safety systems. Unlike toxic content detection, prosociality lacks
well-established definitions and labeled data, requiring new approaches to both
annotation and deployment. We present a practical, three-stage pipeline that
enables scalable, high-precision prosocial content classification while
minimizing human labeling effort and inference costs. First, we identify the
best LLM-based labeling strategy using a small seed set of human-labeled
examples. We then introduce a human-AI refinement loop, where annotators review
high-disagreement cases between GPT-4 and humans to iteratively clarify and
expand the task definition-a critical step for emerging annotation tasks like
prosociality. This process results in improved label quality and definition
alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train
a two-stage inference system: a lightweight classifier handles high-confidence
predictions, while only $\sim$35\% of ambiguous instances are escalated to
GPT-4o. This architecture reduces inference costs by $\sim$70% while achieving
high precision ($\sim$0.90). Our pipeline demonstrates how targeted human-AI
interaction, careful task formulation, and deployment-aware architecture design
can unlock scalable solutions for novel responsible AI tasks.

</details>


### [25] [Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring](https://arxiv.org/abs/2508.05987)
*Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu*

Main category: cs.CL

TL;DR: 本研究通过提出新的对抗性主题感知Prompt调优方法（ATOP），首次联合学习主题共享与特有特征，有效提升了跨主题自动作文评分准确性，在公开数据集上取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 跨主题自动作文评分（AES）模型在目标主题下有转移能力，但不同主题间存在固有分布差异，现有方法多关注于主题间的共同特征抽取，忽略了对主题特有特征的挖掘，影响了模型对主题相关性等重要指标的评估能力。

Method: 提出了一种对抗性主题感知Prompt调优方法（ATOP），联合学习主题共享与特有特征。该方法基于可学习的主题感知Prompt（包括共享与特定组件），结合预训练语言模型对知识进行引出，通过对抗训练提升共享Prompt的鲁棒性，统一回归和分类任务。还采用邻域分类器针对目标主题生成伪标签，用于指导特有Prompt的有监督学习。

Result: 在ASAP++公开数据集上，ATOP在整体和多特征作文评分指标上均显著优于现有主流方法。

Conclusion: 提出的ATOP方法有效提升了跨主题自动作文评分的准确性和泛化能力，能够更好地兼顾主题共同与特有特征。

Abstract: Cross-topic automated essay scoring (AES) aims to develop a transferable
model capable of effectively evaluating essays on a target topic. A significant
challenge in this domain arises from the inherent discrepancies between topics.
While existing methods predominantly focus on extracting topic-shared features
through distribution alignment of source and target topics, they often neglect
topic-specific features, limiting their ability to assess critical traits such
as topic adherence. To address this limitation, we propose an Adversarial
TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns
topic-shared and topic-specific features to improve cross-topic AES. ATOP
achieves this by optimizing a learnable topic-aware prompt--comprising both
shared and specific components--to elicit relevant knowledge from pre-trained
language models (PLMs). To enhance the robustness of topic-shared prompt
learning and mitigate feature scale sensitivity introduced by topic alignment,
we incorporate adversarial training within a unified regression and
classification framework. In addition, we employ a neighbor-based classifier to
model the local structure of essay representations and generate pseudo-labels
for target-topic essays. These pseudo-labels are then used to guide the
supervised learning of topic-specific prompts tailored to the target topic.
Extensive experiments on the publicly available ASAP++ dataset demonstrate that
ATOP significantly outperforms existing state-of-the-art methods in both
holistic and multi-trait essay scoring. The implementation of our method is
publicly available at: https://anonymous.4open.science/r/ATOP-A271.

</details>


### [26] [Crisp Attention: Regularizing Transformers via Structured Sparsity](https://arxiv.org/abs/2508.06016)
*Sagar Gandhi,Vishal Gandhi*

Main category: cs.CL

TL;DR: 通过在微调时给DistilBERT引入注意力稀疏，作者发现模型精度不仅没下降，反而提升，稀疏注意力还可能改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的二次计算成本限制了Transformer模型的可扩展性。虽然引入注意力稀疏性可以提升效率，但通常认为这会损害模型精度。作者希望验证这种假设是否一定成立。

Method: 在DistilBERT模型上，通过在情感分析任务（SST-2数据集）微调阶段后处理引入结构化注意力稀疏性，并评估其对模型精度的影响。

Result: 当注意力稀疏度达到80%时，模型在验证集上达到91.59%的准确率，比稠密基线模型高0.97%。

Conclusion: 注意力稀疏性不仅能带来计算效率，有时还可能作为隐式正则化器提升模型泛化能力和性能。

Abstract: The quadratic computational cost of the self-attention mechanism is a primary
challenge in scaling Transformer models. While attention sparsity is widely
studied as a technique to improve computational efficiency, it is almost
universally assumed to come at the cost of model accuracy. In this paper, we
report a surprising counter-example to this common wisdom. By introducing
structured, post-hoc sparsity to the attention mechanism of a DistilBERT model
during fine-tuning on the SST-2 sentiment analysis task, we find that model
accuracy improves significantly. Our model with 80\% attention sparsity
achieves a validation accuracy of 91.59\%, a 0.97\% absolute improvement over
the dense baseline. We hypothesize that this phenomenon is due to sparsity
acting as a powerful implicit regularizer, preventing the model from
overfitting by forcing it to make predictions with a more constrained and
robust set of features. Our work recasts attention sparsity not just as a tool
for computational efficiency, but as a potential method for improving the
generalization and performance of Transformer models.

</details>


### [27] [Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future](https://arxiv.org/abs/2508.06026)
*Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.CL

TL;DR: 针对自我奖励语言模型学习信号逐渐消失的问题，论文提出利用过去和未来模型输出对样本进行锚定与选择的方法（时间自我奖励模型），大幅提升语言模型的效果和泛化能力，并在多种任务和主流模型上表现显著优越。


<details>
  <summary>Details</summary>
Motivation: 现有的自我奖励语言模型在优化偏好学习时存在局限性。具体来说，随着模型生成能力的同步提升，选择的和拒绝的样本间差异变小，导致偏好信号逐渐消失，影响学习效果。

Method: 提出了时间自我奖励语言模型（Temporal Self-Rewarding Language Models），通过协调模型代际（过去、现在、未来）的生成结果，持续维持有效的学习信号。该方法包括：（1）锚定拒绝（Anchored Rejection）：用过去初始模型的输出作为拒绝样本；（2）未来导向选择（Future-Guided Chosen）：用下一代模型动态生成选择样本。

Result: 在Llama、Qwen、Mistral三大家族和不同规模（Llama3B/8B/70B）的模型上进行了大量实验，对比同样计算资源下的自我奖励基线。以Llama3.1-8B为例，AlpacaEval 2.0胜率提升至29.44，显著高于基线的19.69。同时，在数学推理（GSM8K）、知识问答（ARC、TruthfulQA）和代码生成（HumanEval）等分布外任务中也有更好的泛化能力，无需专门收集训练数据。

Conclusion: 本研究针对自我奖励语言模型学习信号衰减问题，提出并验证了时间自我奖励框架，有效提升了模型性能和泛化能力。

Abstract: Self-Rewarding Language Models propose an architecture in which the Large
Language Models(LLMs) both generates responses and evaluates its own outputs
via LLM-as-a-Judge prompting, dynamically improving its generative capabilities
through iterative Direct Preference Optimization (DPO). However, our analysis
reveals a critical limitation in existing Self-Rewarding paradigms: the
synchronized improvement of chosen and rejected responses progressively narrows
the representational difference between contrasting samples, undermining
effective preference learning. We propose \textbf{Temporal Self-Rewarding
Language Models} that strategically coordinate past, present, and future model
generations to sustain learning signals. Our dual-phase framework introduces:
(1) \textit{Anchored Rejection} - fixing rejected responses using the past
initial model's outputs and (2) \textit{Future-Guided Chosen} - dynamically
curating chosen samples using next-generation model predictions. Extensive
experiments across three model families (Llama, Qwen, Mistral) and different
model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained
with our method compared to Self-Rewarding using same computation resources.
For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our
method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our
method also demonstrates superior out-of-distribution generalization across
mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code
generation (HumanEval) tasks, even though we do not specifically collect such
training data.

</details>


### [28] [Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings](https://arxiv.org/abs/2508.06030)
*Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar*

Main category: cs.CL

TL;DR: 本文提出利用预训练文本嵌入模型作为代理，通过简单微调即可高效推断LLM知识分布，在多个数据集和模型上预测准确率达90%。该方法计算成本低，可用于大规模知识评估和内部机理分析。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成式预训练过程中掌握了大量跨领域的知识，但由于其随机性，目前难以准确预测它们具体掌握了哪些知识。以往探测LLM知识的方法多依赖模型正向推理，计算代价高、耗时长，这限制了大规模知识评估的可能性。

Method: 作者提出了PEEK方法：通过利用预训练的文本或图结构嵌入模型作为LLM的知识代理。流程为：首先利用已有的探测方法确定LLM已知的事实训练集；然后用一个线性解码层将嵌入模型微调，使其可以预测LLM输出，从而推断LLM掌握的知识。

Result: 在3个维基百科衍生数据集、4个LLM以及7个嵌入模型上的评估显示，这种基于嵌入的代理方法能在留出测试集上高达90%的准确率预测LLM知识。进一步发现，相比于图嵌入模型，句子嵌入模型更适合充当LLM知识代理。

Conclusion: 知识适配后的嵌入模型可用于大规模识别LLM的知识盲点，并帮助探索LLM内在的归纳偏置机制。

Abstract: Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

</details>


### [29] [EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](https://arxiv.org/abs/2508.06046)
*Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang*

Main category: cs.CL

TL;DR: 作者提出EvolvR框架，通过自进化多智能体策略生成高质量推理链数据，训练更强的故事评估模型，不仅在评测基准上取得最好成绩，还促进了故事生成的提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评判方法在故事类开放性任务中性能受限。现有closed-source模型的prompt工程适应性差，open-source模型微调方法缺乏严格推理，急需兼具高推理能力与适应性的评估方法。

Method: 提出自进化成对推理（EvolvR）框架，通过多角色策略自合成与分数对齐的CoT数据，再经多智能体自过滤，最后用精炼后数据训练评估模型，并将其作为奖励模型指导故事生成。

Result: EvolvR 在StoryER、HANNA、OpenMEVA等评测基准取得SOTA表现，同时作为奖励模型显著提升了生成故事的质量。

Conclusion: EvolvR 框架作为评估者在多个故事评测基准上达到SOTA，并显著提升故事生成的质量，有效验证了其自进化方法的优越性。

Abstract: Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

</details>


### [30] [ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline](https://arxiv.org/abs/2508.06094)
*Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš*

Main category: cs.CL

TL;DR: 本文提出 ConlangCrafter，基于大模型通过多阶段流程自动生成构造语言，无需人工参与，能创作出连贯和多样的虚构语言。


<details>
  <summary>Details</summary>
Motivation: 构造语言在艺术、哲学和国际交流等领域具有多样作用，但传统构造方法对人工语言学知识要求高。随着大模型在创作领域的革命性进展，探索其在自动化创造构造语言过程中的潜能具有重要意义。

Method: 提出了 ConlangCrafter，多阶段管道利用大模型在音系、形态、句法、词汇等模块化流程中，结合随机性与自我反馈机制，实现端到端的构造语言生成。

Result: 系统在连贯性与类型学多样性指标上表现良好，证明其可生成连贯且多样化的构造语言。

Conclusion: ConlangCrafter 能够在没有人工语言学专业知识的情况下，利用大模型自动生成连贯且多样的构造语言。

Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

</details>


### [31] [Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs](https://arxiv.org/abs/2508.06103)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 通过专门为阿拉伯语古兰经问答设计的少样本指令提示和后处理系统，显著提升了大型语言模型的答案准确率和鲁棒性，特别适合处理语义复杂、低资源的抽取式问答任务。


<details>
  <summary>Details</summary>
Motivation: 古兰经文本具有复杂语言、独特术语和深层含义，常规问答系统难以高效处理。因此，研究面向语义丰富、低资源场景的抽取式问答方法至关重要。

Method: 提出两种方法：一是少样本指令提示微调（few-shot prompting with instruction-tuned LLMs），如Gemini和DeepSeek；二是开发专门的阿拉伯语提示框架用于答案片段抽取，并辅以强大的后处理系统，包括子词对齐、重叠抑制和语义过滤。

Result: 所提指令微调的LLMs在评测中优于传统微调模型，最佳配置pAP10得分为0.637，说明开发的方法在语义丰富问答任务上表现有效。

Conclusion: 基于指令微调的大型语言模型（LLMs）在古兰经的抽取式问答任务中表现优于传统微调模型。提出的方法可显著提升准确率并减少幻觉发生。

Abstract: This paper presents two effective approaches for Extractive Question
Answering (QA) on the Quran. It addresses challenges related to complex
language, unique terminology, and deep meaning in the text. The second uses
few-shot prompting with instruction-tuned large language models such as Gemini
and DeepSeek. A specialized Arabic prompt framework is developed for span
extraction. A strong post-processing system integrates subword alignment,
overlap suppression, and semantic filtering. This improves precision and
reduces hallucinations. Evaluations show that large language models with Arabic
instructions outperform traditional fine-tuned models. The best configuration
achieves a pAP10 score of 0.637. The results confirm that prompt-based
instruction tuning is effective for low-resource, semantically rich QA tasks.

</details>


### [32] [You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures](https://arxiv.org/abs/2508.06105)
*Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang*

Main category: cs.CL

TL;DR: LogicRAG是一种无需预建图的逻辑感知型RAG方法。它按需构建逻辑依赖结构、优化检索顺序，并剪枝冗余信息，从而明显提升了多步推理的性能和效率，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）在处理超出其知识范围的问题时，常常出现“幻觉”，生成事实不准确的内容。尽管检索增强生成（RAG）可通过知识库检索相关信息来支持推理，现有基于图的RAG方法却需要高昂的代价来建立图结构，且不易适应不同类型与复杂度的查询。预先构建的图也无法针对不同问题提供最合适的逻辑结构，导致检索效果不理想。

Method: 提出了LogicRAG框架，在推理阶段动态提取逻辑结构以指导检索，无需预先构建图。具体方法为：将输入问题分解为子问题，并通过构建有向无环图（DAG）来建模它们之间的逻辑依赖；再利用拓扑排序实现逻辑一致的多步推理；通过图剪枝和上下文剪枝减少冗余检索和无关内容，从而大幅降低token消耗。

Result: 实验表明，LogicRAG在性能和效率上均优于现有最先进的基线方法，既提高了推理质量，也有效控制了计算资源消耗。

Conclusion: LogicRAG通过动态逻辑结构建模与剪枝策略，有效解决了传统GraphRAG在灵活性和资源消耗上的瓶颈，为复杂问题提供了更精准且高效的推理和检索方案。

Abstract: Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

</details>


### [33] [AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models](https://arxiv.org/abs/2508.06124)
*Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee*

Main category: cs.CL

TL;DR: 本文提出了AURA框架，利用过程奖励模型，结合自我批判和安全解码机制，有效提升了大语言模型推理中的安全性和逻辑性，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在处理基于可供性（affordance）的安全风险方面存在挑战，即模型输出可能因忽视某些逻辑推断而意外促使有害行为。传统的安全解决方案（如基于结果的奖励模型、参数调节或启发式解码策略）无法细致且主动地检测和干预这些关键推理环节。

Method: 提出了一种创新的多层次框架AURA，核心为过程奖励模型（Process Reward Models, PRM），通过逻辑一致性和安全意识在每一步进行全面评估。该框架融合自我反思、细致的PRM评估和自适应的安全解码方法，以动态引导模型安全推理。

Result: 实验证据表明，该方法在模型输出的逻辑完整性和基于可供性的安全性方面显著优于现有方法。

Conclusion: AURA框架为大语言模型实现更安全、负责任和环境感知的推理提供了重要进展，并为对齐敏感型应用设立了新标杆。

Abstract: Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

</details>


### [34] [Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2508.06135)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: SRD是一种针对KD训练数据筛选优化的新方法，通过自动反思和课程学习，实现更快且更有效的大语言模型压缩，提升模型表现并显著降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）在压缩大语言模型（LLMs）为高效的小模型时起着关键作用，但现有方法主要平衡真实标签与学生模型生成的响应，忽略了训练数据质量和学生模型兼容性。作者旨在解决这两个核心问题，提升蒸馏效率和效果。

Method: 提出了Selective Reflection Distillation（SRD）框架：利用学生模型对训练数据的“反思”动态筛选高质量、与学生模型兼容的训练样本。具体做法是比较真实标签与学生模型输出进行自动难度排序，依此选择样本，并采用课程学习策略分批引入样本到蒸馏流程中。SRD作为即插即用模块，不改动原有KD算法，仅优化数据选择与调度。

Result: SRD在多种语言模型基准和KD方法下均带来一致的性能提升，同时最多可减少39%的训练时间。SRD提升了样本效率和模型表现，并在不同模型架构下适用。

Conclusion: 训练数据质量与模型兼容性对蒸馏效果至关重要。SRD框架为高质量、兼容性训练数据选择和调度提供可行方案，显著增强了KD性能与效率。该方法加深了对数据驱动KD的理解，并为压缩LLMs提供了实际改进路径。

Abstract: Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

</details>


### [35] [Scaling Personality Control in LLMs with Big Five Scaler Prompts](https://arxiv.org/abs/2508.06149)
*Gunhee Cho,Yun-Gyung Cheong*

Main category: cs.CL

TL;DR: Big5-Scaler能通过修改提示词，无需训练，精准控制LLM的大五人格特质，是构建个性化对话系统的高效工具。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）在个性化方面受限，希望通过更高效的方法实现对模型性格特质的细粒度可控，尤其是基于大五人格模型。

Method: 提出Big5-Scaler框架，将数值化的人格特质嵌入自然语言提示词，无需额外训练，即可实现对LLM的性格特质精准调控。

Result: 在性格表达、对话生成以及模仿人类性格特质等任务上进行评估，Big5-Scaler能稳定、有区分度地诱导模型展现不同性格特质，不同提示类型与强度影响表现。简洁提示语和较低特质强度效果更佳。

Conclusion: Big5-Scaler是一种高效且无需再训练的方法，用于让对话智能体更好地具备和展现个性特征，对构建具备人格意识的对话代理有重要意义。

Abstract: We present Big5-Scaler, a prompt-based framework for conditioning large
language models (LLMs) with controllable Big Five personality traits. By
embedding numeric trait values into natural language prompts, our method
enables fine-grained personality control without additional training. We
evaluate Big5-Scaler across trait expression, dialogue generation, and human
trait imitation tasks. Results show that it induces consistent and
distinguishable personality traits across models, with performance varying by
prompt type and scale. Our analysis highlights the effectiveness of concise
prompts and lower trait intensities, providing a efficient approach for
building personality-aware dialogue agents.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [36] [Sandwich Monotonicity and the Recognition of Weighted Graph Classes](https://arxiv.org/abs/2508.06216)
*Jesse Beisegel,Nina Chiarelli,Ekkehard Köhler,Matjaž Krnc,Martin Milanič,Nevena Pivač,Robert Scheffler,Martin Strehler*

Main category: cs.DM

TL;DR: 本文提出了利用度夹心单调性质，通过边消除顺序，对分裂图、阈值图和链图等类别的加权图进行线性时间识别。还为更一般的图类识别算法提供了充要条件。


<details>
  <summary>Details</summary>
Motivation: 加权图在Robinsonian矩阵和相似性理论中具有重要作用，特别是通过层次图的概念。作者希望探索如何将无权图的某个类别自然地扩展到加权图，并基于所有层次图属于某一类别进行分类识别。

Method: 引入“度夹心单调图类”的概念，通过定义“夹心单调性”和“度夹心单调性”，研究这些属性对加权图的层次图识别问题。利用特殊的边消除顺序，实现对所有层次图为分裂图、阈值图或链图的加权图进行线性时间识别。

Result: 证明了所有层次图为分裂图、阈值图或链图的加权图可通过线性时间算法识别，并提出了针对任意度夹心单调且包含空图的无权图类，对其加权版本给出线性时间识别的充要条件。

Conclusion: 使用度夹心单调的思想，可以高效地识别在特定无权图类基础上扩展的加权图类，并且这种方法对于分裂图、阈值图和链图表现出良好的识别效率（线性时间）。同样为更广泛的图类线性时间识别算法提供了理论基础。

Abstract: Edge-weighted graphs play an important role in the theory of Robinsonian
matrices and similarity theory, particularly via the concept of level graphs,
that is, graphs obtained from an edge-weighted graph by removing all
sufficiently light edges. This suggest a natural way of associating to any
class $\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted
graphs, namely by requiring that all level graphs belong to $\mathcal{G}$. We
show that weighted graphs for which all level graphs are split, threshold, or
chain graphs can be recognized in linear time using special edge elimination
orderings. We obtain these results by introducing the notion of degree sandwich
monotone graph classes. A graph class $\mathcal{G}$ is sandwich monotone if
every edge set which may be removed from a graph in $\mathcal{G}$ without
leaving the class also contains a single edge that can be safely removed.
Furthermore, if we require the safe edge to fulfill a certain degree property,
then $\mathcal{G}$ is called degree sandwich monotone. We present necessary and
sufficient conditions for the existence of a linear-time recognition algorithm
for any weighted graph class whose corresponding unweighted class is degree
sandwich monotone and contains all edgeless graphs.

</details>


### [37] [On Approximate MMS Allocations on Restricted Graph Classes](https://arxiv.org/abs/2508.06343)
*Václav Blažej,Michał Dębski ad Zbigniew Lonc,Marta Piecyk,Paweł Rzążewski*

Main category: cs.DM

TL;DR: 本文系统性研究了带连通约束下不可分割物品分配的公平性，证明了多类典型图结构上存在连通的近似maximin share分配，推动了相关理论进展。


<details>
  <summary>Details</summary>
Motivation: 论文考虑在存在连通性约束时，将不可分割物品公平分配给多个代理的问题。具体来说，物品被表示为连通图的顶点，每个代理获得的物品集合必须为该图的连通子图。此前研究表明，即使没有连通性约束（即物品图为完全图），满足maximin share标准的分配可能也不存在，因此迫切需要研究近似分配方法。

Method: 论文在各类受限图结构（如块图、仙人掌图、完全多部图和分割图）下，系统性地研究了是否存在近似maximin share分配。方法上，结合图论与分配算法，证明了在这些特定图结构下，能够为每个代理分配价值至少为maximin share常数倍且连通的物品子集。

Result: 论文证明了上述特殊类型的图（块图、仙人掌图、完全多部图和分割图）都存在连通的近似maximin share分配。这为该领域内更广泛图结构的可行性研究提供了新进展。

Conclusion: 对于许多特殊的图结构，本文证明了可以实现具备连通性的近似maximin share分配，但在所有一般图上的存在性问题仍未解决。

Abstract: We study the problem of fair division of a set of indivisible goods with
connectivity constraints. Specifically, we assume that the goods are
represented as vertices of a connected graph, and sets of goods allocated to
the agents are connected subgraphs of this graph. We focus on the
widely-studied maximin share criterion of fairness. It has been shown that an
allocation satisfying this criterion may not exist even without connectivity
constraints, i.e., if the graph of goods is complete. In view of this, it is
natural to seek approximate allocations that guarantee each agent a connected
bundle of goods with value at least a constant fraction of the maximin share
value to the agent. It is known that for some classes of graphs, such as
complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such
approximate allocations indeed exist. However, it is an open problem whether
they exist for the class of all graphs.
  In this paper, we continue the systematic study of the existence of
approximate allocations on restricted graph classes. In particular, we show
that such allocations exist for several well-studied classes, including block
graphs, cacti, complete multipartite graphs, and split graphs.

</details>
