{"id": "2506.15174", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.15174", "abs": "https://arxiv.org/abs/2506.15174", "authors": ["Hossein Albakri", "Kazem Cheshmi"], "title": "A Novel Compiler Transformation for Fast Sparse Matrix Multiplication in GPUs", "comment": null, "summary": "Sparse data structures are commonly used in neural networks to reduce the\nmemory footprint. These data structures are compact but cause irregularities\nsuch as random memory accesses, which prevent efficient use of the memory\nhierarchy. GPUs are a common platform for machine learning practitioners, but\nrunning compact data structures on these devices often leads to slow-downs due\nto inefficient use of computing and memory resources. This paper proposes a new\ncompiler transformation, enumerate-and-sparse-coarsen, that accelerates sparse\nmatrix-matrix multiplication (SPMM) on GPU devices. The transformation\nincreases data reuse in registers and caches while creating more balanced\nworkloads for GPU computing resources. The transformation is tested on sparse\nneural networks in convolutional and transformer models. On an A100 GPU and\nacross a columns of matrix B (bCols) in $ A \\times B = C$ from range of 32 to\n128, the transformation yields a geometric mean speedup of 1.84$\\times$ to\n2.27$\\times$ compared to cuBLAS and cuSPARSE baselines, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7f16\u8bd1\u5668\u53d8\u6362\u65b9\u6cd5\uff08enumerate-and-sparse-coarsen\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86GPU\u4e0a\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7684\u6548\u7387\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u573a\u666f\u4e2d\u76f8\u8f83\u4e3b\u6d41\u5de5\u5177\u63d0\u5347\u4e86\u7ea62\u500d\u6027\u80fd\u3002", "motivation": "\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u4e3a\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u7ecf\u5e38\u91c7\u7528\u7a00\u758f\u6570\u636e\u7ed3\u6784\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u5185\u5b58\u8bbf\u95ee\u4e0d\u89c4\u5219\uff0c\u9650\u5236\u4e86GPU\u7b49\u786c\u4ef6\u5e73\u53f0\u7684\u6548\u7387\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u9ad8\u6548\u5229\u7528GPU\u6267\u884c\u7a00\u758f\u6570\u636e\u7ed3\u6784\u64cd\u4f5c\u662f\u4e00\u4e2a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u8bd1\u5668\u53d8\u6362\u65b9\u6cd5\u2014\u2014enumerate-and-sparse-coarsen\uff0c\u7528\u4e8e\u52a0\u901fGPU\u4e0a\u7684\u7a00\u758f\u77e9\u9635-\u77e9\u9635\u4e58\u6cd5\uff08SPMM\uff09\u3002\u8be5\u65b9\u6cd5\u589e\u52a0\u6570\u636e\u5728\u5bc4\u5b58\u5668\u548c\u7f13\u5b58\u4e2d\u7684\u590d\u7528\uff0c\u5e76\u4e3aGPU\u8ba1\u7b97\u8d44\u6e90\u521b\u5efa\u66f4\u5747\u8861\u7684\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u5728A100 GPU\u4e0a\uff0c\u5bf9\u7a00\u758f\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u548cTransformer\u6a21\u578b\u6d4b\u8bd5\uff0c\u77e9\u9635B\u5217\u6570\u8303\u56f432\u5230128\u65f6\uff0c\u8be5\u65b9\u6cd5\u6bd4cuBLAS\u548ccuSPARSE\u57fa\u7ebf\u5206\u522b\u53d6\u5f97\u4e861.84\u500d\u548c2.27\u500d\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\u3002", "conclusion": "\u63d0\u51fa\u7684\u7f16\u8bd1\u5668\u8f6c\u6362\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86GPU\u4e0a\u7a00\u758f\u77e9\u9635\u8fd0\u7b97\u7684\u901f\u5ea6\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u7a00\u758f\u795e\u7ecf\u7f51\u7edc\u9ad8\u6548\u6267\u884c\u63d0\u4f9b\u4e86\u65b0\u7684\u786c\u4ef6\u652f\u6301\u601d\u8def\u3002"}}
{"id": "2506.15424", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.15424", "abs": "https://arxiv.org/abs/2506.15424", "authors": ["Michael Mendler", "Marc Pouzet"], "title": "PSM: Policy Synchronised Deterministic Memory", "comment": "This report summarises work on coding the theory of\n  policy-synchronised memory (see https://rdcu.be/erBwl) in Haskell. This was\n  developed for a graduate level course on Functional Reactive Programming\n  taught at Bamberg University by the first author during 2020-2023. An early\n  version of the PSM library had been presented at the SYNCHRON Workshop\n  (Aussois, France), November 2019", "summary": "Concurrency and determinacy do not go well with each other when resources\nmust be shared. Haskell provides parallel programming abstractions such as IVar\nand LVar in the Par monad and concurrent abstractions such as MVar and TVar in\nthe in IO and STM monads, respectively. The former are determinate but have no\ndestructive updates and the latter have destructive updates but do not\nguarantee determinacy. Programming patterns that are both concurrent and\ndeterminate, such as those provided by Kahn or Berry require memory\nabstractions at a higher level than is currently available. In this paper we\ndescribe a new type context PSM for policy synchronised memory in Haskell. Like\nSTM and IO, the computations in PSM can access persistent state and, as a\nside-effect, update the memory in imperative style. Like the Par and IO monads,\nPSM supports concurrent threads and shared state. However, in contrast to IO,\nour PSM contexts are race-free since concurrent accesses are policy coordinated\nwhich guarantees determinacy.Well-typed transactions in the PSM context can\naccommodate abstract data structures that are imperative, concurrently\nshareable and still behave deterministically, by construction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PSM\u7c7b\u578b\u4e0a\u4e0b\u6587\uff0c\u4e3aHaskell\u5e26\u6765\u4e00\u79cd\u65b0\u7684\u5e76\u53d1\u7f16\u7a0b\u673a\u5236\uff0c\u80fd\u591f\u540c\u65f6\u4fdd\u8bc1\u5e76\u53d1\u6027\u3001\u547d\u4ee4\u5f0f\u5171\u4eab\u4e0e\u7ed3\u679c\u7684\u786e\u5b9a\u6027\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u5de5\u5177\u4e4b\u95f4\u96be\u4ee5\u517c\u987e\u7684\u96be\u9898\u3002", "motivation": "\u5728\u5177\u6709\u5171\u4eab\u8d44\u6e90\u7684\u5e76\u53d1\u7f16\u7a0b\u4e2d\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\uff08determinacy\uff09\u662f\u4e00\u5927\u96be\u9898\u3002Haskell \u73b0\u6709\u7684\u5e76\u53d1\u7f16\u7a0b\u62bd\u8c61\uff08\u5982IVar\u3001LVar\u3001MVar\u3001TVar\uff09\u5728\u786e\u5b9a\u6027\u548c\u53ef\u7834\u574f\u66f4\u65b0\u4e4b\u95f4\u96be\u4ee5\u517c\u987e\u3002\u73b0\u6709\u6a21\u5f0f\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u5e76\u53d1\u6027\u548c\u786e\u5b9a\u6027\uff0c\u4e14\u7f3a\u4e4f\u66f4\u9ad8\u5c42\u6b21\u7684\u5185\u5b58\u62bd\u8c61\u6765\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7c7b\u578b\u4e0a\u4e0b\u6587PSM\uff08policy synchronised memory\uff09\u7528\u4e8eHaskell\u3002PSM\u7ed3\u5408\u4e86STM\u548cIO\u7684\u6301\u4e45\u72b6\u6001\u8bbf\u95ee\uff0c\u4ee5\u53caPar\u548cIO\u7684\u5e76\u53d1\u7ebf\u7a0b\u53ca\u5171\u4eab\u72b6\u6001\uff0c\u4f7f\u7528\u653f\u7b56\u534f\u8c03\u7684\u65b9\u5f0f\u6765\u540c\u6b65\u5e76\u53d1\u8bbf\u95ee\uff0c\u4fdd\u8bc1\u4e8b\u52a1\u7684\u65e0\u7ade\u4e89\uff08race-free\uff09\u548c\u786e\u5b9a\u6027\u3002", "result": "PSM\u80fd\u8ba9\u62bd\u8c61\u6570\u636e\u7ed3\u6784\u5373\u5177\u5907\u547d\u4ee4\u5f0f\u3001\u5e76\u53d1\u5171\u4eab\u7684\u80fd\u529b\uff0c\u53c8\u80fd\u591f\u4fdd\u8bc1\u5176\u64cd\u4f5c\u7ed3\u679c\u7684\u786e\u5b9a\u6027\u3002\u7c7b\u578b\u6b63\u786e\u7684\u4e8b\u52a1\u80fd\u591f\u81ea\u52a8\u907f\u514d\u7ade\u6001\u6761\u4ef6\uff08race condition\uff09\uff0c\u4e14\u6613\u4e8e\u6784\u5efa\u540c\u65f6\u6ee1\u8db3\u5e76\u53d1\u6027\u548c\u786e\u5b9a\u6027\u7684\u7a0b\u5e8f\u3002", "conclusion": "PSM\u7c7b\u578b\u4e0a\u4e0b\u6587\u4e3aHaskell\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u5e76\u53d1\u5171\u4eab\u5185\u5b58\u73af\u5883\u4e0b\uff0c\u5b9e\u73b0\u65e2\u786e\u5b9a\u53c8\u547d\u4ee4\u5f0f\u62bd\u8c61\u6570\u636e\u7ed3\u6784\u7684\u652f\u6491\u65b9\u6cd5\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5e76\u53d1\u5de5\u5177\u65e0\u6cd5\u517c\u5f97\u5e76\u53d1\u6027\u4e0e\u786e\u5b9a\u6027\u7684\u7f3a\u9677\u3002"}}
{"id": "2506.15135", "categories": ["cs.SE", "cs.LO", "cs.PL", "F.3.1; F.1.2"], "pdf": "https://arxiv.org/pdf/2506.15135", "abs": "https://arxiv.org/abs/2506.15135", "authors": ["Zhengqun Koo"], "title": "Towards Bug-Free Distributed Go Programs", "comment": "Version 1. B.Comp. Dissertation", "summary": "Programmers of distributed systems need to reason about concurrency to avoid\nraces. However, reasoning about concurrency is difficult, and unexpected races\nshow up as bugs. Data race detection in shared memory systems is well-studied\n(dynamic data race detection [13], behavioral types [15], dynamic race\ndetection [31]). Similar to how a data race consists of reads and writes not\nrelated by happens-before at a shared memory location, a communication race\nconsists of receives and sends not related by happens-before on a shared\nchannel. Communication races are problematic: a receiver expects a specific\nmessage from a specific sender, but with a communication race, the receiver can\nreceive a message meant for another receiver, or not receive anything at all.\nIn this work, we describe a verification framework that can prove the absence\nof communication races for distributed programs that use a subset of the Go\nprogramming language, where synchronization is mainly achieved via message\npassing. We statically reason about how a distributed program executes, using a\nhappens-before order, extended to buffered and unbuffered channels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u9759\u6001\u68c0\u6d4bGo\u5206\u5e03\u5f0f\u7a0b\u5e8f\u901a\u4fe1\u7ade\u6001\u7684\u65b0\u578b\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c55happens-before\u987a\u5e8f\u5bf9\u6d88\u606f\u4f20\u9012\u8def\u5f84\u8fdb\u884c\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u7ade\u6001\u7684\u9759\u6001\u8bc1\u660e\u3002", "motivation": "\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u7a0b\u5e8f\u5458\u9700\u8981\u5904\u7406\u5e76\u53d1\u6027\u4ee5\u907f\u514d\u7ade\u6001\u6761\u4ef6\uff0c\u4f46\u5e76\u53d1\u63a8\u7406\u672c\u8eab\u5341\u5206\u56f0\u96be\uff0c\u7ade\u6001\u5f15\u53d1\u7684\u9519\u8bef\u5f88\u5e38\u89c1\u3002\u867d\u7136\u5728\u5171\u4eab\u5185\u5b58\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u7ade\u4e89\u68c0\u6d4b\u5df2\u6709\u6210\u719f\u7814\u7a76\uff0c\u4f46\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\uff0c\u6d88\u606f\u4f20\u9012\u4e2d\u7684\u901a\u4fe1\u7ade\u6001\u95ee\u9898\u540c\u6837\u4e25\u91cd\u4e14\u96be\u4ee5\u68c0\u6d4b\uff0c\u9700\u8981\u6709\u6548\u7684\u9759\u6001\u9a8c\u8bc1\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9a8c\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u8bc1\u660e\u4f7f\u7528Go\u8bed\u8a00\u5b50\u96c6\uff08\u4ee5\u6d88\u606f\u4f20\u9012\u4e3a\u4e3b\u540c\u6b65\u624b\u6bb5\uff09\u7684\u5206\u5e03\u5f0f\u7a0b\u5e8f\u4e0d\u5b58\u5728\u901a\u4fe1\u7ade\u6001\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u9759\u6001\u5206\u6790\u624b\u6bb5\uff0c\u57fa\u4e8ehappens-before\u987a\u5e8f\u6269\u5c55\u5230\u5e26\u7f13\u51b2\u4e0e\u4e0d\u5e26\u7f13\u51b2\u7684\u901a\u9053\uff0c\u63a8\u6f14\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\u4e2d\u7684\u4e8b\u4ef6\u987a\u5e8f\u3002", "result": "\u7528\u6240\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u4ee5\u5bf9\u7279\u5b9a\u7c7b\u578b\u7684Go\u5206\u5e03\u5f0f\u7a0b\u5e8f\u9759\u6001\u8bc1\u660e\u5176\u4e0d\u5b58\u5728\u901a\u4fe1\u7ade\u6001\uff0c\u4ece\u800c\u63d0\u5347\u7a0b\u5e8f\u6b63\u786e\u6027\uff0c\u964d\u4f4e\u56e0\u672a\u9884\u6599\u540c\u6b65\u884c\u4e3a\u5bfc\u81f4\u7684\u9519\u8bef\u98ce\u9669\u3002", "conclusion": "\u672c\u6587\u7684\u9759\u6001\u9a8c\u8bc1\u6846\u67b6\u80fd\u591f\u6709\u6548\u68c0\u6d4bGo\u6d88\u606f\u4f20\u9012\u7a0b\u5e8f\u4e2d\u7684\u901a\u4fe1\u7ade\u6001\uff0c\u4e3a\u5206\u5e03\u5f0f\u5e76\u53d1\u7a0b\u5e8f\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u5de5\u5177\u57fa\u7840\u3002"}}
{"id": "2506.14866", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14866", "abs": "https://arxiv.org/abs/2506.14866", "authors": ["Thomas Kuntz", "Agatha Duzan", "Hao Zhao", "Francesco Croce", "Zico Kolter", "Nicolas Flammarion", "Maksym Andriushchenko"], "title": "OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents", "comment": null, "summary": "Computer use agents are LLM-based agents that can directly interact with a\ngraphical user interface, by processing screenshots or accessibility trees.\nWhile these systems are gaining popularity, their safety has been largely\noverlooked, despite the fact that evaluating and understanding their potential\nfor harmful behavior is essential for widespread adoption. To address this gap,\nwe introduce OS-Harm, a new benchmark for measuring safety of computer use\nagents. OS-Harm is built on top of the OSWorld environment and aims to test\nmodels across three categories of harm: deliberate user misuse, prompt\ninjection attacks, and model misbehavior. To cover these cases, we create 150\ntasks that span several types of safety violations (harassment, copyright\ninfringement, disinformation, data exfiltration, etc.) and require the agent to\ninteract with a variety of OS applications (email client, code editor, browser,\netc.). Moreover, we propose an automated judge to evaluate both accuracy and\nsafety of agents that achieves high agreement with human annotations (0.76 and\n0.79 F1 score). We evaluate computer use agents based on a range of frontier\nmodels - such as o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro - and provide\ninsights into their safety. In particular, all models tend to directly comply\nwith many deliberate misuse queries, are relatively vulnerable to static prompt\ninjections, and occasionally perform unsafe actions. The OS-Harm benchmark is\navailable at https://github.com/tml-epfl/os-harm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faOS-Harm\u57fa\u51c6\uff0c\u9996\u6b21\u7cfb\u7edf\u6d4b\u8bd5\u7535\u8111\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u6db5\u76d6\u7528\u6237\u8bef\u7528\u3001\u653b\u51fb\u548c\u6a21\u578b\u5931\u8bef\u3002\u8bc4\u6d4b\u7ed3\u679c\u8b66\u793a\u73b0\u6709\u7cfb\u7edf\u5b89\u5168\u9690\u60a3\u4e25\u91cd\u3002", "motivation": "\u867d\u7136LLM\u9a71\u52a8\u7684\u201ccomputer use agents\u201d\u5728\u81ea\u52a8\u4e0e\u56fe\u5f62\u754c\u9762\u4ea4\u4e92\u65b9\u9762\u8d8a\u6765\u8d8a\u6d41\u884c\uff0c\u4f46\u5173\u4e8e\u5176\u5b89\u5168\u6027\u5c24\u5176\u662f\u5176\u6f5c\u5728\u5371\u5bb3\u7684\u8bc4\u4f30\u5374\u88ab\u5ffd\u89c6\u4e86\u3002\u4e3a\u4e86\u5b9e\u73b0\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u8fd9\u4e9b\u7cfb\u7edf\u5728\u9762\u5bf9\u7528\u6237\u8bef\u7528\u3001\u653b\u51fb\u7b49\u60c5\u51b5\u4e0b\u7684\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u65b0\u57fa\u51c6OS-Harm\uff0c\u57fa\u4e8eOSWorld\u73af\u5883\u8bbe\u8ba1\uff0c\u65e8\u5728\u6d4b\u8bd5\u7535\u8111\u4f7f\u7528\u4ee3\u7406\u5728\u6076\u610f\u7528\u6237\u64cd\u4f5c\u3001\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u548c\u6a21\u578b\u81ea\u8eab\u4e0d\u826f\u884c\u4e3a\u4e09\u4e2a\u65b9\u9762\u7684\u5b89\u5168\u6027\u3002\u57fa\u51c6\u5171\u5305\u542b150\u4e2a\u6db5\u76d6\u591a\u79cd\u5b89\u5168\u8fdd\u89c4\uff08\u5982\u9a9a\u6270\u3001\u7248\u6743\u4fb5\u72af\u7b49\uff09\u7684\u4efb\u52a1\uff0c\u6d89\u53ca\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf\u5e94\u7528\u3002\u8fd8\u8bbe\u8ba1\u4e86\u81ea\u52a8\u8bc4\u5224\u673a\u5236\uff0c\u5728\u7cbe\u5ea6\u548c\u5b89\u5168\u5224\u522b\u4e0a\u4e0e\u4eba\u5de5\u6807\u6ce8\u9ad8\u5ea6\u4e00\u81f4\u3002", "result": "\u901a\u8fc7OS-Harm\u57fa\u51c6\u5bf9\u591a\u79cd\u524d\u6cbf\u6a21\u578b\u7684\u4ee3\u7406\uff08\u5982o4-mini\u3001Claude 3.7 Sonnet\u3001Gemini 2.5 Pro\uff09\u8fdb\u884c\u5b89\u5168\u80fd\u529b\u8bc4\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\uff1a\u6240\u6709\u6a21\u578b\u5728\u9762\u5bf9\u7528\u6237\u6076\u610f\u8bf7\u6c42\u65f6\u666e\u904d\u987a\u4ece\uff0c\u5bb9\u6613\u906d\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4e14\u5076\u53d1\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "conclusion": "OS-Harm\u4e3a\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u8bc4\u4f30\u5e73\u53f0\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u4e3b\u6d41\u4ee3\u7406\u5b89\u5168\u6027\u4ecd\u5b58\u5728\u8f83\u5927\u9690\u60a3\u3002"}}
{"id": "2506.14900", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14900", "abs": "https://arxiv.org/abs/2506.14900", "authors": ["Imane Guellil", "Salom\u00e9 Andres", "Atul Anand", "Bruce Guthrie", "Huayu Zhang", "Abul Hasan", "Honghan Wu", "Beatrice Alex"], "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings", "comment": "Accepted and will be published at ACL2025 (main conference)", "summary": "In this work, we present a manually annotated corpus for Adverse Event (AE)\nextraction from discharge summaries of elderly patients, a population often\nunderrepresented in clinical NLP resources. The dataset includes 14 clinically\nsignificant AEs-such as falls, delirium, and intracranial haemorrhage, along\nwith contextual attributes like negation, diagnosis type, and in-hospital\noccurrence. Uniquely, the annotation schema supports both discontinuous and\noverlapping entities, addressing challenges rarely tackled in prior work. We\nevaluate multiple models using FlairNLP across three annotation granularities:\nfine-grained, coarse-grained, and coarse-grained with negation. While\ntransformer-based models (e.g., BERT-cased) achieve strong performance on\ndocument-level coarse-grained extraction (F1 = 0.943), performance drops\nnotably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly\nfor rare events and complex attributes. These results demonstrate that despite\nhigh-level scores, significant challenges remain in detecting underrepresented\nAEs and capturing nuanced clinical language. Developed within a Trusted\nResearch Environment (TRE), the dataset is available upon request via DataLoch\nand serves as a robust benchmark for evaluating AE extraction methods and\nsupporting future cross-dataset generalisation.", "AI": {"tldr": "\u8be5\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5173\u6ce8\u8001\u5e74\u60a3\u8005\u4e0d\u826f\u4e8b\u4ef6\u62bd\u53d6\u7684\u9ad8\u8d28\u91cf\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u8868\u660e\u5f53\u524dNLP\u6a21\u578b\u5728\u5904\u7406\u7ec6\u7c92\u5ea6\u548c\u7f55\u89c1\u4e8b\u4ef6\u65f6\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\u3002", "motivation": "\u8001\u5e74\u60a3\u8005\u5728\u4e34\u5e8aNLP\u8d44\u6e90\u4e2d\u5e38\u5e38\u88ab\u4f4e\u4f30\uff0c\u4e14\u5bf9\u4e8e\u4e0d\u826f\u4e8b\u4ef6\uff08AE\uff09\u7684\u62bd\u53d6\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u6d89\u53ca\u7f55\u89c1\u4e8b\u4ef6\u548c\u590d\u6742\u5c5e\u6027\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u624b\u5de5\u6ce8\u91ca\u7684\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u4ece\u8001\u5e74\u60a3\u8005\u7684\u51fa\u9662\u5c0f\u7ed3\u4e2d\u63d0\u53d614\u79cd\u4e34\u5e8a\u663e\u8457\u7684AE\uff0c\u5e76\u5305\u62ec\u5426\u5b9a\u3001\u8bca\u65ad\u7c7b\u578b\u3001\u4f4f\u9662\u65f6\u53d1\u751f\u7b49\u4e0a\u4e0b\u6587\u5c5e\u6027\u3002\u91c7\u7528\u53ef\u5904\u7406\u4e0d\u8fde\u7eed\u548c\u91cd\u53e0\u5b9e\u4f53\u7684\u6ce8\u91ca\u4f53\u7cfb\u3002\u7528FlairNLP\u6d4b\u8bd5\u4e86\u591a\u79cd\u6a21\u578b\uff0c\u5728\u4e09\u79cd\u4e0d\u540c\u7c92\u5ea6\uff08\u7ec6\u7c92\u5ea6\u3001\u7c97\u7c92\u5ea6\u3001\u5e26\u5426\u5b9a\u7684\u7c97\u7c92\u5ea6\uff09\u4e0a\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u3002", "result": "BERT\u7b49transformer\u6a21\u578b\u5728\u6587\u6863\u7ea7\u7c97\u7c92\u5ea6AE\u62bd\u53d6\u4e0a\u8868\u73b0\u5f3a\u52b2\uff08F1=0.943\uff09\uff0c\u4f46\u5728\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u7ea7\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff08\u5982F1=0.675\uff09\uff0c\u7279\u522b\u662f\u7f55\u89c1\u4e8b\u4ef6\u548c\u590d\u6742\u5c5e\u6027\u4e0a\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u5c3d\u7ba1\u5728\u9ad8\u5c42\u6b21\u62bd\u53d6\u4e0a\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u4f4e\u9891AE\u548c\u590d\u6742\u4e34\u5e8a\u8bed\u8a00\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002\u6570\u636e\u96c6\u53ef\u4f5c\u4e3a\u6807\u51c6\u6d4b\u8bd5\u96c6\u7528\u4e8e\u65b9\u6cd5\u8bc4\u4f30\u548c\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u7814\u7a76\u3002"}}
{"id": "2506.15532", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2506.15532", "abs": "https://arxiv.org/abs/2506.15532", "authors": ["Mikael Bisgaard Dahlsen-Jensen", "Baptiste Fievet", "Laure Petrucci", "Jaco van de Pol"], "title": "Controller Synthesis for Parametric Timed Games", "comment": "This is the full version of the paper under the same title accepted\n  to QEST+FORMATS 2025. 29 pages", "summary": "We present a (semi)-algorithm to compute winning strategies for parametric\ntimed games. Previous algorithms only synthesized constraints on the clock\nparameters for which the game is winning. A new definition of (winning)\nstrategies is proposed, and ways to compute them. A transformation of these\nstrategies to (parametric) timed automata allows for building a controller\nenforcing them. The feasibility of the method is demonstrated by an\nimplementation and experiments for the Production Cell case study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u53ef\u81ea\u52a8\u5408\u6210\u53c2\u6570\u65f6\u5e8f\u535a\u5f08\u83b7\u80dc\u7b56\u7565\u7684\u7b97\u6cd5\uff0c\u5e76\u80fd\u8f6c\u5316\u4e3a\u5b9e\u9645\u63a7\u5236\u5668\uff0c\u5f25\u8865\u4e86\u4ee5\u5f80\u53ea\u80fd\u5408\u6210\u83b7\u80dc\u53c2\u6570\u7684\u4e0d\u8db3\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\u3002", "motivation": "\u4ee5\u5f80\u7684\u65f6\u5e8f\u535a\u5f08\u53c2\u6570\u5408\u6210\u7b97\u6cd5\u53ea\u80fd\u6c42\u51fa\u5bf9\u4e8e\u83b7\u80dc\u7684\u53c2\u6570\uff0c\u4f46\u4e0d\u80fd\u76f4\u63a5\u5408\u6210\u7b56\u7565\u3002\u672c\u6587\u51fa\u4e8e\u81ea\u52a8\u5316\u63a7\u5236\u7cfb\u7edf\u9700\u8981\uff0c\u4e0d\u4ec5\u8981\u77e5\u9053\u4ec0\u4e48\u53c2\u6570\u53ef\u4ee5\u83b7\u80dc\uff0c\u8fd8\u8981\u53ef\u5b9e\u73b0\u83b7\u80dc\u7684\u63a7\u5236\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\uff08\u534a\uff09\u7b97\u6cd5\uff0c\u80fd\u591f\u8ba1\u7b97\u53c2\u6570\u65f6\u5e8f\u535a\u5f08\u7684\u83b7\u80dc\u7b56\u7565\u3002\u5f15\u5165\u65b0\u7684\u83b7\u80dc\u7b56\u7565\u5b9a\u4e49\uff0c\u5e76\u63d0\u51fa\u6c42\u89e3\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u7b56\u7565\u53ef\u8f6c\u6362\u4e3a\u53c2\u6570\u65f6\u5e8f\u81ea\u52a8\u673a\uff0c\u4ece\u800c\u80fd\u7528\u4e8e\u5b9e\u9645\u63a7\u5236\u5668\u8bbe\u8ba1\u3002\u901a\u8fc7\u5b9e\u9645\u5b9e\u4f8b\uff08Production Cell\u6848\u4f8b\uff09\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u57fa\u4e8e\u672c\u6587\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u5408\u6210\u53c2\u6570\u535a\u5f08\u7684\u5177\u4f53\u83b7\u80dc\u7b56\u7565\uff0c\u5e76\u4e14\u53ef\u4ee5\u8f6c\u5316\u4e3a\u63a7\u5236\u5668\u5b9e\u65bd\u3002\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u53c2\u6570\u65f6\u5e8f\u535a\u5f08\u4e2d\u4ec5\u80fd\u5408\u6210\u53c2\u6570\u4e0d\u80fd\u5408\u6210\u7b56\u7565\u7684\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u83b7\u80dc\u7b56\u7565\u7684\u5408\u6210\u548c\u63a7\u5236\u5668\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.15612", "categories": ["cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2506.15612", "abs": "https://arxiv.org/abs/2506.15612", "authors": ["Alexandros V. Gerbessiotis"], "title": "A survey of Chernoff and Hoeffding bounds", "comment": null, "summary": "This is a survey paper that discusses the original bounds of the seminal\npapers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative\nbounds in a variety of forms. Complete proofs are provided as needed. The\nintent is to provide a repository of reference bounds for the interested\nresearcher.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86Chernoff\u548cHoeffding\u754c\u9650\u53ca\u53d8\u5f62\uff0c\u5e76\u6c47\u96c6\u4e86\u5b8c\u6574\u8bc1\u660e\uff0c\u6210\u4e3a\u7814\u7a76\u8005\u7684\u91cd\u8981\u53c2\u8003\u8d44\u6599\u5e93\u3002", "motivation": "\u4e3a\u7814\u7a76\u8005\u63d0\u4f9bChernoff\u548cHoeffding\u91cd\u8981\u5b9a\u7406\u539f\u59cb\u754c\u9650\u53ca\u5176\u5404\u79cd\u884d\u751f\u754c\u9650\u7684\u5168\u9762\u53c2\u8003\uff0c\u4ee5\u4fbf\u67e5\u9605\u548c\u5e94\u7528\u3002", "method": "\u6574\u7406\u5e76\u7efc\u8ff0Chernoff\u548cHoeffding\u5b9a\u7406\u7684\u539f\u59cb\u754c\u9650\uff0c\u540c\u65f6\u6536\u96c6\u548c\u6c47\u603b\u5404\u79cd\u4e0d\u540c\u5f62\u5f0f\u7684\u884d\u751f\u754c\u9650\uff0c\u5e76\u5728\u9700\u8981\u65f6\u63d0\u4f9b\u5b8c\u6574\u7684\u8bc1\u660e\u3002", "result": "\u8bba\u6587\u6536\u96c6\u5e76\u6574\u7406\u4e86Chernoff\u548cHoeffding\u7b49\u5b9a\u7406\u7684\u539f\u59cb\u754c\u9650\u53ca\u5176\u884d\u751f\u53d8\u4f53\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u53c2\u8003\u8d44\u6599\u5e93\uff0c\u5e76\u4e3a\u90e8\u5206\u7ed3\u679c\u63d0\u4f9b\u4e86\u5b8c\u6574\u8bc1\u660e\u3002", "conclusion": "\u672c\u6587\u4f5c\u4e3a\u7efc\u8ff0\u6027\u6587\u732e\uff0c\u7cfb\u7edf\u6027\u5730\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86Chernoff\u53caHoeffding\u754c\u9650\u53ca\u5404\u79cd\u884d\u53d8\u5f62\u6001\u7684\u8be6\u7ec6\u6c47\u7f16\u548c\u8bc1\u660e\uff0c\u662f\u76f8\u5173\u9886\u57df\u53c2\u8003\u548c\u7814\u7a76\u7684\u6709\u7528\u8d44\u6e90\u3002"}}
{"id": "2506.15084", "categories": ["cs.SE", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.15084", "abs": "https://arxiv.org/abs/2506.15084", "authors": ["Weiqi Lu", "Yongqiang Tian", "Xiaohan Zhong", "Haoyang Ma", "Zhenyang Xu", "Shing-Chi Cheung", "Chengnian Sun"], "title": "An Empirical Study of Bugs in Data Visualization Libraries", "comment": "Proc. ACM Softw. Eng. 2, FSE", "summary": "Data visualization (DataViz) libraries play a crucial role in presentation,\ndata analysis, and application development, underscoring the importance of\ntheir accuracy in transforming data into visual representations. Incorrect\nvisualizations can adversely impact user experience, distort information\nconveyance, and influence user perception and decision-making processes. Visual\nbugs in these libraries can be particularly insidious as they may not cause\nobvious errors like crashes, but instead mislead users of the underlying data\ngraphically, resulting in wrong decision making. Consequently, a good\nunderstanding of the unique characteristics of bugs in DataViz libraries is\nessential for researchers and developers to detect and fix bugs in DataViz\nlibraries.\n  This study presents the first comprehensive analysis of bugs in DataViz\nlibraries, examining 564 bugs collected from five widely-used libraries. Our\nstudy systematically analyzes their symptoms and root causes, and provides a\ndetailed taxonomy. We found that incorrect/inaccurate plots are pervasive in\nDataViz libraries and incorrect graphic computation is the major root cause,\nwhich necessitates further automated testing methods for DataViz libraries.\nMoreover, we identified eight key steps to trigger such bugs and two test\noracles specific to DataViz libraries, which may inspire future research in\ndesigning effective automated testing techniques. Furthermore, with the recent\nadvancements in Vision Language Models (VLMs), we explored the feasibility of\napplying these models to detect incorrect/inaccurate plots. The results show\nthat the effectiveness of VLMs in bug detection varies from 29% to 57%,\ndepending on the prompts, and adding more information in prompts does not\nnecessarily increase the effectiveness. More findings can be found in our\nmanuscript.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6536\u96c6\u5e76\u5206\u6790\u4e86\u4e3b\u6d41\u6570\u636e\u53ef\u89c6\u5316\u5e93\u4e2d\u7684564\u4e2a\u7f3a\u9677\uff0c\u53d1\u73b0\u4e0d\u7cbe\u786e\u7ed8\u56fe\u5e7f\u6cdb\u5b58\u5728\uff0c\u4e3b\u8981\u7531\u56fe\u5f62\u8ba1\u7b97\u9519\u8bef\u5f15\u53d1\u3002\u63d0\u51fa\u4e86\u5b8c\u6574\u7684\u7f3a\u9677\u5206\u7c7b\u3001\u89e6\u53d1\u6d41\u7a0b\u548c\u68c0\u6d4b\u5224\u636e\uff0c\u5e76\u521d\u6b65\u8bd5\u9a8c\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u9677\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u5176\u6548\u679c\u6709\u5f85\u52a0\u5f3a\u3002\u7814\u7a76\u4e3a\u672a\u6765\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u7f3a\u9677\u68c0\u6d4b\u6280\u672f\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u6570\u636e\u53ef\u89c6\u5316\u5e93\u5728\u6570\u636e\u5c55\u793a\u4e0e\u5206\u6790\u4e2d\u6781\u5176\u91cd\u8981\uff0c\u4e0d\u51c6\u786e\u7684\u53ef\u89c6\u5316\u53ef\u80fd\u4f1a\u8bef\u5bfc\u7528\u6237\u3001\u5e26\u6765\u9519\u8bef\u51b3\u7b56\uff0c\u4f46\u5176\u53ef\u89c6\u5316\u7f3a\u9677\u901a\u5e38\u9690\u853d\uff0c\u4e0d\u4f1a\u50cf\u7a0b\u5e8f\u5d29\u6e83\u7b49\u660e\u663e\u66b4\u9732\u3002\u8fd9\u5bf9\u76f8\u5173\u7814\u7a76\u548c\u5f00\u53d1\u8005\u63d0\u51fa\u4e86\u68c0\u6d4b\u4e0e\u4fee\u590d\u6b64\u7c7b\u7f3a\u9677\u7684\u8feb\u5207\u9700\u6c42\u3002", "method": "\u6536\u96c6\u5e76\u7cfb\u7edf\u5206\u6790\u4e86\u4e94\u4e2a\u4e3b\u6d41\u6570\u636e\u53ef\u89c6\u5316\u5e93\u4e2d\u7684564\u4e2a\u7f3a\u9677\uff0c\u4ece\u7f3a\u9677\u75c7\u72b6\u548c\u6839\u56e0\u51fa\u53d1\uff0c\u5efa\u7acb\u4e86\u8be6\u5c3d\u7684\u7f3a\u9677\u5206\u7c7b\u4f53\u7cfb\u3002\u540c\u65f6\uff0c\u63a2\u7d22\u51fa\u89e6\u53d1\u6b64\u7c7b\u7f3a\u9677\u7684\u5173\u952e\u6d41\u7a0b\u4e0e\u9002\u7528\u7684\u68c0\u9a8c\u5224\u636e\uff0c\u5e76\u521d\u6b65\u8bc4\u4f30\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u76f8\u5173\u7f3a\u9677\u68c0\u6d4b\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0d\u6b63\u786e/\u4e0d\u7cbe\u786e\u7684\u56fe\u5f62\u5728\u6570\u636e\u53ef\u89c6\u5316\u5e93\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4e14\u56fe\u5f62\u8ba1\u7b97\u9519\u8bef\u662f\u4e3b\u8981\u6839\u56e0\u3002\u6587\u4e2d\u660e\u786e\u6307\u51fa\u9700\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\u3002\u7814\u7a76\u8fd8\u603b\u7ed3\u4e86\u89e6\u53d1\u6b64\u7c7b\u6f0f\u6d1e\u7684\u516b\u5927\u5173\u952e\u6b65\u9aa4\u4e0e\u4e24\u4e2a\u4e13\u7528\u7684\u68c0\u9a8c\u5224\u636e\u3002\u53e6\u5916\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u65f6\u8868\u73b0\u6548\u679c\u5dee\u5f02\u8f83\u5927\uff08\u51c6\u786e\u738729%\u81f357%\uff09\uff0c\u4e14\u4ec5\u9760\u4e30\u5bcc\u63d0\u793a\u8bcd\u672a\u5fc5\u80fd\u63d0\u5347\u6548\u679c\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u5206\u6790\u6570\u636e\u53ef\u89c6\u5316\u5e93\u7f3a\u9677\u7684\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u5176\u72ec\u7279\u7684\u7f3a\u9677\u7279\u5f81\u4e0e\u6839\u56e0\uff0c\u5e76\u4e3a\u81ea\u52a8\u5316\u68c0\u6d4b\u3001\u5224\u636e\u8bbe\u8ba1\u548c\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002\u6b64\u5916\uff0c\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u9677\u68c0\u6d4b\u5e94\u7528\u4e2d\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2506.14901", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14901", "abs": "https://arxiv.org/abs/2506.14901", "authors": ["Marija \u0160akota", "Robert West"], "title": "Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction", "comment": null, "summary": "Many recent approaches to structured NLP tasks use an autoregressive language\nmodel $M$ to map unstructured input text $x$ to output text $y$ representing\nstructured objects (such as tuples, lists, trees, code, etc.), where the\ndesired output structure is enforced via constrained decoding. During training,\nthese approaches do not require the model to be aware of the constraints, which\nare merely implicit in the training outputs $y$. This is advantageous as it\nallows for dynamic constraints without requiring retraining, but can lead to\nlow-quality output during constrained decoding at test time. We overcome this\nproblem with Boosted Constrained Decoding (BoostCD), which combines constrained\nand unconstrained decoding in two phases: Phase 1 decodes from the base model\n$M$ twice, in constrained and unconstrained mode, obtaining two weak\npredictions. In phase 2, a learned autoregressive boosted model combines the\ntwo weak predictions into one final prediction. The mistakes made by the base\nmodel with vs. without constraints tend to be complementary, which the boosted\nmodel learns to exploit for improved performance. We demonstrate the power of\nBoostCD by applying it to closed information extraction. Our model, BoostIE,\noutperforms prior approaches both in and out of distribution, addressing\nseveral common errors identified in those approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u5148\u540e\u7528\u57fa\u6a21\u578b\u505a\u7ea6\u675f\u4e0e\u975e\u7ea6\u675f\u9884\u6d4b\uff0c\u518d\u8bad\u7ec3\u4e00\u4e2a\u63d0\u5347\u6a21\u578b\u7ed3\u5408\u4e24\u8005\u7ed3\u679c\uff0c\u6709\u6548\u63d0\u5347\u7ed3\u6784\u5316NLP\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u5c24\u5176\u5728\u4fe1\u606f\u62bd\u53d6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u7ed3\u6784\u5316NLP\u4efb\u52a1\u91c7\u7528\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u8f93\u5165\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u3002\u867d\u7136\u5728\u8bad\u7ec3\u65f6\u4e0d\u5f3a\u5236\u6a21\u578b\u9075\u5b88\u7ed3\u6784\u7ea6\u675f\u4f7f\u5f97\u7cfb\u7edf\u7075\u6d3b\uff0c\u4f46\u5728\u6d4b\u8bd5\u65f6\u57fa\u4e8e\u7ea6\u675f\u7684\u89e3\u7801\u5f80\u5f80\u4ea7\u751f\u4f4e\u8d28\u91cf\u8f93\u51fa\u3002\u4f5c\u8005\u52a8\u673a\u662f\u89e3\u51b3\u7ea6\u675f\u89e3\u7801\u65f6\u8f93\u51fa\u8d28\u91cf\u4e0d\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faBoosted Constrained Decoding\uff08BoostCD\uff09\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5206\u522b\u7528\u7ea6\u675f\u548c\u975e\u7ea6\u675f\u6a21\u5f0f\u4ece\u57fa\u6a21\u578b\u8fdb\u884c\u4e24\u6b21\u89e3\u7801\uff1b\u7b2c\u4e8c\u9636\u6bb5\uff0c\u8bad\u7ec3\u4e00\u4e2a\u81ea\u56de\u5f52\u63d0\u5347\u6a21\u578b\uff0c\u7ed3\u5408\u8fd9\u4e24\u79cd\u9884\u6d4b\uff0c\u5229\u7528\u5b83\u4eec\u5728\u9519\u8bef\u4e0a\u7684\u4e92\u8865\u6027\u751f\u6210\u66f4\u597d\u6700\u7ec8\u8f93\u51fa\u3002", "result": "\u5e94\u7528BoostCD\u4e8e\u95ed\u5408\u5f0f\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\uff0c\u5e76\u63d0\u51faBoostIE\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u5728\u5206\u5e03\u5185\u5916\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ee5\u5f80\u7cfb\u7edf\u4e2d\u7684\u5e38\u89c1\u9519\u8bef\u3002", "conclusion": "BoostCD\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u7ed3\u6784\u5316\u4efb\u52a1\u4e2d\u7684\u89e3\u7801\u8f93\u51fa\u8d28\u91cf\uff0c\u5728\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u8868\u73b0\uff0c\u663e\u793a\u4e86\u8fd9\u4e00\u8303\u5f0f\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.15088", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15088", "abs": "https://arxiv.org/abs/2506.15088", "authors": ["Miao Miao"], "title": "Program Feature-based Fuzzing Benchmarking", "comment": null, "summary": "Fuzzing is a powerful software testing technique renowned for its\neffectiveness in identifying software vulnerabilities. Traditional fuzzing\nevaluations typically focus on overall fuzzer performance across a set of\ntarget programs, yet few benchmarks consider how fine-grained program features\ninfluence fuzzing effectiveness. To bridge this gap, we introduce a novel\nbenchmark designed to generate programs with configurable, fine-grained program\nfeatures to enhance fuzzing evaluations. We reviewed 25 recent grey-box fuzzing\nstudies, extracting 7 program features related to control-flow and data-flow\nthat can impact fuzzer performance. Using these features, we generated a\nbenchmark consisting of 153 programs controlled by 10 fine-grained configurable\nparameters. We evaluated 11 popular fuzzers using this benchmark. The results\nindicate that fuzzer performance varies significantly based on the program\nfeatures and their strengths, highlighting the importance of incorporating\nprogram characteristics into fuzzing evaluations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5177\u5907\u53ef\u914d\u7f6e\u3001\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u57fa\u51c6\u7a0b\u5e8f\u96c6\uff0c\u7528\u4ee5\u8bc4\u4f3011\u4e2a\u4e3b\u6d41\u6a21\u7cca\u5668\uff0c\u7ed3\u679c\u53d1\u73b0\u7a0b\u5e8f\u7279\u6027\u5bf9\u6a21\u7cca\u5668\u8868\u73b0\u5f71\u54cd\u663e\u8457\uff0c\u5f3a\u8c03\u5728\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30\u4e2d\u7eb3\u5165\u7a0b\u5e8f\u7279\u5f81\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30\u901a\u5e38\u4fa7\u91cd\u4e8e\u6a21\u7cca\u5668\u5728\u4e00\u7ec4\u76ee\u6807\u7a0b\u5e8f\u4e0a\u7684\u6574\u4f53\u6027\u80fd\uff0c\u4f46\u5f88\u5c11\u5173\u6ce8\u5177\u4f53\u7684\u7a0b\u5e8f\u7ec6\u7c92\u5ea6\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\u3002\u7f3a\u4e4f\u8fd9\u6837\u7684\u57fa\u51c6\u963b\u788d\u4e86\u5bf9\u6a21\u7cca\u5668\u7ec6\u81f4\u6bd4\u8f83\u4e0e\u63d0\u5347\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u53ef\u914d\u7f6e\u3001\u7ec6\u7c92\u5ea6\u7a0b\u5e8f\u7279\u5f81\u7684\u7a0b\u5e8f\uff0c\u5e2e\u52a9\u66f4\u7cfb\u7edf\u3001\u66f4\u6df1\u5165\u5730\u8bc4\u4f30\u6a21\u7cca\u6d4b\u8bd5\u5668\u3002\u901a\u8fc7\u8c03\u781425\u7bc7\u4e0e\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u76f8\u5173\u7684\u8fd1\u671f\u7814\u7a76\uff0c\u63d0\u53d6\u4e867\u79cd\u4e0e\u63a7\u5236\u6d41\u3001\u6570\u636e\u6d41\u76f8\u5173\u3001\u4f1a\u5f71\u54cd\u6a21\u7cca\u5668\u6027\u80fd\u7684\u7a0b\u5e8f\u7279\u5f81\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7279\u5f81\uff0c\u4f5c\u8005\u751f\u6210\u4e86\u753110\u4e2a\u7ec6\u7c92\u5ea6\u53ef\u914d\u7f6e\u53c2\u6570\u63a7\u5236\u7684153\u4e2a\u7a0b\u5e8f\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u7a0b\u5e8f\u8bc4\u4f30\u4e8611\u6b3e\u6d41\u884c\u6a21\u7cca\u5668\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6a21\u7cca\u5668\u7684\u6027\u80fd\u4f1a\u968f\u7740\u7a0b\u5e8f\u7279\u5f81\u53ca\u5176\u5f3a\u5ea6\u7684\u53d8\u5316\u800c\u663e\u8457\u6ce2\u52a8\uff0c\u8868\u660e\u5728\u6a21\u7cca\u6d4b\u8bd5\u8bc4\u4f30\u4e2d\u5f15\u5165\u7a0b\u5e8f\u7279\u6027\u975e\u5e38\u91cd\u8981\u3002", "conclusion": "\u5f15\u5165\u5177\u5907\u53ef\u63a7\u3001\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u57fa\u51c6\u7a0b\u5e8f\u80fd\u591f\u66f4\u5168\u9762\u3001\u7cbe\u786e\u5730\u8bc4\u4f30\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u53d1\u73b0\u5176\u6027\u80fd\u74f6\u9888\u5e76\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u4f18\u5316\u3002"}}
{"id": "2506.14912", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14912", "abs": "https://arxiv.org/abs/2506.14912", "authors": ["Dyah Adila", "Shuai Zhang", "Boran Han", "Bonan Min", "Yuyang Wang"], "title": "CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision", "comment": null, "summary": "The integration of contextual information has significantly enhanced the\nperformance of large language models (LLMs) on knowledge-intensive tasks.\nHowever, existing methods often overlook a critical challenge: the credibility\nof context documents can vary widely, potentially leading to the propagation of\nunreliable information. In this paper, we introduce CrEst, a novel weakly\nsupervised framework for assessing the credibility of context documents during\nLLM inference--without requiring manual annotations. Our approach is grounded\nin the insight that credible documents tend to exhibit higher semantic\ncoherence with other credible documents, enabling automated credibility\nestimation through inter-document agreement. To incorporate credibility into\nLLM inference, we propose two integration strategies: a black-box approach for\nmodels without access to internal weights or activations, and a white-box\nmethod that directly modifies attention mechanisms. Extensive experiments\nacross three model architectures and five datasets demonstrate that CrEst\nconsistently outperforms strong baselines, achieving up to a 26.86% improvement\nin accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst\nmaintains robust performance even under high-noise conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCrEst\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u81ea\u52a8\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\uff0c\u5e76\u901a\u8fc7\u767d\u76d2\u548c\u9ed1\u76d2\u4e24\u79cd\u65b9\u5f0f\u63d0\u5347LLM\u8868\u73b0\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u9ad8\u566a\u58f0\u4e0b\u4f9d\u7136\u7a33\u5b9a\u3002", "motivation": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u96c6\u6210\u4e0a\u4e0b\u6587\u4fe1\u606f\u5df2\u663e\u8457\u63d0\u5347\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u7684\u8868\u73b0\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\u53c2\u5dee\u4e0d\u9f50\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u53ef\u80fd\u4f20\u64ad\u4e0d\u53ef\u9760\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6709\u65b9\u6cd5\u6709\u6548\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6587\u6863\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCrEst\u7684\u5f31\u76d1\u7763\u6846\u67b6\uff0c\u5728\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\uff0c\u8bc4\u4f30LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\u3002CrEst\u57fa\u4e8e\u4e00\u4e2a\u7406\u8bba\u6d1e\u89c1\uff1a\u53ef\u4fe1\u6587\u6863\u4e4b\u95f4\u5728\u8bed\u4e49\u4e0a\u901a\u5e38\u66f4\u4e3a\u4e00\u81f4\uff0c\u56e0\u6b64\u53ef\u4ee5\u901a\u8fc7\u6587\u6863\u95f4\u7684\u4e00\u81f4\u6027\u81ea\u52a8\u8bc4\u4f30\u53ef\u4fe1\u5ea6\u3002\u540c\u65f6\uff0c\u5206\u522b\u63d0\u51fa\u9ed1\u76d2\u548c\u767d\u76d2\u4e24\u79cd\u6a21\u578b\u96c6\u6210\u7b56\u7565\uff0c\u524d\u8005\u9002\u7528\u4e8e\u4e0d\u53ef\u8bbf\u95ee\u6a21\u578b\u6743\u91cd\u7684\u60c5\u51b5\u4e0b\uff0c\u540e\u8005\u5219\u76f4\u63a5\u4fee\u6539\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u4e09\u79cd\u6a21\u578b\u67b6\u6784\u548c\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCrEst\u5728\u5404\u9879\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534726.86%\uff0cF1\u5206\u6570\u63d0\u53473.49%\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u5728\u9ad8\u566a\u58f0\u6761\u4ef6\u4e0b\uff0cCrEst\u4f9d\u7136\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "CrEst\u80fd\u6709\u6548\u8bc4\u4f30\u5e76\u6574\u5408\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.15098", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15098", "abs": "https://arxiv.org/abs/2506.15098", "authors": ["Haosheng Zuo", "Feifei Niu", "Chuanyi Li"], "title": "Enhancement Report Approval Prediction: A Comparative Study of Large Language Models", "comment": null, "summary": "Enhancement reports (ERs) serve as a critical communication channel between\nusers and developers, capturing valuable suggestions for software improvement.\nHowever, manually processing these reports is resource-intensive, leading to\ndelays and potential loss of valuable insights. To address this challenge,\nenhancement report approval prediction (ERAP) has emerged as a research focus,\nleveraging machine learning techniques to automate decision-making. While\ntraditional approaches have employed feature-based classifiers and deep\nlearning models, recent advancements in large language models (LLM) present new\nopportunities for enhancing prediction accuracy. This study systematically\nevaluates 18 LLM variants (including BERT, RoBERTa, DeBERTa-v3, ELECTRA, and\nXLNet for encoder models; GPT-3.5-turbo, GPT-4o-mini, Llama 3.1 8B, Llama 3.1\n8B Instruct and DeepSeek-V3 for decoder models) against traditional methods\n(CNN/LSTM-BERT/GloVe). Our experiments reveal two key insights: (1)\nIncorporating creator profiles increases unfine-tuned decoder-only models'\noverall accuracy by 10.8 percent though it may introduce bias; (2) LoRA\nfine-tuned Llama 3.1 8B Instruct further improve performance, reaching 79\npercent accuracy and significantly enhancing recall for approved reports (76.1\npercent vs. LSTM-GLOVE's 64.1 percent), outperforming traditional methods by 5\npercent under strict chronological evaluation and effectively addressing class\nimbalance issues. These findings establish LLM as a superior solution for ERAP,\ndemonstrating their potential to streamline software maintenance workflows and\nimprove decision-making in real-world development environments. We also\ninvestigated and summarized the ER cases where the large models underperformed,\nproviding valuable directions for future research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cdLLM\u53ca\u5176\u5728\u589e\u5f3a\u62a5\u544a\u5ba1\u6279\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793aLLM\uff08\u7279\u522b\u662f\u5fae\u8c03\u540e\u7684\u6a21\u578b\uff09\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u6709\u671b\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u6548\u7387\uff0c\u5e76\u9488\u5bf9\u6a21\u578b\u4e0d\u8db3\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u624b\u5de5\u5904\u7406\u8f6f\u4ef6\u589e\u5f3a\u62a5\u544a\uff08ER\uff09\u8017\u8d39\u8d44\u6e90\u4e14\u5b58\u5728\u5ef6\u8fdf\u548c\u4fe1\u606f\u635f\u5931\u95ee\u9898\uff0c\u9700\u8981\u81ea\u52a8\u5316\u624b\u6bb5\u63d0\u5347\u6548\u7387\u3002", "method": "\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e8618\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53d8\u4f53\uff08\u5305\u62ec\u591a\u79cd\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u6a21\u578b\uff09\uff0c\u5e76\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982CNN/LSTM-BERT/GloVe\uff09\u8fdb\u884c\u5bf9\u6bd4\u3002\u7814\u7a76\u8fd8\u63a2\u7d22\u4e86\u52a0\u5165\u521b\u9020\u8005\u4fe1\u606f\u548cLoRA\u5fae\u8c03\u7684\u5f71\u54cd\u3002", "result": "\uff081\uff09\u5f15\u5165\u521b\u9020\u8005\u6863\u6848\u4f7f\u672a\u5fae\u8c03\u7684\u7eaf\u89e3\u7801\u5668\u6a21\u578b\u51c6\u786e\u7387\u63d0\u534710.8%\uff0c\u4f46\u53ef\u80fd\u5e26\u6765\u504f\u89c1\uff1b\uff082\uff09\u901a\u8fc7LoRA\u5fae\u8c03\u7684Llama 3.1 8B Instruct\u6a21\u578b\u53d6\u5f97\u4e8679%\u7684\u51c6\u786e\u7387\uff0c\u83b7\u6279\u62a5\u544a\u53ec\u56de\u7387\u663e\u8457\u63d0\u5347\uff0876.1%\u5bf9\u6bd4LSTM-GLOVE\u768464.1%\uff09\uff0c\u5728\u4e25\u683c\u65f6\u5e8f\u8bc4\u6d4b\u4e0b\u6bd4\u4f20\u7edf\u65b9\u6cd5\u9ad85%\uff0c\u5e76\u6709\u6548\u514b\u670d\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "conclusion": "LLM\u5728\u589e\u5f3a\u62a5\u544a\u5ba1\u6279\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u53ef\u63d0\u5347\u8f6f\u4ef6\u7ef4\u62a4\u548c\u51b3\u7b56\u6d41\u7a0b\u3002\u7814\u7a76\u4e5f\u5206\u6790\u4e86LLM\u8868\u73b0\u4e0d\u4f73\u7684\u6848\u4f8b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.14927", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.14927", "abs": "https://arxiv.org/abs/2506.14927", "authors": ["Joseph J. Peper", "Wenzhao Qiu", "Ali Payani", "Lu Wang"], "title": "MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance", "comment": "ACL 2025 Findings", "summary": "Natural language processing evaluation has made significant progress, largely\ndriven by the proliferation of powerful large language mod-els (LLMs). New\nevaluation benchmarks are of increasing priority as the reasoning capabilities\nof LLMs are expanding at a rapid pace. In particular, while multi-document (MD)\nreasoning is an area of extreme relevance given LLM capabilities in handling\nlonger-context inputs, few benchmarks exist to rigorously examine model\nbehavior in this setting. Moreover, the multi-document setting is historically\nchallenging for benchmark creation due to the expensive cost of annotating long\ninputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs\non the task of multi-document reasoning. Notably, MDBench is created through a\nnovel synthetic generation process, allowing us to controllably and efficiently\ngenerate challenging document sets and the corresponding question-answer (QA)\nexamples. Our novel technique operates on condensed structured seed knowledge,\nmodifying it through LLM-assisted edits to induce MD-specific reasoning\nchallenges. We then convert this structured knowledge into a natural text\nsurface form, generating a document set and corresponding QA example. We\nanalyze the behavior of popular LLMs and prompting techniques, finding that\nMDBENCH poses significant challenges for all methods, even with relatively\nshort document sets. We also see our knowledge-guided generation technique (1)\nallows us to readily perform targeted analysis of MD-specific reasoning\ncapabilities and (2) can be adapted quickly to account for new challenges and\nfuture modeling improvements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u591a\u6587\u6863\u63a8\u7406\u8bc4\u6d4b\u7684\u65b0\u6570\u636e\u96c6MDBench\uff0c\u901a\u8fc7\u5408\u6210\u7684\u65b9\u6cd5\u9ad8\u6548\u751f\u6210\u5177\u6709\u9488\u5bf9\u6027\u7684\u96be\u9898\uff0c\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u4ecd\u6709\u8bf8\u591a\u6311\u6218\uff0c\u5e76\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u4e0e\u9002\u5e94\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u80fd\u529b\u7684\u98de\u901f\u63d0\u5347\uff0c\u5bf9\u4e8e\u591a\u6587\u6863\uff08MD\uff09\u63a8\u7406\u7684\u8bc4\u6d4b\u9700\u6c42\u9010\u6e10\u589e\u52a0\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u591a\u6587\u6863\u63a8\u7406\u7684\u7cfb\u7edf\u6027\u8bc4\u4ef7\u57fa\u51c6\uff0c\u5e76\u4e14\u56e0\u4eba\u5de5\u6807\u6ce8\u957f\u6587\u672c\u7684\u9ad8\u6602\u6210\u672c\uff0cMD\u8bc4\u6d4b\u96c6\u7684\u6784\u5efa\u5c24\u4e3a\u56f0\u96be\u3002", "method": "\u4f5c\u8005\u63d0\u51faMDBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u8fc7\u5408\u6210\u751f\u6210\u6d41\u7a0b\u521b\u5efa\u7684\u65b0\u578b\u6570\u636e\u96c6\u3002\u5177\u4f53\u505a\u6cd5\u662f\uff1a\u5148\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u4f5c\u4e3a\u79cd\u5b50\uff0c\u901a\u8fc7LLM\u8f85\u52a9\u7684\u7f16\u8f91\u64cd\u4f5c\uff0c\u5f15\u5165\u591a\u6587\u6863\u63a8\u7406\u6311\u6218\uff0c\u518d\u5c06\u7ed3\u6784\u5316\u77e5\u8bc6\u8f6c\u6362\u4e3a\u81ea\u7136\u6587\u672c\uff0c\u5b9e\u73b0\u591a\u6587\u6863\u96c6\u548c\u76f8\u5e94\u95ee\u7b54\u5bf9\u7684\u9ad8\u6548\u751f\u6210\u3002", "result": "MDBench\u80fd\u591f\u6709\u6548\u4ea7\u751f\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u6587\u6863\u53ca\u5bf9\u5e94\u7684\u95ee\u7b54\u6837\u672c\u3002\u5b9e\u9a8c\u5206\u6790\u8868\u660e\uff0c\u65e0\u8bba\u662f\u4e3b\u6d41\u6a21\u578b\u8fd8\u662f\u5404\u79cd\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5bf9MDBench\u7684\u5e94\u5bf9\u90fd\u6781\u5177\u6311\u6218\uff0c\u5373\u4f7f\u6587\u6863\u6570\u76ee\u4e0d\u591a\u3002\u6b64\u5916\uff0c\u8be5\u751f\u6210\u6280\u672f\u53ef\u4ee5\u7075\u6d3b\u5730\u9488\u5bf9\u7279\u5b9a\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u5206\u6790\uff0c\u4e5f\u6709\u826f\u597d\u9002\u5e94\u6027\uff0c\u53ef\u5e94\u5bf9\u672a\u6765\u65b0\u6311\u6218\u3002", "conclusion": "MDBench\u4e3aLLM\u7684\u591a\u6587\u6863\u63a8\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u63a7\u7684\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5\uff0c\u6709\u671b\u63a8\u52a8\u66f4\u591a\u76f8\u5173\u7814\u7a76\u4e0e\u6a21\u578b\u6539\u8fdb\u3002"}}
{"id": "2506.14949", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.14949", "abs": "https://arxiv.org/abs/2506.14949", "authors": ["Shadman Sakib", "Oishy Fatema Akhand", "Ajwad Abrar"], "title": "From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?", "comment": "Accepted in 1st IEEE QPAIN 2025", "summary": "While Machine Learning (ML) and Deep Learning (DL) models have been widely\nused for diabetes prediction, the use of Large Language Models (LLMs) for\nstructured numerical data is still not well explored. In this study, we test\nthe effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and\nthree-shot prompting methods. We conduct an empirical analysis using the Pima\nIndian Diabetes Database (PIDD). We evaluate six LLMs, including four\nopen-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We\nalso test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we\ncompare their performance with three traditional machine learning models:\nRandom Forest, Logistic Regression, and Support Vector Machine (SVM). We use\naccuracy, precision, recall, and F1-score as evaluation metrics. Our results\nshow that proprietary LLMs perform better than open-source ones, with GPT-4o\nand Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,\nGemma-2-27B also outperforms the traditional ML models in terms of F1-score.\nHowever, there are still issues such as performance variation across prompting\nstrategies and the need for domain-specific fine-tuning. This study shows that\nLLMs can be useful for medical prediction tasks and encourages future work on\nprompt engineering and hybrid approaches to improve healthcare predictions.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u516d\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7cd6\u5c3f\u75c5\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e13\u6709LLM\u4f18\u4e8e\u5f00\u6e90LLM\uff0c\u90e8\u5206\u6a21\u578b\u53ef\u8d85\u8d8a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u793a\u5de5\u7a0b\u548c\u9886\u57df\u5fae\u8c03\u4ecd\u662f\u4eca\u540e\u63d0\u5347\u6027\u80fd\u7684\u91cd\u70b9\u3002", "motivation": "\u5927\u6a21\u578b\uff08LLM\uff09\u5728\u5904\u7406\u7ed3\u6784\u5316\u6570\u503c\u533b\u7597\u6570\u636e\uff08\u5982\u7cd6\u5c3f\u75c5\u9884\u6d4b\uff09\u4e0a\u7684\u7814\u7a76\u8fd8\u8f83\u5c11\uff0c\u800c\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u548c\u5bf9\u6bd4LLM\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u4ee5\u586b\u8865\u76f8\u5173\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u672c\u6587\u91c7\u7528\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u548c\u4e09\u6837\u672c\u63d0\u793a\u6cd5\uff0c\u57fa\u4e8ePima Indian Diabetes Database\uff0c\u5bf9\u516d\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5305\u62ec\u56db\u4e2a\u5f00\u6e90\u6a21\u578b\u548c\u4e24\u4e2a\u4e13\u6709\u6a21\u578b\uff09\u5728\u7cd6\u5c3f\u75c5\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u4ee5\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u3001\u903b\u8f91\u56de\u5f52\u3001\u652f\u6301\u5411\u91cf\u673a\uff09\u4f5c\u53c2\u7167\uff0c\u8bc4\u4ef7\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e13\u6709LLM\uff08\u5982GPT-4o\uff09\u6574\u4f53\u4f18\u4e8e\u5f00\u6e90LLM\uff0c\u4e14\u5728\u5c11\u6837\u672c\u63d0\u793a\u4e0b\uff0cGPT-4o\u548cGemma-2-27B\u53d6\u5f97\u4e86\u6700\u9ad8\u51c6\u786e\u7387\u3002Gemma-2-27B\u7684F1\u5206\u6570\u751a\u81f3\u8d85\u8fc7\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0bLLM\u8868\u73b0\u6ce2\u52a8\u660e\u663e\uff0c\u4e14\u4ecd\u5b58\u5728\u9886\u57df\u5fae\u8c03\u9700\u6c42\u3002", "conclusion": "LLM\u5728\u533b\u5b66\u9884\u6d4b\u4efb\u52a1\u4e0a\u5177\u6709\u53ef\u884c\u6027\u548c\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u67d0\u4e9b\u6307\u6807\u4e0a\u53ef\u8d85\u8d8a\u4f20\u7edf\u6a21\u578b\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u5173\u6ce8\u63d0\u793a\u5de5\u7a0b\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u533b\u7597\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2506.15172", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15172", "abs": "https://arxiv.org/abs/2506.15172", "authors": ["Maria Spichkova", "Kevin Iwan", "Madeleine Zwart", "Hina Lee", "Yuwon Yoon", "Xiaohan Qin"], "title": "Advanced approach for Agile/Scrum Process: RetroAI++", "comment": "Preprint. Accepted to the 29th International Conference on\n  Knowledge-Based and Intelligent Information & Engineering Systems (KES 2025).\n  Final version to be published by Elsevier (In Press)", "summary": "In Agile/Scrum software development, sprint planning and retrospective\nanalysis are the key elements of project management. The aim of our work is to\nsupport software developers in these activities. In this paper, we present our\nprototype tool RetroAI++, based on emerging intelligent technologies. In our\nRetroAI++ prototype, we aim to automate and refine the practical application of\nAgile/Scrum processes within Sprint Planning and Retrospectives. Leveraging AI\ninsights, our prototype aims to automate and refine the many processes involved\nin the Sprint Planning, Development and Retrospective stages of Agile/Scrum\ndevelopment projects, offering intelligent suggestions for sprint organisation\nas well as meaningful insights for retrospective reflection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8eAI\u7684\u539f\u578b\u5de5\u5177RetroAI++\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u548c\u4f18\u5316\u654f\u6377/Scrum\u4e2d\u7684\u51b2\u523a\u89c4\u5212\u4e0e\u56de\u987e\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u6d41\u7a0b\u6548\u7387\u4e0e\u667a\u80fd\u5316\u6c34\u5e73\u3002", "motivation": "\u654f\u6377/Scrum\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u51b2\u523a\u89c4\u5212\u548c\u56de\u987e\u5206\u6790\u662f\u9879\u76ee\u7ba1\u7406\u7684\u5173\u952e\u73af\u8282\u3002\u5f53\u524d\u8fd9\u4e9b\u73af\u8282\u4e2d\uff0c\u624b\u52a8\u64cd\u4f5c\u8f83\u591a\uff0c\u6548\u7387\u548c\u667a\u80fd\u5316\u6c34\u5e73\u6709\u5f85\u63d0\u5347\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u667a\u80fd\u6280\u672f\u652f\u6301\u5f00\u53d1\u8005\u3001\u63d0\u5347\u8fd9\u4e9b\u6d3b\u52a8\u7684\u6548\u7387\u4e0e\u6548\u679c\u3002", "method": "\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aRetroAI++\u7684\u539f\u578b\u5de5\u5177\u3002\u8be5\u5de5\u5177\u57fa\u4e8e\u65b0\u5174\u7684\u667a\u80fd\u6280\u672f\uff0c\u81ea\u52a8\u5316\u654f\u6377/Scrum\u6d41\u7a0b\u4e2d\u7684\u51b2\u523a\u89c4\u5212\u4e0e\u56de\u987e\u73af\u8282\uff0c\u540c\u65f6\u5728\u5f00\u53d1\u9636\u6bb5\u63d0\u4f9b\u667a\u80fd\u5316\u5efa\u8bae\u548c\u6d1e\u5bdf\u3002", "result": "RetroAI++\u539f\u578b\u80fd\u591f\u5728\u51b2\u523a\u89c4\u5212\u3001\u5f00\u53d1\u548c\u56de\u987e\u9636\u6bb5\u63d0\u4f9b\u667a\u80fd\u5efa\u8bae\u4e0e\u6d1e\u5bdf\uff0c\u5e2e\u52a9\u56e2\u961f\u4f18\u5316\u654f\u6377/Scrum\u6d41\u7a0b\uff0c\u63d0\u5347\u7ec4\u7ec7\u548c\u56de\u987e\u7684\u8d28\u91cf\u4e0e\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7RetroAI++\u5de5\u5177\u7684\u5e94\u7528\uff0c\u654f\u6377/Scrum\u5f00\u53d1\u56e2\u961f\u80fd\u591f\u5b9e\u73b0\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\u4e0e\u4f18\u5316\uff0c\u66f4\u9ad8\u6548\u5730\u8fdb\u884c\u51b2\u523a\u89c4\u5212\uff0c\u4ee5\u53ca\u83b7\u5f97\u6709\u9488\u5bf9\u6027\u7684\u56de\u987e\u6d1e\u5bdf\uff0c\u4ece\u800c\u6539\u8fdb\u9879\u76ee\u7ba1\u7406\u548c\u56e2\u961f\u534f\u4f5c\u3002"}}
{"id": "2506.15001", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15001", "abs": "https://arxiv.org/abs/2506.15001", "authors": ["Ignacio Sastre", "Aiala Ros\u00e1"], "title": "Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings", "comment": "This paper will be presented at The First Workshop on Large Language\n  Model Memorization (L2M2) at ACL 2025", "summary": "In this work, we observe an interesting phenomenon: it is possible to\ngenerate reversible sentence embeddings that allow an LLM to reconstruct the\noriginal text exactly, without modifying the model's weights. This is achieved\nby introducing a special memory token, whose embedding is optimized through\ntraining on a fixed sequence. When prompted with this embedding, the model\nreconstructs the fixed sequence exactly. We evaluate this phenomenon across\nEnglish and Spanish datasets, sequences of up to approximately 240 tokens, and\nmodel scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B\nsuccessfully reconstructs all tested sequences. Our findings highlight an\ninteresting capability of LLMs and suggest potential applications in\nmemory-based retrieval, compression, and controlled text generation.", "AI": {"tldr": "\u901a\u8fc7\u4f18\u5316\u7279\u6b8atoken\u7684\u5d4c\u5165\uff0c\u5927\u6a21\u578b\u53ef\u7cbe\u786e\u201c\u8bb0\u5fc6\u201d\u5e76\u91cd\u5efa\u539f\u59cb\u6587\u672c\uff0c\u65e0\u9700\u8c03\u6574\u6a21\u578b\u53c2\u6570\u3002\u8fd9\u4e00\u80fd\u529b\u6709\u671b\u62d3\u5c55\u9ad8\u6548\u4fe1\u606f\u68c0\u7d22\u3001\u538b\u7f29\u3001\u53ef\u63a7\u751f\u6210\u7b49\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u63a2\u7d22LLM\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u662f\u5426\u80fd\u591f\u751f\u6210\u53ef\u9006\u7684\u53e5\u5b50\u5411\u91cf\uff0c\u5e76\u5b9e\u73b0\u539f\u6587\u7684\u7cbe\u786e\u91cd\u6784\uff0c\u5373\u4e00\u79cd\u201c\u8bb0\u5fc6\u201d\u80fd\u529b\uff0c\u800c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u53c2\u6570\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7279\u6b8a\u7684memory token\uff08\u8bb0\u5fc6\u4ee4\u724c\uff09\uff0c\u5e76\u901a\u8fc7\u5728\u56fa\u5b9a\u6587\u672c\u5e8f\u5217\u4e0a\u4f18\u5316\u5176\u5411\u91cf\u8868\u793a\u3002\u968f\u540e\u5c06\u4f18\u5316\u540e\u7684\u5d4c\u5165\u8f93\u5165\u5230LLM\uff0c\u6d4b\u8bd5\u6a21\u578b\u662f\u5426\u80fd\u7cbe\u786e\u8fd8\u539f\u539f\u59cb\u6587\u672c\u3002", "result": "\u5728\u82f1\u8bed\u548c\u897f\u73ed\u7259\u8bed\u6570\u636e\u96c6\u3001\u6700\u957f\u7ea6240 token\u7684\u6587\u672c\u5e8f\u5217\u3001\u6a21\u578b\u53c2\u6570100M\u81f38B\u7684\u4e0d\u540c\u89c4\u6a21\u4e0b\u6d4b\u8bd5\uff0cLlama 3.1 8B\u6a21\u578b\u53ef\u6210\u529f\u91cd\u5efa\u6240\u6709\u6d4b\u8bd5\u6587\u672c\u3002", "conclusion": "LLM\u5177\u5907\u901a\u8fc7\u7279\u6b8a\u5d4c\u5165\u5b9e\u73b0\u6587\u672c\u8bb0\u5fc6\u4e0e\u7cbe\u786e\u91cd\u5efa\u7684\u65b0\u80fd\u529b\uff0c\u6216\u5c06\u4fc3\u8fdb\u57fa\u4e8e\u8bb0\u5fc6\u7684\u68c0\u7d22\u3001\u538b\u7f29\u53ca\u53ef\u63a7\u6587\u672c\u751f\u6210\u7b49\u5e94\u7528\u3002"}}
{"id": "2506.15227", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15227", "abs": "https://arxiv.org/abs/2506.15227", "authors": ["Quanjun Zhang", "Chunrong Fang", "Siqi Gu", "Ye Shang", "Zhenyu Chen", "Liang Xiao"], "title": "Large Language Models for Unit Testing: A Systematic Literature Review", "comment": null, "summary": "Unit testing is a fundamental practice in modern software engineering, with\nthe aim of ensuring the correctness, maintainability, and reliability of\nindividual software components. Very recently, with the advances in Large\nLanguage Models (LLMs), a rapidly growing body of research has leveraged LLMs\nto automate various unit testing tasks, demonstrating remarkable performance\nand significantly reducing manual effort. However, due to ongoing explorations\nin the LLM-based unit testing field, it is challenging for researchers to\nunderstand existing achievements, open challenges, and future opportunities.\nThis paper presents the first systematic literature review on the application\nof LLMs in unit testing until March 2025. We analyze \\numpaper{} relevant\npapers from the perspectives of both unit testing and LLMs. We first categorize\nexisting unit testing tasks that benefit from LLMs, e.g., test generation and\noracle generation. We then discuss several critical aspects of integrating LLMs\ninto unit testing research, including model usage, adaptation strategies, and\nhybrid approaches. We further summarize key challenges that remain unresolved\nand outline promising directions to guide future research in this area.\nOverall, our paper provides a systematic overview of the research landscape to\nthe unit testing community, helping researchers gain a comprehensive\nunderstanding of achievements and promote future research. Our artifacts are\npublicly available at the GitHub repository:\nhttps://github.com/iSEngLab/AwesomeLLM4UT.", "AI": {"tldr": "\u672c\u8bba\u6587\u5bf9\u622a\u81f32025\u5e743\u6708LLMs\u5728\u5355\u5143\u6d4b\u8bd5\u9886\u57df\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u9996\u6b21\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u68b3\u7406\u4e86\u73b0\u6709\u6210\u679c\u3001\u4e3b\u8981\u6311\u6218\u4e0e\u672a\u6765\u673a\u9047\uff0c\u5e76\u5f00\u6e90\u4e86\u8c03\u7814\u6210\u679c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u8868\u73b0\uff0c\u76f8\u5173\u7814\u7a76\u6570\u91cf\u5feb\u901f\u589e\u957f\uff0c\u4f46\u8be5\u9886\u57df\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u5168\u9762\u7406\u89e3\u73b0\u6709\u6210\u679c\u3001\u6311\u6218\u548c\u672a\u6765\u673a\u9047\u3002", "method": "\u672c\u8bba\u6587\u8fdb\u884c\u4e86\u4e00\u9879\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u65e8\u5728\u68b3\u7406\u622a\u81f32025\u5e743\u6708LLMs\u5728\u5355\u5143\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u3002\u4f5c\u8005\u4ece\u5355\u5143\u6d4b\u8bd5\u4e0eLLMs\u4e24\u5927\u89c6\u89d2\u51fa\u53d1\uff0c\u5bf9\u76f8\u5173\u8bba\u6587\u8fdb\u884c\u5206\u7c7b\u3001\u5bf9\u73b0\u6709\u6d4b\u8bd5\u4efb\u52a1\uff08\u5982\u6d4b\u8bd5\u751f\u6210\u3001\u5224\u5b9a\u751f\u6210\u7b49\uff09\u8fdb\u884c\u5f52\u7eb3\uff0c\u603b\u7ed3LLMs\u96c6\u6210\u5230\u5355\u5143\u6d4b\u8bd5\u4e2d\u7684\u5173\u952e\u65b9\u9762\uff08\u6a21\u578b\u4f7f\u7528\u3001\u9002\u914d\u7b56\u7565\u3001\u6df7\u5408\u65b9\u6cd5\uff09\uff0c\u5e76\u5206\u6790\u672a\u89e3\u51b3\u7684\u4e3b\u8981\u6311\u6218\u53ca\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86LLMs\u5728\u5355\u5143\u6d4b\u8bd5\u9886\u57df\u7684\u5e94\u7528\uff0c\u5206\u7c7b\u603b\u7ed3\u4e86\u53d7\u76ca\u4e8eLLMs\u7684\u5355\u5143\u6d4b\u8bd5\u4efb\u52a1\uff0c\u5f52\u7eb3\u4e86\u6a21\u578b\u5e94\u7528\u3001\u9002\u914d\u548c\u7ec4\u5408\u7b56\u7565\uff0c\u5e76\u660e\u786e\u6307\u51fa\u5f53\u524d\u5c1a\u5b58\u7684\u4e00\u4e9b\u5173\u952e\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u4e1a\u754c\u548c\u5b66\u754c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u73b0\u72b6\u8ba4\u77e5\u4e0e\u7814\u7a76\u6307\u5f15\u3002\u76f8\u5173\u6574\u7406\u6570\u636e\u5728GitHub\u516c\u5f00\u3002", "conclusion": "\u672c\u8bba\u6587\u4e3aLLMs\u5728\u5355\u5143\u6d4b\u8bd5\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7efc\u8ff0\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u5168\u9762\u628a\u63e1\u76f8\u5173\u8fdb\u5c55\u3001\u6311\u6218\u548c\u65b9\u5411\uff0c\u5e76\u4ee5\u5f00\u6e90\u7684\u65b9\u5f0f\u8d21\u732e\u4e86\u6574\u7406\u6210\u679c\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2506.15030", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15030", "abs": "https://arxiv.org/abs/2506.15030", "authors": ["Drew Walker", "Swati Rajwal", "Sudeshna Das", "Snigdha Peddireddy", "Abeed Sarker"], "title": "Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods", "comment": "22 pages, 2 figures, 5 tables", "summary": "Social isolation and loneliness, which have been increasing in recent years\nstrongly contribute toward suicide rates. Although social isolation and\nloneliness are not currently recorded within the US National Violent Death\nReporting System's (NVDRS) structured variables, natural language processing\n(NLP) techniques can be used to identify these constructs in law enforcement\nand coroner medical examiner narratives. Using topic modeling to generate\nlexicon development and supervised learning classifiers, we developed\nhigh-quality classifiers (average F1: .86, accuracy: .82). Evaluating over\n300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic\nsocial isolation. Decedents had higher odds of chronic social isolation\nclassification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =\n3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).\nWe found significant predictors for other social isolation topics of recent or\nimpending divorce, child custody loss, eviction or recent move, and break-up.\nOur methods can improve surveillance and prevention of social isolation and\nloneliness in the United States.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7NLP\u4e0e\u673a\u5668\u5b66\u4e60\uff0c\u81ea\u52a8\u8bc6\u522b30\u4e07\u4f59\u81ea\u6740\u6848\u4f8b\u4e2d\u7684\u793e\u4f1a\u5b64\u7acb\u4e0e\u5b64\u72ec\u60c5\u5f62\uff0c\u63ed\u793a\u4e86\u5173\u952e\u98ce\u9669\u56e0\u7d20\uff1b\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u76f8\u5173\u7fa4\u4f53\u7684\u76d1\u6d4b\u4e0e\u9884\u9632\u80fd\u529b\u3002", "motivation": "\u793e\u4f1a\u5b64\u7acb\u548c\u5b64\u72ec\u611f\u8fd1\u5e74\u6765\u65e5\u76ca\u52a0\u5267\uff0c\u5f3a\u70c8\u5f71\u54cd\u81ea\u6740\u7387\uff0c\u4f46\u73b0\u6709\u7684\u7f8e\u56fd\u56fd\u5bb6\u66b4\u529b\u6b7b\u4ea1\u62a5\u544a\u7cfb\u7edf\uff08NVDRS\uff09\u4e2d\u5e76\u672a\u6b63\u5f0f\u8bb0\u5f55\u76f8\u5173\u53d8\u91cf\uff0c\u56e0\u6b64\u6025\u9700\u5f00\u53d1\u65b9\u6cd5\u8bc6\u522b\u8fd9\u4e9b\u98ce\u9669\u56e0\u7d20\u3002", "method": "\u7814\u7a76\u91c7\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6280\u672f\uff0c\u5bf9\u6267\u6cd5\u548c\u9a8c\u5c38\u5b98\u62a5\u544a\u4e2d\u7684\u53d9\u8ff0\u5185\u5bb9\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\u548c\u8bcd\u6c47\u672c\u4f53\u6784\u5efa\uff0c\u5e76\u7528\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u7b5b\u9009\u51fa\u6d89\u53ca\u793e\u4f1a\u5b64\u7acb\u4e0e\u5b64\u72ec\u7684\u81ea\u6740\u6848\u4f8b\u3002", "result": "\u5f00\u53d1\u7684\u5206\u7c7b\u5668\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u51c6\u786e\u6027\uff08F1\u503c\u4e3a0.86\uff0c\u51c6\u786e\u73870.82\uff09\u3002\u5728\u5206\u6790\u8d85\u8fc730\u4e07\u4f8b\u81ea\u6740\u6848\u4f8b\u540e\uff0c\u8bc6\u522b\u51fa1198\u4f8b\u660e\u786e\u63d0\u53ca\u6162\u6027\u793e\u4f1a\u5b64\u7acb\uff0c\u7537\u6027\u3001\u540c\u6027\u604b\u8005\u53ca\u79bb\u5a5a\u8005\u7f79\u60a3\u6162\u6027\u793e\u4f1a\u5b64\u7acb\u7684\u98ce\u9669\u663e\u8457\u66f4\u9ad8\u3002\u540c\u65f6\u4e5f\u53d1\u73b0\u8fd1\u671f\u6216\u5373\u5c06\u79bb\u5a5a\u3001\u5b50\u5973\u629a\u517b\u6743\u4e27\u5931\u3001\u88ab\u9a71\u9010\u6216\u8fd1\u671f\u642c\u5bb6\u3001\u60c5\u611f\u5206\u624b\u7b49\u4e8b\u4ef6\u662f\u65b0\u53d1\u793e\u4f1a\u5b64\u7acb\u7684\u91cd\u8981\u9884\u6d4b\u56e0\u7d20\u3002", "conclusion": "\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0e\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u9ad8\u6548\u8bc6\u522b\u51fa\u81ea\u6740\u76f8\u5173\u7684\u793e\u4f1a\u5b64\u7acb\u4e0e\u5b64\u72ec\u73b0\u8c61\u3002\u8fd9\u4e3a\u7f8e\u56fd\u793e\u4f1a\u5b64\u7acb\u548c\u5b64\u72ec\u7684\u76d1\u6d4b\u53ca\u9884\u9632\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.15453", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.15453", "abs": "https://arxiv.org/abs/2506.15453", "authors": ["Yusuf Sulistyo Nugroho", "Farah Danisha Salam", "Brittany Reid", "Raula Gaikovina Kula", "Kazumasa Shimari", "Kenichi Matsumoto"], "title": "Uncovering Intention through LLM-Driven Code Snippet Description Generation", "comment": "6 pages, 3 figures, 4 tables, conference paper", "summary": "Documenting code snippets is essential to pinpoint key areas where both\ndevelopers and users should pay attention. Examples include usage examples and\nother Application Programming Interfaces (APIs), which are especially important\nfor third-party libraries. With the rise of Large Language Models (LLMs), the\nkey goal is to investigate the kinds of description developers commonly use and\nevaluate how well an LLM, in this case Llama, can support description\ngeneration. We use NPM Code Snippets, consisting of 185,412 packages with\n1,024,579 code snippets. From there, we use 400 code snippets (and their\ndescriptions) as samples. First, our manual classification found that the\nmajority of original descriptions (55.5%) highlight example-based usage. This\nfinding emphasizes the importance of clear documentation, as some descriptions\nlacked sufficient detail to convey intent. Second, the LLM correctly identified\nthe majority of original descriptions as \"Example\" (79.75%), which is identical\nto our manual finding, showing a propensity for generalization. Third, compared\nto the originals, the produced description had an average similarity score of\n0.7173, suggesting relevance but room for improvement. Scores below 0.9\nindicate some irrelevance. Our results show that depending on the task of the\ncode snippet, the intention of the document may differ from being instructions\nfor usage, installations, or descriptive learning examples for any user of a\nlibrary.", "AI": {"tldr": "\u4ee3\u7801\u7247\u6bb5\u6587\u6863\u591a\u4ee5\u7528\u6cd5\u793a\u4f8b\u4e3a\u4e3b\uff0cLLM\uff08\u5982Llama\uff09\u5728\u5f52\u7c7b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u81ea\u52a8\u751f\u6210\u7684\u4ee3\u7801\u63cf\u8ff0\u4e0e\u539f\u59cb\u63cf\u8ff0\u76f8\u5173\u5ea6\u5c1a\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u6587\u6863\u610f\u56fe\u9700\u7ed3\u5408\u5177\u4f53\u4efb\u52a1\u3002", "motivation": "\u4ee3\u7801\u7247\u6bb5\u6587\u6863\u5316\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u548c\u7528\u6237\u5feb\u901f\u4e86\u89e3\u5173\u6ce8\u91cd\u70b9\uff0c\u5c24\u5176\u662f\u7b2c\u4e09\u65b9\u5e93\u793a\u4f8b\u548cAPI\u8bf4\u660e\u3002\u5f53\u524d\u5927\u6a21\u578b\uff08LLM\uff09\u5d1b\u8d77\uff0c\u4e9f\u9700\u4e86\u89e3\u5f00\u53d1\u8005\u5e38\u7528\u63cf\u8ff0\u65b9\u5f0f\uff0c\u4ee5\u53caLLM\u5728\u751f\u6210\u4ee3\u7801\u63cf\u8ff0\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u4eceNPM\u6536\u96c6\u4e86\u5927\u89c4\u6a21\u4ee3\u7801\u7247\u6bb5\u6570\u636e\u96c6\uff0c\u968f\u673a\u62bd\u53d6400\u6761\u4f5c\u4e3a\u6837\u672c\uff0c\u901a\u8fc7\u624b\u52a8\u5206\u7c7b\u5206\u6790\u539f\u59cb\u63cf\u8ff0\u5185\u5bb9\uff0c\u5e76\u8bc4\u4f30Llama\u6a21\u578b\u5bf9\u8fd9\u4e9b\u4ee3\u7801\u7247\u6bb5\u751f\u6210\u63cf\u8ff0\u7684\u8868\u73b0\uff0c\u5305\u62ec\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6587\u672c\u76f8\u4f3c\u5ea6\u3002", "result": "\u624b\u52a8\u6807\u6ce8\u53d1\u73b0\uff0c\u539f\u59cb\u63cf\u8ff0\u670955.5%\u5f3a\u8c03\u7528\u6cd5\u793a\u4f8b\uff0c\u5f3a\u8c03\u6587\u6863\u9700\u8981\u6e05\u6670\u3002Llama\u6a21\u578b\u81ea\u52a8\u5206\u7c7b\u7ed3\u679c\u4e0e\u4eba\u5de5\u4e00\u81f4\u5ea6\u9ad8\uff0879.75%\u4e3a\u201c\u793a\u4f8b\u201d\uff09\uff0c\u4f46\u751f\u6210\u6587\u6863\u7684\u5e73\u5747\u76f8\u4f3c\u5ea6\u4e3a0.7173\uff0c\u8bf4\u660e\u76f8\u5173\u4f46\u8fd8\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u5f97\u5206\u4f4e\u4e8e0.9\u7684\u60c5\u5f62\u663e\u793a\u5728\u90e8\u5206\u5185\u5bb9\u4e0a\u7684\u4e0d\u76f8\u5173\u6027\u3002", "conclusion": "LLM\uff08\u5982Llama\uff09\u5728\u5c06\u4ee3\u7801\u7247\u6bb5\u63cf\u8ff0\u5f52\u7c7b\u4e3a\u201c\u793a\u4f8b\u201d\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u81ea\u52a8\u751f\u6210\u63cf\u8ff0\u8fd8\u5b58\u5728\u4e0e\u539f\u59cb\u63cf\u8ff0\u90e8\u5206\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5c24\u5176\u5728\u8868\u610f\u6e05\u6670\u548c\u7ec6\u8282\u63cf\u8ff0\u4e0a\u5c1a\u6709\u63d0\u5347\u7a7a\u95f4\u3002\u4e0d\u540c\u4efb\u52a1\u5bf9\u6587\u6863\u610f\u56fe\u9700\u6c42\u4e5f\u4e0d\u5c3d\u76f8\u540c\uff0c\u5982\u7528\u6cd5\u6307\u5f15\u3001\u5b89\u88c5\u6559\u7a0b\u6216\u5b66\u4e60\u793a\u4f8b\u7b49\u3002"}}
{"id": "2506.15068", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15068", "abs": "https://arxiv.org/abs/2506.15068", "authors": ["Zongxia Li", "Yapei Chang", "Yuhang Zhou", "Xiyang Wu", "Zichao Liang", "Yoo Yeon Sung", "Jordan Lee Boyd-Graber"], "title": "Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation", "comment": null, "summary": "Evaluating open-ended long-form generation is challenging because it is hard\nto define what clearly separates good from bad outputs. Existing methods often\nmiss key aspects like coherence, style, or relevance, or are biased by\npretraining data, making open-ended long-form evaluation an underexplored\nproblem. To address this gap, we propose PrefBERT, a scoring model for\nevaluating open-ended long-form generation in GRPO and guiding its training\nwith distinct rewards for good and bad outputs. Trained on two response\nevaluation datasets with diverse long-form styles and Likert-rated quality,\nPrefBERT effectively supports GRPO by offering better semantic reward feedback\nthan traditional metrics ROUGE-L and BERTScore do. Through comprehensive\nevaluations, including LLM-as-a-judge, human ratings, and qualitative analysis,\nwe show that PrefBERT, trained on multi-sentence and paragraph-length\nresponses, remains reliable across varied long passages and aligns well with\nthe verifiable rewards GRPO needs. Human evaluations confirm that using\nPrefBERT as the reward signal to train policy models yields responses better\naligned with human preferences than those trained with traditional metrics. Our\ncode is available at https://github.com/zli12321/long_form_rl.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PrefBERT\u6a21\u578b\u7528\u4e8e\u957f\u6587\u672c\u751f\u6210\u8bc4\u4ef7\uff0c\u76f8\u8f83\u4f20\u7edf\u6307\u6807\u66f4\u80fd\u53cd\u6620\u4e30\u5bcc\u8bed\u4e49\u4fe1\u606f\uff0c\u7528\u4f5c\u5956\u52b1\u4fe1\u53f7\u80fd\u63d0\u5347\u6a21\u578b\u8f93\u51fa\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u5ea6\u3002", "motivation": "\u957f\u6587\u672c\u751f\u6210\u7684\u81ea\u52a8\u8bc4\u4ef7\u975e\u5e38\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u5bb9\u6613\u5ffd\u7565\u8fde\u8d2f\u6027\u3001\u98ce\u683c\u548c\u76f8\u5173\u6027\u7b49\u91cd\u8981\u65b9\u9762\uff0c\u5e76\u4e14\u5bb9\u6613\u53d7\u5230\u9884\u8bad\u7ec3\u6570\u636e\u504f\u5dee\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u957f\u6587\u672c\u5f00\u653e\u5f0f\u751f\u6210\u7684\u8bc4\u4ef7\u65b9\u6cd5\u4f9d\u7136\u4e0d\u8db3\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86PrefBERT\u8bc4\u5206\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4ef7\u957f\u6587\u672c\u751f\u6210\uff0c\u5e76\u5728GRPO\u4e2d\u5f15\u5bfc\u8bad\u7ec3\u3002PrefBERT\u5728\u4e24\u4e2a\u5e26\u6709\u4e0d\u540c\u98ce\u683c\u548cLikert\u91cf\u8868\u8d28\u91cf\u8bc4\u5206\u7684\u5bf9\u8bdd\u56de\u590d\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u901a\u8fc7\u4e3a\u4f18\u52a3\u8f93\u51fa\u5206\u522b\u8bbe\u8ba1\u5956\u52b1\u4fe1\u53f7\uff0c\u4ece\u800c\u63d0\u5347\u5956\u52b1\u7684\u8bed\u4e49\u53cd\u9988\u8d28\u91cf\u3002\u6a21\u578b\u6548\u679c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5224\u5b98\u3001\u4eba\u7c7b\u8bc4\u5206\u548c\u5b9a\u6027\u5206\u6790\u7b49\u591a\u79cd\u65b9\u6cd5\u7efc\u5408\u8bc4\u4f30\u3002", "result": "PrefBERT\u76f8\u6bd4ROUGE-L\u548cBERTScore\u7b49\u4f20\u7edf\u6307\u6807\uff0c\u5728\u957f\u6587\u672c\u7684\u8bc4\u5206\u4e0a\u5177\u6709\u66f4\u597d\u7684\u8bed\u4e49\u53cd\u9988\u80fd\u529b\u3002\u4eba\u7c7b\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\uff0c\u4ee5PrefBERT\u4f5c\u4e3a\u8bad\u7ec3\u5956\u52b1\u4fe1\u53f7\u7684\u7b56\u7565\u6a21\u578b\uff0c\u5176\u8f93\u51fa\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u5ea6\u9ad8\u4e8e\u4ee5\u4f20\u7edf\u6307\u6807\u4e3a\u5956\u52b1\u7684\u6a21\u578b\u3002", "conclusion": "PrefBERT\u5728\u957f\u6587\u672c\u751f\u6210\u5956\u52b1\u548c\u8bc4\u4ef7\u65b9\u9762\u6709\u6548\u53ef\u7528\uff0c\u7528\u5176\u505a\u5956\u52b1\u4fe1\u53f7\u80fd\u63d0\u5347\u957f\u6587\u672c\u751f\u6210\u5bf9\u4eba\u7c7b\u504f\u597d\u7684\u5951\u5408\u5ea6\uff0c\u4e3a\u5f00\u653e\u5f0f\u957f\u6587\u672c\u751f\u6210\u8bc4\u4ef7\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u601d\u8def\u3002"}}
{"id": "2506.15655", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.15655", "abs": "https://arxiv.org/abs/2506.15655", "authors": ["Yilin Zhang", "Xinran Zhao", "Zora Zhiruo Wang", "Chenyang Yang", "Jiayi Wei", "Tongshuang Wu"], "title": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become essential for large-scale\ncode generation, grounding predictions in external code corpora to improve\nactuality. However, a critical yet underexplored aspect of RAG pipelines is\nchunking -- the process of dividing documents into retrievable units. Existing\nline-based chunking heuristics often break semantic structures, splitting\nfunctions or merging unrelated code, which can degrade generation quality. We\npropose chunking via Abstract Syntax Trees (\\ourwork), a structure-aware method\nthat recursively breaks large AST nodes into smaller chunks and merges sibling\nnodes while respecting size limits. This approach generates self-contained,\nsemantically coherent units across programming languages and tasks, improving\nperformance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3\npoints on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.\nOur work highlights the importance of structure-aware chunking for scaling\nretrieval-enhanced code intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u6784\u611f\u77e5\u7684AST\u5206\u5757\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u68c0\u7d22\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u7ed3\u6784\u5316\u5206\u5757\u5728RAG\u4ee3\u7801\u667a\u80fd\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u884c\u7684\u4ee3\u7801\u5206\u5757\u65b9\u5f0f\u5f80\u5f80\u7834\u574f\u8bed\u4e49\u7ed3\u6784\uff0c\u5bfc\u81f4\u51fd\u6570\u88ab\u62c6\u5206\u6216\u65e0\u5173\u4ee3\u7801\u5408\u5e76\uff0c\u5f71\u54cd\u751f\u6210\u8d28\u91cf\u3002\u56e0\u6b64\u9700\u8981\u66f4\u7cbe\u7ec6\u4e14\u7ed3\u6784\u5316\u7684\u5206\u5757\u7b56\u7565\uff0c\u63d0\u5347RAG\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u7684\u5206\u5757\u65b9\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u5730\u5c06\u5927\u7684AST\u8282\u70b9\u62c6\u5206\u4e3a\u66f4\u5c0f\u5757\uff0c\u5e76\u5728\u9650\u5b9a\u5927\u5c0f\u7684\u524d\u63d0\u4e0b\u5408\u5e76\u5144\u5f1f\u8282\u70b9\uff0c\u751f\u6210\u81ea\u5305\u542b\u3001\u8bed\u4e49\u4e00\u81f4\u7684\u68c0\u7d22\u5355\u5143\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u63d0\u5347\u660e\u663e\uff1a\u5728RepoEval\u68c0\u7d22\u4efb\u52a1Recall@5\u63d0\u53474.3%\uff0c\u5728SWE-bench\u751f\u6210\u4efb\u52a1Pass@1\u63d0\u53472.67%\u3002", "conclusion": "\u7ed3\u6784\u611f\u77e5\u7684\u5206\u5757\uff08chunking\uff09\u5728\u68c0\u7d22\u589e\u5f3a\u4ee3\u7801\u751f\u6210\uff08RAG\uff09\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u548c\u751f\u6210\u8868\u73b0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u667a\u80fd\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2506.15076", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15076", "abs": "https://arxiv.org/abs/2506.15076", "authors": ["Ruihan Wu", "Konstantin Garov", "Kamalika Chaudhuri"], "title": "Learning-Time Encoding Shapes Unlearning in LLMs", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in the real world,\nthe ability to ``unlearn'', or remove specific pieces of knowledge post hoc,\nhas become essential for a variety of reasons ranging from privacy regulations\nto correcting outdated or harmful content. Prior work has proposed unlearning\nbenchmarks and algorithms, and has typically assumed that the training process\nand the target model are fixed. In this work, we empirically investigate how\nlearning-time choices in knowledge encoding impact the effectiveness of\nunlearning factual knowledge. Our experiments reveal two key findings: (1)\nlearning with paraphrased descriptions improves unlearning performance and (2)\nunlearning individual piece of knowledge from a chunk of text is challenging.\nOur results suggest that learning-time knowledge encoding may play a central\nrole in enabling reliable post-hoc unlearning.", "AI": {"tldr": "\u8bad\u7ec3\u65f6\u91c7\u7528\u4e0d\u540c\u7684\u77e5\u8bc6\u7f16\u7801\u7b56\u7565\uff0c\u6bd4\u5982\u7528\u591a\u6837\u5316\u7684\u91ca\u4e49\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u540e\u7eed\u201c\u9057\u5fd8\u201d\u67d0\u4e9b\u77e5\u8bc6\u65f6\u7684\u6709\u6548\u6027\uff0c\u4f46\u8981\u4ece\u6587\u672c\u5757\u4e2d\u5220\u9664\u5355\u72ec\u77e5\u8bc6\u70b9\u4ecd\u7136\u5f88\u96be\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u201c\u9057\u5fd8\u201d\u7279\u5b9a\u77e5\u8bc6\u7684\u80fd\u529b\u53d8\u5f97\u975e\u5e38\u91cd\u8981\uff0c\u4f8b\u5982\u6ee1\u8db3\u9690\u79c1\u6cd5\u89c4\u6216\u4fee\u6b63\u8fc7\u65f6/\u6709\u5bb3\u5185\u5bb9\u3002\u6b64\u524d\u7684\u5de5\u4f5c\u5927\u591a\u5047\u8bbe\u8bad\u7ec3\u8fc7\u7a0b\u548c\u76ee\u6807\u6a21\u578b\u662f\u56fa\u5b9a\u7684\uff0c\u672a\u6df1\u5165\u63a2\u8ba8\u8bad\u7ec3\u9636\u6bb5\u7684\u9009\u62e9\u5bf9\u540e\u7eed\u9057\u5fd8\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u5206\u6790\u5728\u77e5\u8bc6\u7f16\u7801\u9636\u6bb5\u7684\u4e0d\u540c\u8bad\u7ec3\u65b9\u5f0f\uff08\u5982\u4f7f\u7528\u91ca\u4e49\u63cf\u8ff0\uff09\u5bf9\u4e8b\u5b9e\u77e5\u8bc6\u9057\u5fd8\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5e76\u6d4b\u8bd5\u9488\u5bf9\u6587\u672c\u5757\u4e2d\u5355\u72ec\u77e5\u8bc6\u70b9\u7684\u9057\u5fd8\u96be\u5ea6\u3002", "result": "\uff081\uff09\u91c7\u7528\u91ca\u4e49\u63cf\u8ff0\u8fdb\u884c\u5b66\u4e60\uff0c\u53ef\u4ee5\u63d0\u5347\u9057\u5fd8\u7279\u5b9a\u77e5\u8bc6\u7684\u6709\u6548\u6027\uff1b\uff082\uff09\u4ece\u4e00\u6bb5\u6587\u672c\u4e2d\u5355\u72ec\u9057\u5fd8\u67d0\u4e00\u77e5\u8bc6\u70b9\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u77e5\u8bc6\u7f16\u7801\u7684\u65b9\u5f0f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u540e\u7eed\u201c\u9057\u5fd8\u201d\u80fd\u529b\uff0c\u4f18\u5316\u5b66\u4e60\u9636\u6bb5\u7684\u7f16\u7801\u5bf9\u5b9e\u73b0\u53ef\u9760\u7684\u540e\u9a8c\u9057\u5fd8\u975e\u5e38\u5173\u952e\u3002"}}
